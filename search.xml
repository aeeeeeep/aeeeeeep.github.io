<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Debug æ•‘æ˜Ÿï¼ç”¨ ObjWatch åŠ©åŠ›å¤æ‚ Python é¡¹ç›®çš„é«˜æ•ˆä»£ç ç†è§£ä¸è°ƒè¯•</title>
      <link href="/p/820979d0/"/>
      <url>/p/820979d0/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ä½¿ç”¨ ObjWatch åŠ©åŠ›å¤æ‚ Python é¡¹ç›®çš„é«˜æ•ˆä»£ç ç†è§£ä¸è°ƒè¯•ã€‚</p><span id="more"></span><h2 id="æºç é“¾æ¥"><a href="#æºç é“¾æ¥" class="headerlink" title="æºç é“¾æ¥"></a>æºç é“¾æ¥</h2><p><a href="https://github.com/aeeeeeep/objwatch">https://github.com/aeeeeeep/objwatch</a></p><h2 id="å½“å‰-Debug-ç—›ç‚¹"><a href="#å½“å‰-Debug-ç—›ç‚¹" class="headerlink" title="å½“å‰ Debug ç—›ç‚¹"></a>å½“å‰ Debug ç—›ç‚¹</h2><p>åœ¨é˜…è¯»å’Œ debug å¤æ‚çš„é¡¹ç›®æ—¶ï¼Œå¸¸å¸¸ä¼šé‡åˆ°å¤šè¾¾åå‡ å±‚çš„åµŒå¥—è°ƒç”¨ï¼Œä¸çŸ¥é“è°ƒç”¨çš„é¡ºåºã€‚<br>æœ€éš¾å—çš„æ˜¯åœ¨å¤šè¿›ç¨‹åœºæ™¯ä¸‹ï¼Œåœ¨å•ä¸ªè¿›ç¨‹ä¸Šçš„è°ƒè¯•å¾€å¾€ä¼šå¯¼è‡´å…¶ä»–è¿›ç¨‹ç­‰å¾…è¶…æ—¶ï¼Œéœ€è¦ä¸æ–­é‡å¤å¯åŠ¨è°ƒè¯•ç¨‹åºã€‚<br>å¦‚æœæ˜¯ç”¨ print å¤§æ³•ï¼Œç»å¸¸ä¼šæ¼æ‰ä¸€äº›å‡½æ•°çš„è°ƒç”¨ã€‚è¿™ä¹Ÿå¤ªè´¹æ—¶è´¹åŠ›äº†ï¼Œç›®å‰è¿˜æ²¡æœ‰æ‰¾åˆ°é›†ç®€å•ç®€æ´å¥½ç”¨äºä¸€èº«çš„è°ƒè¯•åº“ï¼Œäºæ˜¯èŠ±äº†ä¸ªå‘¨æœ«è‡ªå·±å†™äº†ä¸ªå·¥å…·ï¼Œç®—æ˜¯è§£å†³äº†è¿™ä¸ªç—›ç‚¹ã€‚</p><h2 id="ä»€ä¹ˆæ˜¯-ObjWatchï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯-ObjWatchï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯ ObjWatchï¼Ÿ"></a>ä»€ä¹ˆæ˜¯ ObjWatchï¼Ÿ</h2><p>ObjWatch æ˜¯ä¸“ä¸ºç®€åŒ–å¤æ‚é¡¹ç›®çš„è°ƒè¯•å’Œç›‘æ§è€Œè®¾è®¡ã€‚é€šè¿‡å®æ—¶è¿½è¸ªå¯¹è±¡å±æ€§å’Œæ–¹æ³•è°ƒç”¨ï¼Œä»¥åŠå…è®¸è‡ªå®šä¹‰ hook æ¥å¸®åŠ©å¼€å‘è€…æ·±å…¥äº†è§£ä»£ç åº“ã€‚</p><h2 id="å¿«é€Ÿç”¨ä¾‹"><a href="#å¿«é€Ÿç”¨ä¾‹" class="headerlink" title="å¿«é€Ÿç”¨ä¾‹"></a>å¿«é€Ÿç”¨ä¾‹</h2><p>å¯ä»¥ç›´æ¥ pip install objwatch å®‰è£…ï¼Œè¿™é‡Œæ¼”ç¤ºç”¨ä¾‹ï¼Œéœ€è¦ clone æºç </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/aeeeeeep/objwatch</span><br><span class="line"><span class="built_in">cd</span> objwatch</span><br><span class="line">python3 examples/example_usage.py</span><br></pre></td></tr></table></figure><p>æ‰§è¡Œä¸Šé¢çš„ä»£ç å°±å¯ä»¥å¾—åˆ°å¦‚ä¸‹è°ƒç”¨ä¿¡æ¯</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: Processed targets:</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span><br><span class="line">examples/example_usage.py</span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><br><span class="line">[2025-01-04 19:15:13] [WARNING] objwatch: wrapper &#x27;BaseLogger&#x27; loaded</span><br><span class="line">[2025-01-04 19:15:13] [INFO] objwatch: Starting ObjWatch tracing.</span><br><span class="line">[2025-01-04 19:15:13] [INFO] objwatch: Starting tracing.</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: run main &lt;-</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.__init__ &lt;- &#x27;0&#x27;:(type)SampleClass, &#x27;1&#x27;:10</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.__init__ -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.increment &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value None -&gt; 10</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 10 -&gt; 11</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.increment -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.increment &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 11 -&gt; 12</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.increment -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.increment &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 12 -&gt; 13</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.increment -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.increment &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 13 -&gt; 14</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.increment -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.increment &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 14 -&gt; 15</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.increment -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.decrement &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 15 -&gt; 14</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.decrement -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.decrement &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 14 -&gt; 13</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.decrement -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | run SampleClass.decrement &lt;- &#x27;0&#x27;:(type)SampleClass</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | | upd SampleClass.value 13 -&gt; 12</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: | end SampleClass.decrement -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [DEBUG] objwatch: end main -&gt; None</span><br><span class="line">[2025-01-04 19:15:13] [INFO] objwatch: Stopping ObjWatch tracing.</span><br><span class="line">[2025-01-04 19:15:13] [INFO] objwatch: Stopping tracing.</span><br></pre></td></tr></table></figure><p>ä»£ç ä¸­æœ€æ ¸å¿ƒçš„æ˜¯è¿™éƒ¨åˆ†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Using as a Context Manager with Detailed Logging</span></span><br><span class="line"><span class="keyword">with</span> objwatch.ObjWatch([<span class="string">&#x27;examples/example_usage.py&#x27;</span>]):</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using the API with Simple Logging</span></span><br><span class="line">obj_watch = objwatch.watch([<span class="string">&#x27;examples/example_usage.py&#x27;</span>])</span><br><span class="line">main()</span><br><span class="line">obj_watch.stop()</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥åŒæ—¶é€šè¿‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨ å’Œ æ¥å£è°ƒç”¨ä½¿ç”¨è¯¥å·¥å…·ã€‚ç”¨ä¾‹ä¸­æˆ‘ä»¬æŒ‡å®šäº†å¯¹ â€˜examples/example_usage.pyâ€™ æ–‡ä»¶çš„è¿½è¸ªï¼Œä¹Ÿå°±æ˜¯åªè¦æœ‰å‡½æ•°æ–¹æ³•æˆ–å˜é‡æ˜¯ examples/example_usage.py ä¸­çš„ï¼Œå·¥å…·å°±ä¼šæ‰“å°ï¼Œè¿™æ ·å°±é€šè¿‡æ¸…æ™°çš„é¡ºåºå±‚çº§æ—¥å¿—è®°å½•ï¼Œå¸®åŠ©å¯è§†åŒ–å¹¶ç›‘æ§è¿™äº›åµŒå¥—çš„å‡½æ•°è°ƒç”¨å’Œå¯¹è±¡äº’åŠ¨ã€‚æ‰“å°æ—¥å¿—ä¼šåŒ…å«å¦‚ä¸‹å‡ ç§æ‰§è¡Œç±»å‹ï¼š</p><ul><li>runï¼šå¼€å§‹æ‰§è¡Œå‡½æ•°æˆ–ç±»çš„æ–¹æ³•</li><li>endï¼šå‡½æ•°æˆ–ç±»çš„æ–¹æ³•æ‰§è¡Œç»“æŸ</li><li>updï¼šæ–°åˆ›å»ºä¸€ä¸ªå˜é‡</li><li>apdï¼š(list, set, dict, tuple) ç±»å‹çš„å˜é‡ä¸­å¢åŠ å…ƒç´ </li><li>popï¼š(list, set, dict, tuple) ç±»å‹çš„å˜é‡ä¸­å‡å°‘å…ƒç´ </li></ul><p>ç”¨ä¾‹æ¯”è¾ƒç®€å•ï¼Œå¦‚æœæ˜¯å¤§å‹é¡¹ç›®çš„æ‰§è¡Œï¼Œè¿™ä¸ªåŠŸèƒ½å°†éå¸¸æœ‰ç”¨ã€‚</p><h2 id="æ•´ä½“åŠŸèƒ½"><a href="#æ•´ä½“åŠŸèƒ½" class="headerlink" title="æ•´ä½“åŠŸèƒ½"></a>æ•´ä½“åŠŸèƒ½</h2><p>objwatch æä¾›äº†å¦‚ä¸‹æ¥å£</p><ul><li><code>targets</code>ï¼ˆåˆ—è¡¨ï¼‰ï¼šè¦ç›‘æ§çš„æ–‡ä»¶æˆ–æ¨¡å—ã€‚</li><li><code>exclude_targets</code>ï¼ˆåˆ—è¡¨ï¼Œå¯é€‰ï¼‰ï¼šè¦æ’é™¤ç›‘æ§çš„æ–‡ä»¶æˆ–æ¨¡å—ã€‚</li><li><code>ranks</code>ï¼ˆåˆ—è¡¨ï¼Œå¯é€‰ï¼‰ï¼šåœ¨ä½¿ç”¨ <code>torch.distributed</code> æ—¶è·Ÿè¸ªçš„ GPU idsã€‚</li><li><code>output</code>ï¼ˆå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰ï¼šå†™å…¥æ—¥å¿—çš„æ–‡ä»¶è·¯å¾„ã€‚</li><li><code>output_xml</code>ï¼ˆå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰ï¼šç”¨äºå†™å…¥ç»“æ„åŒ–æ—¥å¿—çš„ XML æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæŒ‡å®šï¼Œå°†ä»¥åµŒå¥—çš„ XML æ ¼å¼ä¿å­˜è¿½è¸ªä¿¡æ¯ï¼Œä¾¿äºæµè§ˆå’Œåˆ†æã€‚</li><li><code>level</code>ï¼ˆå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰ï¼šæ—¥å¿—çº§åˆ«ï¼ˆä¾‹å¦‚ <code>logging.DEBUG</code>ï¼Œ<code>logging.INFO</code>ï¼Œ<code>force</code> ç­‰ï¼‰ã€‚</li><li><code>simple</code>ï¼ˆå¸ƒå°”å€¼ï¼Œå¯é€‰ï¼‰ï¼šå¯ç”¨ç®€åŒ–æ—¥å¿—æ¨¡å¼ï¼Œæ ¼å¼ä¸º <code>&quot;DEBUG: &#123;msg&#125;&quot;</code>ã€‚</li><li><code>wrapper</code>ï¼ˆFunctionWrapperï¼Œå¯é€‰ï¼‰ï¼šè‡ªå®šä¹‰åŒ…è£…å™¨ï¼Œç”¨äºæ‰©å±•è¿½è¸ªå’Œæ—¥å¿—è®°å½•åŠŸèƒ½ã€‚</li><li><code>with_locals</code>ï¼ˆå¸ƒå°”å€¼ï¼Œå¯é€‰ï¼‰ï¼šå¯ç”¨åœ¨å‡½æ•°æ‰§è¡ŒæœŸé—´å¯¹å±€éƒ¨å˜é‡çš„è¿½è¸ªå’Œæ—¥å¿—è®°å½•ã€‚</li><li><code>with_module_path</code>ï¼ˆå¸ƒå°”å€¼ï¼Œå¯é€‰ï¼‰ï¼šæ§åˆ¶æ˜¯å¦åœ¨æ—¥å¿—ä¸­çš„å‡½æ•°åç§°å‰æ·»åŠ æ¨¡å—è·¯å¾„å‰ç¼€ã€‚</li></ul><h2 id="é‡ç‚¹ï¼šè‡ªå®šä¹‰åŒ…è£…å™¨æ‰©å±•"><a href="#é‡ç‚¹ï¼šè‡ªå®šä¹‰åŒ…è£…å™¨æ‰©å±•" class="headerlink" title="é‡ç‚¹ï¼šè‡ªå®šä¹‰åŒ…è£…å™¨æ‰©å±•"></a>é‡ç‚¹ï¼šè‡ªå®šä¹‰åŒ…è£…å™¨æ‰©å±•</h2><p>ObjWatch æä¾›äº† FunctionWrapper æŠ½è±¡åŸºç±»ï¼Œå…è®¸ç”¨æˆ·åˆ›å»ºè‡ªå®šä¹‰åŒ…è£…å™¨ï¼Œä»¥æ‰©å±•å’Œå®šåˆ¶åº“çš„è¿½è¸ªä¸æ—¥å¿—è®°å½•åŠŸèƒ½ã€‚é€šè¿‡ç»§æ‰¿ FunctionWrapperï¼Œå¼€å‘è€…å¯ä»¥å®ç°ç‰¹å®šé¡¹ç›®éœ€æ±‚çš„å®šåˆ¶åŒ–è¡Œä¸ºï¼Œè¿™äº›è¡Œä¸ºå°†åœ¨å‡½æ•°è°ƒç”¨å’Œè¿”å›æ—¶æ‰§è¡Œï¼Œæä¾›æ›´ä¸“ä¸šçš„ç›‘æ§ã€‚</p><h3 id="FunctionWrapper-ç±»"><a href="#FunctionWrapper-ç±»" class="headerlink" title="FunctionWrapper ç±»"></a>FunctionWrapper ç±»</h3><p><code>FunctionWrapper</code> ç±»å®šä¹‰äº†ä¸¤ä¸ªå¿…é¡»å®ç°çš„æ ¸å¿ƒæ–¹æ³•ï¼š</p><ul><li><p><strong><code>wrap_call(self, func_name: str, frame: FrameType) -&gt; str</code></strong>ï¼š</p><p>è¯¥æ–¹æ³•åœ¨å‡½æ•°è°ƒç”¨å¼€å§‹æ—¶è§¦å‘ï¼Œæ¥æ”¶å‡½æ•°åå’Œå½“å‰çš„å¸§å¯¹è±¡ï¼Œå¸§å¯¹è±¡åŒ…å«äº†æ‰§è¡Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬å±€éƒ¨å˜é‡å’Œè°ƒç”¨æ ˆã€‚åœ¨æ­¤æ–¹æ³•ä¸­å¯ä»¥æå–ã€è®°å½•æˆ–ä¿®æ”¹ä¿¡æ¯ï¼Œåœ¨å‡½æ•°æ‰§è¡Œå‰è¿›è¡Œå¤„ç†ã€‚</p></li><li><p><strong><code>wrap_return(self, func_name: str, result: Any) -&gt; str</code></strong>ï¼š</p><p>è¯¥æ–¹æ³•åœ¨å‡½æ•°è¿”å›æ—¶è§¦å‘ï¼Œæ¥æ”¶å‡½æ•°åå’Œè¿”å›çš„ç»“æœã€‚åœ¨æ­¤æ–¹æ³•ä¸­å¯ä»¥è®°å½•ã€åˆ†ææˆ–ä¿®æ”¹ä¿¡æ¯ï¼Œå‡½æ•°æ‰§è¡Œå®Œæˆåè¿›è¡Œå¤„ç†ã€‚</p></li><li><p><strong><code>wrap_upd(self, old_value: Any, current_value: Any) -&gt; Tuple[str, str]</code></strong>ï¼š</p><p>è¯¥æ–¹æ³•åœ¨å˜é‡æ›´æ–°æ—¶è§¦å‘ï¼Œæ¥æ”¶æ—§å€¼å’Œå½“å‰å€¼ã€‚å¯ç”¨äºè®°å½•å˜é‡çš„å˜åŒ–ï¼Œåˆ†æå…¶å˜åŒ–è¿‡ç¨‹ï¼Œä»è€Œè·Ÿè¸ªå’Œè°ƒè¯•å˜é‡çŠ¶æ€çš„å˜åŒ–ã€‚</p></li></ul><p>æœ‰å…³å¸§å¯¹è±¡çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ <a href="https://docs.python.org/3/library/types.html#types.FrameType">å®˜æ–¹ Python æ–‡æ¡£</a>ã€‚</p><h3 id="TensorShapeLogger"><a href="#TensorShapeLogger" class="headerlink" title="TensorShapeLogger"></a>TensorShapeLogger</h3><p>è¿™æ˜¯æˆ‘æ ¹æ®æˆ‘çš„ä½¿ç”¨åœºæ™¯å®ç°çš„ä¸€ä¸ªè‡ªå®šä¹‰åŒ…è£…å™¨ç¤ºä¾‹ï¼Œä»£ç åœ¨ objwatch/wrappers.py æ–‡ä»¶ä¸­ã€‚è¿™ä¸ªåŒ…è£…å™¨ä¼šè‡ªåŠ¨è®°å½•æŒ‡å®šæ¨¡å—ä¸­æ‰€æœ‰å‡½æ•°æ–¹æ³•è°ƒç”¨ä¸­è¾“å…¥è¾“å‡ºçš„ tensor shapeï¼Œè¿˜æœ‰å˜é‡å€¼å˜é‡çš„æƒ…å†µï¼Œè¿™åœ¨å¸®åŠ©ç†è§£å¤æ‚çš„åˆ†å¸ƒå¼æ¡†æ¶çš„æ‰§è¡Œé€»è¾‘æ—¶éå¸¸æœ‰ç”¨ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TensorShapeLogger</span>(<span class="title class_ inherited__">FunctionWrapper</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    TensorShapeLogger extends FunctionWrapper to log the shapes of torch.Tensor objects.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_process_tensor_item</span>(<span class="params">seq: <span class="type">List</span>[<span class="type">Any</span>]</span>) -&gt; <span class="type">Optional</span>[<span class="type">List</span>[<span class="type">Any</span>]]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Process a sequence to extract tensor shapes if all items are torch.Tensor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            seq (List[Any]): The sequence to process.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Optional[List[Any]]: List of tensor shapes or None if not applicable.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> torch <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">all</span>(<span class="built_in">isinstance</span>(x, torch.Tensor) <span class="keyword">for</span> x <span class="keyword">in</span> seq):</span><br><span class="line">            <span class="keyword">return</span> [x.shape <span class="keyword">for</span> x <span class="keyword">in</span> seq]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrap_call</span>(<span class="params">self, func_name: <span class="built_in">str</span>, frame: FrameType</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Format the function call information, including tensor shapes if applicable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            func_name (str): Name of the function being called.</span></span><br><span class="line"><span class="string">            frame (FrameType): The current stack frame.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            str: Formatted call message.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        args, kwargs = self._extract_args_kwargs(frame)</span><br><span class="line">        call_msg = self._format_args_kwargs(args, kwargs)</span><br><span class="line">        <span class="keyword">return</span> call_msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrap_return</span>(<span class="params">self, func_name: <span class="built_in">str</span>, result: <span class="type">Any</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Format the function return information, including tensor shapes if applicable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            func_name (str): Name of the function returning.</span></span><br><span class="line"><span class="string">            result (Any): The result returned by the function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            str: Formatted return message.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        return_msg = self._format_return(result)</span><br><span class="line">        <span class="keyword">return</span> return_msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrap_upd</span>(<span class="params">self, old_value: <span class="type">Any</span>, current_value: <span class="type">Any</span></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Format the update information of a variable, including tensor shapes if applicable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            old_value (Any): The old value of the variable.</span></span><br><span class="line"><span class="string">            current_value (Any): The new value of the variable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Tuple[str, str]: Formatted old and new values.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        old_msg = self._format_value(old_value)</span><br><span class="line">        current_msg = self._format_value(current_value)</span><br><span class="line">        <span class="keyword">return</span> old_msg, current_msg</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_format_value</span>(<span class="params">self, value: <span class="type">Any</span>, is_return: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Format a value into a string, logging tensor shapes if applicable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            value (Any): The value to format.</span></span><br><span class="line"><span class="string">            is_return (bool): Flag indicating if the value is a return value.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            str: Formatted value string.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> torch <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(value, torch.Tensor):</span><br><span class="line">            formatted = <span class="string">f&quot;<span class="subst">&#123;value.shape&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(value, log_element_types):</span><br><span class="line">            formatted = <span class="string">f&quot;<span class="subst">&#123;value&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(value, log_sequence_types):</span><br><span class="line">            formatted_sequence = EventHandls.format_sequence(value, func=TensorShapeLogger._process_tensor_item)</span><br><span class="line">            <span class="keyword">if</span> formatted_sequence:</span><br><span class="line">                formatted = <span class="string">f&quot;<span class="subst">&#123;formatted_sequence&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                formatted = <span class="string">f&quot;(type)<span class="subst">&#123;value.__class__.__name__&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            formatted = <span class="string">f&quot;(type)<span class="subst">&#123;value.__class__.__name__&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> is_return:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(value, torch.Tensor):</span><br><span class="line">                <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;value.shape&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(value, log_sequence_types) <span class="keyword">and</span> formatted:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">f&quot;[<span class="subst">&#123;formatted&#125;</span>]&quot;</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;formatted&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">return</span> formatted</span><br></pre></td></tr></table></figure><h3 id="åˆ›å»ºå’Œé›†æˆè‡ªå®šä¹‰åŒ…è£…å™¨"><a href="#åˆ›å»ºå’Œé›†æˆè‡ªå®šä¹‰åŒ…è£…å™¨" class="headerlink" title="åˆ›å»ºå’Œé›†æˆè‡ªå®šä¹‰åŒ…è£…å™¨"></a>åˆ›å»ºå’Œé›†æˆè‡ªå®šä¹‰åŒ…è£…å™¨</h3><p>è¦åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰åŒ…è£…å™¨ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š</p><ol><li>ç»§æ‰¿ FunctionWrapperï¼šå®šä¹‰ä¸€ä¸ªæ–°çš„ç±»ï¼Œç»§æ‰¿è‡ª FunctionWrapperï¼Œå¹¶å®ç° wrap_call å’Œ wrap_return æ–¹æ³•ï¼Œä»¥å®šä¹‰æ‚¨çš„è‡ªå®šä¹‰è¡Œä¸ºã€‚</li><li>ä½¿ç”¨è‡ªå®šä¹‰åŒ…è£…å™¨åˆå§‹åŒ– ObjWatchï¼šåœ¨åˆå§‹åŒ– ObjWatch æ—¶ï¼Œé€šè¿‡ wrapper å‚æ•°ä¼ å…¥æ‚¨çš„è‡ªå®šä¹‰åŒ…è£…å™¨å¯¹è±¡ã€‚è¿™å°†æŠŠæ‚¨çš„è‡ªå®šä¹‰è¿½è¸ªé€»è¾‘é›†æˆåˆ° ObjWatch çš„è¿½è¸ªè¿‡ç¨‹ä¸­ã€‚</li></ol><p>é€šè¿‡åˆ©ç”¨è‡ªå®šä¹‰åŒ…è£…å™¨ï¼Œæ‚¨å¯ä»¥å¢å¼º ObjWatch çš„åŠŸèƒ½ï¼Œæ•æ‰é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ‰§è¡Œä¸“ä¸šçš„æ—¥å¿—è®°å½•ï¼Œæˆ–ä¸å…¶ä»–ç›‘æ§å·¥å…·é›†æˆï¼Œä»è€Œä¸ºæ‚¨çš„ Python é¡¹ç›®æä¾›æ›´å…¨é¢å’Œå®šåˆ¶åŒ–çš„è¿½è¸ªè§£å†³æ–¹æ¡ˆã€‚</p><h3 id="ä½¿ç”¨ç¤ºä¾‹"><a href="#ä½¿ç”¨ç¤ºä¾‹" class="headerlink" title="ä½¿ç”¨ç¤ºä¾‹"></a>ä½¿ç”¨ç¤ºä¾‹</h3><p>ä¾‹å¦‚ï¼ŒTensorShapeLogger å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼é›†æˆï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> objwatch.wrappers <span class="keyword">import</span> TensorShapeLogger</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨è‡ªå®šä¹‰çš„ TensorShapeLogger åˆå§‹åŒ– ObjWatch</span></span><br><span class="line">obj_watch = objwatch.ObjWatch([<span class="string">&#x27;your_module.py&#x27;</span>], simple=<span class="literal">False</span>, wrapper=TensorShapeLogger))</span><br><span class="line"><span class="keyword">with</span> obj_watch:</span><br><span class="line">    main()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¹Ÿå¯ä»¥</span></span><br><span class="line">obj_watch = objwatch.watch([<span class="string">&#x27;your_module.py&#x27;</span>], simple=<span class="literal">False</span>, wrapper=TensorShapeLogger)</span><br><span class="line">main()</span><br><span class="line">obj_watch.stop()</span><br></pre></td></tr></table></figure><h3 id="ä½¿ç”¨è‡ªå®šä¹‰åŒ…è£…å™¨çš„ç¤ºä¾‹"><a href="#ä½¿ç”¨è‡ªå®šä¹‰åŒ…è£…å™¨çš„ç¤ºä¾‹" class="headerlink" title="ä½¿ç”¨è‡ªå®šä¹‰åŒ…è£…å™¨çš„ç¤ºä¾‹"></a>ä½¿ç”¨è‡ªå®šä¹‰åŒ…è£…å™¨çš„ç¤ºä¾‹</h3><p>æ¨èé˜…è¯» <a href="https://github.com/aeeeeeep/objwatch/blob/main/tests/test_torch_train.py"><code>tests/test_torch_train.py</code></a> æ–‡ä»¶ã€‚è¯¥æ–‡ä»¶åŒ…å«äº†ä¸€ä¸ªå®Œæ•´çš„ PyTorch è®­ç»ƒè¿‡ç¨‹ç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•é›†æˆ ObjWatch è¿›è¡Œç›‘æ§å’Œæ—¥å¿—è®°å½•ã€‚</p><h2 id="æ³¨æ„äº‹é¡¹"><a href="#æ³¨æ„äº‹é¡¹" class="headerlink" title="æ³¨æ„äº‹é¡¹"></a>æ³¨æ„äº‹é¡¹</h2><h3 id="âš ï¸-æ€§èƒ½è­¦å‘Š"><a href="#âš ï¸-æ€§èƒ½è­¦å‘Š" class="headerlink" title="âš ï¸ æ€§èƒ½è­¦å‘Š"></a>âš ï¸ æ€§èƒ½è­¦å‘Š</h3><p>ObjWatch åœ¨è°ƒè¯•ç¯å¢ƒä¸­ä½¿ç”¨æ—¶ä¼šå¯¹ç¨‹åºçš„æ€§èƒ½äº§ç”Ÿä¸€å®šå½±å“ã€‚å› æ­¤ï¼Œå»ºè®®ä»…åœ¨è°ƒè¯•å’Œå¼€å‘é˜¶æ®µä½¿ç”¨ã€‚<br>å…ˆå†™è¿™ä¹ˆå¤šï¼Œåç»­æœ‰æ—¶é—´å†æ›´ï¼Œè§‰å¾—æœ‰ç”¨å¯ä»¥ç»™ä¸ª starã€‚</p><p>ç›®å‰è¯¥åº“è¿˜åœ¨ç§¯ææ›´æ–°ä¸­ï¼Œå¦‚æœæœ‰ä»»ä½•ç–‘é—®æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨è¯„è®ºåŒºæˆ–ä»“åº“ issues ç•™è¨€ã€‚</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>éšç¬”</title>
      <link href="/p/f77810a8/"/>
      <url>/p/f77810a8/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ä¸€ç›´ä»¥ä¸ºå…³äºä»£ç çš„äº‹æƒ…éƒ½ä¸ä¼šå¾ˆå¤æ‚ã€‚</p><span id="more"></span><p>ä¹‹å‰ä¸€ç›´æ˜¯ä¸€ä¸ªäººè‡ªå­¦ï¼Œçœ‹åšå®¢æ‰“æ¯”èµ›ä»€ä¹ˆçš„ï¼Œä»£ç æ˜¯ä¸€ä¸ªäººç®¡ç†ï¼Œé‡åˆ°çš„é—®é¢˜æ— éæ˜¯è‡ªå·±å†™çš„ bugã€‚æœ€è¿‘é‡åˆ°åˆšç¦»èŒçš„åŒäº‹é—ç•™çš„æœªå®ŒæˆéªŒè¯æ¨¡å—çš„ bugï¼Œæ’æŸ¥äº†ä¸¤å¤©ï¼Œ3k å¤šè¡Œé€»è¾‘ä»£ç ï¼Œçœ¼ç›åˆä¸èˆ’æœäº†ğŸ¥²ã€‚</p><p>ä½†æ˜¯çœ‹ä»£ç è¿˜å¥½ï¼Œå·¥ä½œæ€»æ˜¯å¤šçº¿ç¨‹çš„ï¼Œåé¢çš„äº‹æƒ…è¢«é˜»å¡ï¼Œå„ä½ Owner ä¸ä¼šç®¡è¿™äº›ï¼Œå„ç§é¡¹ç›®éœ€è¦æ”¯æŒï¼Œå‹åŠ›ä¸€ä¸‹å­æ‹‰æ»¡äº†ã€‚</p><p>æ™šä¸Šå›åˆ°å‡ºç§Ÿå±‹å†æ•´ç†ä¸€å¤©çš„å·¥ä½œï¼Œé¢“è´¥æ„Ÿï¼Œè™šåº¦å…‰é˜´çš„æ„Ÿè§‰è®©è‡ªå·±çˆ¬ä¸ŠåºŠçš„åŠ›æ°”ä¹Ÿæ²¡æœ‰ğŸ¥±ï¼Œä¹‹å‰æ‰“æ¯”èµ›å†ç´¯ä¹Ÿæ²¡è¿™ä¹ˆéš¾å—è¿‡ã€‚</p><p>å·¥ä½œä¸­é‡åˆ°çš„åŒäº‹å¾ˆå¤šæ˜¯å‡ å¤©å°±èƒ½å®ç°ä¸€ä¸ªå¤æ‚æ¨¡å—çš„æ°´å¹³ï¼Œæˆ‘åªæ˜¯åˆšè¿›å…¥èŒåœºçš„å°ç™½ï¼Œæ˜¯ä¸æ˜¯èƒ½å‘ç°é—®é¢˜å¹¶å°è¯•è§£å†³å·²ç»å¯ä»¥äº†ã€‚è¿™ä¸ª bug æ˜¯ä¸æ˜¯æš‚æ—¶å¯ä»¥è·³è¿‡ï¼Œæ¯•ç«Ÿç”¨åˆ°çš„åœ°æ–¹æš‚æ—¶æ²¡æœ‰ï¼Œä¹‹å‰ä¹Ÿä¸æ˜¯æ²¡æœ‰é‡åˆ°å…¶ä»–åŒäº‹é—ç•™çš„ bugã€‚</p><p>æš‚æ—¶è·³è¿‡å§ï¼Œåé¢è¿˜æœ‰é¡¹ç›®è¦æ”¯æŒğŸ«¤ã€‚</p><p>å…¨é æ™šä¸Šå›æ¥çš„ä¸¤ä¸ªå°æ—¶å›è¡€ã€‚æœ€è¿‘ç”¨äº† spotify å…è´¹ä½“éªŒäº†ä¸€ä¸ªæœˆçš„éŸ³ä¹ä¼šå‘˜ï¼ŒéŸ³è´¨æå‡ä¸€å¤§æˆªğŸ˜†ï¼Œé‡è¦çš„æ˜¯å¯ä»¥å¬é€¼å“¥çš„æ­Œã€‚å…ˆå†™åˆ°è¿™é‡Œï¼Œè¦ä¿æŒä¸ƒå°æ—¶çš„ç¡çœ ğŸ˜ªã€‚</p><iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/1wFROudevSHtz7NegT9GeX?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>]]></content>
      
      
      <categories>
          
          <category> ç”Ÿæ´» </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Jaxç¼–ç¨‹: è¸©å‘è®°å½•</title>
      <link href="/p/80c749f/"/>
      <url>/p/80c749f/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è®°å½• jax ä½¿ç”¨è¿‡ç¨‹ä¸­çš„å‘ã€‚</p><span id="more"></span><p>gpu ä¸Šå®‰è£… jax éœ€è¦</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U &quot;jax[cuda12_pip]&quot; -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html</span><br></pre></td></tr></table></figure><p>å¦‚æœæ²¡æœ‰ IB ç½‘å¡ï¼Œå¤šæœºè®­ç»ƒè¦å…³é—­é˜²ç«å¢™å¹¶åŠ ä¸Šå¦‚ä¸‹ç¯å¢ƒå˜é‡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export NCCL_DEBUG=INFO </span><br><span class="line">export NCCL_SOCKET_IFNAME=ç½‘å¡ID</span><br><span class="line">export NCCL_IB_DISABLE=1</span><br></pre></td></tr></table></figure><p>æ§åˆ¶ jax å…è®¸ä½¿ç”¨æ˜¾å­˜çš„å˜é‡ï¼Œç¬”è€…ä¸€èˆ¬è®¾ç½®ä¸º 0.95(%)ï¼Œå¦‚å‘ç”Ÿ OOM å¯è°ƒå°</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export XLA_PYTHON_CLIENT_MEM_FRACTION=0.95</span><br></pre></td></tr></table></figure><p>å…³é—­ jax çš„é¢„åˆ†é…æ˜¾å­˜æœºåˆ¶ï¼Œä½†å®¹æ˜“äº§ç”Ÿ GPU å†…å­˜ç¢ç‰‡ï¼Œå¯¼è‡´å‡ºç° OOM</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export XLA_PYTHON_CLIENT_PREALLOCATE=false</span><br></pre></td></tr></table></figure><p>ä½¿ jax æŒ‰éœ€å‡†ç¡®åˆ†é…æ‰€éœ€çš„å†…å®¹ï¼Œå¹¶é‡Šæ”¾ä¸å†éœ€è¦çš„å†…å­˜ï¼Œä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œä¸å»ºè®®ä½¿ç”¨ï¼Œä½†å¯¹å°çš„æ˜¾å­˜å ç”¨è¿è¡Œæˆ–è°ƒè¯• OOM æ•…éšœå¯èƒ½å¾ˆæœ‰ç”¨</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export XLA_PYTHON_CLIENT_ALLOCATOR=platform</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Jax ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDAæµ,å¹¶å‘ä¸ä¸Šä¸‹æ–‡</title>
      <link href="/p/40cda68f/"/>
      <url>/p/40cda68f/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æ·±å…¥ä»‹ç»æµçš„ä½¿ç”¨ï¼ŒåŒ…æ‹¬æµçš„å¹¶å‘ï¼Œå¤šçº¿ç¨‹è°ƒåº¦æµï¼Œå¹¶å‘é™åˆ¶ï¼Œåˆ›å»ºæµé—´ä¾èµ–å…³ç³»ï¼Œé‡å ä¸»æœºä¸è®¾å¤‡çš„æ‰§è¡Œç­‰ï¼ŒåŒæ—¶ï¼Œç»“åˆå®ä¾‹è®²è§£äº† CUDA ä¸Šä¸‹æ–‡ä»¥åŠ MPS çš„æ¦‚å¿µï¼Œç®€å•ä»‹ç»äº† CUDA Driver API å¯¹ Context çš„ç®¡ç†ã€‚</p><span id="more"></span><h2 id="å¹¶å‘æµçš„æ‰§è¡Œ"><a href="#å¹¶å‘æµçš„æ‰§è¡Œ" class="headerlink" title="å¹¶å‘æµçš„æ‰§è¡Œ"></a>å¹¶å‘æµçš„æ‰§è¡Œ</h2><h3 id="éç©ºæµä¸­çš„å¹¶å‘"><a href="#éç©ºæµä¸­çš„å¹¶å‘" class="headerlink" title="éç©ºæµä¸­çš„å¹¶å‘"></a>éç©ºæµä¸­çš„å¹¶å‘</h3><p>ä»¥ä¸‹é¢çš„æ ¸å‡½æ•°ä¸ºä¾‹ï¼Œå®šä¹‰ä¸€ä¸ªéç©ºæµï¼Œå°†å¤šä¸ªæ ¸å‡½æ•°åŠ å…¥åˆ°è¯¥æµä¸­ã€‚å†å¾ªç¯å®šä¹‰å¤šä¸ªæµ</p><blockquote><p>æ³¨æ„æ ¸å‡½æ•°è¦è¶³å¤Ÿå¤æ‚æ‰èƒ½è®©éç©ºæµå¹¶è¡Œ</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_4</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n_stream=<span class="number">12</span>;</span><br><span class="line">    cudaStream_t *stream=(cudaStream_t*)<span class="built_in">malloc</span>(n_stream*<span class="built_in">sizeof</span>(cudaStream_t));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamCreate</span>(&amp;stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line">    cudaEvent_t start,stop;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;n_stream; i++) &#123;</span><br><span class="line">        kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">        kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">        kernel_3&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">        kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamSynchronize</span>(stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop,<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    <span class="type">float</span> elapsed_time;</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsed_time,start,stop);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;elapsed time:%f ms\n&quot;</span>,elapsed_time);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamDestroy</span>(stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(stop);</span><br><span class="line">    <span class="built_in">free</span>(stream);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™äº›å†…æ ¸å¯åŠ¨çš„æ‰§è¡Œé…ç½®è¢«æŒ‡å®šä¸ºå•ä¸€çº¿ç¨‹å—ä¸­çš„å•ä¸€çº¿ç¨‹ï¼Œä»¥ä¿è¯æœ‰è¶³å¤Ÿçš„ GPU èµ„æºèƒ½å¹¶å‘è¿è¡Œæ‰€æœ‰çš„å†…æ ¸ã€‚å› ä¸ºæ¯ä¸ªå†…æ ¸å¯åŠ¨ç›¸å¯¹ä¸»æœºæ¥è¯´éƒ½æ˜¯å¼‚æ­¥çš„ï¼Œæ‰€ä»¥å¯ä»¥é€šè¿‡ä½¿ç”¨å•ä¸€ä¸»æœºçº¿ç¨‹åŒæ—¶è°ƒåº¦å¤šä¸ªå†…æ ¸åˆ°ä¸åŒçš„æµä¸­</p><p>ä¸‹å›¾å¯ä»¥çœ‹åˆ° 12 ä¸ªæµä»¥æœ€å¤§ 8 ä¸ªå·¥ä½œé˜Ÿåˆ—å¹¶è¡Œè¿è¡Œ</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-å¹¶å‘ä¸ä¸Šä¸‹æ–‡/1.webp" alt="1"></p><h3 id="ä½¿ç”¨-OpenMP-è°ƒåº¦æµ"><a href="#ä½¿ç”¨-OpenMP-è°ƒåº¦æµ" class="headerlink" title="ä½¿ç”¨ OpenMP è°ƒåº¦æµ"></a>ä½¿ç”¨ OpenMP è°ƒåº¦æµ</h3><p>å‰é¢æˆ‘ä»¬éƒ½æ˜¯ä½¿ç”¨çš„å•ä¸€ä¸»æœºçº¿ç¨‹è°ƒåº¦æµï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ CPU ä¸Šåˆ©ç”¨å¹¶è¡Œç¼–ç¨‹ï¼Œä½¿å¤šä¸ª CPU çº¿ç¨‹ç®¡ç†å¤šä¸ªæµã€‚è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»ä¸€ä¸‹ï¼Œåœ¨ MPI (Message Passing Interface)ã€OpenMP å’Œ Pthread è¿™ä¸‰ç§å¸¸è§çš„ CPU å¹¶è¡Œç¼–ç¨‹åº“ï¼š</p><ul><li>MPIï¼šMPI æ˜¯ä¸€ç§æ¶ˆæ¯ä¼ é€’åº“ï¼Œé€šå¸¸ç”¨äºåˆ†å¸ƒå¼å†…å­˜ç¯å¢ƒä¸­ã€‚MPI åº“æä¾›äº†ä¸€ç»„å‡½æ•°ï¼Œå¯ä»¥åœ¨å¤šä¸ªè®¡ç®—èŠ‚ç‚¹ä¹‹é—´å‘é€å’Œæ¥æ”¶æ¶ˆæ¯ã€‚é€šè¿‡ä½¿ç”¨ MPIï¼Œç¨‹åºå¯ä»¥åœ¨å¤šä¸ªè®¡ç®—èŠ‚ç‚¹ä¸ŠåŒæ—¶è¿è¡Œï¼Œä»è€Œå®ç°å¹¶è¡Œè®¡ç®—</li><li>OpenMPï¼šOpenMP æ˜¯ä¸€ç§å…±äº«å†…å­˜å¹¶è¡Œç¼–ç¨‹åº“ï¼Œå®ƒå¯ä»¥ç”¨äºåœ¨å•ä¸ªè®¡ç®—èŠ‚ç‚¹çš„å¤šä¸ª CPU æ ¸ä¹‹é—´å¹¶è¡Œæ‰§è¡Œä»£ç ã€‚OpenMP æä¾›äº†ä¸€ç»„æŒ‡ä»¤ï¼Œå¯ä»¥å°†å¹¶è¡Œè®¡ç®—ä»»åŠ¡åˆ†é…åˆ°ä¸åŒçš„çº¿ç¨‹ä¸Šæ‰§è¡Œã€‚è¿™äº›çº¿ç¨‹å…±äº«è¿›ç¨‹çš„å†…å­˜ç©ºé—´ï¼Œå¯ä»¥åœ¨ç¨‹åºçš„ä¸åŒéƒ¨åˆ†ä¹‹é—´å…±äº«æ•°æ®</li><li>Pthreadï¼šPthread æ˜¯ POSIX çº¿ç¨‹åº“çš„ç®€ç§°ï¼Œä¹Ÿæ˜¯ä¸€ç§å…±äº«å†…å­˜å¹¶è¡Œç¼–ç¨‹åº“ï¼Œä¸ OpenMP ç±»ä¼¼ï¼Œå¯ä»¥åœ¨å•ä¸ªè®¡ç®—èŠ‚ç‚¹ä¸Šçš„å¤šä¸ª CPU æ ¸ä¹‹é—´å¹¶è¡Œæ‰§è¡Œä»£ç ã€‚Pthread æä¾›äº†ä¸€ç»„å‡½æ•°ï¼Œç”¨äºåˆ›å»ºå’Œç®¡ç†çº¿ç¨‹ã€‚è¿™äº›çº¿ç¨‹å…±äº«è¿›ç¨‹çš„å†…å­˜ç©ºé—´ï¼Œå¯ä»¥åœ¨ç¨‹åºçš„ä¸åŒéƒ¨åˆ†ä¹‹é—´å…±äº«æ•°æ®</li></ul><p>å…¶ä¸­ OpenMP çš„ç¼–è¯‘éœ€è¦æ·»åŠ ç¼–è¯‘å™¨é¢„å¤„ç†æŒ‡ä»¤<code>#pragma</code>ï¼Œåˆ›å»ºçº¿ç¨‹ç­‰åç»­å·¥ä½œè¦ç¼–è¯‘å™¨æ¥å®Œæˆã€‚è€Œ Pthread æ‰€æœ‰çš„å¹¶è¡Œçº¿ç¨‹åˆ›å»ºéƒ½éœ€è¦æˆ‘ä»¬è‡ªå·±å®Œæˆï¼Œè¾ƒ OpenMP éº»çƒ¦ä¸€ç‚¹ï¼Œä½†æ˜¯æ›´ä¸ºçµæ´»</p><p>æ‰€ä»¥æˆ‘ä»¬ä¸‹é¢å­¦ä¹ ä½¿ç”¨ OpenMP åº“åŒæ—¶è°ƒç”¨å¤šä¸ªçº¿ç¨‹ï¼Œä½¿ç”¨ä¸€ä¸ªçº¿ç¨‹æ¥ç®¡ç†æ¯ä¸ªæµ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;omp.h&gt;</span></span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="built_in">omp_set_num_thread</span>(n_stream);</span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> i=<span class="built_in">omp_get_thread_num</span>();</span><br><span class="line">    kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_3&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è°ƒç”¨ OpenMP çš„ API åˆ›å»º n_stream ä¸ªçº¿ç¨‹ï¼Œ<code>#pragma omp parallel</code>å®æŒ‡ä»¤å‘Šè¯‰ç¼–è¯‘å™¨ä¸‹é¢èŠ±æ‹¬å·ä¸­çš„éƒ¨åˆ†å°±æ˜¯æ¯ä¸ªçº¿ç¨‹éƒ½è¦æ‰§è¡Œçš„éƒ¨åˆ†ï¼Œæ‹¬å·ä¸­çš„éƒ¨åˆ†å¯ä»¥ç§°ä¸ºå¹¶è¡Œå•å…ƒ</p><p>ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤ä½¿ nvcc æ”¯æŒ OpenMP æŒ‡ä»¤ç¼–è¯‘</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc &#123;&#125;.cu -Xcompiler -fopenmp</span><br></pre></td></tr></table></figure><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-å¹¶å‘ä¸ä¸Šä¸‹æ–‡/2.webp" alt="2"></p><p>å…³äº OpenMP ä¸ CUDA ä¹‹é—´æ›´å¤æ‚çš„æ“ä½œæˆ‘ä»¬ä¼šåœ¨ä¹‹åçš„æ–‡ç« å’Œå¤§å®¶ç»†ç»†é“æ¥</p><h3 id="ä½¿ç”¨ç¯å¢ƒå˜é‡è°ƒæ•´æµè¡Œä¸º"><a href="#ä½¿ç”¨ç¯å¢ƒå˜é‡è°ƒæ•´æµè¡Œä¸º" class="headerlink" title="ä½¿ç”¨ç¯å¢ƒå˜é‡è°ƒæ•´æµè¡Œä¸º"></a>ä½¿ç”¨ç¯å¢ƒå˜é‡è°ƒæ•´æµè¡Œä¸º</h3><p>ç›®å‰ Nvidia æ”¯æŒçš„æœ€å¤§ Hyper-Q å·¥ä½œé˜Ÿåˆ—æ•°æ˜¯ 32ï¼Œä½†æ˜¯åœ¨é»˜è®¤æƒ…å†µä¸‹å¹¶ä¸æ˜¯å…¨éƒ¨å¼€å¯ï¼Œè€Œæ˜¯è¢«é™åˆ¶æˆ 8 ä¸ªï¼ŒåŸå› æ˜¯æ¯ä¸ªå·¥ä½œé˜Ÿåˆ—åªè¦å¼€å¯å°±ä¼šæœ‰èµ„æºæ¶ˆè€—ï¼Œå¦‚æœç”¨ä¸åˆ° 32 ä¸ªå¯ä»¥æŠŠèµ„æºç•™ç»™éœ€è¦çš„ 8 ä¸ªé˜Ÿåˆ—ï¼Œä¿®æ”¹è¿™ä¸ªé…ç½®çš„æ–¹æ³•æ˜¯ä¿®æ”¹ä¸»æœºç³»ç»Ÿçš„ç¯å¢ƒå˜é‡</p><p>å¯¹äºLinuxç³»ç»Ÿä¸­ï¼Œå¯ä»¥å¯¼å…¥ç¯å¢ƒå˜é‡ä¿®æ”¹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_DEVICE_MAX_CONNECTIONS=32</span><br></pre></td></tr></table></figure><p>å°† <code>n_stream</code> æ”¹ä¸º 24ï¼Œå†æ¬¡ç¼–è¯‘ï¼Œä¸‹å›¾å¯ä»¥çœ‹åˆ°å¹¶è¡Œå·¥ä½œé˜Ÿåˆ—æ•°æé«˜å¾ˆå¤š</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-å¹¶å‘ä¸ä¸Šä¸‹æ–‡/3.webp" alt="3"></p><h3 id="å¹¶å‘é™åˆ¶"><a href="#å¹¶å‘é™åˆ¶" class="headerlink" title="å¹¶å‘é™åˆ¶"></a>å¹¶å‘é™åˆ¶</h3><p>æœ‰é™çš„å†…æ ¸èµ„æºå¯ä»¥æŠ‘åˆ¶åº”ç”¨ç¨‹åºä¸­å¯èƒ½å‡ºç°çš„å†…æ ¸å¹¶å‘çš„æ•°é‡ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå†…æ ¸å¯åŠ¨æ—¶é€šå¸¸ä¼šåˆ›å»ºå¤§é‡çº¿ç¨‹ï¼Œè¿™æ—¶ï¼Œå¯ç”¨çš„ç¡¬ä»¶èµ„æºå¯èƒ½ä¼šæˆä¸ºå¹¶å‘çš„ä¸»è¦é™åˆ¶å› ç´ ï¼Œå› ä¸ºå®ƒä»¬é˜»æ­¢å¯åŠ¨ç¬¦åˆæ¡ä»¶çš„å†…æ ¸ã€‚ä¸‹é¢æ›´æ”¹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>ä¸º</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">16</span>,<span class="number">32</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">32</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>å°†ä½¿ç”¨çš„ CUDA æµå¢åŠ åˆ° 24ï¼Œä¸‹å›¾å¯ä»¥çœ‹åˆ°åªå®ç°äº† 4 è·¯å¹¶å‘ï¼Œå› ä¸º GPU æ— æ³•åˆ†é…è¶³å¤Ÿçš„èµ„æºï¼Œè¿™é‡Œéœ€è¦æˆ‘ä»¬æ ¹æ®éœ€æ±‚ä¿®æ”¹å„ä¸ªå‚æ•°</p><h3 id="ç©ºæµçš„é˜»å¡è¡Œä¸º"><a href="#ç©ºæµçš„é˜»å¡è¡Œä¸º" class="headerlink" title="ç©ºæµçš„é˜»å¡è¡Œä¸º"></a>ç©ºæµçš„é˜»å¡è¡Œä¸º</h3><p>ä¸ºäº†æ¼”ç¤ºåœ¨ç©ºæµä¸­çš„çš„é˜»å¡è¡Œä¸ºï¼Œå°† <code>n_stream</code> æ”¹å› 12ï¼Œ<code>block</code>å’Œ<code>grid</code>æ”¹å›1ï¼Œæˆ‘ä»¬å°†æ·±åº¦ä¼˜å…ˆè°ƒåº¦å¾ªç¯æ”¹ä¸ºåœ¨ç©ºæµçš„è°ƒç”¨ kernel_3</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">    kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_3&lt;&lt;&lt;grid,block&gt;&gt;&gt;();</span><br><span class="line">    kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> å¯ä»¥çœ‹åˆ°æ‰€æœ‰ kernel_3 å¯åŠ¨ä»¥åï¼Œæ‰€æœ‰å…¶ä»–çš„æµä¸­çš„æ“ä½œå…¨éƒ¨è¢«é˜»å¡ï¼Œç©ºæµå¯¹äºéç©ºæµå…·æœ‰é˜»å¡ä½œç”¨</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-å¹¶å‘ä¸ä¸Šä¸‹æ–‡/5.webp" alt="5"></p><h3 id="åˆ›å»ºæµé—´ä¾èµ–å…³ç³»"><a href="#åˆ›å»ºæµé—´ä¾èµ–å…³ç³»" class="headerlink" title="åˆ›å»ºæµé—´ä¾èµ–å…³ç³»"></a>åˆ›å»ºæµé—´ä¾èµ–å…³ç³»</h3><p>ç†æƒ³æƒ…å†µä¸‹ï¼Œæµä¹‹é—´ä¸åº”å­˜åœ¨éé¢„æœŸçš„ä¾èµ–å…³ç³»ï¼ˆå³è™šå‡çš„ä¾èµ–å…³ç³»ï¼‰ã€‚ç„¶è€Œåœ¨å®é™…ä½¿ç”¨æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæµç­‰å¾…å¦ä¸€ä¸ªæµä¸­çš„æ“ä½œå®Œæˆã€‚å¯ä»¥ä½¿ç”¨äº‹ä»¶åœ¨æµä¹‹é—´åˆ›å»ºä¾èµ–å…³ç³»ã€‚é¦–å…ˆï¼Œä½¿ç”¨æ ‡å¿—<code>cudaEventDisableTiming</code>åˆ›å»ºåŒæ­¥äº‹ä»¶</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t * event=(cudaEvent_t *)<span class="built_in">malloc</span>(n_stream*<span class="built_in">sizeof</span>(cudaEvent_t));</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">    <span class="built_in">cudaEventCreateWithFlags</span>(&amp;event[i],cudaEventDisableTiming);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥ï¼Œä½¿ç”¨<code>cudaEventRecord</code>åœ¨æ¯ä¸ªæµå®Œæˆæ—¶è®°å½•ä¸€ä¸ªä¸åŒçš„äº‹ä»¶ï¼Œå†ä½¿ç”¨<code>cudaStreamWaitEvent</code>æ¥å¼ºåˆ¶æœ€åä¸€ä¸ªæµï¼ˆå³æµ[n_streams-1]ï¼‰ç­‰å¾…å…¶ä»–æ‰€æœ‰æµ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">    kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_3&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(event[i],stream[i]);</span><br><span class="line">    <span class="built_in">cudaStreamWaitEvent</span>(stream[n_stream<span class="number">-1</span>],event[i],<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä»ä¸‹å›¾çš„æ—¶é—´è½´å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æˆåŠŸåˆ›å»ºäº†æµé—´çš„ä¾èµ–å…³ç³»ï¼Œæœ€åä¸€ä¸ªæµä¼šç­‰åˆ°å‰é¢æ‰€æœ‰æµä¸­çš„äº‹ä»¶å®Œæˆï¼Œå†è¿è¡Œ</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-å¹¶å‘ä¸ä¸Šä¸‹æ–‡/6.webp" alt=""></p><h2 id="é‡å å†…æ ¸æ‰§è¡Œå’Œæ•°æ®ä¼ è¾“"><a href="#é‡å å†…æ ¸æ‰§è¡Œå’Œæ•°æ®ä¼ è¾“" class="headerlink" title="é‡å å†…æ ¸æ‰§è¡Œå’Œæ•°æ®ä¼ è¾“"></a>é‡å å†…æ ¸æ‰§è¡Œå’Œæ•°æ®ä¼ è¾“</h2><p>å‰é¢çš„ç« èŠ‚æˆ‘ä»¬å·²ç»äº†è§£äº†æ•°æ®ä¼ è¾“é˜Ÿåˆ—ï¼ˆHtD, DtHï¼‰ï¼Œä¸æ˜¯ç»è¿‡åŒä¸€æ¡é˜Ÿåˆ—çš„ï¼Œè¿™ä¸¤ä¸ªæ“ä½œå¯ä»¥é‡å å®Œæˆï¼Œä½†æ˜¯åŒå‘æ•°æ®ä¼ è¾“çš„æ—¶å€™ä¸èƒ½è¿›è¡Œæ­¤æ“ä½œã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦æ£€æŸ¥æ•°æ®ä¼ è¾“å’Œå†…æ ¸æ‰§è¡Œä¹‹é—´çš„å…³ç³»ï¼š</p><ul><li>å¦‚æœå†…æ ¸ä½¿ç”¨æ•°æ® Aï¼Œå¯¹ A è¿›è¡Œæ•°æ®ä¼ è¾“å¿…é¡»è¦åœ¨å†…æ ¸å¯åŠ¨ä¹‹å‰ï¼Œä¸”å¿…é¡»åœ¨åŒä¸€ä¸ªæµä¸­</li><li>å¦‚æœå†…æ ¸ä¸ä½¿ç”¨æ•°æ®Aï¼Œå†…æ ¸æ‰§è¡Œå’Œæ•°æ®ä¼ è¾“å¯ä»¥ä½äºä¸åŒçš„æµä¸­é‡å æ‰§è¡Œ</li></ul><p>ç¬¬äºŒç§æƒ…å†µå°±æ˜¯é‡å å†…æ ¸æ‰§è¡Œå’Œæ•°æ®ä¼ è¾“çš„åŸºæœ¬åšæ³•ï¼Œå½“æ•°æ®ä¼ è¾“å’Œå†…æ ¸æ‰§è¡Œè¢«åˆ†é…åˆ°ä¸åŒçš„æµä¸­æ—¶ï¼ŒCUDA æ‰§è¡Œçš„æ—¶å€™é»˜è®¤è¿™æ˜¯å®‰å…¨çš„ï¼Œæˆ‘ä»¬è¦ä¿è¯å®ƒä»¬ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚ä½†æ˜¯ç¬¬ä¸€ç§æƒ…å†µä¹Ÿå¯ä»¥è¿›è¡Œé‡å ï¼Œéœ€è¦å¯¹æ ¸å‡½æ•°è¿›è¡Œä¸€å®šçš„åˆ†å‰²ï¼Œæˆ‘ä»¬ç”¨å‘é‡åŠ æ³•æ ¸å‡½æ•°æ¥ä¸¾ä¾‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraysSum</span><span class="params">(<span class="type">float</span>*a, <span class="type">float</span>*b, <span class="type">float</span>*res, <span class="type">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> idx = blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(idx &lt; N) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;N_REPEAT;j++)</span><br><span class="line">            res[idx]=a[idx]+b[idx];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å‘é‡åŠ æ³•çš„è¿‡ç¨‹æ˜¯ä¸º</p><ol><li>å°†ä¸¤ä¸ªè¾“å…¥å‘é‡ä»ä¸»æœºä¼ å…¥è®¾å¤‡</li><li>å†…æ ¸è®¡ç®—ç»“æœ</li><li>å°†ç»“æœä»è®¾å¤‡å›ä¼ åˆ°ä¸»æœº</li></ol><p>ç”±äºè¿™ä¸ªé—®é¢˜å°±æ˜¯ä¸€ä¸ªä¸€æ­¥é—®é¢˜ï¼Œæˆ‘ä»¬æ²¡åŠæ³•è®©å†…æ ¸å’Œæ•°æ®ä¼ è¾“é‡å ï¼Œå› ä¸ºå†…æ ¸éœ€è¦å…¨éƒ¨çš„æ•°æ®ï¼Œä½†æ˜¯ç”±äºå‘é‡åŠ æ³•çš„æ¯ä¸€ä½éƒ½äº’ä¸å¹²æ‰°ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå‘é‡åˆ†å—ï¼Œå¹¶ä¸”æ¯å—ä¸­çš„æ•°æ®åªç”¨äºæ¯å—çš„å†…æ ¸ï¼Œè€Œè·Ÿå…¶å®ƒåˆ†å—çš„å†…æ ¸æ²¡æœ‰å…³ç³»ï¼Œè¿™æ ·å°±å¯ä»¥æŠŠæ•´ä¸ªè¿‡ç¨‹åˆ†æˆ N_SEGMENT ä»½ï¼Œä¹Ÿå°±æ˜¯ N_SEGMENT ä¸ªæµåˆ†åˆ«æ‰§è¡Œ</p><h3 id="æ·±åº¦ä¼˜å…ˆè°ƒåº¦é‡å "><a href="#æ·±åº¦ä¼˜å…ˆè°ƒåº¦é‡å " class="headerlink" title="æ·±åº¦ä¼˜å…ˆè°ƒåº¦é‡å "></a>æ·±åº¦ä¼˜å…ˆè°ƒåº¦é‡å </h3><p>æˆ‘ä»¬é¦–å…ˆä½¿ç”¨æ·±åº¦ä¼˜å…ˆè°ƒåº¦çš„æ–¹å¼ã€‚è¿™é‡Œéœ€è¦æ³¨æ„æ•°æ®ä¼ è¾“æ˜¯å¼‚æ­¥çš„ï¼Œæ‰€ä»¥å¿…é¡»å£°æ˜ä¸ºå›ºå®šå†…å­˜ï¼Œä¸èƒ½æ˜¯åˆ†é¡µå†…å­˜</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N_REPEAT 10</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N_SEGMENT 4</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraysSum</span><span class="params">(<span class="type">float</span>*a,<span class="type">float</span>*b,<span class="type">float</span>*res,<span class="type">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> idx=blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(idx &lt; N) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;N_REPEAT;j++)</span><br><span class="line">            res[idx]=a[idx]+b[idx];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> nElem=<span class="number">1</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Vector size:%d\n&quot;</span>,nElem);</span><br><span class="line">    <span class="type">int</span> nByte=<span class="built_in">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line">    <span class="type">float</span> * a_h,*b_h,*res_h,*res_from_gpu_h;</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;a_h,nByte,cudaHostAllocDefault);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;b_h,nByte,cudaHostAllocDefault);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;res_h,nByte,cudaHostAllocDefault);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;res_from_gpu_h,nByte,cudaHostAllocDefault);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemset</span>(res_h,<span class="number">0</span>,nByte);</span><br><span class="line">    <span class="built_in">cudaMemset</span>(res_from_gpu_h,<span class="number">0</span>,nByte);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *a_d,*b_d,*res_d;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;a_d,nByte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;b_d,nByte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;res_d,nByte);</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">512</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">((nElem<span class="number">-1</span>)/block.x+<span class="number">1</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//asynchronous calculation</span></span><br><span class="line">    <span class="type">int</span> iElem=nElem/N_SEGMENT;</span><br><span class="line">    cudaStream_t stream[N_SEGMENT];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamCreate</span>(&amp;stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    cudaEvent_t start,stop;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;a_d[ioffset],&amp;a_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;b_d[ioffset],&amp;b_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        ArraysSum&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;(&amp;a_d[ioffset],&amp;b_d[ioffset],&amp;res_d[ioffset],iElem);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;res_from_gpu_h[ioffset],&amp;res_d[ioffset],nByte/N_SEGMENT,cudaMemcpyDeviceToHost,stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamDestroy</span>(stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaFree</span>(a_d);</span><br><span class="line">    <span class="built_in">cudaFree</span>(b_d);</span><br><span class="line">    <span class="built_in">cudaFree</span>(a_h);</span><br><span class="line">    <span class="built_in">cudaFree</span>(b_h);</span><br><span class="line">    <span class="built_in">cudaFree</span>(res_h);</span><br><span class="line">    <span class="built_in">cudaFree</span>(res_from_gpu_h);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(stop);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>nvvp å¯è§†åŒ–å¦‚ä¸‹</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-å¹¶å‘ä¸ä¸Šä¸‹æ–‡/7.webp" alt=""></p><h3 id="å¹¿åº¦ä¼˜å…ˆè°ƒåº¦é‡å "><a href="#å¹¿åº¦ä¼˜å…ˆè°ƒåº¦é‡å " class="headerlink" title="å¹¿åº¦ä¼˜å…ˆè°ƒåº¦é‡å "></a>å¹¿åº¦ä¼˜å…ˆè°ƒåº¦é‡å </h3><p>å¾ªç¯ä¿®æ”¹ä¸ºå¦‚ä¸‹ä»£ç </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(&amp;a_d[ioffset],&amp;a_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(&amp;b_d[ioffset],&amp;b_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">    ArraysSum&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;(&amp;a_d[ioffset],&amp;b_d[ioffset],&amp;res_d[ioffset],iElem);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(&amp;res_from_gpu_h[ioffset],&amp;res_d[ioffset],nByte/N_SEGMENT,cudaMemcpyDeviceToHost,stream[i]));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-å¹¶å‘ä¸ä¸Šä¸‹æ–‡/8.webp" alt="8"></p><p>nvvp å¯è§†åŒ–å’Œæ·±åº¦ä¼˜å…ˆè°ƒåº¦é‡å ä¸€æ¨¡ä¸€æ ·ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦å…³æ³¨æ·±åº¦è¿˜æ˜¯å¹¿åº¦çš„è°ƒåº¦é¡ºåº</p><h2 id="é‡å ä¸»æœºä¸è®¾å¤‡çš„æ‰§è¡Œ"><a href="#é‡å ä¸»æœºä¸è®¾å¤‡çš„æ‰§è¡Œ" class="headerlink" title="é‡å ä¸»æœºä¸è®¾å¤‡çš„æ‰§è¡Œ"></a>é‡å ä¸»æœºä¸è®¾å¤‡çš„æ‰§è¡Œ</h2><p>å®ç° GPU å’Œ CPU çš„æ‰§è¡Œé‡åˆæ˜¯ç›¸å¯¹ç›´æ¥çš„ï¼Œå› ä¸ºæ‰€æœ‰çš„å†…æ ¸é»˜è®¤æƒ…å†µä¸‹æ˜¯å¼‚æ­¥å¯åŠ¨çš„ã€‚å› æ­¤ï¼Œåªè¦å¯åŠ¨ä¸€ä¸ªå†…æ ¸ï¼Œå¹¶ç«‹å³åœ¨ä¸»æœºçº¿ç¨‹ä¸­å®ç°æœ‰æ•ˆæ“ä½œï¼Œå°±ä¼šè‡ªåŠ¨äº§ç”Ÿ GPU å’Œ CPU æ‰§è¡Œçš„é‡å </p><p>ä»¥ä¸‹é¢çš„åŠ æ³•æ ¸å‡½æ•°ä¸ºä¾‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">float</span> *g_data, <span class="type">float</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    g_data[idx] = g_data[idx] + value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæœ‰ä¸¤ä¸ªæ‹·è´å’Œä¸€ä¸ªå†…æ ¸å¯åŠ¨æ“ä½œï¼Œè®°å½•äº†ä¸€ä¸ªåœæ­¢äº‹ä»¶ï¼Œä»¥æ ‡è®°æ‰€æœ‰ CUDA æ“ä½œçš„å®Œæˆ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpyAsync</span>(d_a, h_a, nbytes, cudaMemcpyHostToDevice);</span><br><span class="line">kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_a, value);</span><br><span class="line"><span class="built_in">cudaMemcpyAsync</span>(h_a, d_a, nbytes, cudaMemcpyDeviceToHost);</span><br><span class="line"><span class="built_in">cudaEventRecord</span>(stop);</span><br></pre></td></tr></table></figure><p>è¿™äº›æ“ä½œä¸ä¸»æœºéƒ½æ˜¯å¼‚æ­¥çš„ï¼Œå®ƒä»¬éƒ½è¢«ç»‘å®šåˆ°é»˜è®¤æµä¸­ï¼Œä¸€æ—¦æœ€åä¸€ä¸ª<code>cudaMemcpyAsync</code>è¢«å‘å‡ºï¼Œæ§åˆ¶æƒå°†ç«‹å³è¿”å›åˆ°ä¸»æœºã€‚ä¸€æ—¦æ§åˆ¶æƒè¿”å›ç»™ä¸»æœºï¼Œä¸»æœºå°±å¯ä»¥åšä»»ä½•ä¸ä¾èµ–å†…æ ¸è¾“å‡ºçš„æœ‰ç”¨çš„è®¡ç®—ã€‚åœ¨ä¸‹é¢çš„ä»£ç æ®µä¸­ï¼Œä¸»æœºåªæ˜¯ç®€å•åœ°è¿›è¡Œè¿­ä»£ï¼Œç­‰å¾…æ‰€æœ‰CUDAæ“ä½œçš„å®Œæˆï¼ŒåŒæ—¶é€’å¢ä¸€ä¸ªè®¡æ•°å™¨ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œä¸»æœºçº¿ç¨‹æŸ¥è¯¢åœæ­¢äº‹ä»¶ã€‚ä¸€æ—¦è¯¥äº‹ä»¶æ»¡è¶³ï¼Œä¸»æœºçº¿ç¨‹å°±ä¼šç»§ç»­</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> counter = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="built_in">cudaEventQuery</span>(stop) == cudaErrorNotReady) &#123;</span><br><span class="line">counter++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Counter: %ld\n&quot;</span>,counter);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* è¾“å‡º</span></span><br><span class="line"><span class="comment">Vector size:1048576</span></span><br><span class="line"><span class="comment">Counter: 7206</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h3 id="æµå›è°ƒ"><a href="#æµå›è°ƒ" class="headerlink" title="æµå›è°ƒ"></a>æµå›è°ƒ</h3><p>æµå›è°ƒæ˜¯å¦ä¸€ç§å¯ä»¥åˆ° CUDA æµæ’åˆ—ç­‰å¾…çš„æ“ä½œç±»å‹ã€‚ ä¸€æ—¦æµå›è°ƒä¹‹å‰çš„æµä¸­çš„æ‰€æœ‰æ“ä½œéƒ½å·²å®Œæˆï¼ŒCUDA è¿è¡Œæ—¶å°†è°ƒç”¨æµå›è°ƒæŒ‡å®šçš„ä¸»æœºç«¯å‡½æ•°ï¼Œè¯¥å‡½æ•°ç”±åº”ç”¨ç¨‹åºæä¾›ï¼Œè¿™å…è®¸å°†ä»»æ„ä¸»æœºç«¯é€»è¾‘æ’å…¥åˆ° CUDA æµä¸­ã€‚ æµå›è°ƒæ˜¯å¦ä¸€ç§ CPU åˆ° GPU åŒæ­¥æœºåˆ¶ï¼Œä½†æ˜¯æµå›è°ƒæ—¶ï¼Œå›è°ƒå‡½æ•°ä¸­ä¸å¯ä»¥è°ƒç”¨ CUDA çš„ APIï¼Œä¸”ä¸å¯ä»¥æ‰§è¡ŒåŒæ­¥</p><p>æµå‡½æ•°æœ‰ç‰¹æ®Šçš„å‚æ•°è§„æ ¼ï¼Œå¿…é¡»å†™æˆä¸‹é¢å½¢å¼å‚æ•°çš„å‡½æ•°</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> CUDART_CB <span class="title">my_callback</span><span class="params">(cudaStream_t stream, cudaError_t status, <span class="type">void</span> *data)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;callback from stream %d\n&quot;</span>, *((<span class="type">int</span> *)data));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¯¥å‡½æ•°æœ‰ä¸‰ä¸ªå‚æ•°ï¼š</p><ul><li><code>cudaStream_t stream</code>ï¼šè¡¨ç¤ºå›è°ƒå‡½æ•°ä¸å“ªä¸ªCUDAæµç›¸å…³è”ã€‚å½“æµä¸­çš„æ‰€æœ‰æ“ä½œéƒ½å®Œæˆæ—¶ï¼ŒCUDAè¿è¡Œæ—¶å°†è°ƒç”¨æ­¤å›è°ƒå‡½æ•°</li><li><code>cudaError_t status</code>ï¼šè¡¨ç¤ºæµä¸­æœ€åä¸€ä¸ªæ“ä½œçš„çŠ¶æ€ã€‚å¦‚æœçŠ¶æ€æ˜¯<code>cudaSuccess</code>ï¼Œåˆ™è¡¨ç¤ºæ‰€æœ‰æ“ä½œå·²æˆåŠŸå®Œæˆ</li><li><code>void *data</code>ï¼šè¡¨ç¤ºä¼ é€’ç»™å›è°ƒå‡½æ•°çš„æ•°æ®æŒ‡é’ˆã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œè¯¥æŒ‡é’ˆæŒ‡å‘ä¸€ä¸ªæ•´æ•°ï¼Œå…¶ä¸­åŒ…å«ä¸æµç›¸å…³çš„è‡ªå®šä¹‰æ•°æ®</li></ul><p>å¹¶ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°åŠ å…¥æµä¸­</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamAddCallback</span><span class="params">(cudaStream_t stream,cudaStreamCallback_t callback, <span class="type">void</span> *userData, <span class="type">unsigned</span> <span class="type">int</span> flags)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>stream</code>ï¼šCUDA æµï¼Œè¡¨ç¤ºå°†è¦æ·»åŠ å›è°ƒå‡½æ•°çš„æµ</li><li><code>callback</code>ï¼šå›è°ƒå‡½æ•°ï¼Œè¯¥å‡½æ•°ä¼šåœ¨æŒ‡å®šçš„æµä¸Šçš„æ‰€æœ‰æ“ä½œéƒ½å·²ç»å®Œæˆæ—¶è¢«è°ƒç”¨ã€‚å›è°ƒå‡½æ•°çš„åŸå‹ä¸º <code>void (*)(cudaStream_t, cudaError_t, void*)</code>ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå‚æ•°è¡¨ç¤ºå›è°ƒå‡½æ•°æ‰€åœ¨çš„æµï¼Œç¬¬äºŒä¸ªå‚æ•°è¡¨ç¤ºæµä¸Šçš„æœ€åä¸€ä¸ª CUDA æ“ä½œçš„çŠ¶æ€ï¼Œç¬¬ä¸‰ä¸ªå‚æ•°ä¸ºç”¨æˆ·è‡ªå®šä¹‰æ•°æ®</li><li><code>userData</code>ï¼šç”¨æˆ·è‡ªå®šä¹‰æ•°æ®æŒ‡é’ˆï¼Œä¼šåœ¨å›è°ƒå‡½æ•°è¢«è°ƒç”¨æ—¶ä¼ é€’ç»™å›è°ƒå‡½æ•°</li><li><code>flags</code>ï¼šæ ‡å¿—ä½ï¼Œç”¨äºæ§åˆ¶å›è°ƒå‡½æ•°çš„è¡Œä¸ºã€‚ç›®å‰åªæ”¯æŒ <code>cudaStreamCallbackBlocking</code> å’Œ <code>cudaStreamCallbackNonblocking</code> ä¸¤ç§æ ‡å¿—ä½ï¼Œåˆ†åˆ«è¡¨ç¤ºå›è°ƒå‡½æ•°æ˜¯é˜»å¡è¿˜æ˜¯éé˜»å¡çš„ã€‚å¦‚æœä½¿ç”¨é˜»å¡å›è°ƒå‡½æ•°ï¼Œåˆ™è¯¥å›è°ƒå‡½æ•°å¿…é¡»åœ¨æµä¸Šçš„æ‰€æœ‰æ“ä½œå®Œæˆåæ‰èƒ½è¢«è°ƒç”¨ã€‚å¦‚æœä½¿ç”¨éé˜»å¡å›è°ƒå‡½æ•°ï¼Œåˆ™è¯¥å›è°ƒå‡½æ•°å¯èƒ½ä¼šåœ¨æµä¸Šçš„æ“ä½œå°šæœªå…¨éƒ¨å®Œæˆæ—¶è¢«è°ƒç”¨</li></ul><p>ä¸‹é¢æ˜¯æµå›è°ƒçš„ä¸€ä¸ªä¾‹å­</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// å®šä¹‰ä¸€ä¸ªå›è°ƒå‡½æ•° my_callback()ï¼Œç›‘æ§æ¯ä¸ªæµçš„å®Œæˆæƒ…å†µï¼Œå¹¶åœ¨æ¯ä¸ªæµå®Œæˆåè¾“å‡ºç›¸åº”æµçš„ ID å·ï¼Œç”¨äºåœ¨ CUDA å¼‚æ­¥æ“ä½œå®Œæˆåæ‰§è¡Œ</span></span><br><span class="line"><span class="function"><span class="type">void</span> CUDART_CB <span class="title">my_callback</span><span class="params">(cudaStream_t stream,cudaError_t status,<span class="type">void</span> * data)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;call back from stream:%d\n&quot;</span>,*((<span class="type">int</span> *)data));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;a_d[ioffset],&amp;a_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;b_d[ioffset],&amp;b_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        ArraysSum&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;(&amp;a_d[ioffset],&amp;b_d[ioffset],&amp;res_d[ioffset],iElem);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;res_from_gpu_h[ioffset],&amp;res_d[ioffset],nByte/N_SEGMENT,cudaMemcpyDeviceToHost,stream[i]);</span><br><span class="line">        <span class="comment">// ä½¿ç”¨ cudaStreamAddCallback() å°†å›è°ƒå‡½æ•° my_callback() æ·»åŠ åˆ°æ¯ä¸ªæµä¸­ï¼Œä»¥ä¾¿è·Ÿè¸ªæ¯ä¸ªæµçš„å®Œæˆæƒ…å†µ</span></span><br><span class="line">        <span class="built_in">cudaStreamAddCallback</span>(stream[i],my_callback,(<span class="type">void</span> *)(stream+i),<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">/* è¾“å‡º</span></span><br><span class="line"><span class="comment">Vector size:1048576</span></span><br><span class="line"><span class="comment">call back from stream:1947823616</span></span><br><span class="line"><span class="comment">call back from stream:1946969680</span></span><br><span class="line"><span class="comment">call back from stream:1947835744</span></span><br><span class="line"><span class="comment">call back from stream:1947835776</span></span><br><span class="line"><span class="comment">Counter: 5126</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h2 id="CUDA-Context-ä¸Šä¸‹æ–‡"><a href="#CUDA-Context-ä¸Šä¸‹æ–‡" class="headerlink" title="CUDA Context ä¸Šä¸‹æ–‡"></a>CUDA Context ä¸Šä¸‹æ–‡</h2><p>CUDA Context æ˜¯ä¸€ä¸ªç”±ç‰¹å®šè¿›ç¨‹ä¸è®¾å¤‡ç›¸å…³è”çš„çŠ¶æ€é›†åˆï¼ŒåŒ…æ‹¬ï¼š</p><ul><li><p>æ‰€æœ‰åˆ†é…å†…å­˜</p></li><li><p>Modulesï¼Œç±»ä¼¼äºåŠ¨æ€é“¾æ¥åº“ï¼Œä»¥.cubinå’Œ.ptxç»“å°¾ ã€åœ¨jcudaä¸­è¦ä½¿ç”¨ã€‘</p></li><li>CUDA streamsï¼Œç®¡ç†æ‰§è¡Œå•å…ƒçš„å¹¶å‘æ€§</li><li>CUDA events</li><li>textureå’Œsurfaceå¼•ç”¨</li><li>kernelé‡Œé¢ä½¿ç”¨åˆ°çš„æœ¬åœ°å†…å­˜ï¼ˆè®¾å¤‡å†…å­˜ï¼‰</li><li>ç”¨äºè°ƒè¯•ã€åˆ†æå’ŒåŒæ­¥çš„å†…éƒ¨èµ„æº</li><li>ç”¨äºåˆ†é¡µå¤åˆ¶çš„å›ºå®šç¼“å†²åŒº</li></ul><p>CUDA ç¨‹åºé€šè¿‡ä½¿ç”¨ CUDA Context æ¥ç®¡ç†è®¾å¤‡èµ„æºå’Œæ‰§è¡Œ CUDA æŒ‡ä»¤ã€‚æ¯ä¸ªè¿›ç¨‹å¯ä»¥æœ‰å¤šä¸ª CUDA Contextï¼Œæ¯ä¸ª CUDA Context åªèƒ½ä¸ä¸€ä¸ªè®¾å¤‡ç›¸å…³è”ã€‚CUDA ç¨‹åºé€šè¿‡ä½¿ç”¨ CUDA Context æ¥ç®¡ç†è®¾å¤‡èµ„æºå’Œæ‰§è¡Œ CUDA æŒ‡ä»¤</p><p>æ¯ä¸ªè¿›ç¨‹æˆ– GPU å¯ä»¥æœ‰å¤šä¸ª CUDA Contextï¼Œè€Œæ¯ä¸ª CUDA Context åªèƒ½ä¸ä¸€ä¸ª GPU ç›¸å…³è”</p><p>åœ¨ CUDA ä¸­ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹çš„è®¾å¤‡ IDï¼Œæ¯ä¸ªè®¾å¤‡ ID å¯¹åº”ä¸€ä¸ªå”¯ä¸€çš„ CUDA Contextã€‚æ‰€ä»¥ Context ç±»ä¼¼äº CPU ä¸Šçš„è¿›ç¨‹ï¼Œç”± Driver å±‚ç®¡ç†åˆ†é…èµ„æºçš„ç”Ÿå‘½å‘¨æœŸ</p><p>ä¸ CPU è¿›ç¨‹çš„ç®¡ç†ç±»ä¼¼ï¼Œæ¯ä¸ª Context æœ‰è‡ªå·±çš„åœ°å€ç©ºé—´ï¼Œä¸”ä¹‹é—´æ˜¯éš”ç¦»çš„ï¼Œåœ¨ä¸€ä¸ª Context ä¸­æ‰€æœ‰æŒ‡é’ˆåªèƒ½åœ¨è¿™ä¸€ä¸ª Context ä¸­ä½¿ç”¨ï¼Œä½†ä¸€ä¸ª CUDA Context ä¸­çš„ä»»ä½•ä¸€ä¸ª kernel è¢«æŒ‚æ‰åï¼Œåˆ™æ­¤æ—¶å¤„äºåŒä¸€ä¸ª GPU ä¸Šçš„ æ‰€æœ‰ Context çš„æ‰€æœ‰éƒ½ä¼šå¤±æ•ˆ</p><h3 id="éšå¼åˆ›å»º"><a href="#éšå¼åˆ›å»º" class="headerlink" title="éšå¼åˆ›å»º"></a>éšå¼åˆ›å»º</h3><p>CUDA Runtime è½¯ä»¶å±‚çš„åº“æ˜¯éšå¼åˆ›å»º contextï¼Œä¸”ä¸æä¾› API ç›´æ¥åˆ›å»º CUDA contextï¼Œè€Œæ˜¯é€šè¿‡å»¶è¿Ÿåˆå§‹åŒ–ï¼ˆdeferred initializationï¼‰æ¥åˆ›å»º contextï¼Œä¹Ÿå°±æ˜¯ lazy initialization</p><p>åœ¨ Linux ä¸­é€šè¿‡å¯¼å…¥ç¯å¢ƒå˜é‡å»¶è¿Ÿåˆå§‹åŒ–</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_MODULE_LOADING=LAZY</span><br></pre></td></tr></table></figure><blockquote><p>CUDA_MODULE_LOADING é»˜è®¤ä¸º <code>EAGER</code>ï¼Œä¼šæœ€å¤§é™åº¦åœ°å‡å°‘æ¨¡å—åŠ è½½æ—¶çš„å»¶è¿Ÿï¼Œä½†ä¼šå¢åŠ ç¨‹åºå¯åŠ¨æ—¶é—´å’Œå†…å­˜å ç”¨</p></blockquote><p>å…·ä½“æ„æ€æ˜¯åœ¨è°ƒç”¨æ¯ä¸€ä¸ª CUDART åº“å‡½æ•°æ—¶ï¼Œå®ƒä¼šæ£€æŸ¥å½“å‰æ˜¯å¦æœ‰ context å­˜åœ¨ï¼Œå‡å¦‚éœ€è¦ contextï¼Œé‚£ä¹ˆæ‰è‡ªåŠ¨åˆ›å»ºã€‚ä¹Ÿå°±æ˜¯è¯´éœ€è¦åˆ›å»ºä¸Šé¢è¿™äº›å¯¹è±¡çš„æ—¶å€™å°±ä¼šåˆ›å»ºcontextã€‚å¯ä»¥æ˜¾å¼çš„æ§åˆ¶åˆå§‹åŒ–ï¼Œå³è°ƒç”¨ cudaFree(0)ï¼Œå¼ºåˆ¶çš„åˆå§‹åŒ–</p><p>CUDA Runtime å°† context å’Œ device çš„æ¦‚å¿µåˆå¹¶äº†ï¼Œå³åœ¨ä¸€ä¸ª GPU ä¸Šæ“ä½œå¯çœ‹æˆåœ¨ä¸€ä¸ª context ä¸‹</p><h3 id="æ˜¾ç¤ºåˆ›å»º"><a href="#æ˜¾ç¤ºåˆ›å»º" class="headerlink" title="æ˜¾ç¤ºåˆ›å»º"></a>æ˜¾ç¤ºåˆ›å»º</h3><p>å¯ä»¥ä½¿ç”¨ CUDA Driver API æ˜¾ç¤ºåˆ›å»º contextï¼ŒCUDA Driver API æ˜¯ä¸€ç§æ›´åå‘åº•å±‚çš„ APIï¼Œæä¾›äº†å¯¹ç¡¬ä»¶çš„æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œç›´æ¥æ§åˆ¶ GPU çš„æ‰€æœ‰ç¡¬ä»¶èµ„æºã€‚è¿™äº›å‡½æ•°è¢«å®ç°åœ¨ <a href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html">CUDA Driver åº“ </a>ä¸­ï¼Œéœ€è¦æ‰‹åŠ¨é“¾æ¥è¿™ä¸ªåº“å¹¶ç›´æ¥è°ƒç”¨è¿™äº›å‡½æ•°ï¼Œä¸‹é¢å‡ ä¸ªå‡½æ•°ç”¨äºç®¡ç† CUDA ä¸Šä¸‹æ–‡</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CUresult <span class="title">cuCreateContext</span><span class="params">(CUcontext* pctx, <span class="type">unsigned</span> <span class="type">int</span> flags, CUdevice dev)</span></span>;</span><br></pre></td></tr></table></figure><p>åˆ›å»º CUDA ä¸Šä¸‹æ–‡</p><ul><li><p>pctxï¼šè¾“å‡ºå‚æ•°ï¼ŒæŒ‡å‘æ–°åˆ›å»ºçš„CUDAä¸Šä¸‹æ–‡å¥æŸ„</p></li><li><p>flagsï¼šç”¨äºè®¾ç½®ä¸Šä¸‹æ–‡å±æ€§çš„æ ‡å¿—ä½ï¼Œå¯ä»¥ä¸º 0</p></li><li><p>devï¼šç”¨äºåˆ›å»ºä¸Šä¸‹æ–‡çš„è®¾å¤‡å¥æŸ„</p></li><li><p>è¿”å› CUDA_SUCCESS è¡¨ç¤ºå‡½æ•°è°ƒç”¨æˆåŠŸï¼Œå¦åˆ™è¿”å›é”™è¯¯ç </p></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CUresult <span class="title">cuPushCurrent</span><span class="params">(CUcontext ctx)</span></span>;</span><br></pre></td></tr></table></figure><p>å°†å½“å‰çº¿ç¨‹çš„CUDAä¸Šä¸‹æ–‡å‹å…¥ä¸Šä¸‹æ–‡æ ˆä¸­ï¼Œå¹¶å°†ç»™å®šä¸Šä¸‹æ–‡è®¾ç½®ä¸ºå½“å‰ä¸Šä¸‹æ–‡</p><ul><li>ctxï¼šè¦è®¾ç½®ä¸ºå½“å‰ä¸Šä¸‹æ–‡çš„CUDAä¸Šä¸‹æ–‡å¥æŸ„</li><li>è¿”å› CUDA_SUCCESS è¡¨ç¤ºå‡½æ•°è°ƒç”¨æˆåŠŸï¼Œå¦åˆ™è¿”å›é”™è¯¯ç </li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CUresult <span class="title">cuPopCurrent</span><span class="params">(CUcontext *pctx)</span></span>;</span><br></pre></td></tr></table></figure><p>å°†å½“å‰çº¿ç¨‹çš„CUDAä¸Šä¸‹æ–‡ä»ä¸Šä¸‹æ–‡æ ˆä¸­å¼¹å‡ºï¼Œå¹¶å°†ä¸Šä¸‹æ–‡æ ˆé¡¶çš„ä¸Šä¸‹æ–‡è®¾ç½®ä¸ºå½“å‰ä¸Šä¸‹æ–‡</p><ul><li>pctxï¼šè¾“å‡ºå‚æ•°ï¼ŒæŒ‡å‘å¼¹å‡ºçš„CUDAä¸Šä¸‹æ–‡å¥æŸ„</li><li>è¿”å› CUDA_SUCCESS è¡¨ç¤ºå‡½æ•°è°ƒç”¨æˆåŠŸï¼Œå¦åˆ™è¿”å›é”™è¯¯ç </li></ul><p>å…¶ä¸­ï¼Œéšå¼è°ƒç”¨çš„contextæ˜¯ primary contextï¼Œç”± CUDA é©±åŠ¨ç¨‹åºè‡ªåŠ¨åˆ›å»ºå’Œç®¡ç†ï¼› æ˜¾ç¤ºè°ƒç”¨çš„ context æ˜¯standard contextï¼Œéœ€è¦æ‰‹åŠ¨ç®¡ç†å…¶ç”Ÿå‘½å‘¨æœŸå’ŒçŠ¶æ€ï¼Œå¹¶ä¸”å¯ä»¥åŒæ—¶å­˜åœ¨å¤šä¸ª standard contextã€‚æ¯æ¬¡ CUDA åˆå§‹åŒ–æ¯”è¾ƒè´¹æ—¶é—´ï¼Œå¯èƒ½æ˜¯ Runtime è¿›è¡Œäº†éšå¼è°ƒç”¨ contextï¼Œå¯ä»¥ä½¿ç”¨ <code>cudaError_t cudaSetDevice(int device)</code>  æå‰åˆ›å»º context èŠ‚çœè¿™éƒ¨åˆ†æ—¶é—´</p><p>ä½¿ç”¨ CUDA Driver API ç¼–å†™çš„ CUDA ç¨‹åºé€šå¸¸å…·æœ‰æ›´é«˜çš„æ€§èƒ½ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥æ›´å……åˆ†åœ°åˆ©ç”¨ GPU çš„ç¡¬ä»¶èµ„æºã€‚ä½†æ˜¯ï¼Œç”±äºè¿™ç§APIéœ€è¦æˆ‘ä»¬å¯¹ç¡¬ä»¶æœ‰æ›´æ·±å…¥çš„äº†è§£ï¼Œå¹¶ä¸”éœ€è¦ç¼–å†™æ›´å¤šçš„åº•å±‚ä»£ç ï¼Œæ‰€ä»¥è¿™ç§ç¼–ç¨‹æ–¹å¼ä¼šæ›´åŠ å›°éš¾å’Œå®¹æ˜“å‡ºé”™ï¼Œç›®å‰é˜¶æ®µæˆ‘ä»¬æš‚ä¸æ·±å…¥äº†è§£è¿™ä¸ªåº“ï¼Œä¸‹é¢åªç»™å‡ºç®€å•ç¤ºä¾‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This code is modified from https://blog.csdn.net/weicao1990/article/details/123959648</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span><span class="comment">// åŒ…å« cuda driver api</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span> </span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">define</span> checkDriver(op)  __check_cuda_driver((op), #op, __FILE__, __LINE__)</span></span><br><span class="line"> </span><br><span class="line"><span class="type">bool</span> __check_cuda_driver(CUresult code, <span class="type">const</span> <span class="type">char</span>* op, <span class="type">const</span> <span class="type">char</span>* file, <span class="type">int</span> line)&#123;</span><br><span class="line">    <span class="keyword">if</span>(code != CUresult::CUDA_SUCCESS)&#123;    <span class="comment">// å¦‚æœ æˆåŠŸè·å–CUDAæƒ…å†µä¸‹çš„è¿”å›å€¼ ä¸æˆ‘ä»¬ç»™å®šçš„å€¼(0)ä¸ç›¸ç­‰ï¼Œ å³æ¡ä»¶æˆç«‹ï¼Œ è¿”å›å€¼ä¸ºflase</span></span><br><span class="line">        <span class="type">const</span> <span class="type">char</span>* err_name = <span class="literal">nullptr</span>;    <span class="comment">// å®šä¹‰äº†ä¸€ä¸ªå­—ç¬¦ä¸²å¸¸é‡çš„ç©ºæŒ‡é’ˆ</span></span><br><span class="line">        <span class="type">const</span> <span class="type">char</span>* err_message = <span class="literal">nullptr</span>;  </span><br><span class="line">        <span class="built_in">cuGetErrorName</span>(code, &amp;err_name);    </span><br><span class="line">        <span class="built_in">cuGetErrorString</span>(code, &amp;err_message);   </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s:%d  %s failed. \n  code = %s, message = %s\n&quot;</span>, file, line, op, err_name, err_message); <span class="comment">//æ‰“å°é”™è¯¯ä¿¡æ¯</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// æ£€æŸ¥cuda driverçš„åˆå§‹åŒ–</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuInit</span>(<span class="number">0</span>));</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// ä¸ºè®¾å¤‡åˆ›å»ºä¸Šä¸‹æ–‡</span></span><br><span class="line">    CUcontext ctxA = <span class="literal">nullptr</span>;                                   <span class="comment">// CUcontext å…¶å®æ˜¯ struct CUctx_st*ï¼ˆæ˜¯ä¸€ä¸ªæŒ‡å‘ç»“æ„ä½“CUctx_stçš„æŒ‡é’ˆï¼‰</span></span><br><span class="line">    CUcontext ctxB = <span class="literal">nullptr</span>;</span><br><span class="line">    CUdevice device = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxCreate</span>(&amp;ctxA, CU_CTX_SCHED_AUTO, device)); <span class="comment">// è¿™ä¸€æ­¥ç›¸å½“äºå‘ŠçŸ¥è¦æŸä¸€å—è®¾å¤‡ä¸Šçš„æŸå—åœ°æ–¹åˆ›å»º ctxA ç®¡ç†æ•°æ®ã€‚è¾“å…¥å‚æ•° å‚è€ƒ https://www.cs.cmu.edu/afs/cs/academic/class/15668-s11/www/cuda-doc/html/group__CUDA__CTX_g65dc0012348bc84810e2103a40d8e2cf.html</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxCreate</span>(&amp;ctxB, CU_CTX_SCHED_AUTO, device)); </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ctxA = %p\n&quot;</span>, ctxA);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ctxB = %p\n&quot;</span>, ctxB);</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">        contexts æ ˆï¼š</span></span><br><span class="line"><span class="comment">            ctxB -- top &lt;--- current_context</span></span><br><span class="line"><span class="comment">            ctxA </span></span><br><span class="line"><span class="comment">            ...</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">// è·å–å½“å‰ä¸Šä¸‹æ–‡ä¿¡æ¯</span></span><br><span class="line">    CUcontext current_context = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxGetCurrent</span>(&amp;current_context));             <span class="comment">// è¿™ä¸ªæ—¶å€™current_context å°±æ˜¯ä¸Šé¢åˆ›å»ºçš„context</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;current_context = %p\n&quot;</span>, current_context);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// å¯ä»¥ä½¿ç”¨ä¸Šä¸‹æ–‡å †æ ˆå¯¹è®¾å¤‡ç®¡ç†å¤šä¸ªä¸Šä¸‹æ–‡</span></span><br><span class="line">    <span class="comment">// å‹å…¥å½“å‰context</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxPushCurrent</span>(ctxA));                        <span class="comment">// å°†è¿™ä¸ª ctxA å‹å…¥CPUè°ƒç”¨çš„threadä¸Šã€‚ä¸“é—¨ç”¨ä¸€ä¸ªthreadä»¥æ ˆçš„æ–¹å¼æ¥ç®¡ç†å¤šä¸ªcontextsçš„åˆ‡æ¢</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxGetCurrent</span>(&amp;current_context));             <span class="comment">// è·å–current_context (å³æ ˆé¡¶çš„context)</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;after pushing, current_context = %p\n&quot;</span>, current_context);</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">        contexts æ ˆï¼š</span></span><br><span class="line"><span class="comment">            ctxA -- top &lt;--- current_context</span></span><br><span class="line"><span class="comment">            ctxB</span></span><br><span class="line"><span class="comment">            ...</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// å¼¹å‡ºå½“å‰context</span></span><br><span class="line">    CUcontext popped_ctx = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxPopCurrent</span>(&amp;popped_ctx));                   <span class="comment">// å°†å½“å‰çš„context popæ‰ï¼Œå¹¶ç”¨popped_ctxæ‰¿æ¥å®ƒpopå‡ºæ¥çš„context</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxGetCurrent</span>(&amp;current_context));              <span class="comment">// è·å–current_context(æ ˆé¡¶çš„)</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;after poping, popped_ctx = %p\n&quot;</span>, popped_ctx);       <span class="comment">// å¼¹å‡ºçš„æ˜¯ctxA</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;after poping, current_context = %p\n&quot;</span>, current_context); <span class="comment">// current_contextæ˜¯ctxB</span></span><br><span class="line"> </span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxDestroy</span>(ctxA));</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxDestroy</span>(ctxB));</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// æ›´æ¨èä½¿ç”¨cuDevicePrimaryCtxRetainè·å–ä¸è®¾å¤‡å…³è”çš„context</span></span><br><span class="line">    <span class="comment">// æ³¨æ„è¿™ä¸ªé‡ç‚¹ï¼Œä»¥åçš„runtimeä¹Ÿæ˜¯åŸºäºæ­¤, è‡ªåŠ¨ä¸ºè®¾å¤‡åªå…³è”ä¸€ä¸ªcontext</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuDevicePrimaryCtxRetain</span>(&amp;ctxA, device));       <span class="comment">// åœ¨ device ä¸ŠæŒ‡å®šä¸€ä¸ªæ–°åœ°å€å¯¹ctxAè¿›è¡Œç®¡ç†</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ctxA = %p\n&quot;</span>, ctxA);</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuDevicePrimaryCtxRelease</span>(device));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* è¾“å‡º</span></span><br><span class="line"><span class="comment">ctxA = 0x560a174cce50</span></span><br><span class="line"><span class="comment">ctxB = 0x560a179c5810</span></span><br><span class="line"><span class="comment">current_context = 0x560a179c5810</span></span><br><span class="line"><span class="comment">after pushing, current_context = 0x560a174cce50</span></span><br><span class="line"><span class="comment">after poping, popped_ctx = 0x560a174cce50</span></span><br><span class="line"><span class="comment">after poping, current_context = 0x560a179c5810</span></span><br><span class="line"><span class="comment">ctxA = 0x560a174edbd0</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><p>ç¼–è¯‘</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc &#123;&#125;.cu -lcuda</span><br></pre></td></tr></table></figure><h2 id="MPS-å¤šè¿›ç¨‹æœåŠ¡"><a href="#MPS-å¤šè¿›ç¨‹æœåŠ¡" class="headerlink" title="MPS å¤šè¿›ç¨‹æœåŠ¡"></a>MPS å¤šè¿›ç¨‹æœåŠ¡</h2><p>CUDA MPSï¼ˆMulti-Process Serviceï¼‰æ˜¯ä¸€ç§å…è®¸å¤šä¸ªè¿›ç¨‹å…±äº«å•ä¸ª GPU çš„æŠ€æœ¯ã€‚å®ƒå…è®¸åœ¨åŒä¸€æ—¶é—´å¤šä¸ªè¿›ç¨‹ä½¿ç”¨ç›¸åŒçš„GPUï¼Œä»è€Œæé«˜GPUçš„åˆ©ç”¨ç‡ã€‚é€šè¿‡åœ¨ GPU ä¸Šåˆ›å»ºå¤šä¸ª CUDA ä¸Šä¸‹æ–‡æ¥å®ç°çš„ã€‚æ¯ä¸ªè¿›ç¨‹éƒ½å¯ä»¥åˆ›å»ºè‡ªå·±çš„ CUDA ä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”åœ¨è¿™äº›ä¸Šä¸‹æ–‡ä¹‹é—´å…±äº« GPU èµ„æºã€‚åœ¨ MPS æ¨¡å¼ä¸‹ï¼Œå¤šä¸ªè¿›ç¨‹å¯ä»¥å¹¶å‘åœ°ä½¿ç”¨ GPUï¼Œè€Œä¸ä¼šäº’ç›¸å¹²æ‰°</p><p>åœ¨ä½¿ç”¨MPSæ—¶ï¼Œéœ€è¦åœ¨æ¯ä¸ªè¿›ç¨‹ä¸­åˆ›å»ºä¸€ä¸ªCUDAä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”è¿™äº›ä¸Šä¸‹æ–‡éœ€è¦ä½¿ç”¨ç›¸åŒçš„ GPU è®¾å¤‡</p><p>å¼€å¯ MPS æœåŠ¡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-cuda-mps-control -d</span><br></pre></td></tr></table></figure><p>å…³é—­ MPS æœåŠ¡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-cuda-mps-control quit</span><br></pre></td></tr></table></figure><p>åœ¨ä½¿ç”¨ MPS æ—¶ï¼Œéœ€è¦é¿å…ä½¿ç”¨æ‰€æœ‰ GPU èµ„æºï¼Œå› ä¸ºMPSéœ€è¦ä¸€äº› GPU èµ„æºæ¥ç®¡ç†å¤šä¸ªCUDAä¸Šä¸‹æ–‡ã€‚å¯ä»¥ä½¿ç”¨ nvidia-smi å·¥å…·æ¥æ£€æŸ¥ MPS æ‰€ä½¿ç”¨çš„ GPU èµ„æº</p>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDAæµ,äº‹ä»¶ä¸åŒæ­¥</title>
      <link href="/p/5a01a3bf/"/>
      <url>/p/5a01a3bf/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è¯¦ç»†è®²è§£ CUDA æµï¼Œäº‹ä»¶çš„æ¦‚å¿µä»¥åŠå£°æ˜ï¼Œä»¥æ­¤ä¸ºåŸºç¡€ï¼Œæ·±å…¥äº†è§£ CUDA æµæ“ä½œä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œæµçš„åŒæ­¥ä¸å¼‚æ­¥ï¼Œä»¥åŠå¦‚ä½•ä¼˜åŒ–äº‹ä»¶çš„åˆ›å»ºä¸ç®¡ç†ç­‰ç­‰ã€‚</p><span id="more"></span><h2 id="CUDA-æµ"><a href="#CUDA-æµ" class="headerlink" title="CUDA æµ"></a>CUDA æµ</h2><h3 id="æ¦‚å¿µ"><a href="#æ¦‚å¿µ" class="headerlink" title="æ¦‚å¿µ"></a>æ¦‚å¿µ</h3><p>CUDA æµæ˜¯ä¸€ç³»åˆ—å¼‚æ­¥çš„ CUDA æ“ä½œï¼Œè¿™äº›æ“ä½œæŒ‰ç…§ä¸»æœºä»£ç æ‰€å®šä¹‰çš„é¡ºåºåœ¨è®¾å¤‡ä¸Šæ‰§è¡Œã€‚æµä¼šå°è£…è¿™äº›æ“ä½œï¼Œä¿æŒæ“ä½œçš„é¡ºåºï¼Œå…è®¸æ“ä½œåœ¨æµä¸­æ’é˜Ÿï¼Œå¹¶ä½¿å®ƒä»¬åœ¨å…ˆå‰çš„æ‰€æœ‰æ“ä½œä¹‹åæ‰§è¡Œã€‚CUDA æµä¸­çš„æ“ä½œå¯ä»¥æ˜¯ä¸»æœºä¸è®¾å¤‡çš„å†…å­˜æ•°æ®ä¼ è¾“ï¼Œè®¾å¤‡å†…æ ¸å¯åŠ¨ï¼Œä¸»æœºå’Œè®¾å¤‡ä¹‹é—´çš„åŒæ­¥ç­‰ç”±ä¸»æœºå‘èµ·ä½†ç”±è®¾å¤‡å¤„ç†çš„å‘½ä»¤</p><p>åœ¨ CUDA ç¼–ç¨‹ä¸­ï¼Œä¸€èˆ¬çš„æ‰§è¡Œæ¨¡å¼å¦‚ä¸‹</p><ul><li>å°†æ•°æ®ä»ä¸»æœºä¼ è¾“åˆ°è®¾å¤‡</li><li>åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œå†…æ ¸</li><li>å°†ç»“æœä»è®¾å¤‡ä¼ è¾“å›ä¸»æœº</li></ul><p>å› ä¸ºä¸åŒçš„ CUDA æµä¸­çš„æ“ä½œæ˜¯å¼‚æ­¥æ‰§è¡Œçš„ï¼Œè¿™ä½¿å¾—å®ƒä»¬å¯ä»¥å¹¶è¡Œè¿è¡Œï¼Œä¸ä¼šå—åˆ°å…¶å®ƒæµä¸­æ“ä½œçš„å½±å“ï¼Œæ‰€ä»¥å¯ä»¥å°†å†…æ ¸æ‰§è¡Œå’Œæ•°æ®ä¼ è¾“è°ƒåº¦åˆ°ä¸åŒçš„æµä¸­ï¼Œå®Œå…¨éšè—CPUå’ŒGPUä¹‹é—´çš„é€šä¿¡å»¶è¿Ÿï¼Œæé«˜ç¨‹åºçš„æ•ˆç‡</p><p>æµåœ¨ CUDA çš„ API è°ƒç”¨ç²’åº¦ä¸Šå¯å®ç°æµæ°´çº¿æˆ–åŒç¼“å†²æŠ€æœ¯ã€‚CUDA çš„ APIå‡½æ•°ä¸€èˆ¬å¯ä»¥åˆ†ä¸ºåŒæ­¥æˆ–å¼‚æ­¥ã€‚å…·æœ‰åŒæ­¥è¡Œä¸ºçš„å‡½æ•°ä¼šé˜»å¡ä¸»æœºç«¯çº¿ç¨‹ï¼Œç›´åˆ°å®ƒä»¬å®Œæˆã€‚å…·æœ‰å¼‚æ­¥è¡Œä¸ºçš„å‡½æ•°è¢«è°ƒç”¨åï¼Œä¼šç«‹å³å°†æ§åˆ¶æƒå½’è¿˜ç»™ä¸»æœº</p><p>å¼‚æ­¥å‡½æ•°å’Œæµæ˜¯åœ¨ CUDA ä¸­æ„å»ºç½‘æ ¼çº§å¹¶å‘çš„åŸºç¡€ã€‚ä»è½¯ä»¶ä¸Šçœ‹ï¼ŒCUDA æ“ä½œåœ¨ä¸åŒçš„æµä¸­å¹¶å‘è¿è¡Œï¼Œä½†ä»ç¡¬ä»¶ä¸Šçœ‹ï¼Œä¸æ€»æ˜¯å¦‚æ­¤ã€‚æ ¹æ® PCIe æ€»çº¿äº‰ç”¨æˆ–æ¯ä¸ªSMèµ„æºçš„å¯ç”¨æ€§ï¼Œå®Œæˆä¸åŒçš„ CUDA æµå¯èƒ½ä»ç„¶éœ€è¦äº’ç›¸ç­‰å¾…ã€‚ä¸‹é¢å°†è¯¦ç»†äº†è§£åœ¨æœ‰å¤šç§è®¡ç®—èƒ½åŠ›çš„è®¾å¤‡ä¸Šï¼Œæµæ˜¯å¦‚ä½•è¿è¡Œçš„</p><h3 id="å£°æ˜"><a href="#å£°æ˜" class="headerlink" title="å£°æ˜"></a>å£°æ˜</h3><p>æ‰€æœ‰çš„ CUDA æ“ä½œéƒ½æ˜¯åœ¨æµä¸­è¿›è¡Œçš„ï¼Œæµåˆ†ä¸º</p><ul><li>éšå¼å£°æ˜ï¼ˆç©ºæµï¼‰</li><li>æ˜¾å¼å£°æ˜ï¼ˆéç©ºæµï¼‰</li></ul><p>å¦‚æœæ²¡æœ‰æ˜¾å¼åœ°æŒ‡å®šä¸€ä¸ªæµï¼Œé‚£ä¹ˆå†…æ ¸å¯åŠ¨å’Œæ•°æ®ä¼ è¾“å°†é»˜è®¤ä½¿ç”¨ç©ºæµã€‚åœ¨æœ¬ç« ä¹‹å‰æ‰€æœ‰ä¾‹å­éƒ½æ˜¯ç©ºæµ</p><p>åŸºäºæµçš„å¼‚æ­¥å†…æ ¸å¯åŠ¨å’Œæ•°æ®ä¼ è¾“æ”¯æŒä»¥ä¸‹ç±»å‹çš„ç²—ç²’åº¦å¹¶å‘</p><ul><li>ä¸»æœºè®¡ç®— - è®¾å¤‡è®¡ç®—</li><li>ä¸»æœºè®¡ç®— - ä¸»æœºä¸è®¾å¤‡é—´çš„æ•°æ®ä¼ è¾“</li><li>è®¾å¤‡è®¡ç®— - ä¸»æœºä¸è®¾å¤‡é—´çš„æ•°æ®ä¼ è¾“</li><li>å¹¶å‘æ‰§è¡Œå¤šä¸ªè®¾å¤‡çš„è®¡ç®—</li></ul><p>æˆ‘ä»¬é¦–å…ˆè¦æœ‰ä¸€ä¸ªæ¦‚å¿µï¼Œè®¾å¤‡ä¸ä¸»æœºæ˜¯ä¸¤ä¸ªè¿ç®—èŠ‚ç‚¹ï¼Œä»¥ä¸€èˆ¬çš„ CUDA ç¨‹åºä¸¾ä¾‹ï¼Œä¸‹é¢çš„ 3 ä¸ªæ“ä½œä¼šè¢«å‘å¸ƒåˆ°é»˜è®¤çš„æµä¸­ï¼Œè®¾å¤‡åªéœ€è¦æŒ‰å‘å¸ƒé¡ºåºæ‰§è¡Œï¼Œè€Œå…¶ä»–ä¸»æœºä¸Šçš„æ“ä½œè®¾å¤‡ä¸€æ¦‚ä¸çŸ¥</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="built_in">cudaMemcpy</span>(..., cudaMemcpyHostToDevice);</span><br><span class="line">kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(...);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(..., cudaMemcpyDeviceToHost);</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><p>ä½†æ˜¯ä¸»æœºè¦ç­‰å¾…è®¾å¤‡è¿ç®—ï¼Œæ•°æ®å‘ä¸»æœºä¼ è¾“å®Œæˆåæ‰èƒ½æ‰§è¡Œåé¢çš„æ“ä½œï¼Œä¹Ÿå°±æ˜¯ä¹‹å‰æˆ‘ä»¬æ¥è§¦åˆ°çš„æ•°æ®ä¼ è¾“éƒ½æ˜¯åŒæ­¥çš„ã€‚ä¸åŒçš„æ˜¯ï¼Œå†…æ ¸å¯åŠ¨æ˜¯å¼‚æ­¥çš„ï¼Œæ— è®ºå†…æ ¸æ˜¯å¦å®Œæˆï¼Œä¸»æœºçš„åº”ç”¨ç¨‹åºéƒ½ç«‹å³æ¢å¤æ‰§è¡Œã€‚</p><p>ç°åœ¨ä»‹ç»ä¸€ä¸‹å¼‚æ­¥çš„æ•°æ®ä¼ è¾“ï¼Œä¸‹é¢æ˜¯ <code>cudaMemcpy</code> å‡½æ•°çš„å¼‚æ­¥ç‰ˆæœ¬</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaMemcpyAsync</span> <span class="params">( <span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span>* src, <span class="type">size_t</span> count, cudaMemcpyKind kind, cudaStream_t stream = <span class="number">0</span> )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>dst</code>ï¼šç›®æ ‡åœ°å€ï¼ŒæŒ‡å‘è¦å¤åˆ¶æ•°æ®çš„ä½ç½®</li><li><code>src</code>ï¼šæºåœ°å€ï¼ŒæŒ‡å‘è¦å¤åˆ¶çš„æ•°æ®çš„ä½ç½®</li><li><code>count</code>ï¼šè¦å¤åˆ¶çš„å­—èŠ‚æ•°ã€‚</li><li><code>kind</code>ï¼šæŒ‡å®šå¤åˆ¶çš„æ–¹å‘ï¼Œå¯é€‰å€¼ä¸º<code>cudaMemcpyHostToDevice</code>ã€<code>cudaMemcpyDeviceToHost</code>ã€<code>cudaMemcpyDeviceToDevice</code>å’Œ<code>cudaMemcpyDefault</code></li><li><code>stream</code>ï¼šå¯é€‰å‚æ•°ï¼ŒæŒ‡å®šå°†å¼‚æ­¥æ“ä½œæ·»åŠ åˆ°çš„æµ</li></ul><p>å…¶ä¸­<code>stream</code>é»˜è®¤è¢«è®¾ç½®ä¸ºç©ºæµã€‚è¿™ä¸ªå‡½æ•°ä¸ä¸»æœºæ˜¯å¼‚æ­¥çš„ï¼Œåœ¨è°ƒç”¨å‘å¸ƒåï¼Œæ§åˆ¶æƒå°†ç«‹å³è¿”å›åˆ°ä¸»æœºã€‚</p><p>å¦‚æœæˆ‘ä»¬å¸Œæœ›æ•°æ®ä¼ è¾“ä¸éç©ºæµå…³è”ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°æ˜¾å¼åˆ›å»ºä¸€ä¸ªéç©ºæµ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaStreamCreate</span> <span class="params">( cudaStream_t* pStream )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>pStream</code>ï¼šæŒ‡å‘æ–°æµæ ‡è¯†ç¬¦çš„æŒ‡é’ˆ</li></ul><p>è¿”å›åˆ°<code>pStream</code>ä¸­çš„æµå°±å¯ä»¥è¢«å½“ä½œå‚æ•°ç»™å…¶å®ƒå¼‚æ­¥ CUDA çš„ API å‡½æ•°ä½¿ç”¨ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå½“æ‰§è¡Œå¼‚æ­¥æ•°æ®ä¼ è¾“æ—¶ï¼Œå¿…é¡»ä½¿ç”¨å›ºå®šçš„ä¸»æœºå†…å­˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‰é¢ç« èŠ‚æåˆ°çš„ä¸¤ä¸ªå‡½æ•°åˆ†é…å›ºå®šå†…å­˜</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMallocHost</span><span class="params">(<span class="type">void</span> **ptr, <span class="type">size_t</span> size)</span></span>;</span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaHostAlloc</span><span class="params">(<span class="type">void</span> **pHost, <span class="type">size_t</span> size, <span class="type">unsigned</span> <span class="type">int</span> flags)</span></span>;</span><br></pre></td></tr></table></figure><p>åœ¨éç©ºæµä¸­å¯åŠ¨å†…æ ¸ï¼Œéœ€è¦æ³¨æ„æä¾›æµæ ‡è¯†ç¬¦ä½œä¸ºç¬¬å››ä¸ªå‚æ•°</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_name&lt;&lt;&lt;grid, block, sharedMemSize, stream&gt;&gt;&gt;(argument list);</span><br></pre></td></tr></table></figure><p>ä¸€ä¸ªéç©ºæµå£°æ˜ä¸åˆ›å»ºå¦‚ä¸‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cudaStream_t stream;</span><br><span class="line"><span class="built_in">cudaStreamCreate</span>(&amp;stream);</span><br></pre></td></tr></table></figure><p>å¯ä»¥ç”¨å¦‚ä¸‹ä»£ç é‡Šæ”¾æµä¸­çš„èµ„æº</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamDestroy</span><span class="params">(cudaStream_t stream)</span></span>;</span><br></pre></td></tr></table></figure><p>åœ¨ä¸€ä¸ªæµä¸­ï¼Œå½“ <code>cudaStreamDestroy</code> å‡½æ•°è¢«è°ƒç”¨æ—¶ï¼Œå¦‚æœè¯¥æµä¸­ä»æœ‰æœªå®Œæˆçš„å·¥ä½œï¼Œ<code>cudaStreamDestroy</code> å‡½æ•°å°†ç«‹å³è¿”å›ï¼Œå½“æµä¸­æ‰€æœ‰å·¥ä½œéƒ½å·²å®Œæˆæ—¶ï¼Œä¸æµç›¸å…³çš„èµ„æºå°†è¢«è‡ªåŠ¨é‡Šæ”¾</p><p>å› ä¸ºæ‰€æœ‰æµéƒ½æ˜¯å¼‚æ­¥çš„ï¼Œæœ‰ä¸¤ä¸ªä¸“ç”¨çš„å‡½æ•°æ¥æ£€æŸ¥æµä¸­çš„æ‰€æœ‰æ“ä½œæ˜¯å¦éƒ½å·²ç»å®Œæˆ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamSynchronize</span><span class="params">(cudaStream_t stream)</span></span>;</span><br></pre></td></tr></table></figure><p><code>cudaStreamSynchronize</code>å‡½æ•°ç”¨äºå¼ºåˆ¶é˜»å¡ä¸»æœºï¼Œç›´åˆ°ç»™å®šæµä¸­çš„æ‰€æœ‰æ“ä½œéƒ½å®Œæˆ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamQuery</span><span class="params">(cudaStream_t stream)</span></span>;</span><br></pre></td></tr></table></figure><p><code>cudaStreamQuery</code>å‡½æ•°ç”¨äºæ£€æŸ¥æµä¸­çš„æ‰€æœ‰æ“ä½œæ˜¯å¦éƒ½å·²ç»å®Œæˆï¼Œä½†ä¸ä¼šé˜»å¡ä¸»æœºã€‚å½“æ‰€æœ‰æ“ä½œéƒ½å®Œæˆæ—¶å‡½æ•°ä¼šè¿”å›<code>cudaSuccess</code>ã€‚å¦åˆ™è¿”å›<code>cudaErrorNotReady</code></p><p>ä¸‹é¢è¿™æ®µä»£ç æ˜¯ä½¿ç”¨æµçš„ä¸€ä¸ªä¾‹å­ï¼Œåœ¨å¤šä¸ªæµä¸­æ‰§è¡Œ CUDA æ ¸å‡½æ•°å’Œæ•°æ®ä¼ è¾“æ“ä½œ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nStreams; i++) &#123;</span><br><span class="line">    <span class="type">int</span> offset = i * bytesPerStream;</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(&amp;d_a[offset], &amp;a[offset], bytePerStream, streams[i]);</span><br><span class="line">    kernel&lt;&lt;grid, block, <span class="number">0</span>, streams[i]&gt;&gt;(&amp;d_a[offset]);</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(&amp;a[offset], &amp;d_a[offset], bytesPerStream, streams[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nStreams; i++) &#123;</span><br><span class="line">    <span class="built_in">cudaStreamSynchronize</span>(streams[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æµåœ¨ CUDA ä¸­æ‰§è¡Œçš„æ—¶é—´è½´å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒH2D æ˜¯ä¸»æœºåˆ°è®¾å¤‡çš„å†…å­˜ä¼ è¾“ï¼ŒD2H æ˜¯è®¾å¤‡åˆ°ä¸»æœºçš„å†…å­˜ä¼ è¾“ã€‚æ•°æ®ä¼ è¾“å’Œå†…æ ¸æ‰§è¡Œåˆ†å¸ƒåœ¨ 3 ä¸ªå¹¶å‘æµä¸­ï¼Œä½†æ˜¯åœ¨æ‰§è¡Œæ—¶ï¼Œæ•°æ®ä¼ è¾“å¹¶æ²¡æœ‰å¹¶å‘æ‰§è¡Œï¼Œè¿™æ˜¯å› ä¸º PCIe æ€»çº¿æ˜¯å…±äº«çš„ï¼Œå½“ç¬¬ä¸€ä¸ªæµå æ®äº†æ€»çº¿ï¼Œåé¢çš„æµå°±è¦ç­‰å¾…æ€»çº¿ç©ºé—²ï¼Œä½†æ˜¯å¦‚æœ H2D å’Œ D2H åŒæ—¶å‘ç”Ÿï¼Œå°±ä¸ä¼šäº§ç”Ÿç­‰å¾…ï¼Œè€Œæ˜¯åŒæ—¶è¿›è¡Œ</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-äº‹ä»¶ä¸åŒæ­¥/1.webp" alt=""></p><h2 id="æµè°ƒåº¦"><a href="#æµè°ƒåº¦" class="headerlink" title="æµè°ƒåº¦"></a>æµè°ƒåº¦</h2><p>å‰é¢æˆ‘ä»¬è¯´åˆ°ï¼Œæ‰€æœ‰æµéƒ½å¯ä»¥åŒæ—¶è¿è¡Œï¼Œä½†åœ¨ç¡¬ä»¶ä¸­æ²¡æœ‰æµçš„æ¦‚å¿µï¼Œè€Œæ˜¯åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªæ‰§è¡Œå†…å­˜æ‹·è´æ“ä½œçš„å¼•æ“å’Œæ‰§è¡Œæ ¸å‡½æ•°çš„å¼•æ“ã€‚è¿™äº›å¼•æ“å½¼æ­¤ç‹¬ç«‹åœ°å¯¹æ“ä½œè¿›è¡Œæ’é˜Ÿï¼Œè¿™å°†å¯¼è‡´å¦‚ä¸‹å›¾æ‰€ç¤ºçš„ä»»åŠ¡è°ƒåº¦æƒ…å½¢</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-äº‹ä»¶ä¸åŒæ­¥/5.webp" alt=""></p><p>åœ¨ä¸åŒæµçš„æ“ä½œä¸­ï¼Œå­˜åœ¨ç›¸äº’çš„ä¾èµ–ï¼Œæ¯”å¦‚ memcpy A B C ä¸ºä»ä¸»æœºæ‹·è´æ•°æ®åˆ°è®¾å¤‡å†…å­˜ï¼Œkernel éœ€è¦ç­‰å¾… memcpy A B C æ“ä½œå®Œæˆåå†æ‰§è¡Œï¼ŒStream 1 éœ€è¦ç­‰å¾… Stream 0 å®Œæˆæ“ä½œåå†æ‰§è¡Œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-äº‹ä»¶ä¸åŒæ­¥/6.webp" alt=""></p><p>ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥äº¤é”™åœ°æ‰§è¡Œä¸åŒæµçš„æ‹·è´å†…å­˜æ“ä½œå’Œæ ¸å‡½æ•°è¿ç®—æ“ä½œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-äº‹ä»¶ä¸åŒæ­¥/7.webp" alt=""></p><p>ä¸ºäº†è§£å†³å¤šä¸ª Kernel å‡½æ•°åŒæ—¶åœ¨ GPU ä¸­è¿è¡Œçš„é—®é¢˜ï¼ŒèŠ‚çœä»£ç ç¼–å†™æˆæœ¬ï¼Œä» Kepler æ¶æ„å¼€å§‹ï¼ŒNvidia æ¨å‡ºäº† Hyper-Q ç¡¬ä»¶æŠ€æœ¯ï¼Œä¸»æœºä¸è®¾å¤‡ä¹‹é—´æœ€å¤šå¯ä»¥å»ºç«‹ 32 ä¸ªå·¥ä½œé˜Ÿåˆ—ï¼Œæ¯ä¸ªæµåˆ†é…ä¸€ä¸ªå·¥ä½œé˜Ÿåˆ—ï¼Œå¦‚æœåˆ›å»ºçš„æµè¶…è¿‡32ä¸ªï¼Œåˆ™å¤šä¸ªæµå…±ç”¨ä¸€ä¸ªå·¥ä½œé˜Ÿåˆ—</p><p>åŒæ—¶ Hyper-Q æŠ€æœ¯è¿˜å¯ä»¥ä½¿ä¸åŒæµä¸­çš„è®¡ç®—å’Œä½¿ç”¨å¸¦å®½èƒ½å¤Ÿé‡å ï¼Œæœ€å¤§åŒ– GPU çš„èµ„æºåˆ©ç”¨ç‡ã€‚ä¾‹å¦‚ Stream1 ä¸­çš„è®¡ç®—è¦å ç”¨ 60% çš„æ ¸å¿ƒå’Œ 60% çš„æ˜¾å­˜å¸¦å®½ï¼Œè€Œ Stream2 ä¸­çš„è®¡ç®—è¦å ç”¨ 70% çš„æ ¸å¿ƒå’Œ 50% çš„æ˜¾å­˜å¸¦å®½ï¼ŒäºŒè€…åŒæ—¶è¿è¡Œæ—¶ä¼šæŒ‰ä¸€å®šçš„æ¯”ç‡äº‰ç”¨ GPU èµ„æº</p><h2 id="æµä¼˜å…ˆçº§"><a href="#æµä¼˜å…ˆçº§" class="headerlink" title="æµä¼˜å…ˆçº§"></a>æµä¼˜å…ˆçº§</h2><p>å¯¹äºè®¡ç®—èƒ½åŠ›åœ¨ 3.5 ä»¥ä¸Šçš„è®¾å¤‡å¯ä»¥åˆ†é…æµçš„ä¼˜å…ˆçº§ï¼Œä¸‹é¢å‡½æ•°åˆ›å»ºä¸€ä¸ªæœ‰æŒ‡å®šä¼˜å…ˆçº§çš„æµ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaStreamCreateWithPriority</span> <span class="params">( cudaStream_t* pStream, <span class="type">unsigned</span> <span class="type">int</span>  flags, <span class="type">int</span>  priority )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>pStream</code>ï¼šä¸€ä¸ªæŒ‡å‘ <code>cudaStream_t</code> ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨äºå­˜å‚¨åˆ›å»ºçš„æµçš„å¥æŸ„</li><li><code>flags</code>ï¼šæµçš„è¡Œä¸ºæ ‡å¿—ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º0ã€‚å½“å‰æ”¯æŒçš„æ ‡å¿—åªæœ‰ <code>cudaStreamNonBlocking</code>ï¼ŒæŒ‡å®šåœ¨åˆ›å»ºçš„æµä¸­è¿è¡Œçš„å·¥ä½œå¯ä»¥ä¸ Stream0ï¼ˆç©ºæµï¼‰ä¸­çš„å·¥ä½œåŒæ—¶è¿è¡Œï¼Œå¹¶ä¸”åˆ›å»ºçš„æµä¸åº”è¯¥ä¸ Stream0 æ‰§è¡Œéšå¼åŒæ­¥</li><li><code>priority</code>ï¼šæµçš„ä¼˜å…ˆçº§ï¼Œè¾ƒä½çš„æ•°å­—ä»£è¡¨è¾ƒé«˜çš„ä¼˜å…ˆçº§ã€‚0 è¡¨ç¤ºé»˜è®¤ä¼˜å…ˆçº§ã€‚ å¯ä»¥ä½¿ç”¨ <code>cudaDeviceGetStreamPriorityRange</code> æŸ¥è¯¢æœ‰æ„ä¹‰çš„æ•°å€¼ä¼˜å…ˆçº§èŒƒå›´ã€‚ å¦‚æœæŒ‡å®šçš„ä¼˜å…ˆçº§è¶…å‡ºäº† <code>cudaDeviceGetStreamPriorityRange</code> è¿”å›çš„æ•°å€¼èŒƒå›´ï¼Œå®ƒå°†è‡ªåŠ¨è¢«é™åˆ¶åœ¨èŒƒå›´å†…çš„æœ€ä½æˆ–æœ€é«˜æ•°å­—</li></ul><p>ä¸åŒçš„è®¾å¤‡æœ‰ä¸åŒçš„ä¼˜å…ˆçº§ç­‰çº§ï¼Œä¸‹é¢å‡½æ•°å¯ä»¥æŸ¥è¯¢å½“å‰è®¾å¤‡çš„ä¼˜å…ˆçº§åˆ†å¸ƒæƒ…å†µ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaDeviceGetStreamPriorityRange</span> <span class="params">( <span class="type">int</span>* leastPriority, <span class="type">int</span>* greatestPriority )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>leastPriority</code>ï¼šæŒ‡å‘æ•´æ•°çš„æŒ‡é’ˆï¼Œè¿”å›è®¾å¤‡æ”¯æŒçš„æœ€ä½ä¼˜å…ˆçº§</li><li><code>greatestPriority</code>ï¼šæŒ‡å‘æ•´æ•°çš„æŒ‡é’ˆï¼Œè¿”å›è®¾å¤‡æ”¯æŒçš„æœ€é«˜ä¼˜å…ˆçº§</li></ul><p>ç¬”ä¸»çš„æ˜¾å¡ä¼˜å…ˆçº§ç­‰çº§èŒƒå›´ä¸º [0, -5]</p><h2 id="CUDA-äº‹ä»¶"><a href="#CUDA-äº‹ä»¶" class="headerlink" title="CUDA äº‹ä»¶"></a>CUDA äº‹ä»¶</h2><h3 id="æ¦‚å¿µ-1"><a href="#æ¦‚å¿µ-1" class="headerlink" title="æ¦‚å¿µ"></a>æ¦‚å¿µ</h3><p>CUDA äº‹ä»¶æ˜¯ CUDA æµä¸­çš„ä¸€ä¸ªæ ‡è®°ç‚¹ï¼Œæ£€æŸ¥æ­£åœ¨æ‰§è¡Œçš„æµæ“ä½œæ˜¯å¦å·²ç»åˆ°è¾¾äº†è¯¥ç‚¹ã€‚ä½¿ç”¨äº‹ä»¶å¯ä»¥ç”¨æ¥æ‰§è¡Œä»¥ä¸‹ä¸¤ä¸ªåŸºæœ¬ä»»åŠ¡</p><ul><li>åŒæ­¥æµçš„æ‰§è¡Œ</li><li>ç›‘æ§è®¾å¤‡çš„è¿›å±•</li></ul><p>CUDA API æä¾›äº†åœ¨æµä¸­ä»»æ„ç‚¹æ’å…¥äº‹ä»¶ä»¥åŠæŸ¥è¯¢äº‹ä»¶å®Œæˆçš„å‡½æ•°ã€‚åªæœ‰å½“ä¸€ä¸ª CUDA æµä¸­ï¼Œäº‹ä»¶æ ‡æ³¨ç‚¹ä¹‹å‰çš„æ‰€æœ‰æ“ä½œéƒ½æ‰§è¡Œå®Œæˆåï¼Œè¯¥äº‹ä»¶æ‰ä¼šå®Œæˆï¼Œåœ¨é»˜è®¤æµä¸­çš„æŒ‡å®šäº‹ä»¶ï¼Œé€‚ç”¨äº CUDA æµä¸­å…ˆå‰çš„æ‰€æœ‰æ“ä½œ</p><h3 id="å£°æ˜-1"><a href="#å£°æ˜-1" class="headerlink" title="å£°æ˜"></a>å£°æ˜</h3><p>ä¸€ä¸ª CUDA äº‹ä»¶å£°æ˜å¦‚ä¸‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t event;</span><br></pre></td></tr></table></figure><p>åˆ›å»ºäº‹ä»¶</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventCreate</span> <span class="params">( cudaEvent_t* event )</span></span></span><br></pre></td></tr></table></figure><p>é”€æ¯äº‹ä»¶</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaEventDestroy</span> <span class="params">( cudaEvent_t event )</span></span></span><br></pre></td></tr></table></figure><p>å¦‚æœå›æ”¶æŒ‡ä»¤æ‰§è¡Œçš„æ—¶å€™äº‹ä»¶è¿˜æ²¡æœ‰å®Œæˆï¼Œé‚£ä¹ˆå›æ”¶æŒ‡ä»¤ç«‹å³å®Œæˆï¼Œå½“äº‹ä»¶å®Œæˆåï¼Œèµ„æºè¢«å›æ”¶</p><p>äº‹ä»¶ä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯æµçš„ä¸€æ¬¡æ“ä½œï¼Œé€šè¿‡ä¸‹é¢å‡½æ•°æ’é˜Ÿæ·»åŠ åˆ° CUDA æµ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaEventRecord</span> <span class="params">( cudaEvent_t event, cudaStream_t stream = <span class="number">0</span> )</span></span></span><br></pre></td></tr></table></figure><p>åœ¨æµä¸­çš„äº‹ä»¶ç”¨äºç­‰å¾…å‰é¢çš„æ“ä½œå®Œæˆï¼Œæˆ–æµ‹è¯•æµä¸­æ“ä½œçš„å®Œæˆæƒ…å†µï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°é˜»å¡ä¸»æœºçº¿ç¨‹ç›´åˆ°äº‹ä»¶è¢«å®Œæˆï¼Œç±»ä¼¼äº<code>cudaStreamSynchronize</code>å‡½æ•°</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventSynchronize</span> <span class="params">( cudaEvent_t event )</span></span></span><br></pre></td></tr></table></figure><p><code>cudaEventQuery</code>å‡½æ•°ç”¨äºæ£€æŸ¥äº‹ä»¶ä¹‹å‰çš„æ‰€æœ‰æ“ä½œæ˜¯å¦éƒ½å·²ç»å®Œæˆï¼Œä½†ä¸ä¼šé˜»å¡ä¸»æœºã€‚å½“æ‰€æœ‰æ“ä½œéƒ½å®Œæˆæ—¶å‡½æ•°ä¼šè¿”å›<code>cudaSuccess</code>ã€‚å¦åˆ™è¿”å›<code>cudaErrorNotReady</code>ã€‚ç±»ä¼¼äº<code>cudaStreamQuery</code></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventQuery</span> <span class="params">( cudaEvent_t event )</span></span></span><br></pre></td></tr></table></figure><h3 id="è®°å½•äº‹ä»¶å’Œè®¡ç®—è¿è¡Œæ—¶é—´"><a href="#è®°å½•äº‹ä»¶å’Œè®¡ç®—è¿è¡Œæ—¶é—´" class="headerlink" title="è®°å½•äº‹ä»¶å’Œè®¡ç®—è¿è¡Œæ—¶é—´"></a>è®°å½•äº‹ä»¶å’Œè®¡ç®—è¿è¡Œæ—¶é—´</h3><p>ä¸‹é¢å‡½æ•°è®°å½•ä¸¤ä¸ªäº‹ä»¶ start å’Œ stop ä¹‹é—´çš„æ—¶é—´é—´éš”ï¼Œæ¯«ç§’å•ä½ã€‚æ­¤å¤–ï¼Œè¿™ä¸¤ä¸ªäº‹ä»¶å¯ä»¥åœ¨ä¸åŒæµä¸­</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventElapsedTime</span> <span class="params">( <span class="type">float</span>* ms, cudaEvent_t start, cudaEvent_t end )</span></span></span><br></pre></td></tr></table></figure><p>ä¸‹é¢æ˜¯ä¸€æ®µè®°å½•äº‹ä»¶æ—¶é—´é—´éš”çš„ç¤ºä¾‹ä»£ç ï¼Œä¸¤ä¸ªäº‹ä»¶è¢«æ’å…¥åˆ°ç©ºæµä¸­ï¼Œä½œä¸ºæ ‡è®°ï¼Œç„¶åè®°å½•ä»–ä»¬ä¹‹é—´çš„æ—¶é—´é—´éš”ã€‚ä½†æ˜¯è¿™é‡Œæ—¶é—´é—´éš”å¯èƒ½ä¼šæ¯”å®é™…å¤§ä¸€äº›ï¼Œå› ä¸ºè¿™é‡Œç”¨åˆ° <code>cudaEventRecord</code> å‡½æ•°æ˜¯å¼‚æ­¥çš„ï¼Œè®¡ç®—ä¼šæœ‰å»¶æ—¶</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create two events</span></span><br><span class="line">cudaEvent_t start, stop;</span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// record start event on the default stream</span></span><br><span class="line"><span class="built_in">cudaEventRecord</span>(start);</span><br><span class="line"></span><br><span class="line"><span class="comment">// execute kernel</span></span><br><span class="line">kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(arguments);</span><br><span class="line"></span><br><span class="line"><span class="comment">// record stop event on the default stream</span></span><br><span class="line"><span class="built_in">cudaEventRecord</span>(stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// wait until the stop event completes</span></span><br><span class="line"><span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// calculate the elapsed time between two events</span></span><br><span class="line"><span class="type">float</span> time;</span><br><span class="line"><span class="built_in">cudaEventElapsedTime</span>(&amp;time, start, stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// clean up the two events</span></span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(stop);</span><br></pre></td></tr></table></figure><h2 id="æµåŒæ­¥"><a href="#æµåŒæ­¥" class="headerlink" title="æµåŒæ­¥"></a>æµåŒæ­¥</h2><p>åœ¨éç©ºæµä¸­ï¼Œæ‰€æœ‰æ“ä½œå¯¹äºä¸»æœºæ¥è¯´éƒ½æ˜¯å¹¶è¡Œçš„ï¼Œå¦‚æœæˆ‘ä»¬æƒ³åœ¨æŸä¸€åˆ»ç­‰å¾…ï¼Œæ‰§è¡Œå½“å‰æ—¶åˆ»æ‰€æœ‰æ“ä½œåŒæ­¥ï¼Œå°±ä¼šå¯¼è‡´ç­‰å¾…æ—¶èµ„æºçš„é—²ç½®ï¼Œæµªè´¹æ€§èƒ½</p><p>ä»ä¸»æœºçš„è§’åº¦ï¼ŒCUDA æ“ä½œå¯ä»¥åˆ†ä¸ºä¸¤ç±»</p><ul><li>å†…æ ¸å¯åŠ¨</li><li>å†…å­˜æ“ä½œ</li></ul><p>å…¶ä¸­å†…æ ¸å¯åŠ¨æ€»æ˜¯å¼‚æ­¥çš„ï¼Œå†…å­˜æ“ä½œå¯ä»¥æ˜¯åŒæ­¥æˆ–å¼‚æ­¥</p><p>å‰é¢æˆ‘ä»¬è¯´åˆ°æœ‰ä¸¤ç§ç±»å‹çš„æµï¼ŒæŒ‰åŒæ­¥å¼‚æ­¥åˆ†ï¼Œåˆå¯åˆ†ä¸º</p><ul><li>åŒæ­¥æµï¼ˆç©ºæµï¼‰</li><li>å¼‚æ­¥æµï¼ˆéç©ºæµï¼‰</li></ul><p>æ˜¾å¼å£°æ˜çš„éƒ½æ˜¯å¼‚æ­¥æµï¼Œå¼‚æ­¥æµé€šå¸¸ä¸ä¼šé˜»å¡ä¸»æœºã€‚è€Œåœ¨éšå¼å£°æ˜çš„åŒæ­¥æµä¸­ï¼Œéƒ¨åˆ†æ“ä½œä¼šé€ æˆé˜»å¡ï¼Œè®©ä¸»æœºç­‰å¾…</p><p>å¼‚æ­¥æµå¹¶ä¸éƒ½æ˜¯éé˜»å¡çš„ï¼Œå¯è¿›ä¸€æ­¥åˆ†ä¸ºå¦‚ä¸‹ä¸¤ç§ç±»å‹</p><ul><li>é˜»å¡æµ</li><li>éé˜»å¡æµ</li></ul><p>å¦‚æœä¸€ä¸ªå¼‚æ­¥æµè¢«å£°æ˜ä¸ºéé˜»å¡çš„ï¼Œå°±ä¸ä¼šè¢«ç©ºæµé˜»å¡ï¼Œå¦‚æœå£°æ˜ä¸ºé˜»å¡æµï¼Œåˆ™ä¼šè¢«ç©ºæµé˜»å¡</p><h3 id="é˜»å¡æµä¸éé˜»å¡æµ"><a href="#é˜»å¡æµä¸éé˜»å¡æµ" class="headerlink" title="é˜»å¡æµä¸éé˜»å¡æµ"></a>é˜»å¡æµä¸éé˜»å¡æµ</h3><p><code>cudaStreamCreate</code>åˆ›å»ºçš„æ˜¯é˜»å¡æµï¼Œæ„å‘³ç€æµä¸­çš„æ“ä½œå¯ä»¥è¢«é˜»å¡ï¼Œç›´åˆ°ç©ºæµä¸­æŸäº›æ“ä½œå®Œæˆã€‚ä»»ä½•å‘å¸ƒåˆ°é˜»å¡æµä¸­çš„æ“ä½œï¼Œéƒ½è¦ç­‰å¾…ç©ºæµä¸­å…ˆå‰çš„æ“ä½œæ‰§è¡Œç»“æŸæ‰å¼€å§‹æ‰§è¡Œ</p><p>ä¸¾ä¾‹ä»£ç å¦‚ä¸‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kernel1&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, Stream1&gt;&gt;&gt;();</span><br><span class="line">Kernel2&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">Kernel3&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, Stream2&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure><p><code>Kernel1</code>åœ¨æ‰§è¡Œç»“æŸåæ‰æ‰§è¡Œ <code>Kernel2</code>ï¼Œ<code>Kernel2</code> æ‰§è¡Œç»“æŸåæ‰æ‰§è¡Œ <code>Kernel3</code></p><p>ä¸‹é¢çš„å‡½æ•°ç”¨äºåˆ›å»ºä¸€ä¸ªéé˜»å¡æµ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaStreamCreateWithFlags</span> <span class="params">( cudaStream_t* pStream, <span class="type">unsigned</span> <span class="type">int</span>  flags )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>pStream</code>ï¼šä¸€ä¸ªæŒ‡å‘ <code>cudaStream_t</code> ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨äºå­˜å‚¨åˆ›å»ºçš„æµçš„å¥æŸ„</li><li><code>flags</code>ï¼šæµçš„è¡Œä¸ºæ ‡å¿—ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º0ã€‚å½“å‰æ”¯æŒçš„æ ‡å¿—åªæœ‰ <code>cudaStreamNonBlocking</code>ï¼ŒæŒ‡å®šåœ¨åˆ›å»ºçš„æµä¸­è¿è¡Œçš„å·¥ä½œå¯ä»¥ä¸ Stream0ï¼ˆç©ºæµï¼‰ä¸­çš„å·¥ä½œåŒæ—¶è¿è¡Œï¼Œå¹¶ä¸”åˆ›å»ºçš„æµä¸åº”è¯¥ä¸ Stream0 æ‰§è¡Œéšå¼åŒæ­¥</li></ul><h3 id="éšå¼åŒæ­¥"><a href="#éšå¼åŒæ­¥" class="headerlink" title="éšå¼åŒæ­¥"></a>éšå¼åŒæ­¥</h3><p>è¿™é‡Œçš„åŒæ­¥ä¹Ÿå¯ä»¥è¯´æ˜¯é˜»å¡ï¼Œä¾‹å¦‚åœ¨è°ƒç”¨ <code>cudaMemcpy</code> å‡½æ•°æ—¶ï¼Œä¼šéšå¼åŒæ­¥è®¾å¤‡å’Œä¸»æœºï¼Œä¹Ÿå¯ä»¥è¯´å…¶å®ƒæ“ä½œåœ¨æ•°æ®ä¼ è¾“å®Œæˆå‰éƒ½ä¼šè¢«é˜»å¡ã€‚è¿è¡Œå¸¦æœ‰éšå¼åŒæ­¥è¡Œä¸ºçš„æ“ä½œæ—¶ä¼šå¯¼è‡´ä¸å¿…è¦çš„é˜»å¡ï¼Œé€ æˆæ€§èƒ½ä¸‹é™ã€‚æ­¤å¤–ï¼Œå¦‚ä¸‹ä¸å†…å­˜æœ‰å…³çš„æ“ä½œéƒ½ä¼šæœ‰éšå¼åŒæ­¥ï¼Œéœ€è¦æ ¼å¤–æ³¨æ„</p><ul><li>é”é¡µä¸»æœºå†…å­˜åˆ†å¸ƒ</li><li>è®¾å¤‡å†…å­˜åˆ†é…</li><li>è®¾å¤‡å†…å­˜åˆå§‹åŒ–</li><li>åŒä¸€è®¾å¤‡ä¸Šä¸¤åœ°å€ä¹‹é—´çš„å†…å­˜å¤åˆ¶</li><li>ä¸€çº§ç¼“å­˜/å…±äº«å†…å­˜é…ç½®ä¿®æ”¹</li></ul><h3 id="æ˜¾å¼åŒæ­¥"><a href="#æ˜¾å¼åŒæ­¥" class="headerlink" title="æ˜¾å¼åŒæ­¥"></a>æ˜¾å¼åŒæ­¥</h3><p>å¸¸è§çš„æ˜¾å¼åŒæ­¥æœ‰</p><ul><li>åŒæ­¥è®¾å¤‡ï¼š<code>cudaDeviceSynchronize</code></li><li>åŒæ­¥æµï¼š<code>cudaStreamSynchronize</code>ï¼Œ<code>cudaStreamQuery</code></li><li>åŒæ­¥æµä¸­çš„äº‹ä»¶ï¼š<code>cudaEventSynchronize</code>ï¼Œ<code>cudaEventQuery</code></li><li>ä½¿ç”¨äº‹ä»¶è·¨æµåŒæ­¥ï¼š<code>cudaEventRecord</code>ï¼Œ<code>cudaStreamWaitEvent</code></li></ul><p>å…¶ä¸­ï¼Œé™¤äº†æœ€åä¸€ä¸ªå‡½æ•°ï¼Œå…¶ä»–æˆ‘ä»¬éƒ½æœ‰æ‰€ä»‹ç»</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaStreamWaitEvent</span> <span class="params">( cudaStream_t stream, cudaEvent_t event, <span class="type">unsigned</span> <span class="type">int</span>  flags = <span class="number">0</span> )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>stream</code>ï¼šè¦ç­‰å¾…äº‹ä»¶çš„ CUDA æµ</li><li><code>event</code>ï¼šç­‰å¾…çš„ CUDA äº‹ä»¶</li><li><code>flags</code>ï¼šæ§åˆ¶ç­‰å¾…äº‹ä»¶æ—¶çš„è¡Œä¸ºã€‚å¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º 0ã€‚å¯ä»¥ä½¿ç”¨ <code>cudaEventBlockingSync</code>ï¼ˆé˜»å¡åŒæ­¥ï¼‰æˆ–<code>cudaEventDisableTiming</code>ï¼ˆç¦ç”¨äº‹ä»¶è®°å½•ï¼‰ç­‰æ ‡å¿—</li></ul><p>è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯æŒ‡å®šçš„æµç­‰å¾…æŒ‡å®šçš„äº‹ä»¶ï¼Œäº‹ä»¶å®Œæˆåæµæ‰èƒ½ç»§ç»­ï¼Œå…¶ä¸­çš„äº‹ä»¶å¯ä»¥åœ¨ä»»æ„æµä¸­ï¼Œå½“åœ¨ä¸åŒçš„æµçš„æ—¶å€™ï¼Œå°±å®ç°äº†äº‹ä»¶è·¨æµåŒæ­¥</p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒStream2 åœ¨è°ƒç”¨ <code>cudaStreamWaitEvent</code> å‡½æ•°åæ‰§è¡Œè·¨æµåŒæ­¥ï¼Œç¡®ä¿ Stream1 åˆ›å»ºçš„äº‹ä»¶æ˜¯æ»¡è¶³ä¾èµ–å…³ç³»çš„</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæµ-äº‹ä»¶ä¸åŒæ­¥/8.webp" alt=""></p><h3 id="å¯é…ç½®äº‹ä»¶"><a href="#å¯é…ç½®äº‹ä»¶" class="headerlink" title="å¯é…ç½®äº‹ä»¶"></a>å¯é…ç½®äº‹ä»¶</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaEventCreateWithFlags</span> <span class="params">( cudaEvent_t* event, <span class="type">unsigned</span> <span class="type">int</span>  flags )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>event</code>ï¼šæŒ‡å‘<code>cudaEvent_t</code>ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨æ¥å­˜å‚¨åˆ›å»ºçš„CUDAäº‹ä»¶å¯¹è±¡</li><li><code>flags</code>ï¼šç”¨æ¥æŒ‡å®šäº‹ä»¶å¯¹è±¡çš„åˆ›å»ºæ ‡å¿—</li></ul><p>å…¶ä¸­ flag å¯é€‰å‚æ•°å¦‚ä¸‹</p><ul><li><code>cudaEventDefault</code>ï¼šé»˜è®¤äº‹ä»¶åˆ›å»ºæ ‡å¿—</li><li><code>cudaEventBlockingSync</code>ï¼šæŒ‡å®šäº‹ä»¶åº”è¯¥ä½¿ç”¨é˜»å¡åŒæ­¥ã€‚ ä½¿ç”¨ <code>cudaEventSynchronize()</code> ç­‰å¾…ä½¿ç”¨æ­¤æ ‡å¿—åˆ›å»ºçš„äº‹ä»¶çš„ä¸»æœºçº¿ç¨‹å°†é˜»å¡ï¼Œç›´åˆ°äº‹ä»¶å®é™…å®Œæˆ</li><li><code>cudaEventDisableTiming</code>ï¼šæŒ‡å®šåˆ›å»ºçš„äº‹ä»¶ä¸éœ€è¦è®°å½•è®¡æ—¶æ•°æ®ã€‚ å½“ä¸ <code>cudaStreamWaitEvent()</code> å’Œ <code>cudaEventQuery()</code> ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œä½¿ç”¨æŒ‡å®šæ­¤æ ‡å¿—åˆ›å»ºçš„äº‹ä»¶å’ŒæœªæŒ‡å®š <code>cudaEventBlockingSync</code> æ ‡å¿—å°†æä¾›æœ€ä½³æ€§èƒ½</li><li><code>cudaEventInterprocess</code>ï¼šæŒ‡å®šåˆ›å»ºçš„äº‹ä»¶å¯ä»¥ç”¨ä½œè¿›ç¨‹é—´äº‹ä»¶ï¼Œ<code>cudaEventInterprocess</code> å¿…é¡»ä¸ <code>cudaEventDisableTiming</code> ä¸€èµ·æŒ‡å®š</li></ul>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDAå†…å­˜ç®¡ç†ï¼ˆä¸‰ï¼‰</title>
      <link href="/p/d7bb3d7c/"/>
      <url>/p/d7bb3d7c/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>CUDA C ç¼–ç¨‹ä¸­çš„ç®€å•çš„å†…å­˜ç®¡ç†ï¼Œçº¿ç¨‹æ“ä½œï¼Œå¦‚ä½•ç¼–å†™æ ¸å‡½æ•°ï¼Œä½¿ç”¨ Thrust åº“ï¼Œå¹¶è¡Œè®¡ç®—ï¼Œæ€§èƒ½åˆ†æå·¥å…·ã€‚</p><span id="more"></span><h2 id="è·å–-GPU-ä¿¡æ¯"><a href="#è·å–-GPU-ä¿¡æ¯" class="headerlink" title="è·å– GPU ä¿¡æ¯"></a>è·å– GPU ä¿¡æ¯</h2><p>CUDA  æä¾›äº†å‡ ç§è·å– GPU ä¿¡æ¯çš„æ–¹æ³•ï¼Œè¿™é‡Œä»‹ç»ä¸€ä¸‹é€šè¿‡è°ƒç”¨ <code>cuda_runtime.h</code>ä¸­çš„ API å¾—åˆ° GPU çš„ä¸€äº›å±æ€§ã€‚</p><blockquote><p>åœ¨ç¼–å†™ CUDA C ç¨‹åºæ—¶ï¼Œ è¦å°†æ–‡ä»¶å‘½åä¸º <code>*.cu</code>ï¼Œä¸€èˆ¬ä½¿ç”¨ nvcc å‘½ä»¤ç¼–è¯‘è¿è¡Œï¼Œä¸º CUDAç¨‹åºæ–‡ä»¶ï¼Œæ”¯æŒ C/C++ è¯­æ³•ã€‚</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">    cudaDeviceProp devProp;</span><br><span class="line">    <span class="built_in">cudaGetDeviceProperties</span>(&amp;devProp, dev);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;GPU Device Name&quot;</span> &lt;&lt; dev &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; devProp.name &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;SM Count: &quot;</span> &lt;&lt; devProp.multiProcessorCount &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Shared Memory Size per Thread Block: &quot;</span> &lt;&lt; devProp.sharedMemPerBlock / <span class="number">1024.0</span> &lt;&lt; <span class="string">&quot; KB&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Threads per Thread Block: &quot;</span> &lt;&lt; devProp.maxThreadsPerBlock &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Threads per SM: &quot;</span> &lt;&lt; devProp.maxThreadsPerMultiProcessor &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Warps per SM: &quot;</span> &lt;&lt; devProp.maxThreadsPerMultiProcessor / <span class="number">32</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ç¼–è¯‘å‘½ä»¤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc checkDeviceInfor.cu -o checkDeviceInfor</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹ï¼ŒSM æ•°é‡ä¸º 30ï¼Œæ¯ä¸ªçº¿ç¨‹å—çš„å…±äº«å†…å­˜ä¸º 48KBï¼Œæ¯ä¸ªçº¿ç¨‹å—æœ‰ 1024 ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ª SM æœ‰ 1536 ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ª SM æœ‰ 48 ä¸ªçº¿ç¨‹æŸ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GPU Device Name0: NVIDIA GeForce RTX 3060 Laptop GPU</span><br><span class="line">SM Count: 30</span><br><span class="line">Shared Memory Size per Thread Block: 48 KB</span><br><span class="line">Threads per Thread Block: 1024</span><br><span class="line">Threads per SM: 1536</span><br><span class="line">Warps per SM: 48</span><br></pre></td></tr></table></figure><h2 id="åˆæ­¥å†…å­˜ç®¡ç†"><a href="#åˆæ­¥å†…å­˜ç®¡ç†" class="headerlink" title="åˆæ­¥å†…å­˜ç®¡ç†"></a>åˆæ­¥å†…å­˜ç®¡ç†</h2><p>ä¸»æœºå’Œè®¾å¤‡å„è‡ªæ‹¥æœ‰ç‹¬ç«‹çš„å†…å­˜ï¼ŒC æ‹¥æœ‰æ ‡å‡†åº“å¯ä»¥ç®¡ç†ä¸»æœºçš„å†…å­˜ï¼ŒCUDA æä¾›çš„ API ç®¡ç†è®¾å¤‡çš„å†…å­˜ï¼Œä¸‹é¢æ˜¯ C å’Œ CUDA çš„éƒ¨åˆ†å†…å­˜ç®¡ç†å‡½æ•°</p><div class="table-container"><table><thead><tr><th>C</th><th>CUDA</th><th>åŠŸèƒ½</th></tr></thead><tbody><tr><td>malloc</td><td>cudaMalloc</td><td>åˆ†é…å†…å­˜</td></tr><tr><td>memcpy</td><td>cudaMemcpy</td><td>å¤åˆ¶å†…å­˜</td></tr><tr><td>memset</td><td>cudaMemset</td><td>è®¾ç½®å†…å­˜</td></tr><tr><td>free</td><td>cudaFree</td><td>é‡Šæ”¾å†…å­˜</td></tr></tbody></table></div><h3 id="ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´"><a href="#ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´" class="headerlink" title="ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´"></a>ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´</h3><p>ä¸‹é¢çš„ç¨‹åºä¸¾ä¾‹äº†å¦‚ä½•ä½¿ç”¨è¿›è¡Œä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´ï¼Œä½¿ç”¨äº† <code>cudaMalloc</code>ï¼Œ<code>cudaMemcpy</code> å’Œ <code>cudaFree</code> å‡½æ•°ï¼Œå‡½æ•°å½¢å‚å¦‚ä¸‹</p><ul><li><p><code>__host__ cudaError_t cudaMalloc (void** devPtr, size_t size)</code></p><ul><li><code>devPtr</code>: å¼€è¾Ÿæ•°æ®çš„é¦–æŒ‡é’ˆ</li><li><code>size</code>: å¼€è¾Ÿçš„è®¾å¤‡å†…å­˜ç©ºé—´é•¿åº¦</li></ul></li><li><p><code>__host__ cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)</code></p><ul><li><code>dst</code>: ç›®çš„æ•°æ®å†…å­˜é¦–æŒ‡é’ˆ</li><li><code>src</code>: æºæ•°æ®é¦–æŒ‡é’ˆ</li><li><code>count</code>: æ•°æ®é•¿åº¦</li><li><code>kind</code>: æ‹·è´ç±»å‹ï¼Œ<code>cudaMemcpyDeviceToHost</code>: ä»è®¾å¤‡å‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToHost</code>: ä»ä¸»æœºå‘è®¾å¤‡æ‹·è´ | <code>cudaMemcpyHostToHost</code>: ä»ä¸»æœºå‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToDevice</code>: ä»è®¾å¤‡å‘è®¾å¤‡æ‹·è´</li></ul></li><li><p><code>__host__ cudaError_t cudaFree (void* devPtr)</code></p></li><li><code>devPtr</code>: è®¾å¤‡å˜é‡æŒ‡é’ˆ</li></ul><p>ä¸Šè¿°å‡½æ•°çš„è¿”å›å€¼ç±»å‹éƒ½æ˜¯ <code>cudaError_t</code>ï¼Œä»¥æšä¸¾å½¢å¼ä¿å­˜å„ç§é”™è¯¯ç±»å‹</p><p>æ›´å¤šè¿è¡Œæ—¶å‡½æ•°è¯¦è§£è§<a href="https://docs.nvidia.com/cuda/cuda-runtime-api/">å®˜æ–¹æ–‡æ¡£</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> dets[<span class="number">6</span>][<span class="number">4</span>] = &#123;</span><br><span class="line">        &#123;<span class="number">23</span>, <span class="number">34</span>, <span class="number">56</span>, <span class="number">76</span>&#125;,</span><br><span class="line">        &#123;<span class="number">11</span>, <span class="number">23</span>, <span class="number">45</span>, <span class="number">45</span>&#125;,</span><br><span class="line">        &#123;<span class="number">12</span>, <span class="number">22</span>, <span class="number">47</span>, <span class="number">47</span>&#125;,</span><br><span class="line">        &#123;<span class="number">9</span>, <span class="number">45</span>, <span class="number">56</span>, <span class="number">65</span>&#125;,</span><br><span class="line">        &#123;<span class="number">20</span>, <span class="number">37</span>, <span class="number">55</span>, <span class="number">75</span>&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// copy data to gpu</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(dets) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *dev_dets;</span><br><span class="line">    cudaError_t err = cudaSuccess;</span><br><span class="line">    err = <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;dev_dets, <span class="built_in">sizeof</span>(dets));</span><br><span class="line">    <span class="keyword">if</span> (err != cudaSuccess) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;cudaMalloc failed!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(dev_dets, dets, <span class="built_in">sizeof</span>(dets), cudaMemcpyHostToDevice);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied data to GPU.\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get back copied cuda data</span></span><br><span class="line">    <span class="type">float</span> host_dets[<span class="built_in">sizeof</span>(dets)/<span class="built_in">sizeof</span>(<span class="type">float</span>)];</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(&amp;host_dets, dev_dets, <span class="built_in">sizeof</span>(dets), cudaMemcpyDeviceToHost);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied from cuda back to host.\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;host_dets size: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(host_dets) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="built_in">sizeof</span>(dets)/<span class="built_in">sizeof</span>(<span class="type">float</span>);i++) &#123;</span><br><span class="line">        std::cout &lt;&lt; host_dets[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">cudaFree</span>(dev_dets);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;done.\n&quot;</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">96</span></span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: <span class="number">96</span></span><br><span class="line"><span class="number">23</span> <span class="number">34</span> <span class="number">56</span> <span class="number">76</span> <span class="number">11</span> <span class="number">23</span> <span class="number">45</span> <span class="number">45</span> <span class="number">12</span> <span class="number">22</span> <span class="number">47</span> <span class="number">47</span> <span class="number">9</span> <span class="number">45</span> <span class="number">56</span> <span class="number">65</span> <span class="number">20</span> <span class="number">37</span> <span class="number">55</span> <span class="number">75</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> </span><br><span class="line">done.</span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç¨‹åºä½¿ç”¨<code>cudaMalloc</code>æ¥ç”³è¯·è®¾å¤‡å†…å­˜ï¼Œä½†äºŒç»´æ•°ç»„ä¸æ¨èè¿™ä¹ˆåšï¼Œåœ¨ kernel è¿ç®—æ—¶è¾ƒé«˜çš„æ€§èƒ½æŸå¤±ï¼ŒCUDA ç»™å‡ºäº†äºŒç»´æ•°ç»„ä¸“ç”¨çš„å†…å­˜ç”³è¯·å‡½æ•°<code>cudaMallocPitch</code>ï¼Œåœ¨è®¾å¤‡é—´å†…å­˜æ‹·è´æ—¶ï¼Œä¹Ÿè¦ä½¿ç”¨<code>cudaMemcpy2D</code>å‡½æ•°ï¼Œå½¢å‚å¦‚ä¸‹</p><ul><li><code>__host__cudaError_t cudaMallocPitch ( void** devPtr, size_t* pitch, size_t width, size_t height )</code><ul><li><code>devPtr</code>: å¼€è¾ŸçŸ©é˜µçš„æ•°æ®çš„é¦–æŒ‡é’ˆ</li><li><code>pitch</code>: åˆ†é…å­˜å‚¨å™¨çš„å®½åº¦</li><li><code>width</code>: äºŒç»´æ•°ç»„åˆ—æ•°</li><li><code>height</code>: äºŒç»´æ•°ç»„è¡Œæ•°</li></ul></li><li><code>__host__ cudaError_t cudaMemcpy2D ( void* dst, size_t dpitch, const void* src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind )</code><ul><li><code>dst</code>: ç›®çš„çŸ©é˜µå†…å­˜é¦–æŒ‡é’ˆ</li><li><code>dpitch</code>:  dstæŒ‡å‘çš„ 2D æ•°ç»„ä¸­çš„å†…å­˜å®½åº¦ï¼Œä»¥å­—èŠ‚ä¸ºå•ä½ï¼Œæ˜¯cudaä¸ºäº†è¯»å–æ–¹ä¾¿ï¼Œå¯¹é½è¿‡çš„å†…å­˜å®½åº¦ï¼Œå¯èƒ½å¤§äºä¸€è¡Œå…ƒç´ å æ®çš„å®é™…å†…å­˜</li><li><code>src</code>: æºçŸ©é˜µå†…å­˜é¦–æŒ‡é’ˆ</li><li><code>spitch</code>: src æŒ‡å‘çš„ 2D æ•°ç»„ä¸­çš„å†…å­˜å®½åº¦</li><li><code>width</code>: srcæŒ‡å‘çš„2Dæ•°ç»„ä¸­ä¸€è¡Œå…ƒç´ å æ®çš„å®é™…å®½åº¦ï¼Œä¸º <code>width*sizeof(type)</code></li><li><code>height</code>: srcæŒ‡å‘çš„2Dæ•°ç»„çš„è¡Œæ•°</li><li><code>kind</code>: æ‹·è´ç±»å‹ï¼Œ<code>cudaMemcpyDeviceToHost</code>: ä»è®¾å¤‡å‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToHost</code>: ä»ä¸»æœºå‘è®¾å¤‡æ‹·è´ | <code>cudaMemcpyHostToHost</code>: ä»ä¸»æœºå‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToDevice</code>: ä»è®¾å¤‡å‘è®¾å¤‡æ‹·è´</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> dets[<span class="number">6</span>][<span class="number">4</span>] = &#123;</span><br><span class="line">        &#123;<span class="number">23</span>, <span class="number">34</span>, <span class="number">56</span>, <span class="number">76</span>&#125;,</span><br><span class="line">        &#123;<span class="number">11</span>, <span class="number">23</span>, <span class="number">45</span>, <span class="number">45</span>&#125;,</span><br><span class="line">        &#123;<span class="number">12</span>, <span class="number">22</span>, <span class="number">47</span>, <span class="number">47</span>&#125;,</span><br><span class="line">        &#123;<span class="number">9</span>, <span class="number">45</span>, <span class="number">56</span>, <span class="number">65</span>&#125;,</span><br><span class="line">        &#123;<span class="number">20</span>, <span class="number">37</span>, <span class="number">55</span>, <span class="number">75</span>&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="type">size_t</span> width = <span class="number">4</span>;</span><br><span class="line">    <span class="type">size_t</span> height = <span class="number">6</span>;</span><br><span class="line">    <span class="type">size_t</span> pitch;</span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(dets) &lt;&lt; std::endl;</span><br><span class="line">    <span class="type">float</span> *dev_dets;</span><br><span class="line">    cudaError_t err = cudaSuccess;</span><br><span class="line">    err = <span class="built_in">cudaMallocPitch</span>((<span class="type">void</span> **)&amp;dev_dets, &amp;pitch, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, height);</span><br><span class="line">    <span class="keyword">if</span> (err != cudaSuccess) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;cudaMalloc failed!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// copy data to gpu</span></span><br><span class="line">    <span class="built_in">cudaMemcpy2D</span>(dev_dets, pitch, dets, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, height,cudaMemcpyHostToDevice);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied data to GPU.\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get back copied cuda data</span></span><br><span class="line">    <span class="type">float</span> host_dets[<span class="built_in">sizeof</span>(dets)/<span class="built_in">sizeof</span>(<span class="type">float</span>)];</span><br><span class="line">    <span class="built_in">cudaMemcpy2D</span>(&amp;host_dets, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, dev_dets, pitch, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, height,cudaMemcpyDeviceToHost);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied from cuda back to host.\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;host_dets size: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(host_dets) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;width*height;i++) &#123;</span><br><span class="line">        std::cout &lt;&lt; host_dets[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">cudaFree</span>(dev_dets);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;done.\n&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">96</span></span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: <span class="number">96</span></span><br><span class="line"><span class="number">23</span> <span class="number">34</span> <span class="number">56</span> <span class="number">76</span> <span class="number">11</span> <span class="number">23</span> <span class="number">45</span> <span class="number">45</span> <span class="number">12</span> <span class="number">22</span> <span class="number">47</span> <span class="number">47</span> <span class="number">9</span> <span class="number">45</span> <span class="number">56</span> <span class="number">65</span> <span class="number">20</span> <span class="number">37</span> <span class="number">55</span> <span class="number">75</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> </span><br><span class="line">done.</span><br></pre></td></tr></table></figure><p>è¿™ä¸¤ä¸ªå‡½æ•°åº”è¯¥ä¼šä½¿ kernel çš„è¿è¡Œæ—¶é—´å˜çŸ­ï¼Œå› ä¸º pitch å¯¹é½åå¯å®ç° global å†…å­˜è”åˆè®¿é—®ï¼Œä½†<code>cudaMallocPitch</code>å’Œ<code>cudaMemcpy2D</code>ä¼šå˜æ…¢ï¼Œå› ä¸ºæ¯”ä¸€ç»´çš„æ“ä½œå¤šäº†å¯¹é½çš„è€ƒè™‘</p><h2 id="Kernel-å‡½æ•°"><a href="#Kernel-å‡½æ•°" class="headerlink" title="Kernel å‡½æ•°"></a>Kernel å‡½æ•°</h2><h3 id="kernel-é™å®šè¯"><a href="#kernel-é™å®šè¯" class="headerlink" title="kernel é™å®šè¯"></a>kernel é™å®šè¯</h3><ul><li><code>__device__</code>: åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œåªèƒ½åœ¨è®¾å¤‡ä¸Šè°ƒç”¨ï¼›</li><li><code>__global__</code>: åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œåªèƒ½åœ¨ä¸»æœºä¸Šè°ƒç”¨ï¼›</li><li><code>__host__</code>: åœ¨ä¸»æœºä¸Šæ‰§è¡Œï¼Œåªèƒ½åœ¨ä¸»æœºä¸Šè°ƒç”¨ã€‚</li></ul><p><code>__device__</code>å’Œ<code>__global__</code>ä»£è¡¨å‡½æ•°åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œä¸æ”¯æŒé€’å½’ï¼Œä¸èƒ½åœ¨å‡½æ•°ä½“å†…å£°æ˜é™æ€å˜é‡ï¼Œé™æ€å˜é‡å¯¹åº”äºCPUçš„æ•´ä¸ªç¨‹åºç”Ÿå‘½è¿‡ç¨‹ï¼Œä¸èƒ½æœ‰å¯å˜é•¿å‚æ•°ï¼›</p><p><code>__global__</code>å’Œ<code>__host__</code>ä¸èƒ½ä¸€èµ·ä½¿ç”¨ï¼Œè€Œ<code>__device__</code>å’Œ<code>__host__</code>å¯ä»¥ä¸€èµ·ä½¿ç”¨ï¼Œç¼–è¯‘å™¨ä¼šåœ¨ CPU å’Œ GPU å„å¤åˆ¶ä¸€ä»½å‡½æ•°ã€‚</p><p>ä¸æ·»åŠ é™å®šè¯æ—¶ï¼Œå‡½æ•°é»˜è®¤ä¸º<code>__host__</code>ï¼Œä¹Ÿå°±æ˜¯åœ¨ä¸»æœºä¸Šæ‰§è¡Œã€‚</p><p>æ‰€æœ‰çš„ kernel å‡½æ•°è¿”å›ç±»å‹éƒ½æ˜¯ voidï¼Œä¸” kernel å‡½æ•°éƒ½æ˜¯å¼‚æ­¥æ‰§è¡Œã€‚</p><h3 id="kernel-è°ƒç”¨æ–¹å¼"><a href="#kernel-è°ƒç”¨æ–¹å¼" class="headerlink" title="kernel è°ƒç”¨æ–¹å¼"></a>kernel è°ƒç”¨æ–¹å¼</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_func</span> <span class="params">(param list)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line">kernel_func &lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt; (param list);</span><br></pre></td></tr></table></figure><ul><li><code>&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;</code>: æ˜¯è¿ç®—ç¬¦å†…æ˜¯æ ¸å‡½æ•°çš„æ‰§è¡Œå‚æ•°ï¼Œå‘Šè¯‰ç¼–è¯‘å™¨è¿è¡Œæ—¶å¦‚ä½•å¯åŠ¨æ ¸å‡½æ•°</li><li><code>Dg</code>: grid çš„ç»´åº¦å’Œå°ºå¯¸ï¼Œdim3 ç±»å‹ï¼Œæ„ä¸ºä¸€ä¸ª grid æœ‰å¤šå°‘ä¸ª block</li><li><code>Db</code>: block çš„ç»´åº¦å’Œå°ºå¯¸ï¼Œ dim3 ç±»å‹ï¼Œæ„ä¸ºä¸€ä¸ª block æœ‰å¤šå°‘ä¸ª thread</li><li><code>Ns</code>: ï¼ˆå¯é€‰ï¼‰ç”¨äºè®¾ç½®æ¯ä¸ªblocké™¤äº†é™æ€åˆ†é…çš„ shared Memory ä»¥å¤–ï¼Œæœ€å¤šèƒ½åŠ¨æ€åˆ†é…çš„ shared Memory å¤§å°ï¼Œå•ä½ä¸º byte ä¸éœ€è¦åŠ¨æ€åˆ†é…æ—¶è¯¥å€¼ä¸º0æˆ–çœç•¥ä¸å†™</li><li><code>S</code>: ï¼ˆå¯é€‰ï¼‰ cudastream ç±»å‹çš„å‚æ•°ï¼Œè¡¨ç¤ºè¯¥æ ¸å‡½æ•°å¤„åœ¨å“ªä¸ªæµä¹‹ä¸­</li></ul><p>è¿™é‡Œæˆ‘ä»¬å®ç°ä¸€ä¸‹ç¬¬äºŒç« æœ€åçš„ä¾‹å­ï¼Œä¸‹é¢çš„ç¨‹åºä½¿ç”¨äº†<code>cudaDeviceSynchronize</code>å’Œ<code>cudaDeviceReset</code>å‡½æ•°ï¼Œè§£é‡Šå¦‚ä¸‹</p><ul><li><code>__host__ __device__ cudaDeviceSynchronize</code>: ä½¿è®¾å¤‡é˜»å¡åˆ°å®Œæˆæ‰€æœ‰å‰é¢è¯·æ±‚çš„ä»»åŠ¡ï¼ŒCUDA 11.6 åå·²å¼ƒç”¨</li><li><code>__host__ cudaDeviceReset</code>: æ˜¾å¼é”€æ¯å¹¶æ¸…é™¤å½“å‰è¿›ç¨‹ä¸­ä¸è®¾å¤‡å…³è”çš„æ‰€æœ‰èµ„æºï¼Œèµ„æºä¸èƒ½å†è¢«è®¿é—®ï¼Œå¯èƒ½å¯¼è‡´æœªå®šä¹‰çš„è¡Œä¸º</li></ul><p>ç”±äº CUDA printf çš„è¾“å‡ºå­˜å‚¨åœ¨ç¼“å†²ä¸­ï¼Œåå°åŒæ­¥æœºåˆ¶ä¼šæœ‰å»¶æ—¶ï¼Œéœ€è¦ä½¿ç”¨ä¸Šé¢ä¸¤ä¸ªåŒæ­¥å‡½æ•°ä¸­ä»»æ„ä¸€ä¸ªä½¿ printf å‡½æ•°çš„å†…å®¹ä¸ä¸»æœºåŒæ­¥ï¼Œå³å¯è¾“å‡º</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">printThreadIndex</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx = iy*blockDim.x * gridDim.x + ix;</span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x == <span class="number">3</span> &amp;&amp; threadIdx.y == <span class="number">1</span> &amp;&amp; blockIdx.x == <span class="number">0</span> &amp;&amp; blockIdx.y == <span class="number">1</span>)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;thread_id (%d,%d) block_id (%d,%d) coordinate (%d, %d), global index %2d \n&quot;</span>, threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y, ix, iy, idx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span>, <span class="title">block</span><span class="params">(<span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    printThreadIndex&lt;&lt;&lt;grid, block&gt;&gt;&gt;();</span><br><span class="line">    <span class="comment">// cudaDeviceSynchronize(); </span></span><br><span class="line">    <span class="built_in">cudaDeviceReset</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="built_in">thread_id</span> (<span class="number">3</span>,<span class="number">1</span>) <span class="built_in">block_id</span> (<span class="number">0</span>,<span class="number">1</span>) <span class="built_in">coordinate</span> (<span class="number">3</span>, <span class="number">3</span>), global index <span class="number">27</span></span><br></pre></td></tr></table></figure><blockquote><p>åœ¨è¾“å‡ºæ—¶ä¸èƒ½ä½¿ç”¨ std::cout, std å‘½åç©ºé—´ä¸èƒ½ä½¿ç”¨åˆ° GPU ä¸Š</p></blockquote><h2 id="CUDA-çš„-Thrust-åº“"><a href="#CUDA-çš„-Thrust-åº“" class="headerlink" title="CUDA çš„ Thrust åº“"></a>CUDA çš„ Thrust åº“</h2><p>CUDA çš„ Thrust åº“æ˜¯åŸºäºæ ‡å‡†æ¨¡æ¿åº“ STL çš„ CUDA çš„ C++ æ¨¡æ¿åº“ï¼Œ é€šè¿‡ä¸ CUDA C é…åˆä½¿ç”¨ï¼ŒèŠ‚çœäº†å¤§é‡ä¼˜åŒ–ç®—æ³•çš„æ—¶é—´ï¼Œä¿è¯äº†æ€§èƒ½ä¸å¼€å‘æ•ˆç‡ï¼Œåœ¨ CUDA Toolkit ä¸­åŒ…å« Thrustï¼Œæ— éœ€é¢å¤–å®‰è£…ï¼Œåªéœ€å¯¼å…¥ç›¸åº”å¤´æ–‡ä»¶ï¼Œåœ¨è°ƒç”¨æ—¶ä½¿ç”¨ <code>thrust</code> å‘½åç©ºé—´ï¼Œå¹¶å°½é‡ä¸è¦ä½¿ç”¨ <code>using namespace std;</code> è¯­å¥ï¼Œå› ä¸º thrust åº“å’Œ STL åº“éå¸¸å¤šçš„é‡å</p><h3 id="Vector-å®¹å™¨"><a href="#Vector-å®¹å™¨" class="headerlink" title="Vector å®¹å™¨"></a>Vector å®¹å™¨</h3><p>Thrust ä¸­å®šä¹‰äº†ä¸»æœºç«¯å’Œè®¾å¤‡ç«¯çš„ä¸¤ç§ vectorï¼Œåˆ†åˆ«å®šä¹‰åœ¨ host_vector.h å’Œ device_vector.h ä¸­ï¼Œä¸¾ä¾‹å¦‚ä¸‹</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// H has storage for 4 integers</span></span><br><span class="line">    <span class="function">thrust::host_vector&lt;<span class="type">int</span>&gt; <span class="title">H</span><span class="params">(<span class="number">4</span>)</span></span>;</span><br><span class="line">    <span class="comment">// initialize individual elements</span></span><br><span class="line">    H[<span class="number">0</span>] = <span class="number">14</span>;</span><br><span class="line">    H[<span class="number">1</span>] = <span class="number">20</span>;</span><br><span class="line">    H[<span class="number">2</span>] = <span class="number">38</span>;</span><br><span class="line">    H[<span class="number">3</span>] = <span class="number">46</span>;</span><br><span class="line">    H.<span class="built_in">push_back</span>(<span class="number">52</span>);</span><br><span class="line">    <span class="comment">// H.size() returns the size of vector H</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;H has size &quot;</span> &lt;&lt; H.<span class="built_in">size</span>() &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// print contents of H</span></span><br><span class="line">    <span class="comment">// for(int i = 0; i &lt; H.size(); i++)</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i:H)</span><br><span class="line">        std::cout &lt;&lt; i &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// resize H</span></span><br><span class="line">    H.<span class="built_in">resize</span>(<span class="number">2</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;H now has size &quot;</span> &lt;&lt; H.<span class="built_in">size</span>() &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// Copy host_vector H to device_vector D</span></span><br><span class="line">    thrust::device_vector&lt;<span class="type">int</span>&gt; D = H; </span><br><span class="line">    <span class="comment">// elements of D can be modified</span></span><br><span class="line">    D[<span class="number">0</span>] = <span class="number">99</span>;</span><br><span class="line">    D[<span class="number">1</span>] = <span class="number">88</span>;</span><br><span class="line">    <span class="comment">// print contents of D</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i:D)</span><br><span class="line">        std::cout &lt;&lt; i &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// H and D are automatically deleted when the function returns</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line">H has size <span class="number">5</span></span><br><span class="line"><span class="number">14</span></span><br><span class="line"><span class="number">20</span></span><br><span class="line"><span class="number">38</span></span><br><span class="line"><span class="number">46</span></span><br><span class="line"><span class="number">52</span></span><br><span class="line">H now has size <span class="number">2</span></span><br><span class="line"><span class="number">99</span></span><br><span class="line"><span class="number">88</span></span><br></pre></td></tr></table></figure><p>Thrust å…è®¸ä½¿ç”¨ <code>=</code> è¿ç®—ç¬¦å¯¹ <code>host_vector</code> å’Œ <code>device_vector</code> çš„ç›¸äº’æ‹·è´ï¼Œä¹Ÿå…è®¸ä½¿ç”¨ <code>[i]</code> ä¸‹æ ‡è®¿é—® <code>device_vector</code> çš„å„ä¸ªå…ƒç´ ï¼Œä½†æ˜¯ç”¨è¿™ç§æ–¹æ³•è®¿é—®æ¯ä¸€æ¬¡éƒ½éœ€è¦è°ƒç”¨ <code>cudaMemcpy</code>ï¼Œæ€§èƒ½æŸå¤±è¾ƒå¤§ï¼Œåº”è°¨æ…ä½¿ç”¨ã€‚ ä¸‹é¢æˆ‘ä»¬å°†ä»‹ç»ä¸€äº›æ›´æœ‰æ•ˆçš„æŠ€æœ¯</p><p>ä¸‹é¢å±•ç¤º Thrust æä¾›çš„å‡ ç§å¯¹ vector æ“ä½œçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬åˆå§‹åŒ–ï¼Œèµ‹å€¼ï¼Œ<code>iterator</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/copy.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/fill.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/sequence.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// initialize all ten integers of a device_vector to 1</span></span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">D</span><span class="params">(<span class="number">10</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="comment">// set the first seven elements of a vector to 9</span></span><br><span class="line">    thrust::<span class="built_in">fill</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">begin</span>() + <span class="number">7</span>, <span class="number">9</span>);</span><br><span class="line">    <span class="comment">// initialize a host_vector with the first five elements of D</span></span><br><span class="line">    <span class="function">thrust::host_vector&lt;<span class="type">int</span>&gt; <span class="title">H</span><span class="params">(D.begin(), D.begin() + <span class="number">5</span>)</span></span>;</span><br><span class="line">    <span class="comment">// set the elements of H to 0, 1, 2, 3, ...</span></span><br><span class="line">    thrust::<span class="built_in">sequence</span>(H.<span class="built_in">begin</span>(), H.<span class="built_in">end</span>());</span><br><span class="line">    <span class="comment">// copy all of H back to the beginning of D</span></span><br><span class="line">    thrust::<span class="built_in">copy</span>(H.<span class="built_in">begin</span>(), H.<span class="built_in">end</span>(), D.<span class="built_in">begin</span>());</span><br><span class="line">    <span class="comment">// print D</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i:D)dd</span><br><span class="line">        std::cout &lt;&lt; i &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">9</span> <span class="number">9</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç¨‹åºä½¿ç”¨äº†<code>thrust::fill</code>ï¼Œå½“å®ƒå¯¹ <code>device_vector iterator</code> æ“ä½œæ—¶ï¼Œä¼šåœ¨ç¼–è¯‘æ—¶æ£€æŸ¥ <code>iterator</code> åœ¨ä¸»æœºä¸Šè¿˜æ˜¯åœ¨è®¾å¤‡ä¸Šï¼Œè¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸ºé™æ€è°ƒåº¦ï¼Œæ„å‘³ç€è°ƒåº¦è¿‡ç¨‹æ²¡æœ‰è¿è¡Œæ—¶å¼€é”€</p><h3 id="æŒ‡é’ˆ"><a href="#æŒ‡é’ˆ" class="headerlink" title="æŒ‡é’ˆ"></a>æŒ‡é’ˆ</h3><p>thrust ä¸­å®šä¹‰äº† <code>device_ptr</code> æ•°æ®ç±»å‹ï¼Œå½“ä¼ å…¥å‡½æ•°çš„æŒ‡é’ˆæŒ‡å‘è®¾å¤‡ç«¯å†…å­˜æ—¶ï¼Œéœ€è¦ç”¨<code>device_ptr</code>è¿›è¡Œå°è£…</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> N = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// raw pointer to device memory</span></span><br><span class="line"><span class="type">int</span> * raw_ptr;</span><br><span class="line"><span class="built_in">cudaMalloc</span>((<span class="type">void</span> **) &amp;raw_ptr, N * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"><span class="comment">// wrap raw pointer with a device_ptr </span></span><br><span class="line"><span class="function">thrust::device_ptr&lt;<span class="type">int</span>&gt; <span class="title">dev_ptr</span><span class="params">(raw_ptr)</span></span>;</span><br><span class="line"><span class="comment">// use device_ptr in thrust algorithms</span></span><br><span class="line">thrust::<span class="built_in">fill</span>(dev_ptr, dev_ptr + N, (<span class="type">int</span>) <span class="number">0</span>);</span><br></pre></td></tr></table></figure><h3 id="æ•°å€¼æ“ä½œ"><a href="#æ•°å€¼æ“ä½œ" class="headerlink" title="æ•°å€¼æ“ä½œ"></a>æ•°å€¼æ“ä½œ</h3><h4 id="Transformations"><a href="#Transformations" class="headerlink" title="Transformations"></a>Transformations</h4><p>Transformations æ˜¯å¯¹ä¸€ä¸ªè¾“å…¥èŒƒå›´ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ åº”ç”¨æ“ä½œï¼Œå°†ç»“æœå­˜å‚¨åœ¨ç»™å®šèŒƒå›´ä¸­çš„æ–¹æ³•ï¼Œä¸Šé¢ç¨‹åºä¸­å·²ç» <code>thrust::fill</code> å°±æ˜¯ä¸€ä¸ª Transformationsï¼Œå®ƒå°†èŒƒå›´å†…çš„æ‰€æœ‰å…ƒç´ è®¾ç½®ä¸ºæŒ‡å®šå€¼ã€‚ä¸‹é¢çš„ç¨‹åºç”¨åˆ°äº† <code>thrust::sequence</code>ï¼Œ<code>thrust::replace</code>ï¼Œ<code>thrust::transform</code>ï¼Œæ›´å¤š Transformations è¯·æŸ¥çœ‹<a href="https://thrust.github.io/doc/group__transformations.html">å®˜æ–¹æ–‡æ¡£</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/transform.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/sequence.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/copy.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/fill.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/replace.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/functional.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// allocate three device_vectors with 10 elements</span></span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">Y</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">Z</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="comment">// initialize X to 0,1,2,3, ....</span></span><br><span class="line">    thrust::<span class="built_in">sequence</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>());</span><br><span class="line">    <span class="comment">// compute Y = -X</span></span><br><span class="line">    thrust::<span class="built_in">transform</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>(), Y.<span class="built_in">begin</span>(), thrust::<span class="built_in">negate</span>&lt;<span class="type">int</span>&gt;());</span><br><span class="line">    <span class="comment">// fill Z with twos</span></span><br><span class="line">    thrust::<span class="built_in">fill</span>(Z.<span class="built_in">begin</span>(), Z.<span class="built_in">end</span>(), <span class="number">2</span>);</span><br><span class="line">    <span class="comment">// compute Y = X mod 2</span></span><br><span class="line">    thrust::<span class="built_in">transform</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>(), Z.<span class="built_in">begin</span>(), Y.<span class="built_in">begin</span>(), thrust::<span class="built_in">modulus</span>&lt;<span class="type">int</span>&gt;());</span><br><span class="line">    <span class="comment">// replace all the ones in Y with tens</span></span><br><span class="line">    thrust::<span class="built_in">replace</span>(Y.<span class="built_in">begin</span>(), Y.<span class="built_in">end</span>(), <span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">    <span class="comment">// print Y</span></span><br><span class="line">    thrust::<span class="built_in">copy</span>(Y.<span class="built_in">begin</span>(), Y.<span class="built_in">end</span>(), std::<span class="built_in">ostream_iterator</span>&lt;<span class="type">int</span>&gt;(std::cout, <span class="string">&quot; &quot;</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> </span><br></pre></td></tr></table></figure><h4 id="SAXPY"><a href="#SAXPY" class="headerlink" title="SAXPY"></a>SAXPY</h4><p>SAXPYï¼ˆScalar Alpha X Plus Yï¼‰æ˜¯ä¸€ä¸ªåœ¨ BLASï¼ˆBasic Linear Algebra Subprogramsï¼‰å‡½æ•°åº“æä¾›ä¸­çš„å‡½æ•°ï¼Œå¹¶ä¸”æ˜¯ä¸€ä¸ªå¹¶è¡Œå‘é‡å¤„ç†æœºï¼ˆvector processorï¼‰ä¸­å¸¸ç”¨çš„è®¡ç®—æ“ä½œæŒ‡ä»¤ï¼Œä¸ºæ ‡é‡ä¹˜æ³•å’Œå‘é‡åŠ æ³•çš„ç»„åˆï¼Œå¦‚ $y = a*x + y$ï¼Œå…¶ä¸­ $x$ å’Œ $y$ ä¸ºå‘é‡ï¼Œ$a$ ä¸ºæ ‡é‡å¸¸æ•°ã€‚ä¸‹é¢çš„ç¨‹åºå®šä¹‰äº†ä¸€ä¸ª functor å®ç° SAXPY</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">saxpy_functor</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> a;</span><br><span class="line">    <span class="built_in">saxpy_functor</span>(<span class="type">float</span> _a) : <span class="built_in">a</span>(_a) &#123;&#125;</span><br><span class="line">    <span class="function">__host__ __device__</span></span><br><span class="line"><span class="function">        <span class="type">float</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> <span class="type">float</span>&amp; x, <span class="type">const</span> <span class="type">float</span>&amp; y)</span> <span class="type">const</span> </span>&#123; </span><br><span class="line">            <span class="keyword">return</span> a * x + y;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">saxpy</span><span class="params">(<span class="type">float</span> A, thrust::device_vector&lt;<span class="type">float</span>&gt;&amp; X, thrust::device_vector&lt;<span class="type">float</span>&gt;&amp; Y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// y = a * x + y</span></span><br><span class="line">    thrust::<span class="built_in">transform</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>(), Y.<span class="built_in">begin</span>(), Y.<span class="built_in">begin</span>(), <span class="built_in">saxpy_functor</span>(A));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Reductions"><a href="#Reductions" class="headerlink" title="Reductions"></a>Reductions</h4><p>ä½¿ç”¨ <code>thrust::reduce</code> å‡½æ•°å¯¹ä¸€ç»„æ•°æ®è¿›è¡Œæ“ä½œï¼Œè¿”å›å€¼ä¸ºä¸€ä¸ªå…·ä½“æ•°å€¼ï¼Œä¸‹ä¾‹å°±æ˜¯å¯¹ä¸€ç»„æ•°æ®æ±‚å’Œ</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum = thrust::<span class="built_in">reduce</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">end</span>(), (<span class="type">int</span>) <span class="number">0</span>, thrust::<span class="built_in">plus</span>&lt;<span class="type">int</span>&gt;());</span><br></pre></td></tr></table></figure><p>ä¸Šåˆ—ä¸­<code>(int) 0</code>ä¸ºè®¡ç®—çš„åˆå§‹å€¼ï¼Œ<code>thrust::plus&lt;int&gt;()</code>ä¸ºæ“ä½œç¬¦ï¼Œå½“æ²¡æœ‰å®šä¹‰åˆå§‹å€¼å’Œæ“ä½œç¬¦æ—¶ï¼Œå®ƒä»¬æ˜¯é»˜è®¤å€¼ï¼Œå› æ­¤ä¸‹é¢çš„ä¸¤æ¡è¯­å¥å’Œä¸Šé¢çš„ç­‰ä»·ï¼Œæ›´å¤šæ“ä½œç¬¦è¯·æŸ¥çœ‹<a href="https://nvidia.github.io/thrust/api/groups/group__reductions.html">å®˜æ–¹æ–‡æ¡£</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum = thrust::<span class="built_in">reduce</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">end</span>(), (<span class="type">int</span>) <span class="number">0</span>);</span><br><span class="line"><span class="type">int</span> sum = thrust::<span class="built_in">reduce</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">end</span>());</span><br></pre></td></tr></table></figure><p><code>thrust::transform_reduce</code>å…è®¸æ¥å—å¤šä¸ªæ“ä½œç¬¦æ¥å¯¹ä¸€ç»„æ•°æ®æ±‚å€¼</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/transform_reduce.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/functional.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// square&lt;T&gt; computes the square of a number f(x) -&gt; x*x</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">square</span> &#123;</span><br><span class="line">    <span class="function">__host__ __device__</span></span><br><span class="line"><span class="function">        T <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> T&amp; x)</span> <span class="type">const</span> </span>&#123; </span><br><span class="line">            <span class="keyword">return</span> x * x;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// initialize host array</span></span><br><span class="line">    <span class="type">float</span> x[<span class="number">4</span>] = &#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>&#125;;</span><br><span class="line">    <span class="comment">// transfer to device</span></span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">float</span>&gt; <span class="title">d_x</span><span class="params">(x, x + <span class="number">4</span>)</span></span>;</span><br><span class="line">    <span class="comment">// setup arguments</span></span><br><span class="line">    square&lt;<span class="type">float</span>&gt; unary_op;</span><br><span class="line">    thrust::plus&lt;<span class="type">float</span>&gt; binary_op;</span><br><span class="line">    <span class="type">float</span> init = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// compute norm</span></span><br><span class="line">    <span class="type">float</span> norm = std::<span class="built_in">sqrt</span>( thrust::<span class="built_in">transform_reduce</span>(d_x.<span class="built_in">begin</span>(), d_x.<span class="built_in">end</span>(), unary_op, init, binary_op));</span><br><span class="line">    std::cout &lt;&lt; norm &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">5.47723</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç¨‹åºå¯¹ä¸€ç»„æ•°æ®è®¡ç®—å¹³æ–¹å’Œå†å¼€æ–¹ï¼Œè¿™ç§å†™æ³•ä¼šå¤§å¤§ä¼˜åŒ–æ€§èƒ½ã€‚</p><h4 id="Sorting"><a href="#Sorting" class="headerlink" title="Sorting"></a>Sorting</h4><p>å¯¹æ•°æ®è¿›è¡Œæ’åºï¼Œå¾ˆå¸¸ç”¨çš„æ’åºåŠŸèƒ½ï¼Œä¸¾ä¾‹å¦‚ä¸‹</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/sort.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/functional.h&gt;</span></span></span><br><span class="line">...</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">6</span>;</span><br><span class="line"><span class="type">int</span> A[N] = &#123;<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">7</span>&#125;;</span><br><span class="line">thrust::<span class="built_in">sort</span>(A, A + N);</span><br><span class="line"><span class="comment">// A is now &#123;1, 2, 4, 5, 7, 8&#125;</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">6</span>;</span><br><span class="line"><span class="type">int</span>    keys[N] = &#123;  <span class="number">1</span>,   <span class="number">4</span>,   <span class="number">2</span>,   <span class="number">8</span>,   <span class="number">5</span>,   <span class="number">7</span>&#125;;</span><br><span class="line"><span class="type">char</span> values[N] = &#123;<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>&#125;;</span><br><span class="line">thrust::<span class="built_in">sort_by_key</span>(keys, keys + N, values);</span><br><span class="line"><span class="comment">// keys is now   &#123;  1,   2,   4,   5,   7,   8&#125;</span></span><br><span class="line"><span class="comment">// values is now &#123;&#x27;a&#x27;, &#x27;c&#x27;, &#x27;b&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;d&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">6</span>;</span><br><span class="line"><span class="type">int</span> A[N] = &#123;<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">7</span>&#125;;</span><br><span class="line">thrust::<span class="built_in">stable_sort</span>(A, A + N, thrust::<span class="built_in">greater</span>&lt;<span class="type">int</span>&gt;());</span><br><span class="line"><span class="comment">// A is now &#123;8, 7, 5, 4, 2, 1&#125;</span></span><br></pre></td></tr></table></figure><p>ä¸Šä¾‹ä¸­çš„ <code>thrust::stable_sort</code>æ¥å—ç”¨æˆ·è‡ªå®šä¹‰æ¯”è¾ƒè¿ç®—ç¬¦</p><h4 id="max-element-min-element"><a href="#max-element-min-element" class="headerlink" title="max_element(min_element)"></a>max_element(min_element)</h4><p>æ±‚æœ€å¤§ï¼ˆå°ï¼‰å€¼</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/extrema.h&gt;</span></span></span><br><span class="line">...</span><br><span class="line">thrust::device_vector&lt;type&gt;::iterator iter = thrust::<span class="built_in">max_element</span>(dvec.<span class="built_in">begin</span>()ï¼Œdvec.<span class="built_in">end</span>());</span><br><span class="line"><span class="type">int</span> position = iter - dvec.<span class="built_in">begin</span>();</span><br><span class="line">type max_val = *iter;</span><br></pre></td></tr></table></figure><p>å…¶è¿”å›å€¼æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œéœ€è¦è·å–æœ€å¤§ï¼ˆå°ï¼‰å€¼æ‰€åœ¨ä½ç½®ï¼Œå†å¾—åˆ°ç»“æœ</p><h4 id="unique"><a href="#unique" class="headerlink" title="unique"></a>unique</h4><p>å°†ä¸€ç»„æ•°æ®ä¸­æ»¡è¶³æ¡ä»¶çš„æ•°æ®ç­›é€‰å‡ºæ¥ï¼Œå¯è‡ªå®šä¹‰ç­›é€‰æ¡ä»¶</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/unique.h&gt;</span></span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_same</span> &#123;</span><br><span class="line"><span class="function">__host__ __device__</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> float3 &amp;p1, <span class="type">const</span> float3 &amp;p2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> (p1.x==p2.x) &amp;&amp; (p1.y==p2.y) &amp;&amp; (p1.z==p2.z);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">thrust::<span class="built_in">unique</span>(p.<span class="built_in">begin</span>(), p.<span class="built_in">end</span>(),<span class="built_in">is_same</span>()),p.<span class="built_in">end</span>();</span><br><span class="line">p.<span class="built_in">erase</span>(thrust::<span class="built_in">unique</span>(p.<span class="built_in">begin</span>(), p.<span class="built_in">end</span>(),<span class="built_in">is_sam</span>()),p.<span class="built_in">end</span>());</span><br></pre></td></tr></table></figure><p>unique å‡½æ•°çš„åŠŸèƒ½åªæ˜¯å°†æ»¡è¶³æ¡ä»¶çš„æ•°æ®ç­›é€‰å‡ºæ¥ï¼Œæ— æ³•ç›´æ¥åˆ é™¤ï¼Œéœ€è¦ç»“åˆ vector çš„ erase å‡½æ•°è¿›è¡Œåˆ é™¤</p><h2 id="å»ºç«‹-CUDA-çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—"><a href="#å»ºç«‹-CUDA-çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—" class="headerlink" title="å»ºç«‹ CUDA çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—"></a>å»ºç«‹ CUDA çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—</h2><p>ä¸‹é¢çš„ç¨‹åºä¸ºå¤§å®¶æ¼”ç¤ºä»¥ç»“æ„ä½“ç±»å‹å­˜å‚¨çš„çŸ©é˜µè®¡ç®—ï¼Œåç»­ç« èŠ‚ä¼šæ•™å¤§å®¶ä½¿ç”¨ cuBLAS åº“è¿›è¡Œå¹¶è¡Œè®¡ç®—</p><h3 id="çŸ©é˜µåŠ æ³•"><a href="#çŸ©é˜µåŠ æ³•" class="headerlink" title="çŸ©é˜µåŠ æ³•"></a>çŸ©é˜µåŠ æ³•</h3><p>ä¸‹é¢çš„ç¨‹åºè¿›è¡Œäº† $C = A + B$ çŸ©é˜µåŠ æ³•è¿ç®—ï¼Œä¸‹é¢çš„ç¨‹åºä¸­ä½¿ç”¨äº†<code>cudaMallocManaged</code>å‡½æ•°ï¼Œç®€å•æ¥è¯´ï¼Œå°±æ˜¯ç»“åˆäº†ä¹‹å‰è®²åˆ°çš„<code>cudaMalloc</code>å’Œ<code>cudaMemcpy</code>ç­‰å†…å­˜è¿ç§»æ‹·è´çš„æ“ä½œï¼Œè‡ªåŠ¨å†…å­˜ç®¡ç†ï¼Œæ–¹ä¾¿ä»£ç ç¼–å†™ï¼Œå¼Šç«¯æ˜¯åœ¨ kernel æ‰§è¡Œæ—¶ä¼šé™ä½ kernel çš„æ‰§è¡Œæ•ˆç‡ï¼Œåœ¨åç»­ç« èŠ‚ï¼Œæˆ‘ä»¬ä¼šè¯¦ç»†è®²è§£æœ‰å…³ CUDA çš„å†…å­˜ç®¡ç†</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Matrix</span> &#123;</span><br><span class="line">    <span class="type">int</span> w;</span><br><span class="line">    <span class="type">int</span> h;</span><br><span class="line">    <span class="type">float</span> *v;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">float</span> <span class="title">getValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> A-&gt;v[row * A-&gt;w + col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">setValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col, <span class="type">float</span> v)</span> </span>&#123;</span><br><span class="line">        A-&gt;v[row * A-&gt;w + col] = v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatrixAdd</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, <span class="built_in">getValue</span>(A, row, col) + <span class="built_in">getValue</span>(B, row, col));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    Matrix *A, *B, *C;</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="type">int</span> nBytes = w * h * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C-&gt;v, nBytes);</span><br><span class="line"></span><br><span class="line">    A-&gt;h = h;</span><br><span class="line">    A-&gt;w = w;</span><br><span class="line">    B-&gt;h = h;</span><br><span class="line">    B-&gt;w = w;</span><br><span class="line">    C-&gt;h = h;</span><br><span class="line">    C-&gt;w = w;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; w * h; ++i) &#123;</span><br><span class="line">        A-&gt;v[i] = <span class="number">1.0</span>;</span><br><span class="line">        B-&gt;v[i] = <span class="number">2.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">gridSize</span><span class="params">((w + blockSize.x - <span class="number">1</span>) / blockSize.x, (h + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line">    MatrixAdd &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A, B, C);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="çŸ©é˜µä¹˜æ³•"><a href="#çŸ©é˜µä¹˜æ³•" class="headerlink" title="çŸ©é˜µä¹˜æ³•"></a>çŸ©é˜µä¹˜æ³•</h3><p>ä¸‹é¢çš„ç¨‹åºè¿›è¡Œäº† $C = A * B$ çŸ©é˜µä¹˜æ³•è¿ç®—</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatrixMul</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line">        <span class="type">float</span> k = <span class="number">0.0</span>;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;A-&gt;w; i++)</span><br><span class="line">                k += <span class="built_in">getValue</span>(A, row, i) * <span class="built_in">getValue</span>(B, i, col);</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, k);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">    MatrixMul &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A, B, C);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶"><a href="#ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶" class="headerlink" title="ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶"></a>ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶</h2><h3 id="nvprof"><a href="#nvprof" class="headerlink" title="nvprof"></a>nvprof</h3><p>nvprof æ˜¯è¿‡å»æ¯”è¾ƒå¸¸ç”¨çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œä½†åœ¨ç»ˆç«¯ç›´æ¥è¾“å…¥<code>nvprof ./*.o</code>ä¼šå¾—åˆ°ä»¥ä¸‹ Warning</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">======== Warning: nvprof is not supported on devices with compute capability 8.0 and higher.</span><br><span class="line">                  Use NVIDIA Nsight Systems for GPU tracing and CPU sampling and NVIDIA Nsight Compute for GPU profiling.</span><br><span class="line">                  Refer https://developer.nvidia.com/tools-overview for more details.</span><br></pre></td></tr></table></figure><p>ç›®å‰ä¸»æµçš„ CUDA é©±åŠ¨ä¸å†æ”¯æŒ<code>nvprof</code>å‘½ä»¤ï¼Œä½†æˆ‘ä»¬ä»å¯ä»¥åœ¨ NVIDIA Nsight Systems ä¸­ä½¿ç”¨ï¼Œåœ¨ç»ˆç«¯è¾“å…¥ <code>nsys nvprof ./*.o</code>å°±å¯ä»¥çœ‹åˆ°CUDA ç¨‹åºæ‰§è¡Œçš„å…·ä½“å†…å®¹</p><p>è¿™é‡Œæˆ‘ä»¬ä»¥ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´çš„ä¸¤ä¸ªç¨‹åºä¸ºä¾‹</p><p>ä½¿ç”¨<code>cudaMalloc</code>å‡½æ•°çš„ç¨‹åº</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">WARNING: 1d.o and any of its children processes will be profiled.</span><br><span class="line"></span><br><span class="line">96</span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: 96</span><br><span class="line">23 34 56 76 11 23 45 45 12 22 47 47 9 45 56 65 20 37 55 75 0 0 0 0 </span><br><span class="line">done.</span><br><span class="line">Generating &#x27;/tmp/nsys-report-01f4.qdstrm&#x27;</span><br><span class="line">[1/7] [========================100%] report5.nsys-rep</span><br><span class="line">[2/7] [========================100%] report5.sqlite</span><br><span class="line">[3/7] Executing &#x27;nvtxsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report5.sqlite does not contain NV Tools Extension (NVTX) data.</span><br><span class="line">[4/7] Executing &#x27;cudaapisum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)     Name   </span><br><span class="line"> --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ----------</span><br><span class="line">     99.9        137542088          1  137542088.0  137542088.0  137542088  137542088          0.0  cudaMalloc</span><br><span class="line">      0.1           163239          1     163239.0     163239.0     163239     163239          0.0  cudaFree  </span><br><span class="line">      0.0            36460          2      18230.0      18230.0      18070      18390        226.3  cudaMemcpy</span><br><span class="line"></span><br><span class="line">[5/7] Executing &#x27;gpukernsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report5.sqlite does not contain CUDA kernel data.</span><br><span class="line">[6/7] Executing &#x27;gpumemtimesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     </span><br><span class="line"> --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">     51.6             1504      1    1504.0    1504.0      1504      1504          0.0  [CUDA memcpy HtoD]</span><br><span class="line">     48.4             1408      1    1408.0    1408.0      1408      1408          0.0  [CUDA memcpy DtoH]</span><br><span class="line"></span><br><span class="line">[7/7] Executing &#x27;gpumemsizesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     </span><br><span class="line"> ----------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoH]</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy HtoD]</span><br><span class="line"></span><br><span class="line">Generated:</span><br><span class="line">    /root/report5.nsys-rep</span><br><span class="line">    /root/report5.sqlite</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨<code>cudaMallocPitch</code>å‡½æ•°çš„ç¨‹åº</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">WARNING: 2d.o and any of its children processes will be profiled.</span><br><span class="line"></span><br><span class="line">96</span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: 96</span><br><span class="line">23 34 56 76 11 23 45 45 12 22 47 47 9 45 56 65 20 37 55 75 0 0 0 0 </span><br><span class="line">done.</span><br><span class="line">Generating &#x27;/tmp/nsys-report-6614.qdstrm&#x27;</span><br><span class="line">[1/7] [========================100%] report6.nsys-rep</span><br><span class="line">[2/7] [========================100%] report6.sqlite</span><br><span class="line">[3/7] Executing &#x27;nvtxsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report6.sqlite does not contain NV Tools Extension (NVTX) data.</span><br><span class="line">[4/7] Executing &#x27;cudaapisum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)       Name      </span><br><span class="line"> --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ---------------</span><br><span class="line">    100.0        745692893          1  745692893.0  745692893.0  745692893  745692893          0.0  cudaMallocPitch</span><br><span class="line">      0.0           161820          1     161820.0     161820.0     161820     161820          0.0  cudaFree       </span><br><span class="line">      0.0            39090          2      19545.0      19545.0      16590      22500       4179.0  cudaMemcpy2D   </span><br><span class="line"></span><br><span class="line">[5/7] Executing &#x27;gpukernsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report6.sqlite does not contain CUDA kernel data.</span><br><span class="line">[6/7] Executing &#x27;gpumemtimesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     </span><br><span class="line"> --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">     64.8             2880      1    2880.0    2880.0      2880      2880          0.0  [CUDA memcpy HtoD]</span><br><span class="line">     35.2             1567      1    1567.0    1567.0      1567      1567          0.0  [CUDA memcpy DtoH]</span><br><span class="line"></span><br><span class="line">[7/7] Executing &#x27;gpumemsizesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     </span><br><span class="line"> ----------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoH]</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy HtoD]</span><br><span class="line"></span><br><span class="line">Generated:</span><br><span class="line">    /root/report6.nsys-rep</span><br><span class="line">    /root/report6.sqlite</span><br></pre></td></tr></table></figure><p>è¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°<code>Total Time</code>ä¸­<code>cudaMallocPitch</code>å‡½æ•°ç”¨æ—¶å‡ ä¹æ˜¯<code>cudaMalloc</code>çš„ 5 å€ï¼Œæ›´åŠ è‚¯å®šäº†æˆ‘ä»¬çš„è¯´æ³•ï¼Œ<code>cudaMallocPitch</code>å’Œ<code>cudaMemcpy2D</code>éœ€è¦é¢å¤–å¯¹äºŒç»´æ•°æ®è¿›è¡Œå¯¹é½æ“ä½œ</p><h3 id="cudaEvent-è®¡æ—¶å‡½æ•°"><a href="#cudaEvent-è®¡æ—¶å‡½æ•°" class="headerlink" title="cudaEvent è®¡æ—¶å‡½æ•°"></a>cudaEvent è®¡æ—¶å‡½æ•°</h3><p>ä»¥å‰é¢çš„çŸ©é˜µä¹˜æ³•ä¸ºä¾‹ï¼Œåˆ†åˆ«è®¡ç®— CUDA å¼€è¾Ÿå†…å­˜æ—¶é—´å’ŒçŸ©é˜µä¹˜æ³•è¿ç®—æ—¶é—´</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    Matrix *A, *B, *C;</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">float</span> elapsedTime = <span class="number">0.0</span>;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="type">int</span> nBytes = w * h * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C-&gt;v, nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;cudaMalloc cost: &quot;</span> &lt;&lt; elapsedTime &lt;&lt; <span class="string">&quot;s&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    </span><br><span class="line">    A-&gt;h = h;</span><br><span class="line">    A-&gt;w = w;</span><br><span class="line">    B-&gt;h = h;</span><br><span class="line">    B-&gt;w = w;</span><br><span class="line">    C-&gt;h = h;</span><br><span class="line">    C-&gt;w = w;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; w * h; ++i) &#123;</span><br><span class="line">        A-&gt;v[i] = <span class="number">1.0</span>;</span><br><span class="line">        B-&gt;v[i] = <span class="number">2.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">gridSize</span><span class="params">((w + blockSize.x - <span class="number">1</span>) / blockSize.x, (h + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line"></span><br><span class="line">    elapsedTime = <span class="number">0.0</span>;</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    MatrixMul &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A, B, C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Matrix multiplication cost: &quot;</span> &lt;&lt; elapsedTime &lt;&lt; <span class="string">&quot;s&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(stop);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line">cudaMalloc cost: <span class="number">0.161696</span>s</span><br><span class="line">Matrix multiplication cost: <span class="number">0</span>s</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰</title>
      <link href="/p/9aa59e2e/"/>
      <url>/p/9aa59e2e/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è¯¦ç»†è®²è§£å…±äº«å†…å­˜å­˜å‚¨ä½“ã€å­˜å‚¨ä½“å†²çªã€è®¿é—®æ¨¡å¼ä»¥åŠå†…å­˜å¡«å……ç­‰çŸ¥è¯†ç‚¹ã€‚</p><span id="more"></span><h2 id="CUDA-å…±äº«å†…å­˜"><a href="#CUDA-å…±äº«å†…å­˜" class="headerlink" title="CUDA å…±äº«å†…å­˜"></a>CUDA å…±äº«å†…å­˜</h2><p>GPU çš„ç‰©ç†å†…å­˜å¯ä»¥åˆ†ä¸º</p><ul><li>æ¿è½½å†…å­˜</li><li>ç‰‡ä¸Šå†…å­˜</li></ul><p>å…¨å±€å†…å­˜å°±æ˜¯æ¿è½½å†…å­˜ï¼Œæœ‰è¾ƒé«˜çš„å»¶æ—¶ï¼›å…±äº«å†…å­˜å°±æ˜¯è¾ƒå°çš„ç‰‡ä¸Šå†…å­˜ ï¼Œæœ‰è¾ƒä½çš„å»¶æ—¶ã€‚å…±äº«æœ‰æ¯”å…¨å±€å†…å­˜æ›´é«˜çš„å¸¦å®½ï¼Œå¯ä»¥æŠŠå®ƒå½“ä½œä¸€ä¸ªå¯ç¼–ç¨‹çš„ç¼“å­˜ã€‚å…±äº«å†…å­˜é€šå¸¸çš„ç”¨é€”æœ‰</p><ul><li>å—å†…çº¿ç¨‹é€šä¿¡çš„é€šé“</li><li>ç”¨äºå…¨å±€å†…å­˜æ•°æ®çš„å¯ç¼–ç¨‹ç®¡ç†çš„ç¼“å­˜</li><li>é«˜é€Ÿæš‚å­˜å­˜å‚¨å™¨ï¼Œç”¨äºè½¬æ¢æ•°æ®ï¼Œä¼˜åŒ–å…¨å±€å†…å­˜è®¿é—®æ¨¡å¼</li></ul><p>å…±äº«å†…å­˜ï¼ˆShared Memory, SMEMï¼‰ï¼Œåœ¨ GPU ä¸­çš„ä½ç½®å¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/1.webp" alt=""></p><p>æ¯ä¸ª SM éƒ½æœ‰ä¸€ä¸ªå°çš„å†…å­˜æ± ï¼Œè¿™ä¸ªå†…å­˜æ± è¢«å½“å‰æ­£åœ¨è¯¥ SM ä¸Šæ‰§è¡Œçš„çº¿ç¨‹å—ä¸­çš„æ‰€æœ‰çº¿ç¨‹æ‰€å…±äº«ã€‚SMEM ä½¿åŒä¸€ä¸ªçº¿ç¨‹å—ä¸­çš„çº¿ç¨‹èƒ½å¤Ÿäº’ç›¸åä½œï¼Œä»¥é‡ç”¨ç‰‡ä¸Šæ•°æ®ï¼Œå¹¶å¯ä»¥å¤§å¤§é™ä½æ ¸å‡½æ•°æ‰€éœ€çš„å…¨å±€å†…å­˜å¸¦å®½ã€‚ç”±äº SMEM ä¸­çš„å†…å®¹æ˜¯ç”±åº”ç”¨ç¨‹åºæ˜¾å¼ç®¡ç†çš„ï¼Œæ‰€ä»¥æ˜¯å¯ç¼–ç¨‹ç®¡ç†çš„ç¼“å­˜</p><p>ä¸Šå›¾å¯ä»¥çœ‹åˆ° SMEM ä¸éœ€è¦ç»è¿‡ L1ï¼Œç›¸æ¯” DRAMï¼Œå»¶è¿Ÿä½ 20~30 å€ï¼Œå¸¦å®½ä¸º DRAM çš„ 10å€</p><p>åœ¨æ¯ä¸ªçº¿ç¨‹å—è¢«æ‰§è¡Œæ—¶ä¼šåˆ†é…ç»™å®ƒä¸€äº› SMEMï¼Œçº¿ç¨‹å—æ‰§è¡Œå®Œæ¯•å SMEM é‡Šæ”¾ï¼Œçº¿ç¨‹å—å’Œå®ƒçš„ SMEM æœ‰ç›¸åŒçš„ç”Ÿå‘½å‘¨æœŸã€‚æ¯ä¸ªçº¿ç¨‹æŸå¯¹ SMEM çš„è®¿é—®è¯·æ±‚åˆ†ä¸ºä»¥ä¸‹å‡ ç§æƒ…å†µ</p><ul><li><p>æœ€å¥½çš„æƒ…å†µæ˜¯å½“å‰çº¿ç¨‹æŸä¸­çš„æ¯ä¸ªçº¿ç¨‹éƒ½è®¿é—®ä¸€ä¸ªä¸å†²çªçš„å…±äº«å†…å­˜ï¼Œä¸€ä¸ªäº‹åŠ¡å®Œæˆæ•´ä¸ªçº¿ç¨‹æŸçš„è®¿é—®</p></li><li><p>æœ€åçš„æƒ…å†µæ˜¯æœ‰å†²çªè®¿é—®ï¼Œæ¯ä¸ªçº¿ç¨‹æŸçš„ 32 ä¸ªçº¿ç¨‹éœ€è¦ä¸åŒçš„ 32 ä¸ªäº‹åŠ¡æ¥å®Œæˆ</p></li><li><p>å¦‚æœçº¿ç¨‹æŸå†… 32 ä¸ªçº¿ç¨‹è®¿é—® SMEM ä¸­çš„åŒä¸€ä¸ªåœ°å€ï¼Œé‚£ä¹ˆä¸€ä¸ªçº¿ç¨‹è®¿é—®å®Œåä»¥å¹¿æ’­çš„å½¢å¼å‘Šè¯‰å…¶å®ƒçº¿ç¨‹</p></li></ul><p>ä¸€ä¸ª SM ä¸Šçš„æ‰€æœ‰çš„æ­£åœ¨æ‰§è¡Œçš„çº¿ç¨‹å—å…±ä¼šåˆ’åˆ†æœ‰é™çš„ SMEM èµ„æºï¼Œæ‰€ä»¥æ ¸å‡½æ•°ä½¿ç”¨çš„å…±äº«å†…å­˜è¶Šå¤šï¼Œé‚£ä¹ˆå¤„äºå¹¶å‘æ´»è·ƒçŠ¶æ€çš„çº¿ç¨‹å—å°±è¶Šå°‘</p><p>ä¸‹é¢å°†å›´ç»•é¿å… SMEM ä¸­å¤šä¸ªäº‹åŠ¡è®¿é—®å†²çªçš„é—®é¢˜å±•å¼€è®¨è®º</p><h3 id="å…±äº«å†…å­˜åˆ†é…"><a href="#å…±äº«å†…å­˜åˆ†é…" class="headerlink" title="å…±äº«å†…å­˜åˆ†é…"></a>å…±äº«å†…å­˜åˆ†é…</h3><p>å¯ä»¥åŠ¨æ€çš„æˆ–é™æ€çš„å£°æ˜ä½¿ç”¨å…±äº«å†…å­˜çš„å˜é‡ã€‚å…±äº«å†…å­˜å˜é‡åœ¨æ ¸å‡½æ•°ä¸­å£°æ˜ï¼Œä½œç”¨åŸŸå°±åªåœ¨æ ¸å‡½æ•°ä¸­ï¼Œåœ¨æ ¸å‡½æ•°å¤–å£°æ˜ï¼Œå¯¹æ‰€æœ‰æ ¸å‡½æ•°æ¥è¯´ä½œç”¨åŸŸéƒ½æ˜¯å…¨å±€çš„ï¼Œæˆ‘ä»¬å¯ä»¥å£°æ˜ä¸€ç»´ï¼ŒäºŒç»´å’Œä¸‰ç»´çš„å…±äº«å†…å­˜æ•°ç»„</p><p>ä½¿ç”¨<code>__shared__</code>ä¿®é¥°ç¬¦æ¥å£°æ˜å…±äº«å†…å­˜å˜é‡ï¼Œä¸‹é¢å£°æ˜äº†ä½¿ç”¨å…±äº«å†…å­˜çš„ä¸€ç»´ï¼ŒäºŒç»´å’Œä¸‰ç»´æµ®ç‚¹æ•°ç»„</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="type">float</span> a[*];</span><br><span class="line">__shared__ <span class="type">float</span> b[*][*];</span><br><span class="line">__shared__ <span class="type">float</span> c[*][*][*];</span><br></pre></td></tr></table></figure><p>è¿™é‡Œçš„ <code>*</code> å¿…é¡»æ˜¯ä¸€ä¸ªç¼–è¯‘æ—¶ç¡®å®šçš„æ•°å­—ï¼Œä¸èƒ½æ˜¯å˜é‡ï¼Œå¦‚æœå…±äº«å†…å­˜çš„å¤§å°åœ¨ç¼–è¯‘æ—¶æ˜¯æœªçŸ¥çš„ï¼Œä¹Ÿå°±æ˜¯åŠ¨æ€å£°æ˜ä¸€ä¸ªå…±äº«å†…å­˜æ•°ç»„ï¼Œä½¿ç”¨<code>extern</code>å…³é”®å­—<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">int</span> d[];</span><br></pre></td></tr></table></figure></p><p>å¹¶å°†æ‰€éœ€çš„å¤§å°æŒ‰å­—èŠ‚æ•°ä½œä¸ºä¸‰é‡æ‹¬å·å†…çš„ç¬¬ä¸‰ä¸ªå‚æ•°ï¼Œ<code>isize</code>ä¸ºæ•°ç»„çš„ä¸­çš„å…ƒç´ ä¸ªæ•°</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel&lt;&lt;&lt;grid, block, <span class="function">isize * <span class="title">sizeof</span><span class="params">(<span class="type">float</span>)</span>&gt;&gt;&gt;<span class="params">(...)</span></span>;</span><br></pre></td></tr></table></figure><p>æ³¨æ„è¿™é‡Œçš„åŠ¨æ€å£°æ˜åªæ”¯æŒä¸€ç»´æ•°ç»„</p><h3 id="å…±äº«å†…å­˜å­˜å‚¨ä½“å’Œè®¿é—®æ¨¡å¼"><a href="#å…±äº«å†…å­˜å­˜å‚¨ä½“å’Œè®¿é—®æ¨¡å¼" class="headerlink" title="å…±äº«å†…å­˜å­˜å‚¨ä½“å’Œè®¿é—®æ¨¡å¼"></a>å…±äº«å†…å­˜å­˜å‚¨ä½“å’Œè®¿é—®æ¨¡å¼</h3><p>ä¼˜åŒ–å†…å­˜æ€§èƒ½çš„ç€é‡æŒ‡æ ‡å°±æ˜¯</p><ul><li>å»¶æ—¶</li><li>å¸¦å®½</li></ul><p>ä¸Šé¢æåˆ°ï¼Œå…±äº«å†…å­˜éšè—äº†å…¨å±€å†…å­˜å»¶è¿Ÿï¼Œå¹¶ä¸”å¤§å¤§æé«˜äº†å¸¦å®½ï¼Œæ‰€ä»¥äº†è§£å…±äº«å†…å­˜çš„åŸç†å’Œç‰¹æ€§ä¼šè®©æˆ‘ä»¬æ›´ä¸ºæ¸…æ™°åœ°ä½¿ç”¨å…±äº«å†…å­˜</p><h4 id="å…±äº«å†…å­˜å­˜å‚¨ä½“-bank"><a href="#å…±äº«å†…å­˜å­˜å‚¨ä½“-bank" class="headerlink" title="å…±äº«å†…å­˜å­˜å‚¨ä½“ (bank)"></a>å…±äº«å†…å­˜å­˜å‚¨ä½“ (bank)</h4><p>ä¸ºäº†è·å¾—é«˜å†…å­˜å¸¦å®½ï¼Œå…±äº«å†…å­˜è¢«åˆ†ä¸º 32 ä¸ªåŒæ ·å¤§å°çš„å†…å­˜æ¨¡å‹ï¼Œç§°ä¸ºå­˜å‚¨ä½“ï¼ˆbankï¼‰ï¼Œå¯¹åº”ä¸€ä¸ªçº¿ç¨‹æŸä¸­çš„ 32 ä¸ªçº¿ç¨‹ï¼Œå­˜å‚¨ä½“å¯ä»¥åŒæ—¶è¢«è®¿é—®ã€‚å¹¶ä¸”å…±äº«å†…å­˜æ˜¯ä¸€ä¸ªä¸€ç»´åœ°å€ç©ºé—´ã€‚æ ¹æ® GPU çš„è®¡ç®—èƒ½åŠ›ï¼Œå…±äº«å†…å­˜çš„åœ°å€åœ¨ä¸åŒæ¨¡å¼ä¸‹ä¼šæ˜ å°„åˆ°ä¸åŒçš„å­˜å‚¨ä½“ä¸­ã€‚</p><h4 id="å­˜å‚¨ä½“å†²çªï¼ˆbank-conflictï¼‰"><a href="#å­˜å‚¨ä½“å†²çªï¼ˆbank-conflictï¼‰" class="headerlink" title="å­˜å‚¨ä½“å†²çªï¼ˆbank conflictï¼‰"></a>å­˜å‚¨ä½“å†²çªï¼ˆbank conflictï¼‰</h4><p>å¦‚æœçº¿ç¨‹æŸå¯¹å…±äº«å†…å­˜æœ‰æ“ä½œï¼Œä¸”åœ¨ä¸ªå­˜å‚¨ä½“ä¸Šåªè¯·æ±‚è®¿é—®æœ€å¤šä¸€æ¬¡ï¼Œé‚£ä¹ˆå°±ç”±ä¸€ä¸ªå†…å­˜äº‹åŠ¡æ¥å®Œæˆï¼Œå¦‚æœçº¿ç¨‹æŸåœ¨ä»»æ„ä¸€ä¸ªå­˜å‚¨ä½“ä¸Šè¯·æ±‚è®¿é—®å¤§äºä¸€æ¬¡ï¼Œå°±ä¼šç”±å¤šä¸ªå†…å­˜äº‹åŠ¡æ¥å®Œæˆï¼Œç§°ä¸ºå­˜å‚¨ä½“å†²çªï¼ˆbank conflictï¼‰</p><p>bank conflict ä¼šå¯¼è‡´è¯·æ±‚è¢«é‡å¤æ‰§è¡Œï¼ŒGPU ä¼šå°†å­˜å‚¨ä½“å†²çªçš„è¯·æ±‚è®¿é—®åˆ†å‰²åˆ°å°½å¯èƒ½å¤šçš„ç‹¬ç«‹çš„æ— å†²çªäº‹åŠ¡ä¸­ï¼Œè€Œç‹¬ç«‹å†…å­˜äº‹åŠ¡çš„æ•°é‡ä¼šç›´æ¥å½±å“å†…å­˜å¸¦å®½</p><p>çº¿ç¨‹æŸè®¿é—®å…±äº«å†…å­˜æ—¶æœ‰ä»¥ä¸‹ä¸‰ç§æ¨¡å¼</p><ul><li><p>å¹¶è¡Œè®¿é—®ï¼Œå¤šåœ°å€è®¿é—®å¤šå­˜å‚¨ä½“ï¼Œå¸¦å®½åˆ©ç”¨ç‡æœ€é«˜</p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºæ˜¯æœ€å®Œç¾çš„æƒ…å†µï¼Œçº¿ç¨‹æŸä¸­æ¯ä¸ªçº¿ç¨‹å¯¹åº”ä¸€ä¸ªå­˜å‚¨ä½“</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/2.webp" alt=""></p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºä¸ºä¸è§„åˆ™çš„è®¿é—®æ¨¡å¼ï¼Œå¹¶è¡Œå´ä¸å†²çªï¼Œå¸¦å®½åˆ©ç”¨ç‡ä¹Ÿæ˜¯æœ€é«˜</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/3.webp" alt=""></p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºåŒæ ·ä¸ºä¸è§„åˆ™çš„è®¿é—®æ¨¡å¼ï¼Œä½†å¦‚æœçº¿ç¨‹è®¿é—®çš„æ˜¯åŒä¸€ä¸ªå­˜å‚¨ä½“ä¸­ç›¸åŒçš„åœ°å€ï¼Œå¹¿æ’­è®¿é—®å°±ä¸ä¼šå†²çªï¼Œå¦‚æœçº¿ç¨‹è®¿é—®çš„æ˜¯åŒä¸€ä¸ªå­˜å‚¨ä½“ä¸­ä¸åŒçš„åœ°å€ï¼Œå°±ä¼šäº§ç”Ÿå†²çª</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/4.webp" alt=""></p></li><li><p>ä¸²è¡Œè®¿é—®ï¼Œå¤šåœ°å€è®¿é—®åŒä¸€å­˜å‚¨ä½“ï¼Œå°±ä¼šæœ‰å¯¹åº” 32 ä¸ªçº¿ç¨‹çš„ 32 ä¸ªäº‹åŠ¡ï¼Œå¸¦å®½åˆ©ç”¨ç‡æœ€å·®</p></li><li><p>å¹¿æ’­è®¿é—®ï¼Œå•ä¸€åœ°å€è¯»å–å•ä¸€å­˜å‚¨ä½“ï¼Œçº¿ç¨‹æŸä¸­æ‰€æœ‰çš„çº¿ç¨‹éƒ½è¯»å–åŒä¸€å­˜å‚¨ä½“ä¸­ç›¸åŒçš„åœ°å€ã€‚ä¸€ä¸ªå†…å­˜äº‹åŠ¡æ‰§è¡Œåï¼Œé‚£ä¹ˆè¢«è®¿é—®çš„å­—å°±ä¼šè¢«å¹¿æ’­åˆ°æ‰€æœ‰è¯·æ±‚çš„çº¿ç¨‹ä¸­ã€‚è™½ç„¶åªæœ‰ä¸€ä¸ªå†…å­˜äº‹åŠ¡ï¼Œä½†åªæœ‰ä¸€å°éƒ¨åˆ†å­—èŠ‚è¢«è¯»å–ï¼Œæ‰€ä»¥å¸¦å®½åˆ©ç”¨ç‡å¾ˆå·®</p></li></ul><h4 id="è®¿é—®æ¨¡å¼"><a href="#è®¿é—®æ¨¡å¼" class="headerlink" title="è®¿é—®æ¨¡å¼"></a>è®¿é—®æ¨¡å¼</h4><p>å…±äº«å†…å­˜å­˜å‚¨ä½“å®½åº¦ï¼ˆbank widthsï¼‰ç›´æ¥å½±å“è®¿é—®æ¨¡å¼ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªå­˜å‚¨ä½“ï¼ˆbankï¼‰åœ¨ä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå†…çš„å¸¦å®½ï¼Œåœ¨è®¡ç®—èƒ½åŠ› 1.x çš„è®¾å¤‡ä¸­ bank widths ä¸º 2 å­—èŠ‚ï¼ˆ16 ä½ï¼‰ï¼Œè®¡ç®—èƒ½åŠ› 2.x çš„è®¾å¤‡ä¸­ä¸º  4  å­—èŠ‚ï¼ˆ32 ä½wjgï¼‰ï¼Œè®¡ç®—èƒ½åŠ› 3.x ä»¥ä¸Šçš„è®¾å¤‡ä¸­ä¸º 8 å­—èŠ‚ï¼ˆ64 ä½ï¼‰</p><p>å¯¹äºè®¡ç®—èƒ½åŠ›ä¸º 2.0 çš„è®¾å¤‡æ¥è¯´ï¼Œbank widths ä¸º 32 ä½ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºå°±æ˜¯å…±äº«å†…å­˜çš„å­˜å‚¨ä½“çš„è®¿é—®æ¨¡å¼ï¼Œå­—èŠ‚åœ°å€é™¤ä»¥ 4 è½¬æ¢ä¸º 4 å­—èŠ‚ç´¢å¼•ï¼Œå†æ¨¡ 32ï¼Œå°† 4 å­—èŠ‚ç´¢å¼•è½¬æ¢ä¸ºå­˜å‚¨ä½“ç´¢å¼•</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/5.webp" alt=""></p><p>ä¸Šé¢çš„æ“ä½œå¯¹åº”å¦‚ä¸‹å…¬å¼</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bank index = (Byte address Ã· <span class="number">4</span> byte/bank) % <span class="number">32</span> banks</span><br></pre></td></tr></table></figure><p>ç°ä»Šçš„ GPU åŒæ—¶æ”¯æŒ 64 ä½æ¨¡å¼å’Œ 32 ä½æ¨¡å¼ã€‚å¦‚æœä¸º 64 ä½æ¨¡å¼ï¼Œç”±äº SMEM åªæœ‰ 32 ä¸ª bankï¼Œæ‰€ä»¥æ¯ä¸ª bank ä¸­çš„åœ°å€ä¼šè¢«é€»è¾‘åˆ†æˆä¸¤ä¾§ï¼Œæ¯ä¸ªæ—¶é’Ÿå‘¨æœŸå†…çš„æ¯ä¸ª bank éƒ½æœ‰ 64 ä½çš„å¸¦å®½ï¼Œå…¬å¼ä¸­çš„<code>byte/bank</code>å°±æ˜¯ 8ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºæ˜¯ 64 ä½æ¨¡å¼çš„å‡ ç§æƒ…å†µï¼Œè¿™ä¹Ÿè§£é‡Šäº†ä¸ºä»€ä¹ˆç›¸æ¯” 32 ä½æ¨¡å¼ï¼Œå…¶æ›´ä¸å®¹æ˜“å¼•èµ·å†²çª</p><ul><li><p>æ¯ä¸ªçº¿ç¨‹è®¿é—®ä¸åŒçš„ bankï¼Œæ—  bank conflict</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/7.webp" alt=""></p></li><li><p>å¤šä¸ªçº¿ç¨‹è®¿é—®ä¸€ä¸ª bank ä¸­åŒä¸€ä¾§çš„åŒä¸€ä¸ªåœ°å€ï¼Œåœ°å€ä¼šå¹¿æ’­åˆ°æ‰€æœ‰çº¿ç¨‹ï¼›ä¸¤ä¸ªçº¿ç¨‹è®¿é—®åŒä¸€ä¸ª bankï¼Œæ‰€ä»¥ä¼šæ—  bank conflict</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/8.webp" alt=""></p></li><li><p>ä¸¤ä¸ªçº¿ç¨‹è®¿é—®åŒä¸€ä¸ªå­˜å‚¨ä½“çš„åŒä¸€ä¾§ï¼Œä¸º bank conflict</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/9.webp" alt=""></p></li><li><p>åŒä¸€ä¸ª bank çš„å·¦ä¾§è¢«ä¸¤ä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®äº†ä¸åŒçš„åœ°å€ï¼Œä¼šå¯¼è‡´ä¸‰å‘çš„ bank conflict</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/10.webp" alt=""></p></li></ul><p>åœ¨ç°ä»Š GPU çš„ 32 ä½æ¨¡å¼ä¸‹ï¼Œç”±äº GPU çš„æ¯ä¸ªæ—¶é’Ÿå‘¨æœŸéƒ½æ˜¯ 64 å¸¦å®½ï¼Œæ‰€ä»¥ bank ä¸­ 32 ä½çš„æ•°æ®éœ€è¦ 2 ä¸ªæ—¶é’Ÿå‘¨æœŸæ‰èƒ½å‡‘å¤Ÿ 64 ä½ï¼Œè¿™ä¹Ÿå°±ä½¿å¾—ä¸¤ä¸ªçº¿ç¨‹è¯»åŒä¸€ä¸ª bank æ—¶ï¼Œå¦‚æœè¯»å–çš„ä¸¤ä¸ªåœ°å€ç´¢å¼•åˆ†åˆ«åœ¨ä¸¤ä¸ªä¸åŒçš„æ—¶é’Ÿå‘¨æœŸè¢«ä¼ è¾“ï¼Œå°±ä¸ä¼šäº§ç”Ÿå†²çªï¼Œä¾‹å¦‚ä¸¤ä¸ªçº¿ç¨‹å¯ä»¥è¯»<code>4-byte word index</code>ä¸º 0 å’Œ 32 çš„ä¸¤ä¸ªåœ°å€ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/6.webp" alt=""></p><p>cuda_runtime.h æä¾›äº†å¦‚ä¸‹å‡½æ•°è®¾ç½®å½“å‰å…±äº«å†…å­˜è®¿é—®æ¨¡å¼</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaDeviceSetSharedMemConfig</span> <span class="params">( cudaSharedMemConfig config )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>config</code>: è¯·æ±‚çš„ç¼“å­˜é…ç½®ï¼Œæšä¸¾ç±»å‹ï¼Œæœ‰å¦‚ä¸‹å€¼<ul><li><code>cudaSharedMemBankSizeDefault = 0</code>: è®¾ç½® bank widths ä¸ºè®¾å¤‡é»˜è®¤å€¼</li><li><code>cudaSharedMemBankSizeFourByte = 1</code>: è®¾ç½® bank widths ä¸º 4 å­—èŠ‚ï¼ˆ32 ä½ï¼‰</li><li><code>cudaSharedMemBankSizeEightByte = 2</code>: è®¾ç½® bank widths ä¸º 8 å­—èŠ‚ï¼ˆ64 ä½ï¼‰</li></ul></li></ul><blockquote><p>æ³¨æ„<code>cudaDeviceSetSharedMemConfig</code>å‡½æ•°åœ¨å›ºå®šå…±äº«å†…å­˜å¤§å°çš„è®¾å¤‡ä¸Šæ— ä½œç”¨</p></blockquote><p>å¦‚ä¸‹å‡½æ•°æŸ¥è¯¢å½“å‰å…±äº«å†…å­˜è®¿é—®æ¨¡å¼</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaDeviceGetSharedMemConfig</span> <span class="params">( cudaSharedMemConfig ** pConfig )</span></span></span><br></pre></td></tr></table></figure><p><code>pConfig</code>: è¿”å›çš„ç¼“å­˜é…ç½®ï¼Œæšä¸¾ç±»å‹ï¼Œæœ‰å¦‚ä¸‹å€¼</p><ul><li><code>cudaSharedMemBankSizeFourByte = 1</code>: bank widths ä¸º 4 å­—èŠ‚ï¼ˆ32 ä½ï¼‰</li><li><code>cudaSharedMemBankSizeEightByte = 2</code>: bank widths ä¸º 8 å­—èŠ‚ï¼ˆ64 ä½ï¼‰</li></ul><p>åœ¨ä¸åŒçš„æ ¸å‡½æ•°å¯åŠ¨ä¹‹é—´æ›´æ”¹å…±äº«å†…å­˜çš„é…ç½®ï¼Œå¯èƒ½éœ€è¦ä¸€ä¸ªéšå¼çš„è®¾å¤‡åŒæ­¥ç‚¹ï¼Œæ›´æ”¹å…±äº«å†…å­˜å­˜å‚¨ä½“çš„å¤§å°å¯¹æ€§èƒ½æœ‰é‡å¤§çš„å½±å“ã€‚æ›´å¤§çš„ bank widths å¯èƒ½æœ‰æ›´é«˜çš„å¸¦å®½ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´æ›´å¤šçš„ bank conflictï¼Œéœ€è¦å®éªŒå¾—å‡º</p><p>ä¸‹é¢çš„ä»£ç ç®€å•åœ°ä½¿ç”¨äº†ä¸Šé¢ä¸¤ä¸ªå‡½æ•°ï¼Œä»…ä¾›å‚è€ƒï¼Œè¿™é‡Œç¬”ä¸»çš„æ˜¾å¡å›ºå®šäº†å…±äº«å†…å­˜å¤§å°ï¼Œæ— æ³•æ¼”ç¤º</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printSharedMemConfig</span><span class="params">(<span class="keyword">enum</span> cudaSharedMemConfig &amp;sharedMemConfig)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (sharedMemConfig) &#123;</span><br><span class="line">        <span class="keyword">case</span> cudaSharedMemBankSizeDefault:</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Shared memory config: Default\n&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> cudaSharedMemBankSizeFourByte:</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Shared memory config: Bank size of 4 bytes\n&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> cudaSharedMemBankSizeEightByte:</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Shared memory config: Bank size of 8 bytes\n&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">cudaSharedMemConfig</span> sharedMemConfig;</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printSharedMemConfig</span>(sharedMemConfig);</span><br><span class="line">    <span class="built_in">cudaDeviceSetSharedMemConfig</span>(cudaSharedMemBankSizeEightByte);</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printSharedMemConfig</span>(sharedMemConfig);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="å†…å­˜å¡«å……ï¼ˆmemory-paddingï¼‰"><a href="#å†…å­˜å¡«å……ï¼ˆmemory-paddingï¼‰" class="headerlink" title="å†…å­˜å¡«å……ï¼ˆmemory paddingï¼‰"></a>å†…å­˜å¡«å……ï¼ˆmemory paddingï¼‰</h4><p>å†…å­˜å¡«å……æ˜¯é¿å…å­˜å‚¨å•å…ƒå†²çªçš„ä¸€ç§æ–¹æ³•ã€‚å‡è®¾ 5 ä¸ªå…±äº«å†…å­˜å­˜å‚¨å•å…ƒã€‚å¦‚æœæ‰€æœ‰çº¿ç¨‹è®¿é—® bank 0 çš„ä¸åŒåœ°å€ï¼Œé‚£ä¹ˆä¼šå‘ç”Ÿä¸€ä¸ªäº”å‘çš„å­˜å‚¨å•å…ƒå†²çªã€‚è§£å†³è¿™ç§å­˜å‚¨å•å…ƒå†²çªçš„ä¸€ä¸ªæ–¹æ³•æ˜¯åœ¨æ¯ 5 ä¸ªå…ƒç´ ä¹‹åæ·»åŠ ä¸€ä¸ªå¡«å……ï¼Œæ”¹å˜ä»å­—åˆ°å­˜å‚¨å•å…ƒçš„æ˜ å°„ï¼Œä»¥é”™å¼€è®¿é—®æ¯è¡Œæ•°æ®</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/11.webp" alt=""></p><p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œç”±äºå¡«å……ï¼Œä¹‹å‰æ‰€æœ‰å±äº bank 0 çš„å­—ï¼Œç°åœ¨è¢«ä¼ æ’­åˆ°äº†ä¸åŒçš„å­˜å‚¨å•å…ƒä¸­ã€‚ å¡«å……çš„å†…å­˜ä¸èƒ½ç”¨äºæ•°æ®å­˜å‚¨ï¼Œå…¶å”¯ä¸€çš„ä½œç”¨å°±æ˜¯ç§»åŠ¨æ•°æ®å…ƒç´ ï¼Œä»¥ä¾¿å°†åŸæ¥å±äºåŒä¸€ä¸ªå­˜å‚¨å•å…ƒä¸­çš„æ•°æ®åˆ†æ•£åˆ°ä¸åŒå­˜å‚¨å•å…ƒä¸­ã€‚è¿™æ ·å¯ä»¥ä½¿å¾—çº¿ç¨‹å—å¯ç”¨çš„æ€»å…±äº«å†…å­˜çš„æ•°é‡å‡å°‘ã€‚ å¡«å……ä¹‹åè¿˜éœ€è¦æ ¹æ®å‰é¢çš„å…¬å¼é‡æ–°è®¡ç®—æ•°ç»„ç´¢å¼•ä»¥ç¡®ä¿èƒ½è®¿é—®åˆ°æ­£ç¡®çš„æ•°æ®å…ƒç´ ã€‚ä¾‹å¦‚ä¸‹é¢çš„å…±äº«å†…å­˜æ•°ç»„</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="type">int</span> a[<span class="number">5</span>][<span class="number">4</span>];</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥æ›´æ”¹å£°æ˜ä»¥è¿˜åŸå›¾ä¾‹ä¸­çš„æƒ…å†µ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="type">int</span> a[<span class="number">5</span>][<span class="number">5</span>];</span><br></pre></td></tr></table></figure><h3 id="é…ç½®å…±äº«å†…å­˜"><a href="#é…ç½®å…±äº«å†…å­˜" class="headerlink" title="é…ç½®å…±äº«å†…å­˜"></a>é…ç½®å…±äº«å†…å­˜</h3><p>æ¯ä¸ª SM ä¸Šæœ‰ 64KB çš„ç‰‡ä¸Šå†…å­˜ï¼ŒSMEM å’Œ L1 å…±äº«è¿™ 64KBï¼Œå¹¶ä¸”å¯ä»¥é…ç½®ï¼ŒCUDA ä¸ºé…ç½® L1 å’Œ SMEM æä¾›ä»¥ä¸‹ä¸¤ç§æ–¹æ³•</p><ul><li>æŒ‰è®¾å¤‡è¿›è¡Œé…ç½®</li><li>æŒ‰æ ¸å‡½æ•°è¿›è¡Œé…ç½®</li></ul><p>ä¸ºå½“å‰è®¾å¤‡è®¾ç½®é¦–é€‰ç¼“å­˜é…ç½®</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaDeviceSetCacheConfig</span> <span class="params">( cudaFuncCache cacheConfig )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>cacheConfig</code>ï¼šè¯·æ±‚çš„ç¼“å­˜é…ç½®ï¼Œæšä¸¾ç±»å‹</li><li><p><code>cudaFuncCachePreferNone = 0</code>: é»˜è®¤å‡½æ•°ç¼“å­˜é…ç½®ï¼Œæ— ä¼˜å…ˆçº§</p></li><li><p><code>cudaFuncCachePreferShared = 1</code>: é¦–é€‰æ›´å¤§çš„ SMEM å’Œæ›´å°çš„ L1 ç¼“å­˜</p></li><li><p><code>cudaFuncCachePreferL1 = 2</code>: é¦–é€‰è¾ƒå¤§çš„ L1 ç¼“å­˜å’Œè¾ƒå°çš„ SMEM</p></li><li><p><code>cudaFuncCachePreferEqual = 3</code>: é¦–é€‰å¤§å°ç›¸åŒçš„ L1 ç¼“å­˜å’Œ SMEM</p></li></ul><p>ä½¿ç”¨ä¸Šé¢å“ªç§æ›´å¥½è¦æ ¹æ®æ ¸å‡½æ•°ä½¿ç”¨äº†å¤šå°‘ SMEM</p><ul><li>SMEM ä½¿ç”¨è¾ƒå¤šï¼Œé‚£ä¹ˆé¦–é€‰æ›´å¤§çš„ SMEM</li><li>æ›´å¤šçš„å¯„å­˜å™¨ä½¿ç”¨ï¼Œé‚£ä¹ˆé¦–é€‰è¾ƒå¤§çš„ L1</li></ul><p>å¦ä¸€ä¸ªå‡½æ•°æ˜¯ä¸ºå½“å‰æ ¸å‡½æ•°è®¾ç½®é¦–é€‰ç¼“å­˜é…ç½®</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaFuncSetCacheConfig</span> <span class="params">( <span class="type">const</span> <span class="type">void</span>* func, cudaFuncCache cacheConfig )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>func</code>: è®¾å¤‡å‡½æ•°æŒ‡é’ˆ</li><li><code>cacheConfig</code>: è¯·æ±‚çš„ç¼“å­˜é…ç½®</li></ul><p>L1 å’Œ SMEM è™½ç„¶éƒ½åœ¨åŒä¸€ä¸ªç‰‡ä¸Šï¼Œä½†æ˜¯ä¸ SMEM çš„ bank ä¸åŒï¼ŒL1 é€šè¿‡ç¼“å­˜è¡Œè¿›è¡Œè®¿é—®ã€‚æˆ‘ä»¬å¯ä»¥å®Œå…¨æ§åˆ¶ SMEMï¼Œä½† L1 çš„åˆ é™¤å·¥ä½œæ˜¯ç¡¬ä»¶å®Œæˆçš„</p><p>GPUä½¿ç”¨ä¸åŒçš„å¯å‘å¼ç®—æ³•æ¥å¤„ç†æ•°æ®ã€‚åœ¨GPUä¸Šï¼Œæ•°ç™¾ä¸ªçº¿ç¨‹å…±äº«ç›¸åŒçš„ L1ï¼Œæ•°åƒä¸ªçº¿ç¨‹å…±äº«æœ‰ç½‘çš„ L2ã€‚å› æ­¤ï¼Œæ•°æ®å¤„ç†åœ¨ GPUä¸Šå¯èƒ½ä¼šå‘ç”Ÿçš„æ›´é¢‘ç¹è€Œä¸”æ›´ä¸å¯é¢„çŸ¥ï¼Œæ‰€ä»¥ä½¿ç”¨ SMEM ä¸ä»…å¯ä»¥æ˜¾å¼ç®¡ç†æ•°æ®ï¼Œè¿˜å¯ä»¥ä¿è¯ SM çš„å±€éƒ¨æ€§</p><h3 id="åŒæ­¥"><a href="#åŒæ­¥" class="headerlink" title="åŒæ­¥"></a>åŒæ­¥</h3><p>åŒæ­¥æ˜¯å¹¶è¡Œçš„é‡è¦æœºåˆ¶ï¼Œå…¶ä¸»è¦ç›®çš„å°±æ˜¯é˜²æ­¢å†²çªã€‚åŒæ­¥åŸºæœ¬æ–¹æ³•æœ‰</p><ul><li>éšœç¢ï¼Œæ˜¯æ‰€æœ‰è°ƒç”¨çº¿ç¨‹ç­‰å¾…å…¶ä½™è°ƒç”¨çº¿ç¨‹è¾¾åˆ°çš„éšœç¢ç‚¹</li><li>å†…å­˜æ …æ ï¼Œæ‰€æœ‰è°ƒç”¨çº¿ç¨‹å¿…é¡»ç­‰åˆ°å…¨éƒ¨å†…å­˜ä¿®æ”¹å¯¹å…¶ä½™çº¿ç¨‹å¯è§æ—¶æ‰ç»§ç»­è¿›è¡Œ</li></ul><p>é¦–å…ˆéœ€è¦ç†è§£ CUDA é‡‡ç”¨çš„å¼±æ’åºå†…å­˜æ¨¡å‹</p><h4 id="å¼±æ’åºå†…å­˜æ¨¡å‹"><a href="#å¼±æ’åºå†…å­˜æ¨¡å‹" class="headerlink" title="å¼±æ’åºå†…å­˜æ¨¡å‹"></a>å¼±æ’åºå†…å­˜æ¨¡å‹</h4><p>CUDA å…è®¸ç¼–è¯‘å™¨å¤§å¹…ä¼˜åŒ–æºä»£ç ä»¥åŠ é€Ÿç¨‹åºè¿è¡Œæ•ˆç‡ï¼Œè¿™å°±ä¼šå¯¼è‡´å†…å­˜è®¿é—®çš„é¡ºåºè¢«æ”¹å˜ï¼Œä¹Ÿå°±æ˜¯è¯´ GPU çº¿ç¨‹åœ¨ä¸åŒçš„å†…å­˜ï¼Œæ¯”å¦‚ SMEMï¼Œå…¨å±€å†…å­˜ï¼Œé”é¡µå†…å­˜æˆ–å¯¹ç­‰è®¾å¤‡å†…å­˜ä¸­ï¼Œå†™å…¥æ•°æ®çš„é¡ºåºæ˜¯ä¸ä¸€å®šå’Œè¿™äº›æ•°æ®åœ¨æºä»£ç ä¸­è®¿é—®çš„é¡ºåºç›¸åŒã€‚å½“çº¿ç¨‹çš„å†™å…¥é¡ºåºå¯¹å…¶ä»–çº¿ç¨‹å¯è§çš„æ—¶å€™ï¼Œå®ƒå¯èƒ½å’Œå†™æ“ä½œè¢«æ‰§è¡Œçš„å®é™…é¡ºåºä¸ä¸€è‡´ã€‚å¦‚æœæŒ‡ä»¤ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œçº¿ç¨‹ä»ä¸åŒå†…å­˜ä¸­è¯»å–æ•°æ®å’ŒæŒ‡ä»¤çš„é¡ºåºä¹Ÿä¸ä¸€å®šç›¸åŒã€‚åœ¨è¿™ç§ä¸æ­£ç¡®æƒ…å†µä¸‹ï¼Œä¸ºäº†ä¿æŒå†…å­˜ç®¡ç†çš„å¯æ§ï¼Œå¿…é¡»åœ¨ä»£ç ä¸­ä½¿ç”¨éšœç¢å’Œå†…å­˜æ …æ ä»¥é˜²æ­¢å†²çª</p><h4 id="æ˜¾ç¤ºéšœç¢"><a href="#æ˜¾ç¤ºéšœç¢" class="headerlink" title="æ˜¾ç¤ºéšœç¢"></a>æ˜¾ç¤ºéšœç¢</h4><p>CUDA ä¸­ï¼Œéšœç¢ç‚¹åªå¯¹åŒä¸€çº¿ç¨‹å—å†…çš„çº¿ç¨‹æ‰§è¡Œï¼Œä¸”åªèƒ½è®¾ç½®åœ¨æ ¸å‡½æ•°ä¸­ï¼Œä½¿ç”¨å¦‚ä¸‹å‡½æ•°è®¾ç½®ä¸€ä¸ªéšœç¢ç‚¹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> __syncthreads();</span><br></pre></td></tr></table></figure><p><code>__syncthreads()</code>ä½œä¸ºä¸€ä¸ªéšœç¢ç‚¹ï¼Œä¿è¯åœ¨åŒä¸€çº¿ç¨‹å—å†…æ‰€æœ‰çº¿ç¨‹æ²¡åˆ°è¾¾æ­¤éšœç¢ç‚¹æ—¶ï¼Œä¸èƒ½ç»§ç»­å‘ä¸‹æ‰§è¡Œï¼Œä¹Ÿå°±æ˜¯é˜»å¡ block ç›´è‡³ block å†…çš„çº¿ç¨‹å…¨éƒ½æ‰§è¡Œåˆ°è¿™ä¸€è¡Œã€‚ä¸”åœ¨åŒä¸€çº¿ç¨‹å—å†…ï¼Œæ­¤éšœç¢ç‚¹ä¹‹å‰çš„æ‰€æœ‰å…¨å±€å†…å­˜ï¼Œå…±äº«å†…å­˜æ“ä½œï¼Œå¯¹åé¢çš„çº¿ç¨‹éƒ½æ˜¯å¯è§çš„ã€‚</p><p><code>__syncthreads()</code>ä¹Ÿå¯ä»¥è§£å†³åŒä¸€çº¿ç¨‹å—å†…ï¼Œå†…å­˜ç«äº‰çš„é—®é¢˜ï¼Œä¿è¯æ‰§è¡Œçš„å…ˆåé¡ºåº</p><p>æ­¤å¤–åœ¨æ¡ä»¶è¯­å¥ä¸­ä½¿ç”¨<code>__syncthreads()</code>ï¼Œä¼šå¯¼è‡´æ— æ³•é¢„æ–™çš„ä¸¥é‡æƒ…å†µã€‚å¦‚ä¸‹é¢çš„ä»£ç ï¼Œå› å—ä¸­çš„æ‰€æœ‰çº¿ç¨‹éƒ½æ²¡æœ‰è¾¾åˆ°ç›¸åŒçš„éšœç¢ç‚¹ï¼Œä¼šç›´æ¥å¯¼è‡´å†…æ ¸æ­»é”</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (threadID % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">__syncthreads();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">__syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä½†æ˜¯<code>__syncthreads()</code>çš„å±€é™å°±åœ¨äºåªèƒ½è§£å†³ä¸€ä¸ªå—å†…çš„çº¿ç¨‹åŒæ­¥ï¼Œä¸èƒ½è·¨çº¿ç¨‹åŒæ­¥ï¼Œçº¿ç¨‹å—ä¼šä»¥ä»»ä½•é¡ºåºï¼Œå¹¶è¡Œæˆ–ä¸²è¡Œåœ°åœ¨ä»»ä½• SM ä¸Šæ‰§è¡Œï¼Œçº¿ç¨‹å—è¿™ç§ç‹¬ç«‹çš„ç‰¹æ€§ä½¿å¾— CUDA åœ¨ä»»æ„æ•°é‡çš„æ ¸å¿ƒä¸­éƒ½æ˜¯å¯æ‰©å±•çš„ï¼Œå¦‚æœä¸€ä¸ª CUDA æ ¸å‡½æ•°è¦æ±‚çº¿ç¨‹å—å…¨å±€åŒæ­¥ï¼Œé‚£ä¹ˆåªèƒ½ç»“æŸæ ¸å‡½æ•°çš„è¿è¡Œæ¥éšå¼çš„åŒæ­¥çº¿ç¨‹å—</p><h4 id="å†…å­˜æ …æ "><a href="#å†…å­˜æ …æ " class="headerlink" title="å†…å­˜æ …æ "></a>å†…å­˜æ …æ </h4><p>å†…å­˜æ …æ èƒ½ä¿è¯æ …æ å‰çš„å†…æ ¸å†…å­˜å†™æ“ä½œå¯¹æ …æ åçš„å…¶ä»–çº¿ç¨‹éƒ½æ˜¯å¯è§çš„ï¼Œæ ¹æ®æ‰€éœ€èŒƒå›´æœ‰ä»¥ä¸‹ä¸‰ç§æ …æ </p><ul><li><p>çº¿ç¨‹å—ï¼Œåœ¨ block å†…åˆ›å»ºå†…å­˜æ …æ ï¼Œé˜»å¡çº¿ç¨‹æŸç›´è‡³é˜»å¡çº¿ç¨‹æŸå‘å‡ºçš„å†™æ“ä½œå®Œæˆï¼Œä½†ç”±äºé˜»å¡çº¿ç¨‹æŸæœ¬èº«å°±æ˜¯å•æŒ‡ä»¤å¤šçº¿ç¨‹ï¼Œè¯¥æŒ‡ä»¤å°±æ²¡ä»€ä¹ˆç”¨</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  <span class="type">void</span> __threadfence_block();</span><br><span class="line"></span><br><span class="line">* ç½‘æ ¼ï¼Œåœ¨ grid å†…åˆ›å»ºå†…å­˜æ …æ ï¼Œé˜»å¡ grid ç›´è‡³ grid å†…çš„çº¿ç¨‹å‘å‡ºçš„è¯»å†™æ“ä½œå®Œæˆï¼Œå¯ä»¥å®ç°å—é—´åŒæ­¥</span><br><span class="line"></span><br><span class="line">  ```cpp</span><br><span class="line">  <span class="type">void</span> __threadfence();</span><br></pre></td></tr></table></figure></li><li><p>ç³»ç»Ÿï¼Œå¯ä»¥è·¨ç³»ç»Ÿåˆ›å»ºå†…å­˜æ …æ ï¼ŒæŒ‚èµ·è°ƒç”¨çš„çº¿ç¨‹ï¼Œä»¥ç¡®ä¿è¯¥çº¿ç¨‹å¯¹å…¨å±€å†…å­˜ã€é”é¡µä¸»æœºå†…å­˜å’Œå…¶ä»–è®¾å¤‡å†…å­˜ä¸­çš„æ‰€æœ‰å†™æ“ä½œå¯¹å…¨éƒ¨è®¾å¤‡ä¸­çš„çº¿ç¨‹å’Œä¸»æœºçº¿ç¨‹æ˜¯å¯è§çš„</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> __threadfence_system();</span><br></pre></td></tr></table></figure></li></ul><h4 id="Volatile-ä¿®é¥°ç¬¦"><a href="#Volatile-ä¿®é¥°ç¬¦" class="headerlink" title="Volatile ä¿®é¥°ç¬¦"></a>Volatile ä¿®é¥°ç¬¦</h4><p>åœ¨å…¨å±€æˆ–å…±äº«å†…å­˜ä¸­ä½¿ç”¨ volatile ä¿®é¥°ç¬¦å£°æ˜ä¸€ä¸ªå˜é‡ï¼Œé˜»æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–ï¼Œå¯ä»¥é˜²æ­¢è¿™ä¸ªå˜é‡å­˜å…¥ç¼“å­˜ï¼Œè¿™ä¸ªå˜é‡çš„ä»»ä½•å¼•ç”¨éƒ½ä¼šç›´æ¥è¢«ç¼–è¯‘åˆ°å…¨å±€å†…å­˜ä¸­ï¼Œå¿½ç•¥ç¼“å­˜ã€‚ä¸¾ä¾‹å¦‚ä¸‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="type">float</span> vfloat;</span><br></pre></td></tr></table></figure><h2 id="å…±äº«å†…å­˜çš„æ•°æ®å¸ƒå±€"><a href="#å…±äº«å†…å­˜çš„æ•°æ®å¸ƒå±€" class="headerlink" title="å…±äº«å†…å­˜çš„æ•°æ®å¸ƒå±€"></a>å…±äº«å†…å­˜çš„æ•°æ®å¸ƒå±€</h2><p>è¿™éƒ¨åˆ†æˆ‘ä»¬é€šè¿‡ç ”ç©¶å¦‚ä½•ç»„ç»‡å…±äº«å†…å­˜çš„æ•°æ®å¸ƒå±€ï¼Œä»¥è¾¾åˆ°æ›´å°‘çš„ bank conflict å’Œæœ€ä½³çš„æ€§èƒ½</p><h3 id="æ–¹å½¢å…±äº«å†…å­˜"><a href="#æ–¹å½¢å…±äº«å†…å­˜" class="headerlink" title="æ–¹å½¢å…±äº«å†…å­˜"></a>æ–¹å½¢å…±äº«å†…å­˜</h3><p>SMEM å¯ä»¥ç›´æ¥ç¼“å­˜æ–¹å½¢ç»´åº¦çš„å…¨å±€æ•°æ®ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå­—èŠ‚åœ°å€ä¸å­˜å‚¨ä½“åœ°å€çš„é€»è¾‘æ˜ å°„å›¾ï¼Œåœ¨æ¯ä¸ªç»´åº¦å‡è®¾æœ‰ 32 ä¸ªå…ƒç´ ï¼Œä¸”æŒ‰è¡Œä¸»åºè¿›è¡Œå­˜å‚¨</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/12.webp" alt=""></p><p>å¦‚ä¸‹é™æ€å£°æ˜ä¸€ä¸ªäºŒç»´å…±äº«å†…å­˜å˜é‡</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 32</span></span><br><span class="line">__shared__ <span class="type">int</span> a[N][N];</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥ç”¨ä¸¤ç§æ–¹å¼è®¿é—®å…¶ä¸­ä¸€ä¸ªå…ƒç´ </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// è¡Œä¸»åº</span></span><br><span class="line">a[threadIdx.y][threadIdx.x];</span><br><span class="line"></span><br><span class="line"><span class="comment">//åˆ—ä¸»åº</span></span><br><span class="line">a[threadIdx.y][threadIdx.x];</span><br></pre></td></tr></table></figure><p>è¡Œä¸»åºå’Œåˆ—ä¸»åºå“ªä¸ªæ•ˆç‡æ›´é«˜ï¼Œè¿™å–å†³äºçº¿ç¨‹ä¸å…±äº«å†…å­˜å­˜å‚¨ä½“çš„æ˜ å°„å…³ç³»ã€‚åœ¨ä¸€ä¸ªçº¿ç¨‹æŸä¸­çš„çº¿ç¨‹ç”±è¿ç»­çš„<code>threadIdx.x</code>æ¥ç¡®å®šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œ<code>threadIdx.y</code>å¯¹åº”ä¸Šå›¾ä¸­çš„ Row è¡Œï¼Œ<code>threadIdx.x</code>å¯¹åº”ä¸Šå›¾ä¸­çš„ Bank åˆ—ï¼Œè€Œæ¯ä¸ª bank å’Œçº¿ç¨‹æŸä¸­çš„æ¯ä¸ªçº¿ç¨‹å¯¹åº”ï¼Œé‚»è¿‘çº¿ç¨‹åœ¨æœ€å†…å±‚æ•°ç»„ç»´åº¦ä¸Šè®¿é—®ç›¸é‚»çš„é˜µåˆ—å•å…ƒã€‚å› æ­¤ï¼Œç›¸æ¯”åˆ—ä¸»åºï¼Œè¡Œä¸»åºæœ‰æ›´å¥½çš„æ€§èƒ½å’Œæ›´å°‘çš„ bank conflict</p><h4 id="è¡Œä¸»åºè¯»å†™å’Œåˆ—ä¸»åºè¯»å†™å¯¹æ¯”"><a href="#è¡Œä¸»åºè¯»å†™å’Œåˆ—ä¸»åºè¯»å†™å¯¹æ¯”" class="headerlink" title="è¡Œä¸»åºè¯»å†™å’Œåˆ—ä¸»åºè¯»å†™å¯¹æ¯”"></a>è¡Œä¸»åºè¯»å†™å’Œåˆ—ä¸»åºè¯»å†™å¯¹æ¯”</h4><p>ä¸‹é¢çš„ç¨‹åºå°†å…¨å±€çº¿ç¨‹ç´¢å¼•å€¼å­˜å…¥äºŒç»´å…±äº«å†…å­˜ï¼Œå†ä»å…±äº«å†…å­˜ä¸­è¯»å–è¿™äº›å€¼å¹¶å­˜åˆ°å…¨å±€å†…å­˜ä¸­ï¼Œå¯¹æ¯”è¡Œä¸»åºå’Œåˆ—ä¸»åº</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X 32</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y 32</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadCol</span><span class="params">(<span class="type">int</span> * out)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">cudaSharedMemConfig</span> sharedMemConfig;</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, sharedMemConfig);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> nElem = DIM_X * DIM_Y;</span><br><span class="line">    <span class="type">int</span> nByte = <span class="built_in">sizeof</span>(<span class="type">int</span>)*nElem;</span><br><span class="line">    <span class="type">int</span> * out;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">int</span>**)&amp;out,nByte);</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(DIM_Y, DIM_X)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    </span><br><span class="line">    setRowReadRow&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out);</span><br><span class="line">    setColReadCol&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åœ¨ 4 å­—èŠ‚è®¿é—®æ¨¡å¼ä¸‹ï¼Œå› ä¸ºç›¸é‚»çº¿ç¨‹å¼•ç”¨ç›¸é‚»å­—ï¼Œå¯ä»¥çœ‹åˆ°æŒ‰è¡Œè®¿é—®ä½¿ç”¨çš„æ—¶é—´æ¯”åˆ—è®¿é—®å°‘äº†å¾ˆå¤š</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆäºŒï¼‰/13.webp" alt=""></p><p>ä½¿ç”¨ <code>ncu --metrics l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum</code> å‘½ä»¤å¯ä»¥è·å–æ ¸å‡½æ•°è¿è¡Œé˜¶æ®µçš„å…±äº«å†…å­˜åŠ è½½äº‹åŠ¡æ•°ï¼Œ<code>ncu --metrics l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum</code>å‘½ä»¤å¯ä»¥è·å–å…±äº«å†…å­˜å­˜å‚¨äº‹åŠ¡æ•°ï¼Œå…³äº<code>ncu --metrics</code>æ›´å¤šå‚æ•°çš„å…·ä½“è§£é‡Šå¯ä»¥çœ‹çœ‹<a href="https://aeeeeeep.top/2023/01/07/CUDA%E7%BC%96%E7%A8%8B%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7-metrics%E5%8F%82%E6%95%B0%E5%90%AB%E4%B9%89/">è¿™ç¯‡åšå®¢</a></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadRow</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">32</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">32</span></span><br><span class="line"><span class="built_in">setColReadCol</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">1024</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">1024</span></span><br></pre></td></tr></table></figure><p>åœ¨å¯¹å…±äº«å†…å­˜å­˜å‚¨äº‹åŠ¡æ•°/æ‰§è¡Œå…±äº«å†…å­˜çš„è®¿é—®æ¬¡æ•°ï¼Œä¹Ÿå°±æ˜¯äºŒç»´å…±äº«å†…å­˜çš„è¡Œ<code>DIM_Y</code>ï¼Œè¿™é‡Œä¸º 32ï¼Œå¾—åˆ°æ¯æ¬¡è®¿é—®å…±äº«å†…å­˜æ—¶çš„å­˜å‚¨äº‹åŠ¡æ•° 32/32 = 1ï¼Œä¸ä¼šäº§ç”Ÿ bank conflictã€‚ä½†æ˜¯åœ¨<code>setColReadCol</code>ä¸­æ¯æ¬¡è®¿é—®å…±äº«å†…å­˜æ—¶çš„å­˜å‚¨äº‹åŠ¡æ•°ä¸º 1024/32 = 32ï¼Œä¼šæœ‰ 32 è·¯  bank conflictï¼Œå¯¹åº”<code>DIM_Y=32</code>ï¼Œå°±æ˜¯å› ä¸º<code>setRowReadRow</code>æ˜¯é‚»è¿‘çº¿ç¨‹åœ¨æœ€å†…å±‚æ•°ç»„ç»´åº¦ä¸Šè®¿é—®ç›¸é‚»çš„é˜µåˆ—å•å…ƒ</p><p>ä¸‹é¢çš„æ ¸å‡½æ•°ä¸ºæŒ‰è¡Œä¸»åºå†™å’ŒæŒ‰åˆ—ä¸»åºè¯»</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadCol</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_X][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ‰§è¡Œä¸Šé¢ä¸¤ä¸ªæ ¸å‡½æ•°ï¼Œå¯ä»¥çœ‹åˆ°å†²çªæƒ…å†µç¬¦åˆæˆ‘ä»¬çš„ç†è®ºï¼Œå³é‚»è¿‘çº¿ç¨‹åœ¨æœ€å†…å±‚æ•°ç»„ç»´åº¦ä¸Šè®¿é—®ç›¸é‚»çš„é˜µåˆ—å•å…ƒä¼šå‡å°‘å†²çª</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadCol</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">1024</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">32</span></span><br><span class="line"><span class="built_in">setColReadRow</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">32</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">1024</span></span><br></pre></td></tr></table></figure><p>è®¾çŸ©é˜µ size(4,4) æ‰§è¡Œä¸Šé¢çš„å››ä¸ªæ ¸å‡½æ•°ï¼Œè¾“å‡º<code>out</code>çš„å€¼å¯ä»¥çœ‹åˆ°<code>setRowReadCol</code>å’Œ<code>setColReadRow</code>ä¼šå¯¹æ•°ç»„è½¬ç½®ï¼Œè¿™ä¸ºä¹‹åæˆ‘ä»¬å°†ä¼šè®²åˆ°çš„è½¬ç½®ç®—æ³•ä½œäº†åŸºç¡€</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X 4</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y 4</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadCol</span><span class="params">(<span class="type">int</span> * out)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadCol</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_X][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">cudaSharedMemConfig</span> sharedMemConfig;</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, sharedMemConfig);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> nElem = DIM_X * DIM_Y;</span><br><span class="line">    <span class="type">int</span> nByte = <span class="built_in">sizeof</span>(<span class="type">int</span>)*nElem;</span><br><span class="line">    <span class="type">int</span> * out_h, * out_d;</span><br><span class="line">    out_h = (<span class="type">int</span>*)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">int</span>**)&amp;out_d,nByte);</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(DIM_Y, DIM_X)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setRowReadRow: &quot;</span>);</span><br><span class="line">    setRowReadRow&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setColReadCol: &quot;</span>);</span><br><span class="line">    setColReadCol&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setRowReadCol: &quot;</span>);</span><br><span class="line">    setRowReadCol&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setColReadRow: &quot;</span>);</span><br><span class="line">    setColReadRow&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">setRowReadRow: <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> <span class="number">13</span> <span class="number">14</span> <span class="number">15</span> </span><br><span class="line">setColReadCol: <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> <span class="number">13</span> <span class="number">14</span> <span class="number">15</span> </span><br><span class="line">setRowReadCol: <span class="number">0</span> <span class="number">4</span> <span class="number">8</span> <span class="number">12</span> <span class="number">1</span> <span class="number">5</span> <span class="number">9</span> <span class="number">13</span> <span class="number">2</span> <span class="number">6</span> <span class="number">10</span> <span class="number">14</span> <span class="number">3</span> <span class="number">7</span> <span class="number">11</span> <span class="number">15</span> </span><br><span class="line">setColReadRow: <span class="number">0</span> <span class="number">4</span> <span class="number">8</span> <span class="number">12</span> <span class="number">1</span> <span class="number">5</span> <span class="number">9</span> <span class="number">13</span> <span class="number">2</span> <span class="number">6</span> <span class="number">10</span> <span class="number">14</span> <span class="number">3</span> <span class="number">7</span> <span class="number">11</span> <span class="number">15</span></span><br></pre></td></tr></table></figure><p>ä¸‹é¢ç»™å‡ºåŠ¨æ€å£°æ˜ç‰ˆæœ¬ï¼Œå‰é¢æåˆ°è¿‡ï¼ŒåŠ¨æ€å…±äº«å†…å­˜æ•°ç»„åªèƒ½æ˜¯ä¸€ç»´çš„ï¼Œä¸”è¦å°†æ‰€éœ€å¤§å°æŒ‰å­—èŠ‚æ•°ä½œä¸ºæ ¸å‡½æ•°ä¸‰é‡æ‹¬å·å†…çš„ç¬¬ä¸‰ä¸ªå‚æ•°</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColDyn</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> row_idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=threadIdx.x*blockDim.y+threadIdx.y;</span><br><span class="line"></span><br><span class="line">    tile[row_idx]=row_idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[row_idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setRowReadColDyn&lt;&lt;&lt;grid, block, <span class="function">DIM_X * DIM_Y * <span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColDyn</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">1024</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">32</span></span><br></pre></td></tr></table></figure><h4 id="memory-padding"><a href="#memory-padding" class="headerlink" title="memory padding"></a>memory padding</h4><p>ä¸ºäº†è§£å†³<code>setRowReadCol</code>ï¼Œ<code>setColReadRow</code>æ ¸å‡½æ•°çš„ bank conflictï¼Œæˆ‘ä»¬è¦æ ¹æ®å…·ä½“çš„æ•°æ®åˆ†å¸ƒæ¥å¡«å……å†…å­˜ï¼Œåœ¨é™æ€å£°æ˜ä¸­ï¼Œåªéœ€è¦å°†å¡«å……çš„åˆ—æ·»åŠ åˆ°äºŒç»´å…±äº«å†…å­˜åˆ†é…ä¸­å°±å¯ä»¥äº†ï¼Œä»£ç å¦‚ä¸‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PAD 1</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X+PAD];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setRowReadColPad&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out);</span><br></pre></td></tr></table></figure><p>åœ¨åŠ¨æ€å£°æ˜ä¸­ï¼Œç”±äºéœ€è¦æ‰§è¡ŒäºŒç»´çº¿ç¨‹ç´¢å¼•åˆ°ä¸€ç»´çº¿ç¨‹ç´¢å¼•çš„è½¬æ¢ï¼Œæ‰€ä»¥å¯¹äºæ¯ä¸€è¡Œï¼Œéƒ½è¦è·³è¿‡å¡«å……çš„éƒ¨åˆ†ï¼Œä»£ç å¦‚ä¸‹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PAD 1</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColDynPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> row_idx=threadIdx.y* (blockDim.x + PAD) +threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=threadIdx.x* (blockDim.y + PAD) +threadIdx.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> g_idx=threadIdx.y*blockDim.x +threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[row_idx]=g_idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[g_idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setRowReadColDynPad&lt;&lt;&lt;grid, block, (DIM_X + PAD) * <span class="function">DIM_Y * <span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨ ncu å·¥å…·å¯ä»¥çœ‹åˆ°æ¯æ¬¡è®¿é—®å…±äº«å†…å­˜è¯·æ±‚çš„äº‹åŠ¡æ•°é‡ä¸º 1ï¼Œæ—  bank conflict</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColPad</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">32</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">32</span></span><br><span class="line"><span class="built_in">setRowReadColDynPad</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">32</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">32</span></span><br></pre></td></tr></table></figure><h3 id="çŸ©å½¢å…±äº«å†…å­˜"><a href="#çŸ©å½¢å…±äº«å†…å­˜" class="headerlink" title="çŸ©å½¢å…±äº«å†…å­˜"></a>çŸ©å½¢å…±äº«å†…å­˜</h3><p>çŸ©å½¢å…±äº«å†…å­˜å’Œæ–¹å½¢å…±äº«å†…å­˜éå¸¸ç›¸ä¼¼ï¼Œä¸åŒçš„åœ°æ–¹åœ¨äºçº¿ç¨‹ç´¢å¼•çš„è¦å…ˆæ˜ å°„ä¸ºä¸€ç»´ï¼Œä¿è¯è®¿é—®æ˜¯åˆå¹¶çš„</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br></pre></td></tr></table></figure><p>å†é€šè¿‡äºŒç»´æ–¹å¼è®¿é—®ï¼Œè¿™é‡Œå¯¹åŸçŸ©é˜µæŒ‰åˆ—è¯»å–ï¼Œirow å’Œ icol å¯¹åº”çš„æ˜¯è½¬ç½®åçŸ©é˜µä¸­çš„åæ ‡</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br></pre></td></tr></table></figure><p>ä¸‹é¢çš„ç¨‹åºå°†å…¨å±€çº¿ç¨‹ç´¢å¼•å€¼å­˜å…¥äºŒç»´å…±äº«å†…å­˜ï¼Œå†ä»å…±äº«å†…å­˜ä¸­è¯»å–è¿™äº›å€¼å¹¶å­˜åˆ°å…¨å±€å†…å­˜ä¸­ï¼Œå¯¹æ¯”è¡Œä¸»åºå’Œåˆ—ä¸»åº</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X_RECT 32</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y_RECT 16</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRect</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y_RECT][DIM_X_RECT];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[icol][irow];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨ ncu å·¥å…·å¯ä»¥çœ‹åˆ°åŠ è½½æ“ä½œæœ‰ 256/16 = 16 è·¯å†²çªï¼Œè€Œå­˜å‚¨æ“ä½œæ²¡æœ‰å†²çª</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColRect</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">256</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">16</span></span><br></pre></td></tr></table></figure><p>ä¸ºäº†è§£å†³ bank conflictï¼Œä¸‹é¢ç»™å‡º memory padding ç‰ˆæœ¬çš„æ ¸å‡½æ•°ï¼Œè¿™é‡Œçš„<code>PAD_RECT=2</code>æ˜¯å› ä¸ºå°†é•¿æ–¹å½¢çŸ©é˜µä¸€è¡Œæœ‰ 16 ä¸ªå…ƒç´ ï¼Œä¸ºäº†æ»¡è¶³ 32 ä¸ªå­˜å‚¨ä½“çš„æ•°é‡ï¼Œæ¯æ¬¡ä¼šè®¿é—®ä¸¤è¡Œçš„æ•°æ®ï¼Œæ‰€ä»¥è¦å¡«å……å¯¹åº”ä¸¤è¡Œçš„ 2 ä¸ªå…ƒç´ ä»¥é”™å¼€è®¿é—®ï¼Œè€Œæ–¹å½¢çŸ©é˜µä¸€è¡Œæœ‰ 32 ä¸ªå…ƒç´ ï¼ŒåŒ¹é… 32 ä¸ªå­˜å‚¨ä½“çš„æ•°é‡ï¼Œæ¯è¡Œåªéœ€è¦å¡«å……ä¸€ä¸ªæ•°æ®å³å¯é”™å¼€è®¿é—®</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PAD_RECT 2</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRectPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y_RECT][DIM_X_RECT+PAD_RECT];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[icol][irow];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColRectPad</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">16</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">16</span></span><br></pre></td></tr></table></figure><p>ä¸‹é¢å†ç»™å‡ºåŠ¨æ€å£°æ˜å’Œ memory padding ç‰ˆæœ¬çš„æ ¸å‡½æ•°ä¾›å‚è€ƒ</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X_RECT 32</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y_RECT 16</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PAD_RECT 2</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRectDyn</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=icol*blockDim.x+irow;</span><br><span class="line">    tile[idx]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRectDynPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> row_idx=threadIdx.y*(PAD_RECT+blockDim.x)+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=icol*(PAD_RECT+blockDim.x)+irow;</span><br><span class="line">    tile[row_idx]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">block_rect</span><span class="params">(DIM_X_RECT,DIM_Y_RECT)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid_rect</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">setRowReadColRectDyn&lt;&lt;&lt;grid_rect,block_rect, <span class="function">DIM_X_RECT * DIM_Y_RECT*<span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br><span class="line">setRowReadColRectDynPad&lt;&lt;&lt;grid_rect,block_rect, (DIM_X_RECT+PAD_RECT) * <span class="function">DIM_Y_RECT*<span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColRectDyn</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">256</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">16</span></span><br><span class="line"><span class="built_in">setRowReadColRectDynPad</span>(<span class="type">int</span>*)</span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum<span class="number">16</span></span><br><span class="line">l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum<span class="number">16</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰</title>
      <link href="/p/aab372f6/"/>
      <url>/p/aab372f6/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å„ç§å†…å­˜çš„å¯¹é½è®¿é—®ä»¥åŠå®éªŒï¼Œé¿å…å¸¦å®½æµªè´¹ã€‚è¿˜å¯¹æ¯”äº† AoS ä¸ SoA ç»“æ„ä½“åœ¨ GPU ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚</p><span id="more"></span><h2 id="å†…å­˜ç®¡ç†"><a href="#å†…å­˜ç®¡ç†" class="headerlink" title="å†…å­˜ç®¡ç†"></a>å†…å­˜ç®¡ç†</h2><h3 id="å›ºå®šå†…å­˜"><a href="#å›ºå®šå†…å­˜" class="headerlink" title="å›ºå®šå†…å­˜"></a>å›ºå®šå†…å­˜</h3><p>åˆ†é…çš„ä¸»æœºå†…å­˜é»˜è®¤æ˜¯å¯åˆ†é¡µçš„ï¼ˆpageableï¼‰ï¼Œæ“ä½œç³»ç»Ÿä¼šåˆ†é…ç»™ç¨‹åºä¸€ä¸ªå¾ˆå¤§çš„è™šæ‹Ÿå†…å­˜ï¼Œä½†å®é™…çš„ç‰©ç†å†…å­˜ä¼šå°å¾ˆå¤šï¼Œä¸ºäº†è®©ç¨‹åºæ­£å¸¸è¿è¡Œï¼Œæ“ä½œç³»ç»Ÿå¯¹ç‰©ç†å†…å­˜ä»¥é¡µä¸ºå•ä½ç»„ç»‡ï¼Œå°†æ•°æ®å­˜å‚¨åˆ°ä¸åŒçš„é¡µä¸­ï¼Œè¿™äº›é¡µæ˜¯ä¸è¿ç»­çš„ï¼Œç¨‹åºåªå¯ä»¥çœ‹åˆ°è™šæ‹Ÿå†…å­˜åœ°å€ï¼Œè€Œæ“ä½œç³»ç»Ÿå¯èƒ½éšæ—¶æ›´æ¢æ•°æ®çš„åœ¨ç‰©ç†å†…å­˜ä¸­çš„é¡µï¼Œä½†æ˜¯åœ¨ä½¿ç”¨ GPU æ—¶ï¼Œå¦‚æœä»ä¸»æœºä¼ è¾“åˆ°è®¾å¤‡ä¸Šçš„æ—¶å€™ï¼Œé¡µè¢«æ›´æ”¹äº†ï¼Œå¯¹äºä¼ è¾“æ•°æ®è€Œè¨€æ˜¯è‡´å‘½çš„ï¼Œæ‰€ä»¥åœ¨ä¼ è¾“ä¹‹å‰ï¼ŒCUDA é©±åŠ¨ä¼šé”å®šé¡µé¢ï¼Œæˆ–è€…ç›´æ¥åˆ†é…å›ºå®šçš„ä¸»æœºå†…å­˜ï¼Œå°†ä¸»æœºæ•°æ®å¤åˆ¶åˆ°å›ºå®šå†…å­˜ä¸Šï¼Œå†ä»å›ºå®šå†…å­˜ä¼ è¾“æ•°æ®åˆ°è®¾å¤‡ä¸Šï¼Œå¦‚ä¸‹å›¾å·¦è¾¹æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/1.webp" alt=""></p><p>CUDA è¿è¡Œæ—¶å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤ç›´æ¥åˆ†é…å›ºå®šä¸»æœºå†…å­˜ï¼Œä¼šä½¿ä¼ è¾“å¸¦å®½é«˜å¾ˆå¤šï¼Œå¦‚ä¸Šå›¾å³è¾¹æ‰€ç¤º</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaMallocHost</span> <span class="params">( <span class="type">void</span>** ptr, <span class="type">size_t</span> size )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>ptr</code>: æŒ‡é’ˆï¼ŒæŒ‡å‘è¦åˆ†é…çš„å†…å­˜çš„ä½ç½®</li><li><code>size</code>: è¦åˆ†é…çš„å†…å­˜å¤§å°</li></ul><p>åˆ†é…åçš„å†…å­˜å¿…é¡»ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤é‡Šæ”¾</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaFreeHost</span> <span class="params">( <span class="type">void</span>* ptr )</span></span></span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯¹ç¬¬ä¸‰ç« ä¸­çš„çŸ©é˜µç›¸åŠ ä»£ç ä½œä¿®æ”¹ï¼Œå¯¹æ¯”å›ºå®šå†…å­˜å’Œåˆ†é¡µå†…å­˜çš„ä¼ è¾“æ•ˆç‡ï¼Œä¹Ÿå°±æ˜¯å¯¹æ¯”<code>cudaMalloc</code>å’Œ<code>cudaMallocHost</code>å‡½æ•°æ‰€å¼€è¾Ÿå†…å­˜ç©ºé—´çš„ä¼ è¾“æ•ˆç‡ï¼Œä¸‹é¢æ˜¯<code>cudaMalloc</code>ç‰ˆæœ¬</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Matrix</span> &#123;</span><br><span class="line">   <span class="type">int</span> w;</span><br><span class="line">   <span class="type">int</span> h;</span><br><span class="line">   <span class="type">float</span> *v;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">float</span> <span class="title">getValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> A-&gt;v[row * A-&gt;w + col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">setValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col, <span class="type">float</span> v)</span> </span>&#123;</span><br><span class="line">   A-&gt;v[row * A-&gt;w + col] = v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatrixAdd</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, <span class="built_in">getValue</span>(A, row, col) + <span class="built_in">getValue</span>(B, row, col));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">11</span>;</span><br><span class="line">    <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">11</span>;</span><br><span class="line">    Matrix *A = (Matrix*)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    Matrix *B = (Matrix*)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    Matrix *C = (Matrix*)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    A-&gt;h = h;</span><br><span class="line">    A-&gt;w = w;</span><br><span class="line">    B-&gt;h = h;</span><br><span class="line">    B-&gt;w = w;</span><br><span class="line">    C-&gt;h = h;</span><br><span class="line">    C-&gt;w = w;</span><br><span class="line">    <span class="type">int</span> nBytes = w * h * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    A-&gt;v = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    B-&gt;v = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    C-&gt;v = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; w * h; ++i) &#123;</span><br><span class="line">        A-&gt;v[i] = <span class="number">1.0</span>;</span><br><span class="line">        B-&gt;v[i] = <span class="number">2.0</span>;</span><br><span class="line">        C-&gt;v[i] = <span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Matrix *A_d, *B_d, *C_d;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;A_d, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;B_d, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;C_d, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *A_d_v = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">float</span> *B_d_v = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">float</span> *C_d_v = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;A_d_v, <span class="built_in">sizeof</span>(nBytes));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;B_d_v, <span class="built_in">sizeof</span>(nBytes));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;C_d_v, <span class="built_in">sizeof</span>(nBytes));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(A_d_v, A-&gt;v, <span class="built_in">sizeof</span>(nBytes), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(B_d_v, B-&gt;v, <span class="built_in">sizeof</span>(nBytes), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(C_d_v, C-&gt;v, <span class="built_in">sizeof</span>(nBytes), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *A_d_v_t = A-&gt;v;</span><br><span class="line">    <span class="type">float</span> *B_d_v_t = B-&gt;v;</span><br><span class="line">    <span class="type">float</span> *C_d_v_t = C-&gt;v;</span><br><span class="line"></span><br><span class="line">    A-&gt;v = A_d_v;</span><br><span class="line">    B-&gt;v = B_d_v;</span><br><span class="line">    C-&gt;v = C_d_v;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(A_d, A, <span class="built_in">sizeof</span>(Matrix), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(B_d, B, <span class="built_in">sizeof</span>(Matrix), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(C_d, C, <span class="built_in">sizeof</span>(Matrix), cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    A-&gt;v = A_d_v_t;</span><br><span class="line">    B-&gt;v = B_d_v_t;</span><br><span class="line">    C-&gt;v = C_d_v_t;</span><br><span class="line">    </span><br><span class="line">    <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">gridSize</span><span class="params">((w + blockSize.x - <span class="number">1</span>) / blockSize.x, (h + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line">    MatrixAdd &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A_d, B_d, C_d);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä¸‹é¢æ˜¯<code>cudaMallocHost</code>ç‰ˆæœ¬</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Matrix</span> &#123;</span><br><span class="line">   <span class="type">int</span> w;</span><br><span class="line">   <span class="type">int</span> h;</span><br><span class="line">   <span class="type">float</span> *v;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">float</span> <span class="title">getValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> A-&gt;v[row * A-&gt;w + col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">setValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col, <span class="type">float</span> v)</span> </span>&#123;</span><br><span class="line">   A-&gt;v[row * A-&gt;w + col] = v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatrixAdd</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, <span class="built_in">getValue</span>(A, row, col) + <span class="built_in">getValue</span>(B, row, col));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">11</span>;</span><br><span class="line">    <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">11</span>;</span><br><span class="line">    Matrix *A, *B, *C;</span><br><span class="line">    <span class="built_in">cudaMallocHost</span>((<span class="type">void</span> **)&amp;A, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocHost</span>((<span class="type">void</span> **)&amp;B, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocHost</span>((<span class="type">void</span> **)&amp;C, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    A-&gt;h = h;</span><br><span class="line">    A-&gt;w = w;</span><br><span class="line">    B-&gt;h = h;</span><br><span class="line">    B-&gt;w = w;</span><br><span class="line">    C-&gt;h = h;</span><br><span class="line">    C-&gt;w = w;</span><br><span class="line">    <span class="type">int</span> nBytes = w * h * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">cudaMallocHost</span>((<span class="type">void</span> **)&amp;A-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocHost</span>((<span class="type">void</span> **)&amp;B-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocHost</span>((<span class="type">void</span> **)&amp;C-&gt;v, nBytes);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; w * h; ++i) &#123;</span><br><span class="line">        A-&gt;v[i] = <span class="number">1.0</span>;</span><br><span class="line">        B-&gt;v[i] = <span class="number">2.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Matrix *A_d, *B_d, *C_d;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;A_d, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;B_d, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;C_d, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *A_d_v = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">float</span> *B_d_v = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">float</span> *C_d_v = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;A_d_v, <span class="built_in">sizeof</span>(nBytes));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;B_d_v, <span class="built_in">sizeof</span>(nBytes));</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;C_d_v, <span class="built_in">sizeof</span>(nBytes));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(A_d_v, A-&gt;v, <span class="built_in">sizeof</span>(nBytes), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(B_d_v, B-&gt;v, <span class="built_in">sizeof</span>(nBytes), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(C_d_v, C-&gt;v, <span class="built_in">sizeof</span>(nBytes), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *A_d_v_t = A-&gt;v;</span><br><span class="line">    <span class="type">float</span> *B_d_v_t = B-&gt;v;</span><br><span class="line">    <span class="type">float</span> *C_d_v_t = C-&gt;v;</span><br><span class="line"></span><br><span class="line">    A-&gt;v = A_d_v;</span><br><span class="line">    B-&gt;v = B_d_v;</span><br><span class="line">    C-&gt;v = C_d_v;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(A_d, A, <span class="built_in">sizeof</span>(Matrix), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(B_d, B, <span class="built_in">sizeof</span>(Matrix), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(C_d, C, <span class="built_in">sizeof</span>(Matrix), cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    A-&gt;v = A_d_v_t;</span><br><span class="line">    B-&gt;v = B_d_v_t;</span><br><span class="line">    C-&gt;v = C_d_v_t;</span><br><span class="line">    </span><br><span class="line">    <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">gridSize</span><span class="params">((w + blockSize.x - <span class="number">1</span>) / blockSize.x, (h + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line">    MatrixAdd &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A_d, B_d, C_d);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨<code>nsys nvprof &#123;&#125;.o</code>å¾—åˆ°ä¸¤ä¸ªç‰ˆæœ¬çš„æ•°æ®ä¼ è¾“æ—¶é—´</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// cudaMalloc ç‰ˆæœ¬</span></span><br><span class="line"> <span class="title class_">Time</span> (%)  <span class="title class_">Total</span> <span class="title class_">Time</span> (ns)  <span class="title class_">Count</span>  <span class="title class_">Avg</span> (ns)  <span class="title class_">Med</span> (ns)  <span class="title class_">Min</span> (ns)  <span class="title class_">Max</span> (ns)  <span class="title class_">StdDev</span> (ns)      <span class="title class_">Operation</span>     </span><br><span class="line"> --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">    <span class="number">100.0</span>             <span class="number">6817</span>      <span class="number">6</span>    <span class="number">1136.2</span>     <span class="number">992.5</span>       <span class="number">960</span>      <span class="number">1536</span>        <span class="number">243.4</span>  [<span class="variable constant_">CUDA</span> memcpy <span class="title class_">HtoD</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// cudaMallocHost ç‰ˆæœ¬</span></span><br><span class="line"> <span class="title class_">Time</span> (%)  <span class="title class_">Total</span> <span class="title class_">Time</span> (ns)  <span class="title class_">Count</span>  <span class="title class_">Avg</span> (ns)  <span class="title class_">Med</span> (ns)  <span class="title class_">Min</span> (ns)  <span class="title class_">Max</span> (ns)  <span class="title class_">StdDev</span> (ns)      <span class="title class_">Operation</span>     </span><br><span class="line"> --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">    <span class="number">100.0</span>             <span class="number">6304</span>      <span class="number">6</span>    <span class="number">1050.7</span>     <span class="number">992.0</span>       <span class="number">928</span>      <span class="number">1344</span>        <span class="number">153.4</span>  [<span class="variable constant_">CUDA</span> memcpy <span class="title class_">HtoD</span>]</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°ä½¿ç”¨<code>cudaMallocHost</code>å‡½æ•°ç›¸æ¯”<code>cudaMalloc</code>ï¼Œå› å…¶å›ºå®šå†…å­˜çš„ç‰¹æ€§ï¼Œä¼ è¾“æ•ˆç‡é«˜äº†ä¸€äº›</p><blockquote><p>ä¸Šé¢ç¨‹åºä¸­ç”¨<code>cudaMalloc</code>å°†ç»“æ„ä½“ä»ä¸»æœºä¼ è¾“åˆ°è®¾å¤‡çš„æ–¹æ³•ååˆ†ç¹çä¸”å·²ç»è¿‡æ—¶äº†ï¼Œåœ¨è¿™é‡Œåªä½œæµ‹è¯•ï¼Œå»ºè®®ä½¿ç”¨ç¬¬ä¸‰ç« ä¸­æåˆ°çš„<code>cudaMallocManaged</code>å‡½æ•°ï¼Œåç»­ä¼šè¯¦ç»†ä»‹ç»è¯¥å‡½æ•°</p></blockquote><h3 id="é›¶æ‹·è´å†…å­˜"><a href="#é›¶æ‹·è´å†…å­˜" class="headerlink" title="é›¶æ‹·è´å†…å­˜"></a>é›¶æ‹·è´å†…å­˜</h3><p>åœ¨ GPU ç¼–ç¨‹ä¸­ï¼Œä¸»æœºå˜é‡å’Œè®¾å¤‡å˜é‡ä¹‹é—´ä¸€èˆ¬ä¸èƒ½ç›´æ¥ç›¸äº’è®¿é—®ï¼Œä½†ä¸»æœºå˜é‡å’Œè®¾å¤‡å˜é‡éƒ½å¯ä»¥è®¿é—®é›¶æ‹·è´å†…å­˜ã€‚GPUçº¿ç¨‹å¯ä»¥ç›´æ¥è®¿é—®ä¸»æœºé‡Œçš„é›¶æ‹·è´å†…å­˜ï¼Œå½“æœ‰ä»¥ä¸‹å‡ ç§æƒ…å†µæ—¶æ ¸å‡½æ•°ä¼šä½¿ç”¨é›¶æ‹·è´å†…å­˜</p><ul><li>å½“è®¾å¤‡å†…å­˜ä¸è¶³æ—¶</li><li>é¿å…ä¸»æœºå’Œè®¾å¤‡ä¹‹é—´çš„æ˜¾å¼å†…å­˜ä¼ è¾“</li><li>ä¸ºäº†æé«˜PCIeä¼ è¾“ç‡</li></ul><p>å½“ä½¿ç”¨é›¶æ‹·è´å†…å­˜æ—¶è¦åŒæ­¥è®¾å¤‡å’Œä¸»æœºé—´çš„å†…å­˜è®¿é—®ï¼Œé¿å…å†…å­˜ç«äº‰ã€‚é›¶æ‹·è´å†…å­˜æ˜¯å›ºå®šå†…å­˜ï¼Œä¸å¯åˆ†é¡µã€‚ä½¿ç”¨ä»¥ä¸‹å‡½æ•°å¯ä»¥åˆ›å»ºé›¶æ‹·è´å†…å­˜</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaHostAlloc</span> <span class="params">( <span class="type">void</span>** pHost, <span class="type">size_t</span> size, <span class="type">unsigned</span> <span class="type">int</span>  flags )</span></span></span><br></pre></td></tr></table></figure><ul><li><p><code>pHost</code>: æŒ‡å‘å°†è¢«åˆ†é…çš„å†…å­˜åœ°å€</p></li><li><p><code>size</code>: è¦åˆ†é…çš„å†…å­˜å—çš„å¤§å°</p></li><li><p><code>flags</code>: ç”¨äºæ§åˆ¶å‡½æ•°è¡Œä¸ºï¼Œå¯é€‰å¦‚ä¸‹</p><ul><li><p><code>cudaHostAllocDefault</code>: é»˜è®¤ï¼Œå’Œ<code>cudaMallocHost</code>ä¸€è‡´ï¼Œä½¿ç”¨ç³»ç»Ÿçš„é»˜è®¤å†…å­˜ç±»å‹åˆ†é…å†…å­˜ï¼Œ</p></li><li><p><code>cudaHostAllocPortable</code>: åˆ†é…å›ºå®šå†…å­˜ï¼Œå¯ä»¥è¢«æ‰€æœ‰ CUDA ä¸Šä¸‹æ–‡ä½¿ç”¨</p></li><li><p><code>cudaHostAllocMapped</code>: åˆ†é…é›¶æ‹·è´å†…å­˜ï¼Œå°†å†…å­˜åˆ†é…æ˜ å°„åˆ°è®¾å¤‡çš„åœ°å€ç©ºé—´ï¼Œå¿…é¡»ä½¿ç”¨ä»¥ä¸‹å‡½æ•°å¾—åˆ°æŒ‡å‘ä¸»æœºä¸Šé›¶æ‹·è´å†…å­˜çš„è®¾å¤‡æŒ‡é’ˆ <code>pDevice</code>ï¼Œè®¾å¤‡æ‰èƒ½è®¿é—®é›¶æ‹·è´å†…å­˜</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaHostGetDevicePointer</span><span class="params">(<span class="type">void</span> ** pDevice,<span class="type">void</span> * pHost,<span class="type">unsigned</span> flags)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>pDevice</code>: è®¿é—®ä¸»æœºé›¶æ‹·è´å†…å­˜çš„è®¾å¤‡æŒ‡é’ˆ</li><li><code>pHost</code>: åŒä¸Š<code>pHost</code></li><li><code>flags</code>: æ­¤å¤„å¿…é¡»ç½®0ï¼Œåç»­ä»‹ç»åŸå› </li></ul></li><li><p><code>cudaHostAllocWriteCombined</code>: å°†å†…å­˜åˆ†é…ä¸ºå†™ç»„åˆï¼ˆWrite-combined memoryï¼‰ï¼Œå¯ä»¥åœ¨æŸäº›ç³»ç»Ÿé…ç½®ä¸Šæ›´å¿«åœ°é€šè¿‡ PCIe ä¼ è¾“ï¼Œæé«˜è®¾å¤‡å†™å…¥å†…å­˜çš„æ€§èƒ½</p></li></ul></li></ul><p>ä¸»æœºä¸Šå›ºå®šå†…å­˜çš„é‡Šæ”¾</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaFreeHost</span> <span class="params">( <span class="type">void</span>* ptr )</span></span></span><br></pre></td></tr></table></figure><p>ä¸‹é¢çš„ç¨‹åºè®¡ç®—äº†å‘é‡ä¹˜æ³•ï¼Œå¯¹æ¯”äº†<code>cudaMallocHost</code>å’Œ<code>cudaHostAlloc</code>çš„ä¼ è¾“æ•ˆç‡</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraySum</span><span class="params">(<span class="type">float</span>*a,<span class="type">float</span>*b,<span class="type">float</span>*res)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i=blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    res[i]=a[i]+b[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaSetDevice</span>(dev);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nElem=<span class="number">1</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> nBytes=<span class="built_in">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *A_hp,*B_hp;</span><br><span class="line">    <span class="type">float</span> *A_dp,*B_dp,*C_dp;</span><br><span class="line">    A_hp = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    B_hp = (<span class="type">float</span> *)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">    <span class="built_in">memset</span>(A_hp,<span class="number">1</span>,nBytes);</span><br><span class="line">    <span class="built_in">memset</span>(B_hp,<span class="number">2</span>,nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;A_dp,nBytes);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;B_dp,nBytes);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;C_dp,nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(A_dp,A_hp,nBytes,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(B_dp,B_hp,nBytes,cudaMemcpyHostToDevice);</span><br><span class="line">    </span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(nElem/block.x)</span></span>;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *A_hm, *B_hm, *C_hm;</span><br><span class="line">    <span class="type">float</span> *A_dm, *B_dm, *C_dm;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;A_hm, nBytes, cudaHostAllocMapped);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;B_hm, nBytes, cudaHostAllocMapped);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;C_hm, nBytes, cudaHostAllocMapped);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        A_hm[i]=<span class="number">1.0</span>;</span><br><span class="line">        B_hm[i]=<span class="number">2.0</span>;</span><br><span class="line">        C_hm[i]=<span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaHostGetDevicePointer</span>((<span class="type">void</span>**)&amp;A_dm, (<span class="type">void</span>*)A_hm, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaHostGetDevicePointer</span>((<span class="type">void</span>**)&amp;B_dm, (<span class="type">void</span>*)B_hm, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaHostGetDevicePointer</span>((<span class="type">void</span>**)&amp;C_dm, (<span class="type">void</span>*)C_hm, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line">    ArraySum&lt;&lt;&lt;grid, block&gt;&gt;&gt;(A_dp, B_dp, C_dp);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    <span class="type">float</span> elapsedTime=<span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;cudaMallocHost: %f ms\n&quot;</span>,  elapsedTime);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line">    ArraySum&lt;&lt;&lt;grid, block&gt;&gt;&gt;(A_dm, B_dm, C_dm);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    elapsedTime=<span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;cudaHostAlloc: %f ms\n&quot;</span>,  elapsedTime);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(stop);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">free</span>(A_hp);</span><br><span class="line">    <span class="built_in">free</span>(B_hp);</span><br><span class="line">    <span class="built_in">cudaFreeHost</span>(A_hm);</span><br><span class="line">    <span class="built_in">cudaFreeHost</span>(B_hm);</span><br><span class="line">    <span class="built_in">cudaFreeHost</span>(C_hm);</span><br><span class="line">    <span class="built_in">cudaFree</span>(A_dp);</span><br><span class="line">    <span class="built_in">cudaFree</span>(B_dp);</span><br><span class="line">    <span class="built_in">cudaFree</span>(C_dp);</span><br><span class="line">    <span class="built_in">cudaFree</span>(A_dm);</span><br><span class="line">    <span class="built_in">cudaFree</span>(B_dm);</span><br><span class="line">    <span class="built_in">cudaFree</span>(C_dm);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line">cudaMallocHost: <span class="number">0.050720</span> ms</span><br><span class="line">cudaHostAlloc: <span class="number">1.258496</span> ms</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°é›¶æ‹·è´å†…å­˜çš„å†…æ ¸å‡½æ•°æ‰§è¡Œæ•ˆç‡ä¼šå¤§å¤§é™ä½ï¼Œå› ä¸ºå…¶æ•°æ®çš„ä¼ è¾“æ˜¯åœ¨æ‰§è¡Œå†…æ ¸å‡½æ•°æ—¶ï¼Œè¿™ç§æ‰§è¡Œæ–¹å¼ä¸é€‚åˆç¦»æ•£æ¶æ„ï¼Œå¦‚æˆ‘ä»¬å¹³æ—¶ç”¨çš„é€šè¿‡ PCIe æ€»çº¿ä¼ è¾“æ•°æ®çš„ç‹¬æ˜¾ + CPU æ¶æ„ï¼Œè€Œéå¸¸é€‚åˆåœ¨ Nvidia é›†æˆæ¶æ„çš„è®¾å¤‡ä¸Šä½¿ç”¨ï¼Œä¹Ÿå°±æ˜¯å…±äº«ç‰©ç†å†…å­˜çš„æ¶æ„</p><h3 id="ç»Ÿä¸€è™šæ‹Ÿå¯»å€"><a href="#ç»Ÿä¸€è™šæ‹Ÿå¯»å€" class="headerlink" title="ç»Ÿä¸€è™šæ‹Ÿå¯»å€"></a>ç»Ÿä¸€è™šæ‹Ÿå¯»å€</h3><p>ç»Ÿä¸€è™šæ‹Ÿå¯»å€ï¼ˆUVAï¼‰æ˜¯ Nvidia åœ¨è®¡ç®—èƒ½åŠ› 2.0 ä¹‹åçš„è®¾å¤‡æ”¯æŒçš„ç‰¹æ®Šå¯»å€æ–¹å¼ï¼Œè®¾å¤‡å†…å­˜å’Œä¸»æœºå†…å­˜è¢«æ˜ å°„åˆ°ç»Ÿä¸€è™šæ‹Ÿå†…å­˜åœ°å€ä¸­ï¼Œå…±äº«ä¸€ä¸ªè™šæ‹Ÿåœ°å€ç©ºé—´ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/2.webp" alt=""></p><p>åœ¨ UVA å‡ºæ¥ä¹‹å‰ï¼Œä»£ç ä¸­çš„æŒ‡é’ˆå˜é‡éœ€è¦åŒºåˆ†æŒ‡å‘ä¸»æœºå†…å­˜è¿˜æ˜¯è®¾å¤‡å†…å­˜ï¼Œé€šè¿‡UVAï¼Œå¯ä»¥é€šè¿‡<code>cudaHostAlloc</code> å‡½æ•°åˆ†é…å›ºå®šä¸»æœºå†…å­˜ï¼ŒæŒ‡é’ˆæŒ‡å‘ç›¸åŒçš„ä¸»æœºå’Œè®¾å¤‡åœ°å€ï¼Œå¯ä»¥ç›´æ¥å°†æŒ‡é’ˆä¼ é€’ç»™æ ¸å‡½æ•°ï¼Œç›¸å½“äºçœç•¥äº†é›¶æ‹·è´å†…å­˜çš„<code>cudaHostGetDevicePointer</code>æ­¥éª¤</p><p>åˆ é™¤å‰é¢çš„é›¶æ‹·è´å†…å­˜ä»£ç ä¸­<code>cudaHostGetDevicePointer</code>å‡½æ•°å’Œè®¾å¤‡æŒ‡é’ˆéƒ¨åˆ†ï¼Œå¦‚ä¸‹ä»£ç å°±ä½¿ç”¨äº† UVA çš„å¯»å€æ–¹å¼</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaSetDevice</span>(dev);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nElem=<span class="number">1</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> nBytes=<span class="built_in">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(nElem/block.x)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *A_h, *B_h, *C_h;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;A_h, nBytes, cudaHostAllocMapped);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;B_h, nBytes, cudaHostAllocMapped);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;C_h, nBytes, cudaHostAllocMapped);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        A_h[i]=<span class="number">1.0</span>;</span><br><span class="line">        B_h[i]=<span class="number">2.0</span>;</span><br><span class="line">        C_h[i]=<span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ArraySum&lt;&lt;&lt;grid, block&gt;&gt;&gt;(A_h, B_h, C_h);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaFreeHost</span>(A_h);</span><br><span class="line">    <span class="built_in">cudaFreeHost</span>(B_h);</span><br><span class="line">    <span class="built_in">cudaFreeHost</span>(C_h);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ç»Ÿä¸€å†…å­˜å¯»å€"><a href="#ç»Ÿä¸€å†…å­˜å¯»å€" class="headerlink" title="ç»Ÿä¸€å†…å­˜å¯»å€"></a>ç»Ÿä¸€å†…å­˜å¯»å€</h3><p>åœ¨ CUDA 6.0 ä¸­ï¼Œåˆå¼•å…¥äº†ç»Ÿä¸€å†…å­˜å¯»å€çš„ç‰¹æ€§ï¼Œç”¨äºç®€åŒ–å†…å­˜ç®¡ç†ã€‚ç»Ÿä¸€å†…å­˜ä¸­åˆ›å»ºäº†ä¸€ä¸ªæ‰˜ç®¡å†…å­˜æ± ï¼Œå†…å­˜æ± ä¸­å·²åˆ†é…çš„ç©ºé—´å¯ä»¥ç”¨ç›¸åŒçš„æŒ‡é’ˆåœ¨ CPU å’Œ GPU ä¸Šè¿›è¡Œè®¿é—®ã€‚åº•å±‚ç³»ç»Ÿåœ¨ç»Ÿä¸€çš„å†…å­˜ç©ºé—´ä¸­è‡ªåŠ¨çš„è¿›è¡Œè®¾å¤‡å’Œä¸»æœºé—´çš„ä¼ è¾“</p><p>ç»Ÿä¸€å†…å­˜å¯»å€ä¾èµ–äºå‰é¢æåˆ°çš„ UVAï¼Œä¸åŒä¹‹å¤„åœ¨äº</p><ul><li>ç»Ÿä¸€å†…å­˜å¯»å€æä¾›äº†ä¸€ä¸ªâ€œå•æŒ‡é’ˆåˆ°æ•°æ®â€çš„ç¼–ç¨‹æ¨¡å‹ï¼Œé€šè¿‡åº•å±‚ç³»ç»Ÿè¿›è¡Œç»Ÿä¸€å†…å­˜ç®¡ç†ï¼Œè¢«ç§°ä¸ºæ‰˜ç®¡å†…å­˜ï¼Œè‡ªå·±åˆ†é…çš„å†…å­˜ç§°ä¸ºæœªæ‰˜ç®¡å†…å­˜ï¼Œä¸¤ç§ç±»å‹çš„å†…å­˜å¯ä»¥åŒæ—¶ä¼ é€’ç»™æ ¸å‡½æ•°</li><li>UVA çš„åˆ†é…æ˜¯å…ˆåœ¨ä¸»æœºä¸Šå®Œæˆï¼Œåœ¨æ ¸å‡½æ•°è¿è¡Œå‰æ‰ä¼ è¾“æ•°æ®ç»™è®¾å¤‡</li></ul><p>æ‰˜ç®¡å†…å­˜å¯ä»¥è¢«é™æ€åˆ†é…æˆ–åŠ¨æ€åˆ†é…ï¼Œåœ¨å®šä¹‰è®¾å¤‡å˜é‡æ—¶æ·»åŠ  <code>__managed__</code> å…³é”®å­—ä¿®é¥°é™æ€æ‰˜ç®¡å†…å­˜å˜é‡ï¼Œå¦‚ä¸‹ä»£ç æ‰€ç¤ºï¼Œé™æ€å£°æ˜çš„æ‰˜ç®¡å†…å­˜ä½œç”¨åŸŸæ˜¯æ–‡ä»¶ï¼Œè¯¥å˜é‡å¯ä»¥åœ¨ä¸»æœºæˆ–è®¾å¤‡ä»£ç ä¸­ç›´æ¥å¼•ç”¨</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__managed__ <span class="type">float</span> x;</span><br></pre></td></tr></table></figure><p>ç¬¬ä¸‰ç« ä½¿ç”¨è¿‡çš„<code>cudaMallocManaged</code>å‡½æ•°å°±æ˜¯åŠ¨æ€åˆ†é…æ‰˜ç®¡å†…å­˜å˜é‡</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaMallocManaged</span> <span class="params">( <span class="type">void</span>** devPtr, <span class="type">size_t</span> size, <span class="type">unsigned</span> <span class="type">int</span>  flags = cudaMemAttachGlobal )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>devPtr</code>: å¼€è¾Ÿæ•°æ®çš„é¦–æŒ‡é’ˆ</li><li><code>size</code>: å¼€è¾Ÿçš„è®¾å¤‡å†…å­˜ç©ºé—´é•¿åº¦</li><li><code>flags</code>: é»˜è®¤ä¸º<code>cudaMemAttachGlobal</code><ul><li><code>cudaMemAttachGlobal</code>: å¼€è¾Ÿçš„å†…å­˜å¯ä»¥è¢«ä»»ä½•è®¾å¤‡ä¸Šçš„ä»»ä½•æµè®¿é—®ï¼Œæµçš„æ¦‚å¿µå°†åœ¨ä¸‹ä¸€ç« èŠ‚ä»‹ç»</li><li><code>cudaMemAttachHost</code>: å¼€è¾Ÿçš„å†…å­˜ä¸èƒ½è¢«ä»»ä½•è®¾å¤‡ä¸Šçš„ä»»ä½•æµè®¿é—®</li></ul></li></ul><p>ä½¿ç”¨<code>cudaMallocManaged</code>å‡½æ•°åŠ¨æ€å£°æ˜æ•°ç»„ï¼Œåˆ†é…æ‰˜ç®¡å†…å­˜å˜é‡</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaSetDevice</span>(dev);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nElem=<span class="number">1</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> nBytes=<span class="built_in">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(nElem/block.x)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> *A, *B, *C;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;A, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;B, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;C, nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        A[i]=<span class="number">1.0</span>;</span><br><span class="line">        B[i]=<span class="number">2.0</span>;</span><br><span class="line">        C[i]=<span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ArraySum&lt;&lt;&lt;grid, block&gt;&gt;&gt;(A, B, C);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaFree</span>(A);</span><br><span class="line">    <span class="built_in">cudaFree</span>(B);</span><br><span class="line">    <span class="built_in">cudaFree</span>(C);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="å†…å­˜è®¿é—®æ¨¡å¼"><a href="#å†…å­˜è®¿é—®æ¨¡å¼" class="headerlink" title="å†…å­˜è®¿é—®æ¨¡å¼"></a>å†…å­˜è®¿é—®æ¨¡å¼</h2><p>å¤šæ•° GPU ç¨‹åºå®¹æ˜“å—åˆ°å†…å­˜å¸¦å®½çš„é™åˆ¶ï¼Œæ‰€ä»¥æœ€å¤§ç¨‹åº¦çš„åˆ©ç”¨å…¨å±€å†…å­˜å¸¦å®½ï¼Œæé«˜å…¨å±€åŠ è½½æ•ˆç‡ï¼Œæ˜¯è°ƒæ§å†…æ ¸å‡½æ•°æ€§èƒ½çš„åŸºæœ¬æ¡ä»¶ã€‚å¦‚æœä¸èƒ½æ­£ç¡®ç®¡ç†å…¨å±€å†…å­˜ï¼Œé‚£ä¹ˆä¼˜åŒ–æ–¹æ¡ˆå¯èƒ½ä¹Ÿæ”¶æ•ˆç”šå¾®<br>åœ¨ CUDA æ‰§è¡Œæ¨¡å‹ä¸­å¾—çŸ¥ CUDA æ‰§è¡Œçš„åŸºæœ¬å•ä½æ˜¯çº¿ç¨‹æŸï¼Œæ‰€ä»¥å†…å­˜è®¿é—®å’Œæ•°æ®å­˜å‚¨ä¹Ÿæ˜¯ä»¥çº¿ç¨‹æŸä¸ºåŸºæœ¬å•ä½å‘å¸ƒå’Œæ‰§è¡Œçš„ï¼Œåœ¨çº¿ç¨‹æŸçš„ 32 ä¸ªçº¿ç¨‹ä¸­ï¼Œæ¯ä¸ªçº¿ç¨‹éƒ½ä¼šæå‡ºä¸€ä¸ªåŒ…å«è¯·æ±‚åœ°å€çš„å•ä¸€å†…å­˜è®¿é—®è¯·æ±‚ï¼Œæ ¹æ®çº¿ç¨‹æŸä¸­å†…å­˜åœ°å€çš„åˆ†å¸ƒï¼Œå†…å­˜è®¿é—®ä¼šè¢«åˆ†æˆä¸åŒçš„æ¨¡å¼ï¼Œä¸‹é¢å°†ä»‹ç»è¿™äº›ä¸åŒçš„å†…å­˜è®¿é—®æ¨¡å¼ï¼Œå¹¶å­¦ä¹ å®ç°æœ€ä½³çš„å…¨å±€å†…å­˜è®¿é—®</p><h3 id="å¯¹é½ä¸åˆå¹¶è®¿é—®"><a href="#å¯¹é½ä¸åˆå¹¶è®¿é—®" class="headerlink" title="å¯¹é½ä¸åˆå¹¶è®¿é—®"></a>å¯¹é½ä¸åˆå¹¶è®¿é—®</h3><p>å…¨å±€å†…å­˜ï¼ˆDRAMï¼‰æ˜¯ä¸€ä¸ªé€»è¾‘å†…å­˜ç©ºé—´ï¼Œå¯ä»¥é€šè¿‡æ ¸å‡½æ•°è®¿é—®å®ƒï¼Œæ‰€æœ‰çš„ç¨‹åºæ•°æ®éƒ½æ˜¯å‚¨åœ¨ç‰©ç†è®¾å¤‡å†…å­˜ä¸Šï¼Œä¹Ÿå°±æ˜¯ DRAM è®¾å¤‡ä¸Šï¼Œæ ¸å‡½æ•°çš„å†…å­˜è¯·æ±‚é€šå¸¸æ˜¯åœ¨ DRAM è®¾å¤‡å’Œç‰‡ä¸Šå†…å­˜é—´ä¸Šä»¥ 32 å­—èŠ‚æˆ– 128 å­—èŠ‚ç²’åº¦çš„å†…å­˜äº‹åŠ¡æ¥å®ç°ï¼Œå†…å­˜äº‹åŠ¡å°±æ˜¯ä»å†…æ ¸å‡½æ•°å‘èµ·è¯·æ±‚ï¼Œåˆ°ç¡¬ä»¶å“åº”è¿”å›æ•°æ®è¿‡ç¨‹</p><p>æ‰€æœ‰å¯¹å…¨å±€å†…å­˜çš„è®¿é—®éƒ½ä¼šé€šè¿‡äºŒçº§ç¼“å­˜ï¼Œä¹Ÿæœ‰è®¸å¤šè®¿é—®ä¼šé€šè¿‡ä¸€çº§ç¼“å­˜ï¼Œè¿™å–å†³äºè®¿é—®ç±»å‹å’Œ GPU æ¶æ„</p><p>ç§° L1 ä¸ºä¸€çº§ç¼“å­˜ï¼ŒL2 ä¸ºäºŒçº§ç¼“å­˜ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¯ä¸ª SM éƒ½æœ‰è‡ªå·± L1ï¼Œä½†æ˜¯ L2 æ˜¯æ‰€æœ‰ SM å…¬ç”¨çš„ï¼Œæ ¸å‡½æ•°è¿è¡Œæ—¶éœ€è¦ä» DRAM ä¸­è¯»å–æ•°æ®ï¼Œè¯»å–æ—¶å¦‚æœä½¿ç”¨ L1 åˆ™ä» DRAM ä¸Šä¸€æ¬¡åŠ è½½çš„æ•°æ®æ˜¯ 128 å­—èŠ‚ï¼Œå¦‚æœä¸ä½¿ç”¨ L1 åˆ™ä» DRAM ä¸Šä¸€æ¬¡åŠ è½½çš„æ•°æ®æ˜¯ 32 å­—èŠ‚</p><p>ä¸€è¡Œä¸€çº§ç¼“å­˜æ˜¯ 128 å­—èŠ‚ï¼Œæ˜ å°„åˆ°è®¾å¤‡å†…å­˜ä¸­ä¸€ä¸ª 128 å­—èŠ‚çš„å¯¹é½æ®µï¼Œå¦‚æœçº¿ç¨‹æŸä¸­çš„æ¯ä¸ªçº¿ç¨‹è¯·æ±‚ä¸€ä¸ª 4 å­—èŠ‚çš„å€¼ï¼Œé‚£ä¹ˆæ¯æ¬¡è¯·æ±‚éƒ½ä¼šè·å– 4 x 32 = 128 å­—èŠ‚çš„æ•°æ®ï¼Œè¿™æ°å¥½ä¸ç¼“å­˜è¡Œå’Œè®¾å¤‡å†…å­˜æ®µçš„å¤§å°ç›¸å¥‘åˆï¼Œå› æ­¤æˆ‘ä»¬è¦æ³¨æ„è®¾å¤‡å†…å­˜è®¿é—®çš„ï¼š</p><ul><li>å¯¹é½å†…å­˜è®¿é—®</li><li>åˆå¹¶å†…å­˜è®¿é—®</li></ul><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/3.webp" alt=""></p><p>å½“è®¾å¤‡å†…å­˜äº‹åŠ¡çš„ç¬¬ä¸€ä¸ªåœ°å€æ˜¯ç”¨äºäº‹åŠ¡æœåŠ¡çš„ç¼“å­˜ç²’åº¦çš„å¶æ•°å€æ•°æ—¶ï¼ˆ32æˆ–128å­—èŠ‚ï¼‰ï¼Œç§°ä¸ºå¯¹é½å†…å­˜è®¿é—®ï¼Œå½“ä¸€ä¸ªçº¿ç¨‹æŸå†…çš„çº¿ç¨‹è®¿é—®çš„å†…å­˜éƒ½åœ¨ä¸€ä¸ªå†…å­˜å—é‡Œçš„æ—¶å€™ï¼Œå°±ä¼šå‡ºç°åˆå¹¶è®¿é—®ã€‚å¯¹é½ä¸åˆå¹¶è®¿é—®çš„æƒ…å†µå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåªéœ€è¦ 128 å­—èŠ‚çš„å†…å­˜äº‹åŠ¡ä»è®¾å¤‡å†…å­˜ä¸­è¯»å–æ•°æ®</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/4.webp" alt=""></p><p>ä½†å¦‚æœä¸€ä¸ªå†…å­˜äº‹åŠ¡åŠ è½½çš„æ•°æ®åˆ†å¸ƒåœ¨ä¸ä¸€ä¸ªå¯¹é½çš„åœ°å€æ®µä¸Šï¼Œå°±ä¼šæœ‰ä»¥ä¸‹ä¸¤ç§æƒ…å†µ</p><ul><li>å†…å­˜åœ°å€è¿ç»­ï¼Œä½†ä¸åœ¨ä¸€ä¸ªå¯¹é½çš„æ®µä¸Šï¼Œå¦‚è¯·æ±‚è®¿é—®çš„æ•°æ®åˆ†å¸ƒåœ¨å†…å­˜åœ°å€ 1-128ï¼Œé‚£ä¹ˆ 0-127 å’Œ 128-255 è¿™ä¸¤æ®µæ•°æ®è¦ä¼ é€’ä¸¤æ¬¡åˆ° SM</li><li>å†…å­˜åœ°å€ä¸è¿ç»­ï¼Œä¹Ÿä¸åœ¨ä¸€ä¸ªå¯¹é½çš„æ®µä¸Šï¼Œå¦‚è¯·æ±‚è®¿é—®çš„æ•°æ®åˆ†å¸ƒåœ¨å†…å­˜åœ°å€ 0-63 å’Œ 128-191 ä¸Šï¼Œé‚£ä¹ˆè¿™ä¸¤æ®µæ•°æ®ä¹Ÿè¦ä¼ é€’ä¸¤æ¬¡</li></ul><p>ä¸Šè¿°ä¸¤ç§æƒ…å†µä¼šä½¿å†…å­˜äº‹åŠ¡è·å–çš„å¤§éƒ¨åˆ†å­—èŠ‚ä¸èƒ½ä½¿ç”¨ï¼Œé€ æˆå¸¦å®½çš„æµªè´¹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/5.webp" alt=""></p><p>æˆ‘ä»¬éœ€è¦ä¼˜åŒ–å†…å­˜äº‹åŠ¡çš„æ•ˆç‡ï¼Œæé«˜ååé‡</p><h3 id="å…¨å±€å†…å­˜è¯»å–"><a href="#å…¨å±€å†…å­˜è¯»å–" class="headerlink" title="å…¨å±€å†…å­˜è¯»å–"></a>å…¨å±€å†…å­˜è¯»å–</h3><p>SM ä¸­çš„æ•°æ®æ ¹æ®ä¸åŒçš„è®¾å¤‡å’Œç±»å‹ä»¥ 3 ç§ä¸åŒçš„è·¯å¾„è¿›è¡Œä¼ è¾“</p><ul><li>L1 å’Œ L2</li><li>å¸¸é‡ç¼“å­˜</li><li>åªè¯»ç¼“å­˜</li></ul><p>é»˜è®¤è·¯å¾„æ˜¯ L1 å’Œ L2ï¼Œéœ€è¦ä½¿ç”¨å¸¸é‡å’Œåªè¯»ç¼“å­˜çš„éœ€è¦åœ¨ä»£ç ä¸­æ˜¾å¼å£°æ˜ã€‚ä½†æ˜¯æé«˜æ€§èƒ½è¿˜æ˜¯è¦å–å†³äºè®¿é—®æ¨¡å¼ï¼Œå…¨å±€åŠ è½½æ“ä½œæ˜¯å¦é€šè¿‡ L1 å¯ä»¥é€šè¿‡ç¼–è¯‘é€‰é¡¹æ¥æ§åˆ¶ï¼Œåœ¨è®¡ç®—èƒ½åŠ›ä¸º 2.X å’Œ 3.5 ä»¥ä¸Šçš„ GPU ä¸­ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹ç¼–è¯‘å™¨æ ‡è¯†ç¬¦ç¦ç”¨ L1</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -Xptxas -dlcm=cg</span><br></pre></td></tr></table></figure><p>é€šè¿‡ä»¥ä¸‹ç¼–è¯‘å™¨æ ‡è¯†ç¬¦å¯ç”¨ L1</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -Xptxas -dlcm=ca</span><br></pre></td></tr></table></figure><p>å½“ SM æœ‰å…¨å±€åŠ è½½è¯·æ±‚ä¼šé¦–å…ˆå°è¯•é€šè¿‡ L1ï¼Œå¦‚æœ L1 è¢«ç¦ç”¨ï¼Œè¯·æ±‚è½¬å‘ L2ï¼Œå¦‚æœ L2 ç¼ºå¤±ï¼Œåˆ™ç”± DRAM å®Œæˆè¯·æ±‚ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå†…å­˜åŠ è½½è¯·æ±‚ç”± 128 å­—èŠ‚çš„è®¾å¤‡å†…å­˜äº‹åŠ¡å®ç°</p><blockquote><p>Kepler K10, K20, K20X GPU ä¸­ï¼ŒL1 ä¸ç”¨æ¥ç¼“å­˜å…¨å±€å†…å­˜è®¿é—®ï¼Œåªç”¨æ¥å­˜å‚¨å¯„å­˜å™¨æº¢å‡ºçš„æœ¬åœ°æ•°æ®</p></blockquote><h4 id="ç¼“å­˜åŠ è½½"><a href="#ç¼“å­˜åŠ è½½" class="headerlink" title="ç¼“å­˜åŠ è½½"></a>ç¼“å­˜åŠ è½½</h4><p>ç¼“å­˜åŠ è½½æ˜¯æŒ‡ç»è¿‡ L1ï¼Œåœ¨ç²’åº¦ä¸º 128 å­—èŠ‚çš„ L1 ä¸Šç”±è®¾å¤‡å†…å­˜äº‹åŠ¡è¿›è¡Œä¼ è¾“ã€‚ç¼“å­˜åŠ è½½å¯ä»¥åˆ†ä¸ºå¯¹é½/éå¯¹é½ä½†åˆå¹¶/éåˆå¹¶</p><p>ä¸‹å›¾æ‰€ç¤ºä¸ºå¯¹é½åˆå¹¶çš„æƒ…å†µï¼Œåˆ©ç”¨ç‡ä¸º 100%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/6.webp" alt=""></p><p>å¯¹é½ä½†ä¸è¿ç»­çš„æƒ…å†µï¼Œåˆ©ç”¨ç‡ä¸º 100%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/7.webp" alt=""></p><p>éå¯¹é½ä½†è¿ç»­çš„æƒ…å†µï¼Œå› ä¸ºçº¿ç¨‹æŸè¯·æ±‚çš„ 32 ä¸ªè¿ç»­çš„ 4 å­—èŠ‚å…ƒç´ åœ¨ä¸¤ä¸ª 128 å­—èŠ‚æ®µå†…ï¼Œæ‰€ä»¥åˆ©ç”¨ç‡ä¸º 50%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/8.webp" alt=""></p><p>çº¿ç¨‹æŸä¸­æ‰€æœ‰çº¿ç¨‹è¯·æ±‚åŒä¸€ä¸ªåœ°å€çš„æƒ…å†µï¼Œåˆ©ç”¨ç‡ä¸º 4/128 = 3.125%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/9.webp" alt=""></p><p>æœ€åçš„æƒ…å†µï¼Œæ¯ä¸ªçº¿ç¨‹æŸå†…çš„çº¿ç¨‹è¯·æ±‚çš„éƒ½æ˜¯ä¸åŒçš„ç¼“å­˜è¡Œå†…ï¼Œæ¯”è¾ƒåçš„æƒ…å†µå°±æ˜¯æ‰€æœ‰æ•°æ®åˆ†å¸ƒåœ¨ N ä¸ªç¼“å­˜è¡Œä¸Šï¼Œå…¶ä¸­ 1â‰¤Nâ‰¤32ï¼Œè¯·æ±‚ 32 ä¸ª 4 å­—èŠ‚çš„æ•°æ®å°±éœ€è¦ N ä¸ªäº‹åŠ¡æ¥å®Œæˆï¼Œåˆ©ç”¨ç‡ä¸º 1/N</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/10.webp" alt=""></p><blockquote><p>CPU å’Œ GPU çš„ L1 æœ‰æ˜æ˜¾çš„å·®å¼‚ï¼ŒCPU çš„ L1 ä¼˜åŒ–äº†æ—¶é—´å’Œç©ºé—´å±€éƒ¨æ€§ï¼ŒGPU çš„ L1 æ˜¯ä¸“ä¸ºç©ºé—´å±€éƒ¨æ€§è®¾è®¡çš„ï¼Œé¢‘ç¹è®¿é—® L1 ä¸­å†…å­˜ä½ç½®ä¸ä¼šå¢åŠ æ•°æ®ç•™å­˜ç¼“å­˜ä¸­çš„æ¦‚ç‡</p></blockquote><h4 id="æ²¡æœ‰ç¼“å­˜çš„åŠ è½½"><a href="#æ²¡æœ‰ç¼“å­˜çš„åŠ è½½" class="headerlink" title="æ²¡æœ‰ç¼“å­˜çš„åŠ è½½"></a>æ²¡æœ‰ç¼“å­˜çš„åŠ è½½</h4><p>æ²¡æœ‰ç¼“å­˜çš„åŠ è½½æ˜¯æŒ‡ä¸ç»è¿‡ L1ï¼Œåªç»è¿‡ L2ï¼Œåœ¨ç²’åº¦ä¸º 32 å­—èŠ‚çš„ L2 ä¸Šç”±è®¾å¤‡å†…å­˜äº‹åŠ¡è¿›è¡Œä¼ è¾“ï¼Œæ›´ç»†çš„ç²’åº¦ä»£è¡¨æ›´é«˜çš„åˆ©ç”¨ç‡</p><p>ä¸‹å›¾æ‰€ç¤ºä¸ºå¯¹é½åˆå¹¶çš„æƒ…å†µï¼Œ128 å­—èŠ‚è¯·æ±‚çš„åœ°å€å ç”¨äº† 4 ä¸ªå†…å­˜æ®µï¼Œåˆ©ç”¨ç‡ä¸º 100%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/11.webp" alt=""></p><p>å¯¹é½ä½†ä¸è¿ç»­çš„æƒ…å†µï¼Œåˆ©ç”¨ç‡ä¸º 100%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/12.webp" alt=""></p><p>éå¯¹é½ä½†è¿ç»­çš„æƒ…å†µï¼Œå› ä¸ºçº¿ç¨‹æŸè¯·æ±‚çš„ 32 ä¸ªè¿ç»­çš„ 4 å­—èŠ‚å…ƒç´ ä½†åŠ è½½æ²¡æœ‰å¯¹é½åˆ° 128 ä¸ªå­—èŠ‚çš„è¾¹ç•Œï¼Œè¯·æ±‚çš„åœ°å€æœ€å¤šè½åœ¨ 5 ä¸ªå†…å­˜æ®µå†…ï¼Œæ‰€ä»¥åˆ©ç”¨ç‡ä¸º 4/5 = 80%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/13.webp" alt=""></p><p>çº¿ç¨‹æŸä¸­æ‰€æœ‰çº¿ç¨‹è¯·æ±‚åŒä¸€ä¸ªåœ°å€çš„æƒ…å†µï¼Œåˆ©ç”¨ç‡ä¸º 4/32 = 12.5%</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/14.webp" alt=""></p><p>æœ€åçš„æƒ…å†µï¼Œæ¯ä¸ªçº¿ç¨‹æŸå†…çš„çº¿ç¨‹è¯·æ±‚çš„éƒ½æ˜¯ä¸åŒçš„ç¼“å­˜è¡Œå†…ï¼Œç”±äºè¯·æ±‚çš„ 128 ä¸ªå­—èŠ‚æœ€å¤šè½åœ¨ N ä¸ª 32 å­—èŠ‚çš„å†…å­˜æ®µå†…è€Œä¸æ˜¯ N ä¸ª 128 å­—èŠ‚çš„ç¼“å­˜è¡Œå†…ï¼Œæ‰€ä»¥ç›¸æ¯”ç¼“å­˜åŠ è½½ï¼Œå³ä½¿æ˜¯æœ€åçš„æƒ…å†µä¹Ÿæœ‰æ‰€æ”¹å–„</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/15.webp" alt=""></p><h4 id="éå¯¹é½è¯»å–ç¤ºä¾‹"><a href="#éå¯¹é½è¯»å–ç¤ºä¾‹" class="headerlink" title="éå¯¹é½è¯»å–ç¤ºä¾‹"></a>éå¯¹é½è¯»å–ç¤ºä¾‹</h4><p>å¯¹ä¹‹å‰çš„<code>ArraySum</code>æ ¸å‡½æ•°ä»£ç æ‰§è¡ŒåŠ ä¸Šåç§»é‡</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraySum</span><span class="params">(<span class="type">float</span>*a, <span class="type">float</span>*b, <span class="type">float</span>*c, <span class="type">int</span> offset, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">int</span> k = i+offset;</span><br><span class="line">    <span class="keyword">if</span>(k &lt; n)</span><br><span class="line">        c[i] = a[k]+b[k];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaSetDevice</span>(dev);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nElem=<span class="number">1</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> nBytes=<span class="built_in">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> offset=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(argc&gt;=<span class="number">2</span>)</span><br><span class="line">        offset = <span class="built_in">atoi</span>(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(nElem/block.x)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *A, *B, *C;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;A, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;B, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;C, nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        A[i]=<span class="number">1.0</span>;</span><br><span class="line">        B[i]=<span class="number">2.0</span>;</span><br><span class="line">        C[i]=<span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    ArraySum&lt;&lt;&lt;grid, block&gt;&gt;&gt;(A, B, C, offset, nElem);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    <span class="type">float</span> elapsedTime=<span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed: %f ms offset: %d \n&quot;</span>, grid.x, block.x, elapsedTime, offset);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaFree</span>(A);</span><br><span class="line">    <span class="built_in">cudaFree</span>(B);</span><br><span class="line">    <span class="built_in">cudaFree</span>(C);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬è¿™é‡Œä½¿ç”¨ Nsight Compute äº¤äº’å¼å†…æ ¸åˆ†æå·¥å…·ï¼Œä¸€èˆ¬å®‰è£…å®Œ CUDA Toolkit ä¼šåœ¨å®‰è£…ç›®å½•ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦æ·»åŠ ç¯å¢ƒå˜é‡å³å¯ï¼Œå¦‚æ²¡æœ‰è¯·åœ¨<a href="https://developer.nvidia.com/gameworksdownload#?dn=nsight-compute-2022-4-0">å®˜ç½‘ä¸‹è½½</a>ï¼Œè¯¦ç»†çš„ä½¿ç”¨æ–¹æ³•è¯·æŸ¥çœ‹<a href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">å®˜ç½‘æ–‡æ¡£</a></p><blockquote><p>æ³¨æ„ç±»ä¼¼ Docker ä¹‹ç±»çš„è™šæ‹Ÿæœºç”¨æˆ·ï¼ˆå¦‚ç§Ÿèµçš„ GPUï¼‰æ²¡æœ‰æƒé™ä½¿ç”¨ Nsight Compute è®¿é—® GPUï¼Œéœ€è¦åœ¨ç‰©ç†æœºä¸Šä»¥ç®¡ç†å‘˜æƒé™ä½¿ç”¨</p></blockquote><p>ç¼–è¯‘å‘½ä»¤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvcc -Xptxas -dlcm=cg &#123;&#125;.cu -o &#123;&#125;_cg.out<span class="comment"># ç¦ç”¨ L1</span></span><br><span class="line">nvcc -Xptxas -dlcm=ca &#123;&#125;.cu -o &#123;&#125;_ca.out<span class="comment"># å¯ç”¨ L1</span></span><br></pre></td></tr></table></figure><p>æµ‹è¯•ä¸åŒçš„åç§»é‡è·å¾—çš„å…¨å±€åŠ è½½æ•ˆç‡</p><blockquote><p>å…¨å±€åŠ è½½æ•ˆç‡ = è¯·æ±‚çš„å…¨å±€å†…å­˜åŠ è½½ååé‡ / æ‰€éœ€çš„å…¨å±€å†…å­˜åŠ è½½ååé‡</p></blockquote><p>å¯ç”¨ L1</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./&#123;&#125;_ca.out 0</span><br><span class="line">ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./&#123;&#125;_ca.out 11</span><br><span class="line">ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./&#123;&#125;_ca.out 128</span><br></pre></td></tr></table></figure><ul><li>offset=0 :    gld_efficiency    100%</li><li>offset=11 :    gld_efficiency    40%</li><li>offset=128 :    gld_efficiency    100%</li></ul><p>å¯ä»¥çœ‹å‡ºåç§»é‡ä¼šç›´æ¥å¯¼è‡´æ€§èƒ½æŸå¤±</p><p>ç¦ç”¨ L1</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./&#123;&#125;_cg.out 0</span><br><span class="line">ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./&#123;&#125;_cg.out 11</span><br><span class="line">ncu --metrics smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct ./&#123;&#125;_cg.out 128</span><br></pre></td></tr></table></figure><ul><li>offset=0 :    gld_efficiency    100%</li><li>offset=11 :    gld_efficiency    80%</li><li>offset=128 :    gld_efficiency    100%</li></ul><p>ç¦ç”¨ L1 ååŒæ ·åç§» 11 çš„å…¨å±€åŠ è½½æ•ˆç‡æé«˜äº†ä¸å¤šï¼Œä¹ŸéªŒè¯äº†ä¸Šé¢æåˆ°çš„æ›´ç»†çš„è¯ç²’åº¦ä¼šå¸¦æ¥æ›´å¥½çš„æ€§èƒ½</p><h4 id="åªè¯»ç¼“å­˜"><a href="#åªè¯»ç¼“å­˜" class="headerlink" title="åªè¯»ç¼“å­˜"></a>åªè¯»ç¼“å­˜</h4><p>åªè¯»ç¼“å­˜æœ€åˆæ˜¯ç•™ç»™çº¹ç†å†…å­˜åŠ è½½ç”¨çš„ï¼Œåœ¨ è®¡ç®—èƒ½åŠ› 3.5 ä»¥ä¸Šçš„è®¾å¤‡ï¼Œåªè¯»ç¼“å­˜ä¹Ÿæ”¯æŒä½¿ç”¨å…¨å±€å†…å­˜åŠ è½½ä»£æ›¿ä¸€çº§ç¼“å­˜</p><p>åªè¯»ç¼“å­˜ç²’åº¦ä¸º 32 å­—èŠ‚ï¼Œå¯¹äºåˆ†æ•£è¯»å–ï¼Œç»†ç²’åº¦ä¼˜äºä¸€çº§ç¼“å­˜ï¼Œæœ‰ä¸¤ç§æ–¹æ³•è®©å†…å­˜ä»åªè¯»ç¼“å­˜è¯»å–</p><ul><li>ä½¿ç”¨å‡½æ•°<code>__ldg</code></li><li>åœ¨é—´æ¥å¼•ç”¨çš„æŒ‡é’ˆä¸Šä½¿ç”¨ä¿®é¥°ç¬¦</li></ul><p>è€ƒè™‘å¦‚ä¸‹ä»£ç </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraySum</span><span class="params">(<span class="type">float</span>*a,<span class="type">float</span>*b,<span class="type">float</span>*res)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i=blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    res[i]=a[i]+b[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨<code>__ldg</code>é€šè¿‡åªè¯»ç¼“å­˜å¯¹æ•°ç»„è¿›è¡Œè¯»å–è®¿é—®</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraySum</span><span class="params">(<span class="type">float</span>*a,<span class="type">float</span>*b,<span class="type">float</span>*res)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i=blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    res[i]= __ldg(&amp;a[i]) + __ldg(&amp;b[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä¹Ÿå¯ä»¥å¸¸é‡<code>__restrict__</code>ä¿®é¥°ç¬¦åº”ç”¨åˆ°æŒ‡é’ˆä¸Šï¼Œnvcc å°†è‡ªåŠ¨é€šè¿‡åªè¯»ç¼“å­˜æŒ‡å¯¼æ— åˆ«åæŒ‡é’ˆçš„åŠ è½½</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraySum</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* __restrict__ a, <span class="type">const</span> <span class="type">float</span>* __restrict__ b, <span class="type">float</span>* __restrict__ res)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i=blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    res[i]=a[i]+b[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="å…¨å±€å†…å­˜å†™å…¥"><a href="#å…¨å±€å†…å­˜å†™å…¥" class="headerlink" title="å…¨å±€å†…å­˜å†™å…¥"></a>å…¨å±€å†…å­˜å†™å…¥</h3><p>å†…å­˜çš„å­˜å‚¨å’ŒåŠ è½½æ˜¯å®Œå…¨ä¸åŒçš„ï¼Œå¹¶ä¸”å­˜å‚¨ç›¸å¯¹ç®€å•å¾ˆå¤šã€‚å­˜å‚¨æ“ä½œåœ¨32ä¸ªå­—èŠ‚çš„ç²’åº¦ä¸Šè¢«æ‰§è¡Œï¼Œå†…å­˜äº‹åŠ¡ä¹Ÿè¢«åˆ†ä¸ºä¸€æ®µã€ä¸¤ç«¯æˆ–è€…å››æ®µï¼Œä¾‹å¦‚ä¸¤ä¸ªåœ°å€åœ¨ä¸€ä¸ª 128 å­—èŠ‚çš„æ®µå†…ä½†ä¸åœ¨å¯¹é½çš„ 64 å­—èŠ‚åŒºåŸŸå†…ï¼Œåˆ™ä¼šäº§ç”Ÿä¸€ä¸ªå››æ®µçš„äº‹åŠ¡ï¼Œæ‰§è¡Œå››æ®µçš„äº‹åŠ¡æ¯”æ‰§è¡Œä¸¤ä¸ªä¸€æ®µäº‹åŠ¡çš„æ•ˆæœæ›´å¥½</p><blockquote><p>Fermi å’Œ Kepler æ¶æ„çš„å­˜å‚¨æ“ä½œä¸ç»è¿‡ L1 ï¼Œåªç»è¿‡ L2</p></blockquote><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå†…å­˜è®¿é—®æ˜¯å¯¹é½çš„ï¼Œè®¿é—®ä¸€ä¸ªè¿ç»­çš„ 128 å­—èŠ‚èŒƒå›´ï¼Œå­˜å‚¨è¯·æ±‚ä½¿ç”¨ä¸€ä¸ªå››æ®µäº‹åŠ¡å®Œæˆï¼Œè¿™é‡Œæœ€ç†æƒ³çš„æƒ…å†µ</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/16.webp" alt=""></p><p>æ•°æ®åˆ†æ•£åœ¨ä¸€ä¸ª 192 å­—èŠ‚çš„èŒƒå›´å†…ï¼Œå­˜å‚¨ä¸è¿ç»­ï¼Œä½¿ç”¨ä¸‰ä¸ªä¸€æ®µäº‹åŠ¡å®ç°</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/17.webp" alt=""></p><p>å†…å­˜è®¿é—®æ˜¯å¯¹é½çš„ï¼Œè®¿é—®ä¸€ä¸ªè¿ç»­çš„ 64 å­—èŠ‚èŒƒå›´ï¼Œå­˜å‚¨è¯·æ±‚ä½¿ç”¨ä¸€ä¸ªä¸¤æ®µäº‹åŠ¡å®Œæˆ</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/18.webp" alt=""></p><h4 id="éå¯¹é½å†™å…¥ç¤ºä¾‹"><a href="#éå¯¹é½å†™å…¥ç¤ºä¾‹" class="headerlink" title="éå¯¹é½å†™å…¥ç¤ºä¾‹"></a>éå¯¹é½å†™å…¥ç¤ºä¾‹</h4><p>åªéœ€è¦å¯¹æ ¸å‡½æ•°ä½œå¦‚ä¸‹ä¿®æ”¹å³å¯</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraySum</span><span class="params">(<span class="type">float</span>*a, <span class="type">float</span>*b, <span class="type">float</span>*c, <span class="type">int</span> offset, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">int</span> k = i+offset;</span><br><span class="line">    <span class="keyword">if</span>(k &lt; n)</span><br><span class="line">        c[k] = a[i]+b[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æµ‹è¯•ç»“è®ºä¸éå¯¹é½è¯»å–ç¤ºä¾‹ç›¸åŒ</p><h3 id="ç»“æ„ä½“æ•°ç»„ä¸æ•°ç»„ç»“æ„ä½“ï¼ˆSoA-å’Œ-AoSï¼‰"><a href="#ç»“æ„ä½“æ•°ç»„ä¸æ•°ç»„ç»“æ„ä½“ï¼ˆSoA-å’Œ-AoSï¼‰" class="headerlink" title="ç»“æ„ä½“æ•°ç»„ä¸æ•°ç»„ç»“æ„ä½“ï¼ˆSoA å’Œ AoSï¼‰"></a>ç»“æ„ä½“æ•°ç»„ä¸æ•°ç»„ç»“æ„ä½“ï¼ˆSoA å’Œ AoSï¼‰</h3><p>åœ¨ C è¯­è¨€ä¸­ï¼Œç»“æ„ä½“æ˜¯ä¸€ç§å¼ºå¤§çš„æ•°æ®ç»„ç»‡æ–¹å¼ï¼Œç»“æ„ä½“ä¸­çš„æˆå‘˜åœ¨å†…å­˜é‡Œå¯¹é½çš„ä¾æ¬¡æ’å¼€ï¼Œä½†æ˜¯æˆ‘ä»¬ä¿å­˜ä¸€ç»„æ•°æ®æœ‰ä¸¤ç§æ–¹å¼ï¼Œå¯ä»¥å®šä¹‰å¦‚ä¸‹ç»“æ„ä½“</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="type">float</span> x;</span><br><span class="line">    <span class="type">float</span> y;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>å†å®šä¹‰ä¸€ä¸ªæ•°ç»„ç»“æ„ä½“ï¼ˆAoSï¼‰</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> _<span class="title">Aos</span>[<span class="title">N</span>];</span></span><br></pre></td></tr></table></figure><p>ä¹Ÿå¯ä»¥å®šä¹‰ä¸€ä¸ªç»“æ„ä½“æ•°ç»„ï¼ˆSoAï¼‰</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">    <span class="type">float</span> x[N];</span><br><span class="line">    <span class="type">float</span> y[N];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> _<span class="title">SoA</span>[<span class="title">N</span>];</span></span><br></pre></td></tr></table></figure><p>AoS æ–¹å¼ç»„ç»‡çš„æ•°æ®åœ¨ç©ºé—´ä¸Šæ˜¯ç›¸é‚»çš„ï¼Œè¿™åœ¨ CPU ä¸Šä¼šæœ‰è‰¯å¥½çš„ç¼“å­˜å±€éƒ¨æ€§ï¼Œä½†æ˜¯åœ¨ GPU çš„å¹¶è¡Œæ¶æ„ä¸­ï¼Œè¯»å†™ä¸€ä¸ªç»“æ„ä½“å­—æ®µ x æ—¶ä¼šåŒæ—¶åŠ è½½ x å’Œ y ä¸¤ä¸ªå­—æ®µï¼Œè¿™å°±å¯¼è‡´æœ‰ 50 % çš„å¸¦å®½æŸå¤±ï¼Œå†çœ‹ SoAï¼Œè®¿é—®ä¸€ä¸ª SoA å¸ƒå±€çš„ç»“æ„ä½“æ—¶ï¼Œç”±äºæ²¡æœ‰äº¤å‰å­˜å‚¨çš„å­—æ®µï¼Œæ‰€ä»¥æ˜¯åˆå¹¶å†…å­˜è®¿é—®ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨å¸¦å®½ï¼Œå›¾ç¤ºå¦‚ä¸‹</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜ç®¡ç†ï¼ˆä¸€ï¼‰/19.webp" alt=""></p><p>å‰é¢æˆ‘ä»¬ä»‹ç»çš„çŸ©é˜µç›¸ä¹˜ä¸­å®šä¹‰çŸ©é˜µçš„ç»“æ„ä½“å°±æ˜¯ SoA æ–¹å¼ï¼Œä¸‹é¢æ˜¯ AoS æ–¹å¼çš„ä»£ç ï¼Œä¸ SoA æ–¹å¼çš„ä»£ç ä½œå¯¹æ¯”ï¼Œåªåšæµ‹è¯•ç”¨ï¼Œæ— å®é™…æ„ä¹‰</p><blockquote><p>è¿™é‡ŒæŒ‡å‡ºç¬¬ä¸‰ç« ä¸­çŸ©é˜µç›¸ä¹˜ä»£ç çš„é”™è¯¯ï¼Œw å’Œ h è®¾ç½®ä¸º <code>1 &lt;&lt; 20</code> ä¼šå¯¼è‡´æ•°å€¼æº¢å‡ºï¼Œè¿™é‡Œæ”¹ä¸º<code>1 &lt;&lt; 12</code></p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Matrix</span> &#123;</span><br><span class="line">    <span class="type">int</span> w;</span><br><span class="line">    <span class="type">int</span> h;</span><br><span class="line">    <span class="type">float</span> v;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">__device__ <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">12</span>;</span><br><span class="line">__device__ <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">12</span>;</span><br><span class="line"><span class="function">__device__ <span class="type">float</span> <span class="title">getValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> A[row * w + col].v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">setValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col, <span class="type">float</span> v)</span> </span>&#123;</span><br><span class="line">    A[row * w + col].v = v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatrixMul</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> k = <span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i &lt; w; i++)</span><br><span class="line">        k += <span class="built_in">getValue</span>(A, row, i) * <span class="built_in">getValue</span>(B, i, col);</span><br><span class="line">    <span class="built_in">setValue</span>(C, row, col, k);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">12</span>;</span><br><span class="line">    <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">12</span>;</span><br><span class="line">    Matrix *A, *B, *C;</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A, <span class="built_in">sizeof</span>(Matrix) * w * h);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B, <span class="built_in">sizeof</span>(Matrix) * w * h);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C, <span class="built_in">sizeof</span>(Matrix) * w * h);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i &lt; w*h; i++) &#123;</span><br><span class="line">        A[i].w = w;</span><br><span class="line">        A[i].h = h;</span><br><span class="line">        B[i].w = w;</span><br><span class="line">        B[i].h = h;</span><br><span class="line">        C[i].w = w;</span><br><span class="line">        C[i].h = h;</span><br><span class="line">        A[i].v = <span class="number">1.0</span>;</span><br><span class="line">        B[i].v = <span class="number">2.0</span>;</span><br><span class="line">        C[i].v = <span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">gridSize</span><span class="params">((w + blockSize.x - <span class="number">1</span>) / blockSize.x, (h + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line">    MatrixMul &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A, B, C);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">cudaFree</span>(A);</span><br><span class="line">    <span class="built_in">cudaFree</span>(B);</span><br><span class="line">    <span class="built_in">cudaFree</span>(C);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨ nsys å¯¹æ¯”ä¸»æœºåˆ°è®¾å¤‡çš„æ•°æ®ä¼ è¾“</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># AoS æ–¹å¼</span><br><span class="line">Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            </span><br><span class="line"> ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------</span><br><span class="line">    402.653   6951     0.058     0.016     0.004     1.040        0.143  [CUDA Unified Memory memcpy HtoD]</span><br><span class="line"></span><br><span class="line"># SoA æ–¹å¼</span><br><span class="line"> Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            </span><br><span class="line"> ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------</span><br><span class="line">    134.283   2772     0.048     0.008     0.004     1.028        0.142  [CUDA Unified Memory memcpy HtoD]</span><br></pre></td></tr></table></figure><p>å¯ä»¥ç›´è§‚çœ‹åˆ°ï¼ŒAoS å¯¹æŸä¸ªå­—æ®µè¯»å†™æ—¶ä¼šåŒæ—¶åŠ è½½æ‰€æœ‰å­—æ®µï¼Œ<code>Matrix</code>ç»“æ„ä½“æœ‰ä¸‰ä¸ªå­—æ®µï¼Œ134 * 3 = 402ï¼Œä¸æ•°æ®æ˜¾ç¤ºä¸€è‡´</p><h3 id="æ€§èƒ½ä¼˜åŒ–"><a href="#æ€§èƒ½ä¼˜åŒ–" class="headerlink" title="æ€§èƒ½ä¼˜åŒ–"></a>æ€§èƒ½ä¼˜åŒ–</h3><p>ä¼˜åŒ–è®¾å¤‡å†…å­˜å¸¦å®½åˆ©ç”¨ç‡æœ‰ä¸¤ä¸ªç›®æ ‡</p><ul><li>å¯¹é½åˆå¹¶å†…å­˜è®¿é—®ï¼Œå‡å°‘å¸¦å®½æµªè´¹</li><li>è¶³å¤Ÿçš„å¹¶å‘å†…å­˜æ“ä½œï¼Œé™ä½å†…å­˜å»¶è¿Ÿ</li></ul><p>æˆ‘ä»¬å·²ç»äº†è§£äº†å¦‚ä½•ç»„ç»‡å†…å­˜è®¿é—®ä»¥å¯¹å†…å­˜å¯¹é½çš„å†…å­˜è®¿é—®ï¼Œè¿™å¯ä»¥åœ¨ DRAM å’Œ SM ç‰‡ä¸Šå†…å­˜æˆ–å¯„å­˜å™¨ä¹‹é—´ç¡®ä¿æœ‰æ•ˆåˆ©ç”¨å­—èŠ‚ç§»åŠ¨ï¼Œå®ç°å†…å­˜è®¿é—®æœ€å¤§åŒ–ä¸€èˆ¬é€šè¿‡å¢åŠ æ¯ä¸ªçº¿ç¨‹ä¸­æ‰§è¡Œç‹¬ç«‹å†…å­˜æ“ä½œçš„æ•°é‡ï¼Œä»¥åŠå¯¹æ ¸å‡½æ•°å¯åŠ¨çš„æ‰§è¡Œé…ç½®è¿›è¡Œè¯•éªŒ</p><h4 id="å±•å¼€å¾ªç¯"><a href="#å±•å¼€å¾ªç¯" class="headerlink" title="å±•å¼€å¾ªç¯"></a>å±•å¼€å¾ªç¯</h4><p>æˆ‘ä»¬ä½¿ç”¨ 8 å¾ªç¯å±•å¼€æŠ€æœ¯å¯¹<code>ArraySum</code>æ ¸å‡½æ•°ä½œä¿®æ”¹</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraySum</span><span class="params">(<span class="type">float</span>*a, <span class="type">float</span>*b, <span class="type">float</span>*c, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x*blockDim.x*<span class="number">4</span> +threadIdx.x;</span><br><span class="line">    c[i] = a[i]+b[i];</span><br><span class="line">    <span class="keyword">if</span>(i + blockDim.x &lt; n)</span><br><span class="line">        c[i+blockDim.x] = a[i+blockDim.x]+b[i+blockDim.x];</span><br><span class="line">    <span class="keyword">if</span>(i + blockDim.x *<span class="number">2</span> &lt; n)</span><br><span class="line">        c[i+blockDim.x *<span class="number">2</span>] = a[i+blockDim.x *<span class="number">2</span>]+b[i+blockDim.x *<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">if</span>(i + blockDim.x *<span class="number">3</span> &lt; n)</span><br><span class="line">        c[i+blockDim.x *<span class="number">3</span>] = a[i+blockDim.x *<span class="number">3</span>]+b[i+blockDim.x *<span class="number">3</span>];</span><br><span class="line">    <span class="keyword">if</span>(i + blockDim.x *<span class="number">4</span> &lt; n)</span><br><span class="line">        c[i+blockDim.x *<span class="number">4</span>] = a[i+blockDim.x *<span class="number">4</span>]+b[i+blockDim.x *<span class="number">4</span>];</span><br><span class="line">    <span class="keyword">if</span>(i + blockDim.x *<span class="number">5</span> &lt; n)</span><br><span class="line">        c[i+blockDim.x *<span class="number">5</span>] = a[i+blockDim.x *<span class="number">5</span>]+b[i+blockDim.x *<span class="number">5</span>];</span><br><span class="line">    <span class="keyword">if</span>(i + blockDim.x *<span class="number">6</span> &lt; n)</span><br><span class="line">        c[i+blockDim.x *<span class="number">6</span>] = a[i+blockDim.x *<span class="number">6</span>]+b[i+blockDim.x *<span class="number">6</span>];</span><br><span class="line">    <span class="keyword">if</span>(i + blockDim.x *<span class="number">7</span> &lt; n)</span><br><span class="line">        c[i+blockDim.x *<span class="number">7</span>] = a[i+blockDim.x *<span class="number">7</span>]+b[i+blockDim.x *<span class="number">7</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nElem=<span class="number">1</span>&lt;&lt;<span class="number">28</span>;</span><br><span class="line">    <span class="type">int</span> nBytes=<span class="built_in">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(nElem/block.x)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *A, *B, *C;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;A, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;B, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">float</span>**)&amp;C, nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        A[i]=<span class="number">1.0</span>;</span><br><span class="line">        B[i]=<span class="number">2.0</span>;</span><br><span class="line">        C[i]=<span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    ArraySum&lt;&lt;&lt;grid.x/<span class="number">8</span>, block&gt;&gt;&gt;(A, B, C, nElem);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    <span class="type">float</span> elapsedTime=<span class="number">0</span>;</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed: %f ms \n&quot;</span>, grid.x/<span class="number">8</span>, block.x, elapsedTime);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaFree</span>(A);</span><br><span class="line">    <span class="built_in">cudaFree</span>(B);</span><br><span class="line">    <span class="built_in">cudaFree</span>(C);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;<span class="number">32768</span>,<span class="number">1024</span>&gt;&gt;&gt; Time elapsed: <span class="number">353.544189</span> ms</span><br><span class="line">&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;<span class="number">262144</span>,<span class="number">1024</span>&gt;&gt;&gt; Time elapsed: <span class="number">739.468262</span> ms</span><br></pre></td></tr></table></figure><p>ä¸æœ€åˆçš„ç‰ˆæœ¬å¯¹æ¯”ï¼Œå¾ªç¯å±•å¼€æŠ€æœ¯èŠ‚çœäº†å¤§åŠçš„è¿ç®—æ—¶é—´</p><h4 id="å¢å¤§å¹¶è¡Œæ€§"><a href="#å¢å¤§å¹¶è¡Œæ€§" class="headerlink" title="å¢å¤§å¹¶è¡Œæ€§"></a>å¢å¤§å¹¶è¡Œæ€§</h4><p>å¯¹æ•°ç»„æ±‚å’Œæ‰€ç”¨çš„<code>&lt;&lt;&lt;grid, block&gt;&gt;&gt;</code>æµ‹è¯•ï¼Œå¯»æ‰¾æœ€ä½³æ‰§è¡Œé…ç½®</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;<span class="number">262144</span>,<span class="number">1024</span>&gt;&gt;&gt; Time elapsed: <span class="number">865.561584</span> ms </span><br><span class="line">&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;<span class="number">524288</span>,<span class="number">512</span>&gt;&gt;&gt; Time elapsed: <span class="number">757.686401</span> ms </span><br><span class="line">&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;<span class="number">1048576</span>,<span class="number">256</span>&gt;&gt;&gt; Time elapsed: <span class="number">687.030212</span> ms </span><br><span class="line">&lt;&lt;&lt;grid, block&gt;&gt;&gt;: &lt;&lt;&lt;<span class="number">2097152</span>,<span class="number">128</span>&gt;&gt;&gt; Time elapsed: <span class="number">786.416626</span> ms </span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°åœ¨<code>block.x</code>ä¸º 256 æ—¶ï¼Œæ‰§è¡Œæ•ˆç‡æœ€é«˜ï¼Œè¿™æ˜¯å› ä¸ºè¾ƒé«˜çš„<code>block.x</code>ä¼šä½¿ SM çš„å¹¶è¡Œæ€§é™ä½ï¼Œè€Œè¿‡ä½çš„<code>block.x</code>ä¸èƒ½å……åˆ†åˆ©ç”¨ SM çš„è®¡ç®—èµ„æºï¼Œå…·ä½“çš„<code>&lt;&lt;&lt;grid, block&gt;&gt;&gt;</code>å¤§å°å–å†³äºå½“å‰çš„ GPU æ¶æ„ä¸­çš„ SM é…ç½®ï¼Œéœ€è¦å®éªŒå¾—å‡º</p>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDAå†…å­˜æ¨¡å‹æ¦‚è¿°</title>
      <link href="/p/62a8be74/"/>
      <url>/p/62a8be74/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è®²è§£ CUDA å†…å­˜å±‚æ¬¡ç»“æ„ï¼Œå¦‚å¯„å­˜å™¨ï¼Œå…±äº«å†…å­˜ï¼Œçº¹ç†å†…å­˜ï¼Œå…¨å±€å†…å­˜ç­‰ã€‚</p><span id="more"></span><h2 id="å†…å­˜å±‚æ¬¡ç»“æ„"><a href="#å†…å­˜å±‚æ¬¡ç»“æ„" class="headerlink" title="å†…å­˜å±‚æ¬¡ç»“æ„"></a>å†…å­˜å±‚æ¬¡ç»“æ„</h2><p>é¦–å…ˆäº†è§£ä¸€ä¸‹åº”ç”¨ç¨‹åºéµå¾ªçš„å±€éƒ¨æ€§åŸåˆ™</p><ul><li><p>æ—¶é—´å±€éƒ¨æ€§</p><p>ä¸€ä¸ªå†…å­˜åœ°å€è¢«è®¿é—®ï¼Œé‚£ä¹ˆè¿™ä¸ªå†…å­˜åœ°å€å¾ˆå¯èƒ½ä¼šè¢«å¤šæ¬¡è®¿é—®ï¼Œè¢«è®¿é—®çš„æ¦‚ç‡ä¼šéšç€æ—¶é—´é€æ¸é™ä½</p></li><li><p>ç©ºé—´å±€éƒ¨æ€§</p><p>å¦‚æœä¸€ä¸ªå†…å­˜åœ°å€è¢«è®¿é—®ï¼Œé‚£ä¹ˆé™„è¿‘çš„åœ°å€ä¹Ÿæœ‰å¯èƒ½è¢«è®¿é—®</p></li></ul><p>éšç€ç§‘æŠ€çš„å‘å±•ï¼Œæ›´ä½å»¶æ—¶å’Œä½å®¹é‡çš„å†…å­˜å±‚æ¬¡ç»“æ„è¢«è®¾è®¡å‡ºæ¥ä»¥æé«˜è®¡ç®—æœºæ€§èƒ½ï¼Œå†…å­˜ç»“æ„å˜å¾—å¤æ‚ï¼Œè¯ç”Ÿå‡ºäº†ç”±å¤šçº§å¸¦å®½ï¼Œå®¹é‡ç»„æˆçš„å†…å­˜å±‚æ¬¡ç»“æ„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜æ¨¡å‹æ¦‚è¿°/1.webp" alt=""></p><p>ä¸Šè¿°ç»“æ„ä»ä¸‹å¾€ä¸Šæœ‰å¦‚ä¸‹ç‰¹ç‚¹</p><ul><li>æ›´é«˜çš„æˆæœ¬/bit</li><li>æ›´ä½çš„å®¹é‡</li><li>æ›´ä½çš„å»¶æ—¶</li><li>æ›´é«˜çš„è®¿é—®é¢‘ç‡</li></ul><p>CPU çš„ä¸»å­˜é‡‡ç”¨åŠ¨æ€éšæœºå­˜å‚¨å™¨ï¼ˆDRAMï¼‰ï¼Œæ›´å¿«çš„ CPU ä¸€çº§ç¼“å­˜ä½¿ç”¨çš„æ˜¯é™æ€éšæœºå­˜å‚¨å™¨ï¼ˆSRAMï¼‰ï¼Œå½“æ•°æ®è¢«é¢‘ç¹ä½¿ç”¨æ—¶ï¼Œä¼šä¿å­˜åœ¨ä½å»¶æ—¶ã€ä½å®¹é‡çš„å†…å­˜å±‚æ¬¡ä¸­ï¼Œå¦åˆ™ä¼šä¿å­˜åœ¨é«˜å»¶æ—¶ï¼Œå¤§å®¹é‡çš„å®¹å™¨ä¸­ã€‚GPU çš„ä¸»å­˜å’Œ CPU ä¸€æ ·ä½¿ç”¨ DRAMï¼Œå†…å­˜å±‚æ¬¡ç»“æ„ä¹Ÿéå¸¸ç›¸ä¼¼ï¼Œä¸ CPU å†…å­˜æ¨¡å‹ä¸åŒçš„æ˜¯ï¼Œé€šè¿‡ CUDAï¼Œæˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°æ§åˆ¶ GPU çš„å†…å­˜</p><h2 id="CUDA-å†…å­˜æ¨¡å‹"><a href="#CUDA-å†…å­˜æ¨¡å‹" class="headerlink" title="CUDA å†…å­˜æ¨¡å‹"></a>CUDA å†…å­˜æ¨¡å‹</h2><p>CUDA æä¾›äº†å¤šç§å¯ç¼–ç¨‹çš„ä¸åŒç±»å‹çš„å†…å­˜å¯ä»¥æ»¡è¶³ä¸åŒçš„è®¡ç®—éœ€æ±‚ã€‚æ¯ç§å†…å­˜ç±»å‹éƒ½æœ‰å…¶ç‰¹å®šçš„ç”¨é€”å’Œæ€§èƒ½ç‰¹ç‚¹</p><ul><li>å¯„å­˜å™¨ï¼ˆRegistersï¼‰</li><li>å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰</li><li>æœ¬åœ°å†…å­˜ï¼ˆLocal Memoryï¼‰</li><li>å¸¸é‡å†…å­˜ï¼ˆConstant Memoryï¼‰</li><li>çº¹ç†å†…å­˜ï¼ˆTexture Memoryï¼‰</li><li>å…¨å±€å†…å­˜ï¼ˆGlobal Memoryï¼‰</li></ul><p><img src="/image/CUDAç¼–ç¨‹-CUDAå†…å­˜æ¨¡å‹æ¦‚è¿°/2.webp" alt=""></p><p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæ¯ä¸ªæ ¸å‡½æ•°éƒ½æœ‰è‡ªå·±ç§æœ‰çš„æœ¬åœ°å†…å­˜ï¼Œæ¯ä¸ªçº¿ç¨‹å—æœ‰è‡ªå·±çš„å…±äº«å†…å­˜ï¼Œå¯¹åŒä¸€çº¿ç¨‹å—ä¸­æ‰€æœ‰çš„çº¿ç¨‹å¯è§ï¼Œå…¶å†…å®¹ä¼šæŒç»­çº¿ç¨‹å—çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸã€‚æ‰€æœ‰çº¿ç¨‹éƒ½å¯ä»¥è®¿é—®å…¨å±€å†…å­˜ã€‚æ‰€æœ‰çº¿ç¨‹å¯¹å¸¸é‡å†…å­˜å’Œçº¹ç†å†…å­˜éƒ½åªè¯»</p><p>åœ¨å†…å­˜å±‚æ¬¡ç»“æ„ä¸­ï¼Œçº¹ç†å†…å­˜ä¸ºå„ç§æ•°æ®å¸ƒå±€æä¾›äº†ä¸åŒçš„å¯»å€æ¨¡å¼å’Œæ»¤æ³¢æ¨¡å¼ï¼Œå¯¹äºåº”ç”¨ç¨‹åºæ¥è¯´ï¼Œå…¨å±€å†…å­˜ã€å¸¸é‡å†…å­˜ä¸­çš„å†…å®¹å…·æœ‰ç›¸åŒçš„ç”Ÿå‘½å‘¨æœŸ</p><h2 id="å¯„å­˜å™¨"><a href="#å¯„å­˜å™¨" class="headerlink" title="å¯„å­˜å™¨"></a>å¯„å­˜å™¨</h2><p>å¯„å­˜å™¨æ˜¯ä¸€ç§ä½å®¹é‡ã€è¶…é«˜é€Ÿåº¦çš„å†…å­˜ç±»å‹ï¼Œæ¯ä¸ªçº¿ç¨‹éƒ½å¯ä»¥ä½¿ç”¨å¯„å­˜å™¨æ¥å­˜å‚¨ä¸´æ—¶æ•°æ®ã€‚å½“åœ¨æ ¸å‡½æ•°å†…çš„è‡ªå˜é‡æ²¡æœ‰å…¶ä»–ä¿®é¥°ç¬¦ï¼Œè¯¥å˜é‡å°±å­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­ï¼Œåœ¨æ ¸å‡½æ•°ä¸­å®šä¹‰çš„çš„æ•°ç»„ä¹Ÿå­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­</p><p>å¯„å­˜å™¨å¯¹äºæ¯ä¸ªçº¿ç¨‹æ˜¯ç§æœ‰çš„ï¼Œæ ¸å‡½æ•°ä½¿ç”¨å¯„å­˜å™¨æ¥é€šå¸¸ä¿å­˜è¢«é¢‘ç¹ä½¿ç”¨çš„çº¿ç¨‹ç§æœ‰å˜é‡ï¼Œå¯„å­˜å™¨å˜é‡çš„å£°æ˜å‘¨æœŸå’Œæ ¸å‡½æ•°ä¸€è‡´ï¼Œæ‰§è¡Œå®Œæ¯•åï¼Œå¯„å­˜å™¨å°±ä¸èƒ½è®¿é—®äº†ã€‚</p><p>å¯„å­˜å™¨æ˜¯ SM ä¸­çš„è¾ƒå°‘èµ„æºï¼ŒFermi æ¶æ„ä¸­æ¯ä¸ªçº¿ç¨‹æœ€å¤š63ä¸ªå¯„å­˜å™¨ã€‚Keplerç»“æ„æ‰©å±•åˆ°255ä¸ªå¯„å­˜å™¨ï¼Œä¸€ä¸ªçº¿ç¨‹å¦‚æœä½¿ç”¨æ›´å°‘çš„å¯„å­˜å™¨ï¼Œé‚£ä¹ˆå°±ä¼šæœ‰æ›´å¤šçš„å¸¸é©»çº¿ç¨‹å—ï¼ŒSMä¸Šå¹¶å‘çš„çº¿ç¨‹å—è¶Šå¤šï¼Œæ•ˆç‡è¶Šé«˜ï¼Œæ€§èƒ½å’Œä½¿ç”¨ç‡ä¹Ÿå°±è¶Šé«˜ã€‚</p><p>å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å¾—åˆ°æ¯ä¸ªæ ¸å‡½æ•°è¿è¡Œæ—¶ä½¿ç”¨çš„å¯„å­˜å™¨æ•°é‡ã€å…±äº«å†…å­˜å­—èŠ‚æ•°ä»¥åŠæ¯ä¸ªçº¿ç¨‹æ‰€ä½¿ç”¨çš„å¸¸é‡å†…å­˜å’Œå­—èŠ‚æ•°</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -Xptxas -v *.cu</span><br></pre></td></tr></table></figure><p>ä»¥ç¬¬ä¸‰ç« ä¸­çš„çŸ©é˜µä¹˜æ³•å’ŒåŠ æ³•ä¸ºä¾‹ï¼Œè¾“å‡ºè¡¨ç¤ºç¼–è¯‘å™¨è¿›è¡Œäº†ä¸¤ä¸ªæ“ä½œï¼šç¼–è¯‘çŸ©é˜µä¹˜æ³•å‡½æ•°<code>Z9MatrixMulP6MatrixS0_S0</code>å’ŒçŸ©é˜µåŠ æ³•å‡½æ•°<code>Z9MatrixAddP6MatrixS0_S0</code>ï¼Œåˆ†åˆ«é’ˆå¯¹<code>sm_52</code>æ¶æ„ï¼Œå¯¹äºæ¯ä¸ªå‡½æ•°ï¼Œéƒ½ä¼šè¾“å‡ºå‡½æ•°å±æ€§ï¼Œå¦‚å †æ ˆå¸§å¤§å°ã€æº¢å‡ºå­˜å‚¨å’Œæº¢å‡ºåŠ è½½çš„å¤§å°ï¼Œå¹¶ä¸”æŠ¥å‘Šä½¿ç”¨çš„å¯„å­˜å™¨æ•°é‡å’Œå…¨å±€å†…å­˜<code>cmem[0]</code>å¤§å°</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ptxas info    : 0 bytes gmem</span><br><span class="line">ptxas info    : Compiling entry <span class="keyword">function</span> <span class="string">&#x27;_Z9MatrixMulP6MatrixS0_S0_&#x27;</span> <span class="keyword">for</span> <span class="string">&#x27;sm_52&#x27;</span></span><br><span class="line">ptxas info    : Function properties <span class="keyword">for</span> _Z9MatrixMulP6MatrixS0_S0_</span><br><span class="line">    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads</span><br><span class="line">ptxas info    : Used 32 registers, 344 bytes cmem[0]</span><br><span class="line">ptxas info    : Compiling entry <span class="keyword">function</span> <span class="string">&#x27;_Z9MatrixAddP6MatrixS0_S0_&#x27;</span> <span class="keyword">for</span> <span class="string">&#x27;sm_52&#x27;</span></span><br><span class="line">ptxas info    : Function properties <span class="keyword">for</span> _Z9MatrixAddP6MatrixS0_S0_</span><br><span class="line">    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads</span><br><span class="line">ptxas info    : Used 18 registers, 344 bytes cmem[0]</span><br></pre></td></tr></table></figure><p>å¦‚æœä¸€ä¸ªæ ¸å‡½æ•°ä½¿ç”¨äº†è¶…è¿‡ç¡¬ä»¶æ•°é‡çš„å¯„å­˜å™¨ï¼Œä¼šç”¨æœ¬åœ°å†…å­˜ä»£æ›¿å¤šå ç”¨çš„å¯„å­˜å™¨ã€‚nvcc ä¼šä½¿ç”¨å¯å‘å¼ç­–ç•¥æ¥æœ€å°åŒ–å¯„å­˜å™¨çš„ä½¿ç”¨ï¼Œä¸ºäº†é¿å…å¯„å­˜å™¨æº¢å‡ºï¼Œå¯ä»¥åœ¨æ ¸å‡½æ•°çš„ä»£ç ä¸­é…ç½®é¢å¤–çš„ä¿¡æ¯æ¥è¾…åŠ©ç¼–è¯‘å™¨ä¼˜åŒ–ï¼Œä¸‹é¢ä»£ç ä¸­çš„<code>maxThreadsPerBlock</code>æ„ä¸ºæ¯ä¸ªå—æœ€å¤šå¯ä»¥å¯åŠ¨çš„çº¿ç¨‹æ•°é‡ï¼Œ<code>minBlocksPerMultiprocessor</code>æ„ä¸ºæ¯ä¸ª SM æœ€å°‘è¿è¡Œçš„çº¿ç¨‹å—æ•°é‡</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> __launch_bounds__ (maxThreadsPerBlock, minBlocksPerMultiprocessor)</span><br><span class="line"><span class="built_in">kernel_func</span> (...) &#123;</span><br><span class="line"><span class="comment">//kernel body</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åœ¨è°ƒç”¨ä¸‹é¢çš„æ ¸å‡½æ•°æ—¶ï¼Œæœ€å¤šå¯ä»¥ä½¿ç”¨ 1024 ä¸ªçº¿ç¨‹æ¥æ‰§è¡Œè¯¥å†…æ ¸å‡½æ•°ï¼Œåœ¨æ¯ä¸ª SM æœ€å°‘è¿è¡Œçš„çº¿ç¨‹å—æ•°é‡ä¸º 1</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> __launch_bounds__ (<span class="number">1024</span>, <span class="number">1</span>) <span class="built_in">MatrixAdd</span>(Matrix *A, Matrix *B, Matrix *C) &#123;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, <span class="built_in">getValue</span>(A, row, col) + <span class="built_in">getValue</span>(B, row, col));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿˜å¯ä»¥åœ¨ç¼–è¯‘æ—¶ä½¿ç”¨<code>-maxrregcount</code>æ¥æ§åˆ¶ä¸€ä¸ªç¼–è¯‘å•å…ƒé‡Œæ‰€æœ‰æ ¸å‡½æ•°ä½¿ç”¨çš„å¯„å­˜å™¨çš„æœ€å¤§æ•°é‡ï¼Œä½†è¿™å¯èƒ½ä¼šå’Œ<code>__launch_bounds__</code>äº§ç”Ÿå†²çªï¼Œå¦‚æœä½¿ç”¨<code>-maxrregcount</code>å‚æ•°é™åˆ¶æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨çš„å¯„å­˜å™¨æ•°é‡ä¸º32ï¼Œå¹¶ä¸”ä½¿ç”¨<code>__launch_bounds__</code>å±æ€§é™åˆ¶æ¯ä¸ªå—å¯ä»¥å¯åŠ¨çš„çº¿ç¨‹æ•°é‡ä¸º1024ï¼Œé‚£ä¹ˆæ¯ä¸ªå—ä¸­å®é™…å¯ä»¥å¯åŠ¨çš„çº¿ç¨‹æ•°é‡å°±ä¼šå—åˆ°é™åˆ¶ï¼Œåªèƒ½å¯åŠ¨32ä¸ªçº¿ç¨‹</p><h2 id="æœ¬åœ°å†…å­˜"><a href="#æœ¬åœ°å†…å­˜" class="headerlink" title="æœ¬åœ°å†…å­˜"></a>æœ¬åœ°å†…å­˜</h2><p>æœ¬åœ°å†…å­˜æ˜¯æ¯ä¸ªçº¿ç¨‹ç§æœ‰çš„å†…å­˜ç©ºé—´ï¼Œç”¨æ¥å­˜å‚¨çº¿ç¨‹ç§æœ‰çš„ä¸´æ—¶æ•°æ®ã€‚æ ¸å‡½æ•°ä¸­ç¬¦åˆå­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­ä½†ä¸èƒ½è¿›å…¥è¢«æ ¸å‡½æ•°åˆ†é…çš„å¯„å­˜å™¨ç©ºé—´ä¸­çš„å˜é‡å°†å­˜å‚¨åœ¨æœ¬åœ°å†…å­˜ä¸­ï¼Œä»¥ä¸‹å‡ ç§å˜é‡å¯èƒ½å­˜æ”¾åœ¨æœ¬åœ°å†…å­˜ä¸­çš„</p><ul><li>ä½¿ç”¨æœªçŸ¥ç´¢å¼•å¼•ç”¨çš„æœ¬åœ°æ•°ç»„</li><li>å¯èƒ½ä¼šå ç”¨å¤§é‡å¯„å­˜å™¨ç©ºé—´çš„è¾ƒå¤§æœ¬åœ°æ•°ç»„æˆ–è€…ç»“æ„ä½“</li><li>ä»»ä½•ä¸æ»¡è¶³æ ¸å‡½æ•°å¯„å­˜å™¨é™å®šæ¡ä»¶çš„å˜é‡</li></ul><p>æœ¬åœ°å†…å­˜æœ¬è´¨ä¸Šå’Œå…¨å±€å†…å­˜å­˜å‚¨åœ¨åŒä¸€å—å­˜å‚¨åŒºåŸŸï¼Œä½†æœ¬åœ°å†…å­˜ä¸ºæ¯ä¸ªçº¿ç¨‹ç§æœ‰ï¼Œä¸”ä¼šæ¯”è®¿é—®å…¨å±€å†…å­˜æ›´å¿«ï¼Œå¯¹äº2.0ä»¥ä¸Šçš„è®¾å¤‡ï¼Œæœ¬åœ°å†…å­˜å­˜å‚¨åœ¨æ¯ä¸ª SM çš„ä¸€çº§ç¼“å­˜å’Œè®¾å¤‡çš„äºŒçº§ç¼“å­˜ä¸Š</p><h2 id="å…±äº«å†…å­˜"><a href="#å…±äº«å†…å­˜" class="headerlink" title="å…±äº«å†…å­˜"></a>å…±äº«å†…å­˜</h2><p>å…±äº«å†…å­˜æ˜¯ä¸€ç§ç”±å¤šä¸ªçº¿ç¨‹å…±åŒä½¿ç”¨çš„å†…å­˜ï¼Œæ˜¯çº¿ç¨‹ä¹‹é—´ç›¸äº’é€šä¿¡çš„åŸºæœ¬æ–¹å¼ï¼Œç”¨æ¥å­˜å‚¨ä¸´æ—¶æ•°æ®å’Œé«˜é¢‘ä½¿ç”¨çš„æ•°æ®ã€‚å…±äº«å†…å­˜ç±»ä¼¼äº CPU çš„ä¸€çº§ç¼“å­˜ï¼Œä½†å¯è¢«ç¼–ç¨‹ã€‚æ¯ä¸ª SM éƒ½æœ‰ä¸€äº›ç”±çº¿ç¨‹å—åˆ†é…çš„å…±äº«å†…å­˜ï¼Œå› æ­¤ï¼Œä¸èƒ½è¿‡åº¦ä½¿ç”¨å…±äº«å†…å­˜ï¼Œå¦åˆ™å¯èƒ½ä¼šé™åˆ¶æ´»è·ƒçº¿ç¨‹æŸçš„æ•°é‡ã€‚</p><p>å…±äº«å†…å­˜åœ¨æ ¸å‡½æ•°å†…å£°æ˜ï¼Œç”Ÿå‘½å‘¨æœŸå’Œçº¿ç¨‹å—ä¸€è‡´ï¼Œçº¿ç¨‹å—è¿è¡Œå¼€å§‹ï¼Œæ­¤å—çš„å…±äº«å†…å­˜è¢«åˆ†é…ï¼Œå½“æ­¤å—ç»“æŸï¼Œåˆ™å…±äº«å†…å­˜è¢«é‡Šæ”¾</p><p>å¯ä»¥é€šè¿‡åœ¨æ ¸å‡½æ•°ä¸­ä½¿ç”¨<code>__shared__</code>ä¿®é¥°ç¬¦å°†å˜é‡æ”¾åœ¨å…±äº«å†…å­˜ä¸­</p><p>å› ä¸ºå…±äº«å†…å­˜æ˜¯çº¿ç¨‹å—ä¸­çº¿ç¨‹éƒ½å¯ä»¥è®¿é—®ï¼Œä¸”çº¿ç¨‹æ˜¯å¹¶å‘æ‰§è¡Œçš„ï¼Œæ‰€ä»¥å½“åŒä¸€ä¸ªçº¿ç¨‹å—ä¸­çš„å¤šä¸ªçº¿ç¨‹è®¿é—®åŒä¸€ä¸ªå†…å­˜åœ°å€æ—¶å¯èƒ½ä¼šå‘ç”Ÿä»¥ä¸‹æƒ…å†µ</p><ul><li>çº¿ç¨‹ a å’Œçº¿ç¨‹ b åŒæ—¶å°†åŒä¸€æ•°ç»„ä¸­çš„æ•°æ®æ‹·è´åˆ°å…±äº«å†…å­˜ä¸­ï¼Œå¯¼è‡´æ•°æ®å†²çª</li><li>çº¿ç¨‹ a å’Œçº¿ç¨‹ b åŒæ—¶è®¡ç®— x å’Œ y æ•°ç»„å¯¹åº”ä½ç½®çš„å’Œï¼Œå¹¶å°†ç»“æœå­˜å‚¨åˆ° z æ•°ç»„ä¸­ï¼Œå¯¼è‡´ç»“æœä¸æ­£ç¡®</li></ul><p>æ‰€ä»¥è®¿é—®å…±äº«å†…å­˜å‰å¿…é¡»ä½¿ç”¨å¦‚ä¸‹çš„åŒæ­¥è¯­å¥</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> __syncthreads();</span><br></pre></td></tr></table></figure><p>å¦‚æœé¢‘ç¹ä½¿ç”¨ä»¥ä¸Šè¯­å¥è®© SM è¿›å…¥ç©ºé—²çŠ¶æ€ï¼Œä¼šå½±å“æ€§èƒ½</p><p>SMä¸­çš„ä¸€çº§ç¼“å­˜å’Œå…±äº«å†…å­˜å…±äº«ç‰‡ä¸Šå†…å­˜ï¼Œç‰‡ä¸Šå†…å­˜ï¼ˆon-chip memoryï¼‰æ˜¯æŒ‡ä½äºGPUç‰‡ä¸Šçš„å†…å­˜ï¼Œå³ä¸ SM å¤„ç†å™¨ç›¸è¿çš„å†…å­˜ï¼ŒåŒ…æ‹¬ä¸€çº§ç¼“å­˜ã€å…±äº«å†…å­˜å’Œå¸¸é‡ç¼“å­˜ç­‰</p><p>ç‰‡ä¸Šå†…å­˜çš„å¤§å°æ ¹æ® SM  ç‰ˆæœ¬è€Œä¸åŒï¼Œä»¥æœ¬äººç”µè„‘çš„ sm_52 ç‰ˆæœ¬ä¸ºä¾‹ï¼Œä¸€çº§ç¼“å­˜å’Œå…±äº«å†…å­˜å…±äº«çš„ç‰‡ä¸Šå†…å­˜å¤§å°é»˜è®¤ä¸º</p><ul><li>ä¸€çº§ç¼“å­˜ï¼š64KB</li><li>å…±äº«å†…å­˜ï¼š32KB</li></ul><p>å› æ­¤ï¼Œsm_52 ç‰ˆæœ¬çš„ SM ä¸­å…±äº«çš„ç‰‡ä¸Šå†…å­˜å¤§å°ä¸º 64KB + 32KB = 96KBï¼Œé»˜è®¤é€šè¿‡é™æ€åˆ’åˆ†ï¼Œè¿è¡Œæ—¶å¯ä»¥é€šè¿‡ä¸‹é¢è¯­å¥è¿›è¡Œè®¾ç½®åˆ†é…æ–¹æ¡ˆ</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaFuncSetCacheConfig</span><span class="params">(<span class="type">const</span> <span class="type">void</span> * func,<span class="keyword">enum</span> cudaFuncCache cacheConfig)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>func</code>: æŒ‡å‘å†…æ ¸å‡½æ•°çš„æŒ‡é’ˆï¼Œè¡¨ç¤ºéœ€è¦è®¾ç½®ç¼“å­˜é…ç½®çš„å†…æ ¸å‡½æ•°</li><li><code>cudaFuncCache</code>: è¡¨ç¤ºå†…æ ¸å‡½æ•°çš„ç¼“å­˜é…ç½®ï¼Œå¯ä»¥æ˜¯ä»¥ä¸‹å€¼ä¹‹ä¸€<ul><li><code>cudaFuncCachePreferNone</code>: è¡¨ç¤ºä¸ä½¿ç”¨ç¼“å­˜</li><li><code>cudaFuncCachePreferShared</code>: è¡¨ç¤ºä¼˜å…ˆä½¿ç”¨å…±äº«å†…å­˜</li><li><code>cudaFuncCachePreferL1</code>: è¡¨ç¤ºä¼˜å…ˆä½¿ç”¨ä¸€çº§ç¼“å­˜</li><li><code>cudaFuncCachePreferEqual</code>: è¡¨ç¤ºä¼˜å…ˆä½¿ç”¨ L1 ç¼“å­˜æˆ–å…±äº«å†…å­˜ï¼Œå–å†³äºå“ªä¸ªæ›´å¿«ï¼Œä½¿ç”¨è¯¥é€‰é¡¹å¯èƒ½ä¼šå¸¦æ¥é¢å¤–çš„æ€§èƒ½å¼€é”€ï¼Œä¸å»ºè®®ä½¿ç”¨</li></ul></li></ul><p>ä¸‹é¢çš„ç¨‹åºå®šä¹‰äº†ä¸€ä¸ªç”¨äºè®¾ç½®ç¼“å­˜é…ç½®çš„å‡½æ•°<code>cudaFuncSetCacheConfig</code>ï¼Œå®ƒæ¥å—ä¸€ä¸ªæŒ‡å‘CUDAå‡½æ•°çš„æŒ‡é’ˆã€ä¸€ä¸ªé¢„å®šä¹‰çš„ç¼“å­˜é…ç½®æšä¸¾å€¼ã€ä¸€ä¸ªå¤‡é€‰çš„ç¼“å­˜é…ç½®æšä¸¾å€¼ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªé”™è¯¯ç ï¼Œè¿˜å®šä¹‰äº†ä¸€ä¸ªç©ºçš„å†…æ ¸å‡½æ•°<code>Kernel_func</code>ç”¨äºæ¼”ç¤º</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// è®¾ç½®æŒ‡å®šå‡½æ•°çš„ç¼“å­˜é…ç½®</span></span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaFuncSetCacheConfig</span><span class="params">(<span class="type">const</span> <span class="type">void</span> * func, <span class="keyword">enum</span> cudaFuncCache cacheConfig, <span class="keyword">enum</span> cudaFuncCache cacheConfigAlt)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// å®šä¹‰é”™è¯¯ç </span></span><br><span class="line">  cudaError_t error = cudaSuccess;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ä½¿ç”¨ CUDA é©±åŠ¨ API è®¾ç½®ç¼“å­˜é…ç½®</span></span><br><span class="line">  error = <span class="built_in">cudaFuncSetCacheConfig</span>(func, cacheConfig);</span><br><span class="line">  <span class="keyword">if</span> (error != cudaSuccess) &#123;</span><br><span class="line">    <span class="keyword">return</span> error;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ä½¿ç”¨ CUDA é©±åŠ¨ API è®¾ç½®å¤‡ç”¨ç¼“å­˜é…ç½®</span></span><br><span class="line">  error = <span class="built_in">cudaFuncSetCacheConfig</span>(func, cacheConfigAlt);</span><br><span class="line">  <span class="keyword">if</span> (error != cudaSuccess) &#123;</span><br><span class="line">    <span class="keyword">return</span> error;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// è¿”å›æˆåŠŸ</span></span><br><span class="line">  <span class="keyword">return</span> cudaSuccess;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">Kernel_func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// è¿™æ˜¯ä¸€ä¸ªä»€ä¹ˆä¹Ÿä¸åšçš„ç©ºå†…æ ¸</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// å®šä¹‰è¦è®¾ç½®çš„å‡½æ•°</span></span><br><span class="line">  <span class="type">void</span> *func = (<span class="type">void</span>*)Kernel_func;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// å®šä¹‰æ‰€éœ€çš„ç¼“å­˜é…ç½®</span></span><br><span class="line">  <span class="keyword">enum</span> <span class="title class_">cudaFuncCache</span> cacheConfig = cudaFuncCachePreferL1;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ä¸ºå‡½æ•°è®¾ç½®ç¼“å­˜é…ç½®</span></span><br><span class="line">  cudaError_t error = <span class="built_in">cudaFuncSetCacheConfig</span>(func, cacheConfig, cudaFuncCachePreferNone);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// æ£€æŸ¥é”™è¯¯</span></span><br><span class="line">  <span class="keyword">if</span> (error != cudaSuccess) &#123;</span><br><span class="line">    <span class="comment">// æ‰“å°é”™è¯¯æ¶ˆæ¯å¹¶é€€å‡º</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Error setting cache configuration: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(error));</span><br><span class="line">    <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Success!\n&quot;</span>);</span><br><span class="line">  <span class="comment">// ç¼“å­˜é…ç½®è®¾ç½®æˆåŠŸ</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="å¸¸é‡å†…å­˜"><a href="#å¸¸é‡å†…å­˜" class="headerlink" title="å¸¸é‡å†…å­˜"></a>å¸¸é‡å†…å­˜</h2><p>å¸¸é‡å†…å­˜é©»ç•™åœ¨è®¾å¤‡å†…å­˜ä¸­ï¼Œæ¯ä¸ªSMéƒ½æœ‰ä¸“ç”¨çš„å¸¸é‡å†…å­˜ç¼“å­˜ï¼Œå¯ä»¥é€šè¿‡åœ¨æ ¸å‡½æ•°ä¸­ä½¿ç”¨<code>__constant__</code>ä¿®é¥°ç¬¦å°†å˜é‡æ”¾åœ¨å¸¸é‡å†…å­˜ä¸­</p><p>å¸¸é‡å†…å­˜éœ€è¦åœ¨æ ¸å‡½æ•°å¤–ï¼Œå…¨å±€èŒƒå›´å†…å£°æ˜ï¼Œå¯¹äºæ‰€æœ‰è®¾å¤‡ï¼Œåªå¯ä»¥å£°æ˜ 64KB çš„å¸¸é‡å†…å­˜ï¼Œå¸¸é‡å†…å­˜æ˜¯é™æ€å£°æ˜çš„ï¼Œä¸»æœºç«¯ä»£ç å¯ä»¥åˆå§‹åŒ–å¸¸é‡å†…å­˜ï¼Œåˆå§‹åŒ–åä¸èƒ½è¢«æ ¸å‡½æ•°ä¿®æ”¹ï¼Œå¹¶ä¸”å¯¹åŒä¸€ç¼–è¯‘å•å…ƒä¸­çš„æ‰€æœ‰æ ¸å‡½æ•°å¯è§ï¼Œç›¸å…³å‡½æ•°å°†æ•°æ®ä»ä¸»å†…å­˜å¤åˆ¶åˆ°å¸¸é‡ç¼“å­˜ï¼ˆconstant memoryï¼‰</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMemcpyToSymbol</span><span class="params">(<span class="type">const</span> <span class="type">void</span>* symbol,<span class="type">const</span> <span class="type">void</span> *src,<span class="type">size_t</span> count)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>symbol</code>: æŒ‡å‘å¸¸é‡ç¼“å­˜çš„æŒ‡é’ˆï¼Œå¸¸é‡ç¼“å­˜æ˜¯ä¸€ç§ç‰¹æ®Šçš„å†…å­˜ç±»å‹ï¼Œç”¨äºå­˜å‚¨åœ¨ç¼–è¯‘æ—¶ä¸å˜çš„å˜é‡</li><li><code>src</code>: æŒ‡å‘ä¸»å†…å­˜ä¸­çš„æ•°æ®çš„æŒ‡é’ˆï¼Œè¦å¤åˆ¶çš„æ•°æ®å¿…é¡»ä½äºä¸»å†…å­˜ä¸­ï¼Œå› ä¸ºSMå¤„ç†å™¨æ— æ³•ç›´æ¥è®¿é—®ä¸»å†…å­˜</li><li><code>count</code>: è¦å¤åˆ¶çš„æ•°æ®çš„å­—èŠ‚æ•°</li></ul><p>ä¸‹é¢çš„ç¨‹åºåœ¨å¸¸é‡å†…å­˜ä¸­å®šä¹‰äº†ä¸€ä¸ªåä¸º <code>a</code> çš„å¸¸é‡æ•°ç»„ï¼Œå¹¶é€šè¿‡ <code>cudaMemcpyToSymbol</code> å‡½æ•°å°†ä¸€ä¸ªä¸»æœºä¸Šçš„æ•°ç»„ <code>h_a</code> å¤åˆ¶åˆ°è¯¥å¸¸é‡æ•°ç»„ä¸­</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line">__constant__ <span class="type">int</span> a[<span class="number">100</span>];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> h_a[<span class="number">100</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++)</span><br><span class="line">        h_a[i] = i;</span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(a, h_a, <span class="built_in">sizeof</span>(h_a));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="çº¹ç†å†…å­˜"><a href="#çº¹ç†å†…å­˜" class="headerlink" title="çº¹ç†å†…å­˜"></a>çº¹ç†å†…å­˜</h2><p>çº¹ç†å†…å­˜æ˜¯ä¸€ç§ç”¨æ¥å­˜å‚¨çº¹ç†æ•°æ®çš„å†…å­˜ç±»å‹ï¼Œåœ¨æ¯ä¸ª SM çš„åªè¯»ç¼“å­˜ä¸­ç¼“å­˜ï¼Œçº¹ç†å†…å­˜æ˜¯é€šè¿‡æŒ‡å®šçš„ç¼“å­˜è®¿é—®çš„å…¨å±€å†…å­˜ï¼Œåªè¯»ç¼“å­˜åŒ…æ‹¬ç¡¬ä»¶æ»¤æ³¢çš„æ”¯æŒï¼Œå®ƒå¯ä»¥å°†æµ®ç‚¹æ’å…¥ä½œä¸ºè¯»å–è¿‡ç¨‹ä¸­çš„ä¸€éƒ¨åˆ†æ¥æ‰§è¡Œï¼Œçº¹ç†å†…å­˜æ˜¯å¯¹äºŒç»´ç©ºé—´å±€éƒ¨æ€§çš„ä¼˜åŒ–ï¼Œæ‰€ä»¥é€šå¸¸ç”¨æ¥å­˜å‚¨æ¸²æŸ“å›¾åƒå’Œè§†é¢‘çš„æ•°æ®ï¼ŒåŒæ—¶å¯¹äºæŸäº›éœ€è¦æ»¤æ³¢çš„ç¨‹åºæ€§èƒ½æ›´å¥½ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡ç¡¬ä»¶å®Œæˆè®¡ç®—</p><p>å®šä¹‰ä¸€ä¸ª CUDA çº¹ç†å¯¹è±¡éœ€è¦ä½¿ç”¨<code>cudaCreateTextureObject</code> å‡½æ•°ï¼Œè§£é‡Šå¦‚ä¸‹</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaCreateTextureObject</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    cudaTextureObject_t *pTexObject,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> cudaResourceDesc *pResDesc,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> cudaTextureDesc *pTexDesc,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> cudaResourceViewDesc *pResViewDesc</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>pTexObject</code>ï¼šæŒ‡å‘ä¸€ä¸ª <code>cudaTextureObject_t</code> ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨äºå­˜å‚¨æ–°åˆ›å»ºçš„çº¹ç†å¯¹è±¡</li><li><code>pResDesc</code>ï¼šæŒ‡å‘ä¸€ä¸ª <code>cudaResourceDesc</code> ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨äºæè¿°çº¹ç†èµ„æº</li><li><code>pTexDesc</code>ï¼šæŒ‡å‘ä¸€ä¸ª <code>cudaTextureDesc</code> ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨äºæè¿°çº¹ç†å¯¹è±¡çš„å±æ€§</li><li><code>pResViewDesc</code>ï¼šæŒ‡å‘ä¸€ä¸ª <code>cudaResourceViewDesc</code> ç±»å‹çš„æŒ‡é’ˆï¼Œç”¨äºæè¿°çº¹ç†è§†å›¾çš„å±æ€§</li></ul><p>æ›´å…·ä½“çš„è§£é‡Šè¯·çœ‹<a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TEXTURE__OBJECT.html#group__CUDART__TEXTURE__OBJECT_1g16ac75814780c3a16e4c63869feb9ad3">å®˜æ–¹æ–‡æ¡£</a></p><p>ä¸‹é¢çš„ä»£ç åˆ›å»ºäº†ä¸€ä¸ªäºŒç»´æ•°æ®ç®€å•åœ°æ¨¡æ‹Ÿå›¾åƒä½¿ç”¨çº¹ç†å†…å­˜</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// å®šä¹‰ CUDA å†…æ ¸å‡½æ•°ï¼Œåä¸º transformKernel</span></span><br><span class="line"><span class="comment">// è¯¥å‡½æ•°æœ‰ä¸‰ä¸ªè¾“å…¥å‚æ•°ï¼š</span></span><br><span class="line"><span class="comment">// - outputï¼šæµ®ç‚¹å‹æŒ‡é’ˆï¼ŒæŒ‡å‘ç»“æœæ•°ç»„</span></span><br><span class="line"><span class="comment">// - texObjï¼šcudaTextureObject_t ç±»å‹ï¼Œè¡¨ç¤ºä¸€ä¸ª CUDA çº¹ç†å¯¹è±¡</span></span><br><span class="line"><span class="comment">// - width å’Œ heightï¼šè¡¨ç¤ºçº¹ç†å¯¹è±¡çš„å®½åº¦å’Œé«˜åº¦</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transformKernel</span><span class="params">(<span class="type">float</span>* output, cudaTextureObject_t texObj, <span class="type">int</span> width, <span class="type">int</span> height)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// è®¡ç®—å½“å‰çº¿ç¨‹çš„çºµæ¨ªåæ ‡</span></span><br><span class="line">    <span class="type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// å¦‚æœè¶…å‡ºçº¹ç†å¯¹è±¡çš„èŒƒå›´ï¼Œåˆ™é€€å‡ºè¯¥å‡½æ•°</span></span><br><span class="line">    <span class="keyword">if</span> ( x&lt;<span class="number">0</span> || x&gt;width || y&lt;<span class="number">0</span> || y&gt;height )</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="comment">// åœ¨çº¹ç†å¯¹è±¡ä¸­æŸ¥æ‰¾ (x+0.5, y+0.5) å¤„çš„å€¼ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™ output æ•°ç»„å¯¹åº”çš„ä½ç½®</span></span><br><span class="line">    output[ y*width+x ] = <span class="built_in">tex2D</span>&lt;<span class="type">float</span>&gt;(texObj, x+<span class="number">0.5f</span>, y+<span class="number">0.5f</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// å®šä¹‰çº¹ç†å¯¹è±¡çš„å°ºå¯¸</span></span><br><span class="line">    <span class="type">int</span> width = <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span> height = <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span> size = width*height*<span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// åˆ†é…å†…å­˜ç©ºé—´ç»™æºæ•°æ®</span></span><br><span class="line">    <span class="type">float</span> *h_data = <span class="keyword">new</span> <span class="type">float</span>[width*height];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// åˆå§‹åŒ–åŸå§‹æ•°æ®</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> y = <span class="number">0</span>; y&lt;height; y++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x&lt;width; x++) &#123;</span><br><span class="line">                h_data[y*width + x] = x;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// æ‰“å°åŸå§‹æ•°æ®</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;old:\n&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> y = <span class="number">0</span>; y&lt;height; y++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x&lt;width; x++) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%f &quot;</span>, h_data[y*width + x]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// åˆ›å»ºä¸€ä¸ªç”¨äºå­˜å‚¨æºæ•°æ®çš„ CUDA æ•°ç»„</span></span><br><span class="line">    cudaChannelFormatDesc channelDesc = <span class="built_in">cudaCreateChannelDesc</span>(<span class="number">32</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, cudaChannelFormatKindFloat);</span><br><span class="line">    cudaArray* cuArray;</span><br><span class="line">    <span class="built_in">cudaMallocArray</span>(&amp;cuArray, &amp;channelDesc, width, height);</span><br><span class="line">    <span class="comment">// å°†æºæ•°æ®å¤åˆ¶åˆ° CUDA æ•°ç»„ä¸­</span></span><br><span class="line">    <span class="built_in">cudaMemcpyToArray</span>(cuArray, <span class="number">0</span>, <span class="number">0</span>, h_data, size,cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// å®šä¹‰ä¸€ä¸ª cudaResourceDesc ç»“æ„ä½“ï¼Œç”¨äºæè¿°çº¹ç†èµ„æº</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">cudaResourceDesc</span> resDesc;</span><br><span class="line">    <span class="comment">// å°†è¯¥ç»“æ„ä½“çš„æ‰€æœ‰å­—æ®µæ¸…é›¶</span></span><br><span class="line">    <span class="built_in">memset</span>(&amp;resDesc, <span class="number">0</span>, <span class="built_in">sizeof</span>(resDesc));</span><br><span class="line">    <span class="comment">// è®¾ç½®çº¹ç†èµ„æºçš„ç±»å‹ä¸ºæ•°ç»„èµ„æº</span></span><br><span class="line">    resDesc.resType = cudaResourceTypeArray;</span><br><span class="line">    <span class="comment">// è®¾ç½®çº¹ç†èµ„æºæ‰€æŒ‡å‘çš„æ•°ç»„</span></span><br><span class="line">    resDesc.res.array.array = cuArray;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// å®šä¹‰ä¸€ä¸ª cudaTextureDesc ç»“æ„ä½“ï¼Œç”¨äºæè¿°çº¹ç†å¯¹è±¡</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">cudaTextureDesc</span> texDesc;</span><br><span class="line">    <span class="comment">// å°†è¯¥ç»“æ„ä½“çš„æ‰€æœ‰å­—æ®µæ¸…é›¶</span></span><br><span class="line">    <span class="built_in">memset</span>(&amp;texDesc, <span class="number">0</span>, <span class="built_in">sizeof</span>(texDesc));</span><br><span class="line">    <span class="comment">// è®¾ç½®çº¹ç†åæ ‡è¶…å‡ºçº¹ç†èŒƒå›´æ—¶çš„é‡‡æ ·æ¨¡å¼</span></span><br><span class="line">    texDesc.addressMode[<span class="number">0</span>] = cudaAddressModeBorder;</span><br><span class="line">    texDesc.addressMode[<span class="number">1</span>] = cudaAddressModeBorder;</span><br><span class="line">    <span class="comment">// è®¾ç½®çº¹ç†é‡‡æ ·æ»¤æ³¢æ¨¡å¼</span></span><br><span class="line">    texDesc.filterMode = cudaFilterModeLinear;</span><br><span class="line">    <span class="comment">// è®¾ç½®çº¹ç†çš„è¯»å–æ¨¡å¼</span></span><br><span class="line">    texDesc.readMode = cudaReadModeElementType;</span><br><span class="line">    <span class="comment">// è®¾ç½®çº¹ç†åæ ‡æ˜¯å¦å½’ä¸€åŒ–</span></span><br><span class="line">    texDesc.normalizedCoords = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// å®šä¹‰ä¸€ä¸ª cudaTextureObject_t ç±»å‹çš„å˜é‡ï¼Œè¡¨ç¤ºçº¹ç†å¯¹è±¡</span></span><br><span class="line">    cudaTextureObject_t texObj = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// ä½¿ç”¨çº¹ç†èµ„æºå’Œçº¹ç†æè¿°åˆ›å»ºçº¹ç†å¯¹è±¡</span></span><br><span class="line">    <span class="built_in">cudaCreateTextureObject</span>(&amp;texObj, &amp;resDesc, &amp;texDesc, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// åˆ†é…å†…å­˜ç»™å­˜å‚¨ç»“æœæ•°æ®çš„æ•°ç»„</span></span><br><span class="line">    <span class="type">float</span>* output;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;output, size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// è®¡ç®—çº¿ç¨‹å—å’Œç½‘æ ¼çš„ç»´åº¦</span></span><br><span class="line">    <span class="function">dim3 <span class="title">dimBlock</span><span class="params">(<span class="number">4</span>, <span class="number">4</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">dimGrid</span><span class="params">( max( (width  + dimBlock.x - <span class="number">1</span>) / dimBlock.x,<span class="number">1</span>),</span></span></span><br><span class="line"><span class="params"><span class="function">                      max( (height + dimBlock.y - <span class="number">1</span>) / dimBlock.y,<span class="number">1</span>) )</span></span>;</span><br><span class="line">    <span class="comment">// æ‰§è¡Œ CUDA å†…æ ¸å‡½æ•°</span></span><br><span class="line">    transformKernel &lt;&lt;&lt;dimGrid, dimBlock &gt;&gt;&gt;(output, texObj, width, height);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// å°†ç»“æœæ•°æ®ä» GPU æ‹·è´åˆ° CPU ä¸Š</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(h_data, output, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// æ‰“å°ç»“æœæ•°æ®</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;new:\n&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> y = <span class="number">0</span>; y&lt;height; y++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x&lt;width; x++) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%f &quot;</span>,h_data[y*width + x]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// é”€æ¯çº¹ç†å¯¹è±¡</span></span><br><span class="line">    <span class="built_in">cudaDestroyTextureObject</span>(texObj);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// é‡Šæ”¾ CUDA æ•°ç»„çš„å†…å­˜</span></span><br><span class="line">    <span class="built_in">cudaFreeArray</span>(cuArray);</span><br><span class="line">    <span class="comment">// é‡Šæ”¾ç»“æœæ•°æ®çš„å†…å­˜</span></span><br><span class="line">    <span class="built_in">cudaFree</span>(output);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// é‡Šæ”¾åŸå§‹æ•°æ®çš„å†…å­˜</span></span><br><span class="line">    <span class="keyword">delete</span>[]h_data;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>çº¹ç†å†…å­˜è¿™éƒ¨åˆ†çŸ¥è¯†ç‚¹åå¤šï¼Œåé¢æœ‰æœºä¼šå’Œå¤§å®¶ç»†ç»†é“æ¥</p><h2 id="å…¨å±€å†…å­˜"><a href="#å…¨å±€å†…å­˜" class="headerlink" title="å…¨å±€å†…å­˜"></a>å…¨å±€å†…å­˜</h2><p>å…¨å±€å†…å­˜ä¹Ÿå¯ä»¥è¯´æ˜¯ GPU çš„ä¸»å­˜ã€‚å®ƒæ˜¯ GPU å†…å­˜å±‚æ¬¡ç»“æ„ä¸­æœ€å¤§å®¹é‡ã€æœ€é«˜å»¶æ—¶çš„å†…å­˜ç±»å‹ï¼Œå®ƒçš„å£°æ˜å¯ä»¥åœ¨æ‰€æœ‰ SM è®¾å¤‡ä¸Šè¢«è®¿é—®åˆ°ï¼Œå¹¶ä¸”ä¸ç¨‹åºåŒç”Ÿå‘½å‘¨æœŸï¼Œå…¨å±€å˜é‡æ”¯æŒé™æ€å£°æ˜å’ŒåŠ¨æ€å£°æ˜</p><p>å¯ä»¥é€šè¿‡åœ¨æ ¸å‡½æ•°ä¸­ä½¿ç”¨<code>__device__</code>ä¿®é¥°ç¬¦å°†å˜é‡æ”¾åœ¨å…¨å±€å†…å­˜ä¸­</p><p>æˆ‘ä»¬åœ¨ç¬¬ä¸‰ç« ä¸­çš„æ‰€æœ‰ç¨‹åºåœ¨ GPU ä¸Šè®¿é—®çš„å†…å­˜éƒ½æ˜¯å…¨å±€å†…å­˜ï¼Œå› ä¸ºçº¿ç¨‹çš„æ‰§è¡Œä¸èƒ½è·¨çº¿ç¨‹å—åŒæ­¥ï¼Œå½“æœ‰å¤šä¸ªçº¿ç¨‹å¹¶å‘åœ°ä¿®æ”¹å…¨å±€å†…å­˜çš„åŒä¸€ä½ç½®æ—¶ï¼Œä¼šå¯¼è‡´æœªå®šä¹‰çš„ç¨‹åºè¡Œä¸º</p><p>å…¨å±€å†…å­˜è®¿é—®å¿…é¡»æ˜¯è‡ªç„¶å¯¹é½çš„ï¼Œä¹Ÿå°±æ˜¯ä¸€æ¬¡è¦è¯»å– 32 çš„æ•´æ•°å€å­—èŠ‚çš„å†…å­˜ï¼Œæ‰€ä»¥å½“çº¿ç¨‹æŸæ‰§è¡Œå†…å­˜åŠ è½½æˆ–å­˜å‚¨æ—¶ï¼Œéœ€è¦æ»¡è¶³çš„ä¼ è¾“æ•°é‡é€šå¸¸å–å†³äº</p><ul><li>è·¨çº¿ç¨‹çš„å†…å­˜åœ°å€åˆ†å¸ƒ</li><li>å†…å­˜äº‹åŠ¡çš„å¯¹é½æ–¹å¼ã€‚</li></ul><p>ä¸€èˆ¬æ»¡è¶³å†…å­˜è¯·æ±‚çš„äº‹åŠ¡è¶Šå¤šï¼Œæœªä½¿ç”¨çš„å­—èŠ‚è¢«ä¼ è¾“çš„å¯èƒ½æ€§è¶Šå¤§ï¼Œæ•°æ®ååé‡å°±ä¼šé™ä½ï¼Œä¹Ÿå¯ä»¥è¯´ï¼Œå¯¹é½çš„è¯»å†™æ¨¡å¼ä½¿å¾—ä¸éœ€è¦çš„æ•°æ®ä¹Ÿè¢«ä¼ è¾“ï¼Œæ‰€ä»¥ï¼Œåˆ©ç”¨ç‡ä½åˆ°æ—¶ååé‡ä¸‹é™ã€‚è¿‡å»çš„è®¾å¤‡å› ä¸ºæ²¡æœ‰è¶³å¤Ÿçš„ç¼“å­˜ï¼Œå¯¹å†…å­˜è®¿é—®è¦æ±‚éå¸¸ä¸¥æ ¼ï¼Œç°åœ¨è¦æ±‚å®½æ¾äº†ä¸€äº›</p><h2 id="GPU-ç¼“å­˜"><a href="#GPU-ç¼“å­˜" class="headerlink" title="GPU ç¼“å­˜"></a>GPU ç¼“å­˜</h2><p>åœ¨ CUDA ä¸­ï¼ŒGPU ç¼“å­˜æ˜¯ä¸å¯ç¼–ç¨‹çš„å†…å­˜ï¼Œæœ‰å¦‚ä¸‹å››ç§ç¼“å­˜</p><ul><li>ä¸€çº§ç¼“å­˜</li><li>äºŒçº§ç¼“å­˜</li><li>åªè¯»å¸¸é‡ç¼“å­˜</li><li>åªè¯»çº¹ç†ç¼“å­˜</li></ul><p>æ¯ä¸ª SM éƒ½æœ‰ä¸€ä¸ªä¸€çº§ç¼“å­˜ï¼Œæ‰€æœ‰ SM å…¬ç”¨ä¸€ä¸ªäºŒçº§ç¼“å­˜ï¼Œä¸€çº§å’ŒäºŒçº§ç¼“å­˜éƒ½è¢«ç”¨æ¥å­˜å‚¨æœ¬åœ°å†…å­˜å’Œå…¨å±€å†…å­˜ä¸­çš„æ•°æ®ï¼Œä¹ŸåŒ…æ‹¬å¯„å­˜å™¨æº¢å‡ºçš„éƒ¨åˆ†ã€‚CUDA å…è®¸æˆ‘ä»¬é…ç½®è¯»æ“ä½œçš„æ•°æ®æ˜¯ä½¿ç”¨ä¸€çº§ç¼“å­˜å’ŒäºŒçº§ç¼“å­˜ï¼Œè¿˜æ˜¯åªä½¿ç”¨äºŒçº§ç¼“å­˜</p><p>CPU è¯»å†™è¿‡ç¨‹éƒ½æœ‰å¯èƒ½è¢«ç¼“å­˜ï¼Œä¸ CPU ä¸åŒçš„æ˜¯ï¼ŒGPU å†™çš„è¿‡ç¨‹ä¸è¢«ç¼“å­˜ï¼Œåªæœ‰è¯»å–ä¼šè¢«ç¼“å­˜ï¼Œæ¯ä¸ª SM æœ‰ä¸€ä¸ªåªè¯»å¸¸é‡ç¼“å­˜ï¼Œåªè¯»çº¹ç†ç¼“å­˜ï¼Œå®ƒä»¬ç”¨äºè®¾å¤‡å†…å­˜ä¸­æé«˜æ¥è‡ªäºå„è‡ªå†…å­˜ç©ºé—´å†…çš„è¯»å–æ€§èƒ½</p><h2 id="CUDA-å˜é‡å£°æ˜æ€»ç»“"><a href="#CUDA-å˜é‡å£°æ˜æ€»ç»“" class="headerlink" title="CUDA å˜é‡å£°æ˜æ€»ç»“"></a>CUDA å˜é‡å£°æ˜æ€»ç»“</h2><p>ä¸‹é¢æ€»ç»“äº† CUDA å˜é‡å£°æ˜å’Œå®ƒä»¬ç›¸åº”çš„å­˜å‚¨ä½ç½®ã€ä½œç”¨åŸŸã€ç”Ÿå‘½å‘¨æœŸå’Œä¿®é¥°ç¬¦</p><div class="table-container"><table><thead><tr><th>ä¿®é¥°ç¬¦</th><th>å˜é‡åç§°</th><th>å­˜å‚¨å™¨</th><th>ä½œç”¨åŸŸ</th><th>ç”Ÿå‘½å‘¨æœŸ</th></tr></thead><tbody><tr><td></td><td><code>float var</code></td><td>å¯„å­˜å™¨</td><td>çº¿ç¨‹</td><td>çº¿ç¨‹</td></tr><tr><td></td><td><code>float var[100]</code></td><td>æœ¬åœ°</td><td>çº¿ç¨‹</td><td>çº¿ç¨‹</td></tr><tr><td><code>__shared__</code></td><td><code>float var +</code></td><td>å…±äº«</td><td>å—</td><td>å—</td></tr><tr><td><code>__device__</code></td><td><code>float var +</code></td><td>å…¨å±€</td><td>å…¨å±€</td><td>åº”ç”¨ç¨‹åº</td></tr><tr><td><code>__constant__</code></td><td><code>float var +</code></td><td>å¸¸é‡</td><td>å…¨å±€</td><td>åº”ç”¨ç¨‹åº</td></tr></tbody></table></div><blockquote><p><code>float var +</code> è¡¨ç¤ºæ ‡é‡æˆ–æ•°ç»„</p></blockquote><p>ä¸‹é¢æ€»ç»“äº†å„ç±»å­˜å‚¨å™¨çš„ä¸»è¦ç‰¹å¾</p><div class="table-container"><table><thead><tr><th>å­˜å‚¨å™¨</th><th>ç‰‡ä¸Š/ç‰‡å¤–</th><th>ç¼“å­˜</th><th>å­˜å–</th><th>èŒƒå›´</th><th>ç”Ÿå‘½å‘¨æœŸ</th></tr></thead><tbody><tr><td>å¯„å­˜å™¨</td><td>ç‰‡ä¸Š</td><td>N/A</td><td>R/W</td><td>ä¸€ä¸ªçº¿ç¨‹</td><td>çº¿ç¨‹</td></tr><tr><td>æœ¬åœ°</td><td>ç‰‡å¤–</td><td>+</td><td>R/W</td><td>ä¸€ä¸ªçº¿ç¨‹</td><td>çº¿ç¨‹</td></tr><tr><td>å…±äº«</td><td>ç‰‡ä¸Š</td><td>N/A</td><td>R/W</td><td>å—å†…æ‰€æœ‰çº¿ç¨‹</td><td>å—</td></tr><tr><td>å…¨å±€</td><td>ç‰‡å¤–</td><td>+</td><td>R/W</td><td>æ‰€æœ‰çº¿ç¨‹ + ä¸»æœº</td><td>ä¸»æœºé…ç½®</td></tr><tr><td>å¸¸é‡</td><td>ç‰‡å¤–</td><td>Yes</td><td>R</td><td>æ‰€æœ‰çº¿ç¨‹ + ä¸»æœº</td><td>ä¸»æœºé…ç½®</td></tr><tr><td>çº¹ç†</td><td>ç‰‡å¤–</td><td>Yes</td><td>R</td><td>æ‰€æœ‰çº¿ç¨‹ + ä¸»æœº</td><td>ä¸»æœºé…ç½®</td></tr></tbody></table></div><blockquote><p><code>+</code> è¡¨ç¤ºè®¡ç®—èƒ½åŠ›åœ¨ 2.X ä»¥ä¸Šçš„ GPU æ”¯æŒ</p></blockquote><h2 id="é™æ€å…¨å±€å†…å­˜"><a href="#é™æ€å…¨å±€å†…å­˜" class="headerlink" title="é™æ€å…¨å±€å†…å­˜"></a>é™æ€å…¨å±€å†…å­˜</h2><p>æˆ‘ä»¬åœ¨ç¬¬ä¸‰ç« ä¸­ä½¿ç”¨ cudaMalloc å‡½æ•°ç”³è¯·çš„éƒ½æ˜¯åŠ¨æ€å†…å­˜ï¼Œä¹Ÿå°±æ˜¯åŠ¨æ€åˆ†é…ï¼Œåœ¨ CUDA ä¸­ä¹Ÿæ”¯æŒé™æ€å†…å­˜ï¼Œä¹Ÿå¯ä»¥è¯´æ˜¯é™æ€åˆ†é…ï¼Œä¸åŠ¨æ€åˆ†é…ç›¸åŒï¼Œéœ€è¦æ˜¾å¼çš„å°†å†…å­˜æ‹·è´åˆ°è®¾å¤‡ç«¯ï¼Œéœ€è¦ä½¿ç”¨çš„å‡½æ•°å¦‚ä¸‹</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaMemcpyToSymbol</span> <span class="params">( <span class="type">const</span> <span class="type">void</span>* symbol, <span class="type">const</span> <span class="type">void</span>* src, <span class="type">size_t</span> count, <span class="type">size_t</span> offset = <span class="number">0</span>, cudaMemcpyKind kind = cudaMemcpyHostToDevice )</span></span></span><br></pre></td></tr></table></figure><p>ä» CPU å†…å­˜ä¸­çš„å˜é‡å€¼å¤åˆ¶åˆ° GPU çš„å…¨å±€å†…å­˜ä¸­</p><ul><li><code>symbol</code>: è¦å¤åˆ¶æ•°æ®çš„æ ‡è¯†ç¬¦ï¼ŒæŒ‡çš„æ˜¯å®šä¹‰åœ¨ GPU çš„å…¨å±€å†…å­˜ä¸­çš„å˜é‡ï¼Œä¸æ˜¯å˜é‡åœ°å€</li><li><code>src</code>: æºæ•°æ®çš„åœ°å€</li><li><code>count</code>: è¦å¤åˆ¶çš„æ•°æ®çš„å­—èŠ‚æ•°</li><li><code>offset</code>: ç›®æ ‡æ ‡è¯†ç¬¦ä¸­çš„åç§»é‡ï¼Œè¡¨ç¤ºä»ç¬¦å·çš„å“ªä¸ªä½ç½®å¼€å§‹å¤åˆ¶æ•°æ®</li><li><code>kind</code>: å¤åˆ¶æ•°æ®çš„ç±»å‹ï¼Œå¯ä»¥æ˜¯ <code>cudaMemcpyHostToDevice</code> æˆ– <code>cudaMemcpyDeviceToHost</code></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaMemcpyFromSymbol</span> <span class="params">( <span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span>* symbol, <span class="type">size_t</span> count, <span class="type">size_t</span> offset = <span class="number">0</span>, cudaMemcpyKind kind = cudaMemcpyDeviceToHost )</span></span></span><br></pre></td></tr></table></figure><p>å°† GPU çš„å…¨å±€å†…å­˜ä¸­çš„å˜é‡å€¼å¤åˆ¶åˆ° CPU å†…å­˜ä¸­</p><ul><li>dstï¼šç›®æ ‡æ•°æ®çš„åœ°å€</li><li>symbolï¼šè¦å¤åˆ¶æ•°æ®çš„æ ‡è¯†ç¬¦ï¼ŒæŒ‡çš„æ˜¯å®šä¹‰åœ¨ GPU çš„å…¨å±€å†…å­˜ä¸­çš„å˜é‡ï¼Œä¸æ˜¯å˜é‡åœ°å€</li><li>countï¼šè¦å¤åˆ¶çš„æ•°æ®çš„å­—èŠ‚æ•°</li><li>offsetï¼šæºæ ‡è¯†ç¬¦ä¸­çš„åç§»é‡ï¼Œè¡¨ç¤ºä»ç¬¦å·çš„å“ªä¸ªä½ç½®å¼€å§‹å¤åˆ¶æ•°æ®</li><li>kindï¼šå¤åˆ¶æ•°æ®çš„ç±»å‹ï¼Œå¯ä»¥æ˜¯ <code>cudaMemcpyHostToDevice</code> æˆ– <code>cudaMemcpyDeviceToHost</code></li></ul><p>ä¸¾ä¾‹ç¨‹åºå¦‚ä¸‹</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line">__device__ <span class="type">float</span> devData;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">checkGlobalVariable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Device: The value of the global variable is %f\n&quot;</span>,devData);</span><br><span class="line">    devData+=<span class="number">2.0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> value=<span class="number">3.1415926f</span>;</span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(devData,&amp;value,<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Host: copy %f to the global variable\n&quot;</span>,value);</span><br><span class="line">    checkGlobalVariable&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaMemcpyFromSymbol</span>(&amp;value,devData,<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Host: the value changed by the kernel to %f \n&quot;</span>,value);</span><br><span class="line">    <span class="built_in">cudaDeviceReset</span>();</span><br><span class="line">    <span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åœ¨ä»¥ä¸Šä»£ç ä¸­ï¼Œå¦‚æœä½¿ç”¨å¦‚ä¸‹ä»£ç æ‹·è´æ˜¯æ— æ•ˆçš„ï¼Œå› ä¸ºåŠ¨æ€æ‹·è´çš„æ–¹æ³•æ— æ³•å¯¹é™æ€å˜é‡èµ‹å€¼</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpy</span>(&amp;value,devData,<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br></pre></td></tr></table></figure><p>ä½†æ˜¯å¯ä»¥ä½¿ç”¨ <code>cudaGetSymbolAddress</code> å‡½æ•°è·å–è®¾å¤‡çš„å…¨å±€å˜é‡çš„åœ°å€ï¼Œè€Œä¸èƒ½ä½¿ç”¨ <code>&amp;</code> ç›´æ¥å–åœ°å€ï¼Œä¹‹å å†ä½¿ç”¨ <code>cudaMemcpy</code> å°†å€¼æ‹·è´åˆ°ä¸»æœºä¸Š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> *dptr=<span class="literal">NULL</span>;</span><br><span class="line"><span class="built_in">cudaGetSymbolAddress</span>((<span class="type">void</span>**)&amp;dptr,devData);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(dptr,&amp;value,<span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyHostToDevice);</span><br></pre></td></tr></table></figure><p>æœ‰ä¸€ä¸ªä¾‹å¤–ï¼ŒCUDA å›ºå®šå†…å­˜å¯ä»¥ç›´æ¥ä»ä¸»æœºå¼•ç”¨ GPU å†…å­˜ï¼Œä¸‹ä¸€ç« èŠ‚æˆ‘ä»¬å°†è¯¦ç»†äº†è§£</p>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: PyCUDAç¼–ç¨‹ç®€ä»‹</title>
      <link href="/p/ec855d6e/"/>
      <url>/p/ec855d6e/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>PyCUDA GPU ç¼–ç¨‹ã€‚ä¸»è¦å†…å®¹æ˜¯æŒæ¡å‡ ç§PyCUDA çš„åŸºæœ¬å†…æ ¸å‡½æ•°ï¼Œåœ¨ Python ä¸­ç”Ÿæˆå’Œè°ƒç”¨å¹¶è¡ŒåŒ–çš„ CUDA C å†…æ ¸å‡½æ•°ï¼Œä»¥åŠäº†è§£ PyCUDA çš„å¹¶è¡Œå‰ç¼€ç®—æ³•ã€‚</p><span id="more"></span><h2 id="è·å–-GPU-ä¿¡æ¯"><a href="#è·å–-GPU-ä¿¡æ¯" class="headerlink" title="è·å– GPU ä¿¡æ¯"></a>è·å– GPU ä¿¡æ¯</h2><p>é¦–å…ˆï¼Œéœ€è¦åˆå§‹åŒ– CUDAï¼Œä½¿ç”¨ <code>pycuda.driver.init()</code>æˆ–é€šè¿‡<code>import pycuda.autoinit</code>ä½¿ç”¨<code>autoinit</code>å­æ¨¡å—åˆå§‹åŒ–ï¼Œæ¥ä¸‹æ¥ä½¿ç”¨<code>pycuda.driver.Device(i)</code>æ¥è®¿é—®ä¸åŒçš„ GPU è®¾å¤‡ï¼Œè¿™é‡Œç¬”è€…çš„ç”µè„‘ä¸ºå• GPU</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pycuda</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pycuda.driver <span class="keyword">as</span> drv</span><br><span class="line">drv.init()</span><br><span class="line"><span class="comment"># æˆ–</span></span><br><span class="line"><span class="comment"># import pycuda.autoinit</span></span><br><span class="line"><span class="comment"># è¿›è¡Œè‡ªåŠ¨åˆå§‹åŒ–</span></span><br><span class="line"></span><br><span class="line">gpu_device = drv.Device(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;GPU Device Name&#123;&#125;: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="number">0</span>, gpu_device.name()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;SM Count: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(gpu_device.MULTIPROCESSOR_COUNT))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Shared Memory Size per Thread Block: &#123;&#125; KB&#x27;</span>.<span class="built_in">format</span>(gpu_device.MAX_SHARED_MEMORY_PER_BLOCK / <span class="number">1024.0</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Threads per Thread Block: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(gpu_device.MAX_THREADS_PER_BLOCK))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Threads per SM: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(gpu_device.MAX_THREADS_PER_MULTIPROCESSOR))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Warps per SM: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(gpu_device.MAX_THREADS_PER_MULTIPROCESSOR / <span class="number">32</span>))</span><br></pre></td></tr></table></figure><p>è¿è¡Œå‘½ä»¤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python infogpu.py</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹ï¼ŒSM æ•°é‡ä¸º 30ï¼Œæ¯ä¸ªçº¿ç¨‹å—çš„å…±äº«å†…å­˜ä¸º 48KBï¼Œæ¯ä¸ªçº¿ç¨‹å—æœ‰ 1024 ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ª SM æœ‰ 1536 ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ª SM æœ‰ 48 ä¸ªçº¿ç¨‹æŸ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GPU Device Name0: NVIDIA GeForce RTX 3060 Laptop GPU</span><br><span class="line">SM Count: 30</span><br><span class="line">Shared Memory Size per Thread Block: 48.0 KB</span><br><span class="line">Threads per Thread Block: 1024</span><br><span class="line">Threads per SM: 1536</span><br><span class="line">Warps per SM: 48.0</span><br></pre></td></tr></table></figure><h2 id="ä½¿ç”¨-gpuarray-ç±»"><a href="#ä½¿ç”¨-gpuarray-ç±»" class="headerlink" title="ä½¿ç”¨ gpuarray ç±»"></a>ä½¿ç”¨ gpuarray ç±»</h2><p>PyCUDA åº“ä¸­ï¼Œgpuarray ä¸ºæ•°æ®çš„å­˜å‚¨ç±»å‹ï¼Œæ­£å¦‚ Numpy åº“ä¸­çš„ array ä¸ºæ•°æ®çš„å­˜å‚¨ç±»å‹</p><h3 id="ä¼ è¾“æ•°æ®"><a href="#ä¼ è¾“æ•°æ®" class="headerlink" title="ä¼ è¾“æ•°æ®"></a>ä¼ è¾“æ•°æ®</h3><p>åœ¨ CUDA C ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ <code>cudaMemcpyHostToDevice</code>å’Œ<code>cudaMemcpyDeviceToHost</code>ç­‰å‡½æ•°æ¥è¿›è¡Œä¸»æœºä¸è®¾å¤‡çš„æ•°æ®ä¼ è¾“ï¼Œéœ€è¦è·Ÿè¸ªä¸»æœºä¸è®¾å¤‡å†…å­˜ç©ºé—´ä¸­çš„å¤šä¸ªæŒ‡é’ˆï¼Œè¿˜è¦è¿›è¡Œå†…å­˜åˆ†é…ï¼Œä¼šä½¿ä»£ç å˜å¾—å¤æ‚ï¼ŒPyCUDA çš„ gpuarray èƒ½å¤Ÿè‡ªåŠ¨å®Œæˆå†…å­˜åˆ†é…ï¼Œå¹¶æ ¹æ®ç”Ÿå‘½å‘¨æœŸè‡ªåŠ¨é‡Šæ”¾ã€‚ä¸¾ä¾‹å¦‚ä¸‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_host = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=np.float32)</span><br><span class="line">y_host = np.array([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], dtype=np.float32)</span><br><span class="line">z_host = np.array([<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], dtype=np.float32)</span><br><span class="line"></span><br><span class="line">x_device = gpuarray.to_gpu(x_host)</span><br><span class="line">y_device = gpuarray.to_gpu(y_host)</span><br><span class="line">z_device = gpuarray.to_gpu(z_host)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>((x_device + y_device + z_device).get())</span><br><span class="line"><span class="built_in">print</span>((x_device ** y_device).get())</span><br><span class="line"><span class="built_in">print</span>((x_device / z_device).get())</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºä¸º</span></span><br><span class="line">[<span class="number">12.</span> <span class="number">15.</span> <span class="number">18.</span>]</span><br><span class="line">[  <span class="number">1.</span>       <span class="number">32.</span>      <span class="number">729.00006</span>]</span><br><span class="line">[<span class="number">0.14285715</span> <span class="number">0.25</span>       <span class="number">0.33333334</span>]</span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç¨‹åºä½¿ç”¨<code>gpuarray.to_gpu()</code>å°† array è½¬ä¸º gpuarrayï¼Œä½¿ç”¨ gpuarray çš„<code>get()</code>å±æ€§å°† gpuarray è½¬ä¸º arrayï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œgpuarray è¿˜å…·æœ‰å¦‚ä¸‹å±æ€§</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pycuda.gpuarray.zeros(shape, dtype=np.float64, *, allocator=<span class="literal">None</span>, order=<span class="string">&#x27;C&#x27;</span>)<span class="comment"># å¼€è¾Ÿgpuå†…å­˜ç©ºé—´ï¼Œåˆ›å»º (m,n) çš„0çŸ©é˜µ</span></span><br><span class="line">pycuda.gpuarray.empty(shape, dtype, *, allocator=<span class="literal">None</span>, order=<span class="string">&#x27;C&#x27;</span>)<span class="comment"># å¼€è¾Ÿgpuå†…å­˜ç©ºé—´ï¼Œåˆ›å»º (m,n) çš„ç©ºçŸ©é˜µ</span></span><br><span class="line">pycuda.gpuarray.zeros_like(other_ary, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;K&#x27;</span>)<span class="comment"># å¼€è¾Ÿgpuå†…å­˜ç©ºé—´ï¼Œåˆ›å»º size åŒ ary çš„ 0çŸ©é˜µï¼Œå› æ­¤aryæœ€å¥½</span></span><br><span class="line">pycuda.gpuarray.empty_like(other_ary, dtype=<span class="literal">None</span>, order=<span class="string">&#x27;K&#x27;</span>)<span class="comment"># å¼€è¾Ÿgpuå†…å­˜ç©ºé—´ï¼Œåˆ›å»º size åŒ ary çš„ç©ºçŸ©é˜µ</span></span><br><span class="line">pycuda.gpuarray.arange(start, stop, step, dtype=<span class="literal">None</span>, stream=<span class="literal">None</span>)<span class="comment"># åˆ›å»ºé¡ºåºåºåˆ—</span></span><br><span class="line">pycuda.gpuarray.take(a, indices, stream=<span class="literal">None</span>)<span class="comment"># è¿”å› gpu_ary[a[index[0]], ..., a[index[n]]]</span></span><br><span class="line">pycuda.gpuarray.maximum(a, b, out=<span class="literal">None</span>, stream=<span class="literal">None</span>)<span class="comment"># gpu_ary å¯¹åº”aå’Œbä¸­çš„è¾ƒå¤§å…ƒç´ </span></span><br><span class="line">pycuda.gpuarray.minimum(a, b, out=<span class="literal">None</span>, stream=<span class="literal">None</span>)<span class="comment"># gpu_ary å¯¹åº”aå’Œbä¸­çš„è¾ƒå°å…ƒç´ </span></span><br><span class="line">pycuda.gpuarray.<span class="built_in">max</span>(a, stream=<span class="literal">None</span>)<span class="comment"># gpu_ary æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å…ƒç´ </span></span><br><span class="line">pycuda.gpuarray.<span class="built_in">min</span>(a, stream=<span class="literal">None</span>)<span class="comment"># gpu_ary æ‰€æœ‰å…ƒç´ çš„æœ€å°å…ƒç´ </span></span><br><span class="line">pycuda.gpuarray.<span class="built_in">sum</span>(a, dtype=<span class="literal">None</span>, stream=<span class="literal">None</span>)<span class="comment"># gpu_ary æ‰€æœ‰å…ƒç´ æ±‚å’Œ</span></span><br><span class="line">pycuda.gpuarray.dot(a, b, dtype=<span class="literal">None</span>, stream=<span class="literal">None</span>)<span class="comment"># gpu_ary æ±‚ç‚¹ç§¯</span></span><br></pre></td></tr></table></figure><p>ä¸Šè¿°å‡½æ•°ä¸­çš„<code>stream=None</code>æ„ä¸ºæŒ‡å®š CUDA æµï¼Œæˆ‘ä»¬ä¼šåœ¨åé¢çš„ç« èŠ‚è¯¦ç»†è®²è§£ã€‚</p><p>æ›´å¤šå±æ€§ä½¿ç”¨æ–¹æ³•è¯·æŸ¥çœ‹<a href="https://documen.tician.de/pycuda/array.html#constructing-gpuarray-instances">å®˜æ–¹æ–‡æ¡£</a></p><h2 id="PyCUDA-ç”Ÿæˆå¹¶è¡ŒåŒ–-Kernel-å‡½æ•°"><a href="#PyCUDA-ç”Ÿæˆå¹¶è¡ŒåŒ–-Kernel-å‡½æ•°" class="headerlink" title="PyCUDA ç”Ÿæˆå¹¶è¡ŒåŒ– Kernel å‡½æ•°"></a>PyCUDA ç”Ÿæˆå¹¶è¡ŒåŒ– Kernel å‡½æ•°</h2><p>PyCUDA æä¾›äº†å¤§é‡å‡½æ•°æ¥ç”Ÿæˆå†…è”çš„ CUDA C å†…æ ¸å‡½æ•°ï¼Œå†…è”å‡½æ•°é€šè¿‡ NVIDIA NVCC ç¼–è¯‘å™¨åœ¨å¤–éƒ¨ç¼–è¯‘ç¼“å­˜ï¼Œç”± PyCUDA ç¨‹åºåœ¨è¿è¡Œæ—¶è°ƒç”¨ï¼Œä¸‹é¢ä¸ºå¤§å®¶ä¸¾å‡ ä¸ªä¸»è¦ä¾‹å­ï¼Œæ›´è¯¦ç»†çš„ PyCUDA å†…æ ¸å‡½æ•°ä»‹ç»è¯·çœ‹<a href="https://documen.tician.de/pycuda/array.html#module-pycuda.elementwise">å®˜æ–¹æ–‡æ¡£</a></p><h3 id="ElementwiseKernel-é€å…ƒç´ è¿ç®—"><a href="#ElementwiseKernel-é€å…ƒç´ è¿ç®—" class="headerlink" title="ElementwiseKernel é€å…ƒç´ è¿ç®—"></a>ElementwiseKernel é€å…ƒç´ è¿ç®—</h3><p><code>ElementwiseKernel</code>å‡½æ•°ç”¨äºå¯¹ gpuarray æ•°ç»„å¹¶è¡ŒåŒ–é€å…ƒç´ è®¡ç®—ï¼Œå‡½æ•°å£°æ˜å¦‚ä¸‹</p><p><code>class pycuda.elementwise.ElementwiseKernel(arguments, operation, name=&#39;kernel&#39;, keep=False, options=[], preamble=&#39;&#39;)</code></p><ul><li><code>arguments</code>: æ„ä¸ºå‚æ•°åˆ—è¡¨ï¼Œå†…å®¹æ˜¯å£°æ˜å˜é‡çš„å­—ç¬¦ä¸²ï¼Œä¸º C/C++ è¯­æ³•ï¼Œæœ«å°¾æ— åˆ†å·</li><li><code>operation</code>: ä¸ºå˜é‡èµ‹å€¼ï¼Œå¯¹æ•°ç»„çš„æ“ä½œéœ€è¦ç”¨ <code>i</code> è¿›è¡Œç´¢å¼•ï¼Œç±»ä¼šè‡ªåŠ¨ å¹¶è¡ŒåŒ– GPU å„æ ¸å¿ƒä¸­ä¸ <code>i</code> æœ‰å…³çš„è®¡ç®—ï¼Œä¸º C/C++ è¯­æ³•ï¼Œæœ«å°¾æ— åˆ†å·</li><li><code>name</code>: æŒ‡å®šå†…æ ¸å‡½æ•°åç§°ï¼Œå‘½åç©ºé—´åœ¨ CUDA C ä¸­</li><li><code>options</code>: æ„å»ºæ—¶è¦ä½¿ç”¨çš„ç¼–è¯‘å™¨é€‰é¡¹ï¼Œä¸º<code>list</code>ç±»å‹</li><li><code>keep</code>: ä¸º<code>True</code>åˆ™ä¿ç•™ç¼–è¯‘å™¨è¾“å‡ºç›®å½•ï¼Œå¹¶æ‰“å°ä¸€è¡ŒæŒ‡ç¤ºå…¶æ‰€åœ¨ç›®å½•ä»¥ç”¨äºè°ƒè¯•ï¼Œ<code>False</code>åˆ™ä¸ä¿ç•™</li><li><code>preamble</code>: æŒ‡å®šå†…æ ¸æ„é€ ä¹‹å‰åŒ…å«çš„ä»£ç ï¼Œå¯ä»¥ä½¿ç”¨å®ƒæ¥åŒ…å«å…¶ä»–æ–‡ä»¶å’Œå®šä¹‰<code>operation</code>ä½¿ç”¨çš„å‡½æ•°</li></ul><p>ä¸‹ä¾‹çš„ç¨‹åºå®šä¹‰äº†ä¸€ä¸ªåä¸º <code>gpu_x2_kernel</code>çš„å†…æ ¸å‡½æ•°ï¼Œå®ç°äº†è¾“å…¥æ•°ç»„<code>in</code>ä¸­æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹ï¼Œå°†ç»“æœæ•°ç»„<code>out</code>ä¸­</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> pycuda.elementwise <span class="keyword">import</span> ElementwiseKernel</span><br><span class="line">host_data = np.float32(np.random.random(<span class="number">1</span>&lt;&lt;<span class="number">20</span>))</span><br><span class="line">gpu_x2_kernel = ElementwiseKernel(</span><br><span class="line">    <span class="string">&quot;float *in, float *out&quot;</span>,    <span class="comment"># arguments</span></span><br><span class="line">    <span class="string">&quot;out[i] = in[i] * in[i]&quot;</span>,   <span class="comment"># operation</span></span><br><span class="line">    <span class="string">&quot;gpu_x2_kernel&quot;</span>             <span class="comment"># name</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>ä¸‹é¢çš„ç¨‹åºæ¯”è¾ƒäº† gpuarray æ•°ç»„è¿ç®—ä¸<code>ElementwiseKernel</code>ç±»è¿ç®—çš„é€Ÿåº¦ï¼Œ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> pycuda.elementwise <span class="keyword">import</span> ElementwiseKernel</span><br><span class="line"></span><br><span class="line">host_data = np.float32(np.random.random(<span class="number">1</span>&lt;&lt;<span class="number">29</span>))</span><br><span class="line"></span><br><span class="line">gpu_x2_kernel = ElementwiseKernel(</span><br><span class="line">    <span class="string">&quot;float *in, float *out&quot;</span>,</span><br><span class="line">    <span class="string">&quot;out[i] = in[i] * in[i]&quot;</span>,</span><br><span class="line">    <span class="string">&quot;gpu_x2_kernel&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">speedcomparison</span>():</span><br><span class="line">    t1 = time()</span><br><span class="line">    host_data_x2 =  host_data * host_data</span><br><span class="line">    t2 = time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;total time to compute on CPU: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(t2 - t1))</span><br><span class="line">    device_data = gpuarray.to_gpu(host_data)</span><br><span class="line">    <span class="comment"># allocate memory for output</span></span><br><span class="line">    device_data_2x = gpuarray.empty_like(device_data)</span><br><span class="line">    t1 = time()</span><br><span class="line">    gpu_x2_kernel(device_data, device_data_2x)</span><br><span class="line">    t2 = time()</span><br><span class="line">    from_device = device_data_2x.get()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;total time to compute on GPU: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(t2 - t1))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Is the host computation the same as the GPU computation? : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.allclose(from_device, host_data_x2)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    speedcomparison()</span><br><span class="line">    </span><br><span class="line"><span class="comment"># åœ¨ ipython ä¸­è¿è¡Œè¾“å‡ºä¸º</span></span><br><span class="line">In [<span class="number">1</span>]: run speedcomparison.py</span><br><span class="line">total time to compute on CPU: <span class="number">0.36846113204956055</span></span><br><span class="line">total time to compute on GPU: <span class="number">0.07349300384521484</span></span><br><span class="line">Is the host computation the same <span class="keyword">as</span> the GPU computation? : <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: run speedcomparison.py</span><br><span class="line">total time to compute on CPU: <span class="number">0.368114709854126</span></span><br><span class="line">total time to compute on GPU: <span class="number">0.03887605667114258</span></span><br><span class="line">Is the host computation the same <span class="keyword">as</span> the GPU computation? : <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: run speedcomparison.py</span><br><span class="line">total time to compute on CPU: <span class="number">0.3670005798339844</span>dair_v2x_root</span><br><span class="line">total time to compute on GPU: <span class="number">0.039081573486328125</span></span><br><span class="line">Is the host computation the same <span class="keyword">as</span> the GPU computation? : <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°åœ¨é¦–æ¬¡è¿è¡Œ GPU çš„å†…æ ¸å‡½æ•°åï¼Œè¿ç®—æ—¶é—´ä¼šå¤§å¹…å‡å°‘ï¼Œè¿™æ­£æ˜¯å› ä¸º NVCC ç¼–è¯‘å™¨ä¼šç¼–è¯‘å¥½çš„å†…æ ¸å‡½æ•°ç¼“å­˜èµ·æ¥ï¼Œä»¥é‡å¤ä½¿ç”¨</p><p>å…¶ä¸­åœ¨å†…æ ¸å‡½æ•°ä¸­å®šä¹‰çš„<code>float *out</code>ä¸º C è¯­è¨€çš„æµ®ç‚¹å‹æŒ‡é’ˆï¼Œæ‰€ä»¥ä¼šä½¿ç”¨<code>gpuarray.empty_like</code>å…ˆåœ¨ GPU å¼€è¾Ÿå†…å­˜ç©ºé—´ï¼Œå°†è¿ç®—ç»“æœæ”¾å…¥å…¶ä¸­ï¼Œå†ä½¿ç”¨<code>get</code>å‡½æ•°æ‹·è´å›ä¸»æœº</p><h3 id="InclusiveScanKernel-æ‰«æå†…æ ¸å‡½æ•°"><a href="#InclusiveScanKernel-æ‰«æå†…æ ¸å‡½æ•°" class="headerlink" title="InclusiveScanKernel æ‰«æå†…æ ¸å‡½æ•°"></a>InclusiveScanKernel æ‰«æå†…æ ¸å‡½æ•°</h3><p><code>InclusiveScanKernel</code>å‡½æ•°é€šè¿‡æŒ‡å®šè¾“å…¥ç±»å‹<code>dtype</code>å’Œ<code>string</code>ç±»å‹çš„ç®—æœ¯è¡¨è¾¾å¼<code>scan_expr</code>è¿›è¡Œå†…æ ¸å‡½æ•°æ„é€ ï¼Œå†å¯¹æ•°ç»„é€å…ƒç´ è¿›è¡Œå¹¶è¡ŒåŒ–è¿ç®—ï¼Œå‡½æ•°å£°æ˜å¦‚ä¸‹</p><p><code>class pycuda.scan.InclusiveScanKernel(dtype, scan_expr, neutral=None, name_prefix=&#39;scan&#39;, options=[], preamble=&#39;&#39;, devices=None)</code></p><ul><li><code>dtype</code>: æŒ‡å®šè¾“å…¥æ•°ç»„ç±»å‹</li><li><code>scan_expr</code>: ä»»æ„ç¬¦åˆç»“åˆå¾‹çš„äºŒå…ƒè¿ç®—è¡¨è¾¾å¼ï¼Œå¿…é¡»æ˜¯ C è¯­è¨€ç¼–å†™</li><li><code>neutral</code>: ä¸­æ€§å…ƒï¼ŒåŠ æ³•åº”ä¸º 0ï¼Œä¹˜æ³•åº”ä¸º 1ï¼Œæœ¬å°èŠ‚åé¢ä¼šè¯¦ç»†è®²è§£åŸå› </li><li><code>name_prefix</code>: ç”¨äºå†…æ ¸åç§°ä»¥ç¡®ä¿é…ç½®æ–‡ä»¶å’Œæ—¥å¿—ä¸­çš„å¯è¯†åˆ«æ€§</li><li><code>options</code> ä¸ <code>preamble</code> å«ä¹‰åŒä¸Š</li></ul><p>ä¸‹é¢çš„ç¨‹åºå¯¹å‘é‡é€å…ƒç´ ä½œåŠ æ³•ä»¥åŠé€å…ƒç´ æŸ¥æ‰¾æœ€å¤§å€¼</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">from</span> pycuda.scan <span class="keyword">import</span> InclusiveScanKernel</span><br><span class="line"></span><br><span class="line">seq1 = np.array(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10</span>)),dtype=np.int32)</span><br><span class="line">seq2 = np.array([<span class="number">1</span>,<span class="number">100</span>,-<span class="number">3</span>,-<span class="number">1000</span>,<span class="number">4</span>,<span class="number">1000000</span>,<span class="number">65</span>,<span class="number">2454</span>],dtype=np.int32)</span><br><span class="line">seq1_gpu = gpuarray.to_gpu(seq1)</span><br><span class="line">seq2_gpu = gpuarray.to_gpu(seq2)</span><br><span class="line">sum_gpu = InclusiveScanKernel(np.int32, <span class="string">&quot;a + b&quot;</span>)</span><br><span class="line">max_gpu = InclusiveScanKernel(np.int32, <span class="string">&quot;a&gt;b ? a : b&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(sum_gpu(seq1_gpu).get())</span><br><span class="line"><span class="built_in">print</span>(max_gpu(seq2_gpu).get())</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºä¸º</span></span><br><span class="line">[ <span class="number">0</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">6</span> <span class="number">10</span> <span class="number">15</span> <span class="number">21</span> <span class="number">28</span> <span class="number">36</span> <span class="number">45</span>]</span><br><span class="line">[      <span class="number">1</span>     <span class="number">100</span>     <span class="number">100</span>     <span class="number">100</span>     <span class="number">100</span> <span class="number">1000000</span> <span class="number">1000000</span> <span class="number">1000000</span>]</span><br></pre></td></tr></table></figure><p>ä¸Šä¾‹æ‰€ç¤ºï¼Œ<code>sum_gpu</code>ä¸º<code>&quot;a + b&quot;</code>ï¼ŒåŒ…å«<code>a</code>å’Œ<code>b</code>ä»£æŒ‡çš„äºŒå…ƒè¿ç®—çš„ä¸¤ä¸ªå…ƒç´ ï¼Œç±»ä¼¼ Python ä¸­çš„ <code>lambda a,b : a + b</code>ï¼Œ<code>max_gpu</code>ç±»ä¼¼<code>lambda a,b : max(a,b)</code></p><h3 id="ReductionKernel-è§„çº¦å†…æ ¸å‡½æ•°"><a href="#ReductionKernel-è§„çº¦å†…æ ¸å‡½æ•°" class="headerlink" title="ReductionKernel è§„çº¦å†…æ ¸å‡½æ•°"></a>ReductionKernel è§„çº¦å†…æ ¸å‡½æ•°</h3><p><code>ReductionKernel</code>å‡½æ•°å¯¹<code>arguments</code>å¹¶è¡Œæ‰§è¡Œ <code>map expr</code>ï¼Œç„¶åå¯¹å…¶ç»“æœæ‰§è¡Œ <code>reduce expr</code>ï¼Œç›¸å½“äº<code>InclusiveScanKernel</code>å‡½æ•°åæ¥ç€<code>ElementwiseKernel</code>å‡½æ•°ï¼Œå‡½æ•°å£°æ˜å¦‚ä¸‹</p><p><code>class pycuda.reduction.ReductionKernel(dtype_out, neutral, reduce_expr, map_expr=None, arguments=None, name=&#39;reduce_kernel&#39;, keep=False, options=[], preamble=&#39;&#39;, allocator=None)</code></p><ul><li><code>dtype_out</code>: æŒ‡å®šè¿”å›æ•°æ®ç±»å‹</li><li><code>neutral</code>: ä¸­æ€§å…ƒï¼ŒåŠ æ³•åº”ä¸º 0ï¼Œä¹˜æ³•åº”ä¸º 1ï¼Œæœ¬å°èŠ‚åé¢ä¼šè¯¦ç»†è®²è§£åŸå› </li><li><code>reduce_expr</code>: ç›¸å½“äº<code>InclusiveScanKernel</code>å‡½æ•°çš„<code>reduce_expr</code></li><li><code>map_expr</code>: ç›¸å½“äº<code>ElementwiseKernel</code>å‡½æ•°çš„<code>operation</code></li><li>å…¶ä½™å…³é”®å­—åŒä¸Š</li></ul><p>ä¸‹é¢çš„ç¨‹åºè®¡ç®—äº†ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">from</span> pycuda.reduction <span class="keyword">import</span> ReductionKernel</span><br><span class="line"></span><br><span class="line">seq1 = np.array(<span class="built_in">range</span>(<span class="number">10</span>),dtype=np.float32)</span><br><span class="line">seq2 = np.array(<span class="built_in">range</span>(<span class="number">10</span>),dtype=np.float32)</span><br><span class="line">seq1_gpu = gpuarray.to_gpu(seq1)</span><br><span class="line">seq2_gpu = gpuarray.to_gpu(seq2)</span><br><span class="line">dot_prod = ReductionKernel(np.float32, neutral=<span class="string">&quot;0&quot;</span>, reduce_expr=<span class="string">&quot;a+b&quot;</span>, map_expr=<span class="string">&quot;x[i] * y[i]&quot;</span>,arguments=<span class="string">&quot;float *x, float *y&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(np.dot(seq1,seq2))</span><br><span class="line"><span class="built_in">print</span>(dot_prod(seq1_gpu, seq2_gpu).get())</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">285.0</span></span><br><span class="line"><span class="number">285.0</span></span><br></pre></td></tr></table></figure><h2 id="PyCUDA-SourceModule-å¹¶è¡Œå‡½æ•°"><a href="#PyCUDA-SourceModule-å¹¶è¡Œå‡½æ•°" class="headerlink" title="PyCUDA SourceModule å¹¶è¡Œå‡½æ•°"></a>PyCUDA SourceModule å¹¶è¡Œå‡½æ•°</h2><p><code>SourceModule</code>å‡½æ•°å°†åŸæ¥çš„å†…è” CUDA C ä»£ç ç¼–è¯‘æˆå¯ä»¥ä» Python å¯åŠ¨çš„å†…æ ¸å‡½æ•°ï¼Œä¸ä¸Šè¿°æ‰€æœ‰å‡½æ•°ä¸åŒçš„æ˜¯ï¼Œ<code>SourceModule</code>å‡½æ•°åœ¨<code>source</code>ä¸­ç›´æ¥ç¼–å†™ CUDA C æ•´ä½“å†…æ ¸å‡½æ•°ä»£ç ï¼Œå‡½æ•°å£°æ˜å¦‚ä¸‹</p><p><code>class pycuda.compiler.SourceModule(source, nvcc=&#39;nvcc&#39;, options=None, keep=False, no_extern_c=False, arch=None, code=None, cache_dir=None, include_dirs=[])</code></p><ul><li><code>source</code>: å†…æ ¸å‡½æ•°ä»£ç ï¼Œä½¿ç”¨ CUDA C ç¼–å†™</li><li><code>nvcc</code>: ç¼–è¯‘å™¨å‘½ä»¤</li><li><code>no_extern_c</code>: é»˜è®¤ä¸º <code>False</code>ï¼Œ<code>source</code>ä¼šè¢«åŒ…è£…åœ¨ extern â€œCâ€ { â€¦ } ä¸­ä»¥é˜²æ­¢ C++ åç§°é‡æ•´ï¼Œä¸º<code>True</code>åˆ™ä¸ä¼šè¢«åŒ…è£…åœ¨ extern â€œCâ€ { â€¦ } ä¸­</li><li><code>arch</code>: æŒ‡å®šä¼ é€’ç»™ nvcc å‘½ä»¤ä¸Š <code>-arch</code> é€‰é¡¹çš„å€¼</li><li><code>code</code>: æŒ‡å®šä¼ é€’ç»™ nvcc å‘½ä»¤ä¸Š <code>-code</code> é€‰é¡¹çš„å€¼</li><li><code>cache_dir</code>: æŒ‡å®šç”¨äºç¼–è¯‘å™¨ç¼“å­˜çš„ç›®å½•ï¼Œé»˜è®¤ä¸º<code>PYCUDA_CACHE_DIR</code>æ‰€æŒ‡ç›®å½•ï¼Œä¸º<code>False</code>åˆ™ç¦ç”¨ç¼“å­˜ï¼Œå¦‚æœç¯å¢ƒå˜é‡<code>PYCUDA_DISABLE_CACHE</code>è¢«èµ‹å€¼ï¼Œæ„ä¸ºå…¨å±€ç¦ç”¨ç¼“å­˜ï¼Œ<code>cache_dir</code>å°†è¢«è¦†ç›–</li><li><code>include_dirs</code>: å°†ä¸€ä¸ªæˆ–å¤šä¸ªå¤–éƒ¨ç±»ä¼ é€’ç»™<code>source</code>ï¼Œç±»å‹ä¸º string list</li><li>å…¶ä½™å…³é”®å­—åŒä¸Š</li></ul><p>éœ€è¦ä½¿ç”¨<code>get_function</code>å¾—åˆ°å·²ç¼–è¯‘å¥½çš„å†…æ ¸å‡½æ•°çš„å¼•ç”¨ï¼Œæ‰å¯ä½¿ç”¨å†…æ ¸å‡½æ•°ï¼Œä¸‹ä¾‹ç¨‹åºè®¡ç®—äº†çŸ©é˜µä¹˜æ³•</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pycuda.driver <span class="keyword">as</span> cuda</span><br><span class="line"><span class="keyword">import</span> pycuda.tools</span><br><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numpy.linalg <span class="keyword">as</span> la</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">from</span> pycuda.compiler <span class="keyword">import</span> SourceModule</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line">mod = SourceModule(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">__global__ void matrixMultiply(float * A, float * B, float * C,</span></span><br><span class="line"><span class="string">                   int A_shape_0,int A_shape_1,int B_shape_1) &#123;</span></span><br><span class="line"><span class="string">    float cValue = 0;</span></span><br><span class="line"><span class="string">    int Row = blockIdx.y * blockDim.y + threadIdx.y;</span></span><br><span class="line"><span class="string">    int Col = blockIdx.x * blockDim.x + threadIdx.x;</span></span><br><span class="line"><span class="string">    if ((Row &lt; A_shape_0) &amp;&amp; (Col &lt; B_shape_1)) &#123;</span></span><br><span class="line"><span class="string">        for (int k = 0; k &lt; A_shape_1; k++) &#123;</span></span><br><span class="line"><span class="string">            cValue += A[Row*A_shape_1 + k] * B[k*B_shape_1 + Col];</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        C[Row*B_shape_1 + Col] = cValue;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line">matrixMultiply = mod.get_function(<span class="string">&quot;matrixMultiply&quot;</span>)</span><br><span class="line">n = <span class="number">1000</span></span><br><span class="line">A = np.random.randint(<span class="number">0</span>,<span class="number">10</span>,<span class="number">1000000</span>).reshape(<span class="number">1000</span>,<span class="number">1000</span>).astype(np.float32)</span><br><span class="line">B = np.random.randint(<span class="number">0</span>,<span class="number">10</span>,<span class="number">1000000</span>).reshape(<span class="number">1000</span>,<span class="number">1000</span>).astype(np.float32)</span><br><span class="line"></span><br><span class="line">BLOCK_SIZE = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">A_gpu = gpuarray.to_gpu(A)</span><br><span class="line">B_gpu = gpuarray.to_gpu(B)</span><br><span class="line">C_gpu = gpuarray.empty_like(A_gpu)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> n % BLOCK_SIZE != <span class="number">0</span>:</span><br><span class="line">    grid=(n // BLOCK_SIZE+<span class="number">1</span>, n // BLOCK_SIZE+<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    grid=(n // BLOCK_SIZE, n // BLOCK_SIZE,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;grid size: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(grid))</span><br><span class="line">start = time.time()</span><br><span class="line">matrixMultiply(A_gpu, B_gpu, C_gpu, np.int32(A.shape[<span class="number">0</span>]),np.int32(A.shape[<span class="number">1</span>]),np.int32(B.shape[<span class="number">1</span>]), block=(BLOCK_SIZE,BLOCK_SIZE,<span class="number">1</span>), grid=grid);</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;result:\n&quot;</span>, C_gpu.get())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;time cost: %ss&quot;</span> %(time.time() - start))</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºä¸º</span></span><br><span class="line">grid size: (<span class="number">32</span>, <span class="number">32</span>, <span class="number">1</span>)</span><br><span class="line">result:</span><br><span class="line"> [[<span class="number">19305.</span> <span class="number">18274.</span> <span class="number">18786.</span> ... <span class="number">19130.</span> <span class="number">19501.</span> <span class="number">18229.</span>]</span><br><span class="line"> [<span class="number">19945.</span> <span class="number">19823.</span> <span class="number">20158.</span> ... <span class="number">19853.</span> <span class="number">20397.</span> <span class="number">19848.</span>]</span><br><span class="line"> [<span class="number">20651.</span> <span class="number">19959.</span> <span class="number">20910.</span> ... <span class="number">20715.</span> <span class="number">21033.</span> <span class="number">20364.</span>]</span><br><span class="line"> ...</span><br><span class="line"> [<span class="number">20196.</span> <span class="number">19777.</span> <span class="number">20198.</span> ... <span class="number">20291.</span> <span class="number">20736.</span> <span class="number">19916.</span>]</span><br><span class="line"> [<span class="number">20239.</span> <span class="number">19820.</span> <span class="number">20210.</span> ... <span class="number">20171.</span> <span class="number">20685.</span> <span class="number">19244.</span>]</span><br><span class="line"> [<span class="number">19595.</span> <span class="number">19444.</span> <span class="number">19546.</span> ... <span class="number">19862.</span> <span class="number">20462.</span> <span class="number">19508.</span>]]</span><br><span class="line">time cost: <span class="number">0.003673076629638672</span>s</span><br></pre></td></tr></table></figure><h2 id="å¹¶è¡Œå‰ç¼€ç®—æ³•"><a href="#å¹¶è¡Œå‰ç¼€ç®—æ³•" class="headerlink" title="å¹¶è¡Œå‰ç¼€ç®—æ³•"></a>å¹¶è¡Œå‰ç¼€ç®—æ³•</h2><p>å‰é¢æåˆ°çš„<code>InclusiveScanKernel</code>å‡½æ•°å’Œå‡½æ•°å°±æ˜¯å¹¶è¡Œæ‰«æç®—æ³•ä¹‹ä¸€ï¼Œå¹¶è¡Œæ‰«æç®—æ³•å®šä¹‰å¦‚ä¸‹</p><p>å®šä¹‰äºŒå…ƒè¿ç®—ç¬¦ $\oplus$ å’Œä¸€ä¸ªæœ‰ $n$ ä¸ªå…ƒç´ çš„æ•°ç»„ $[x<em>0, x_1, x_2, \cdots, x</em>{n-1}]$</p><p>è¿”å›</p><script type="math/tex; mode=display">[x_0, (x_0 \oplus x_1), (x_0 \oplus x_1 \oplus x_2), \cdots, (x_0 \oplus x_1 \oplus \cdots \oplus x_{n-1})]</script><p>ä»¥åŠ æ³•ä¸¾ä¾‹ï¼Œè¾“å…¥ä¸º <code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</code>ï¼Œè¿”å›ä¸º<code>[ 0  1  3  6 10 15 21 28 36 45]</code>ï¼Œå¦‚æœç”¨ä¸²è¡Œçš„è®¡ç®—æ–¹å¼ï¼Œéœ€è¦è®¡ç®— $n$ æ¬¡æ±‚å’Œï¼Œæ—¶é—´å¤æ‚åº¦ä¸º$O(n)$ï¼Œæˆ‘ä»¬è¦å°½é‡é™ä½æ—¶é—´å¤æ‚åº¦</p><h3 id="æœ´ç´ å¹¶è¡Œå‰ç¼€ç®—æ³•"><a href="#æœ´ç´ å¹¶è¡Œå‰ç¼€ç®—æ³•" class="headerlink" title="æœ´ç´ å¹¶è¡Œå‰ç¼€ç®—æ³•"></a>æœ´ç´ å¹¶è¡Œå‰ç¼€ç®—æ³•</h3><p>æœ´ç´ å¹¶è¡Œæ‰«æç®—æ³•æ˜¯å¹¶è¡Œæ‰«æç®—æ³•çš„åˆå§‹ç‰ˆæœ¬ï¼Œæˆ‘ä»¬å‡è®¾è¾“å…¥å…ƒç´ ä¸º n ä¸ªï¼Œä¸” n ä¸º 2 çš„æ¬¡å¹‚ï¼ŒåŒæ—¶åœ¨ n ä¸ªçº¿ç¨‹ä¸Šå¹¶è¡Œè®¡ç®—ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º $O(\log_{2} n)$ï¼Œä¸‹å›¾ä¸ºç®—æ³•ç¤ºæ„å›¾ï¼ˆ<a href="https://www.geeksforgeeks.org/hillis-steele-scan-parallel-prefix-scan-algorithm/">åŸå›¾é“¾æ¥</a>ï¼‰</p><p><img src="/image/CUDAç¼–ç¨‹-PyCUDAç¼–ç¨‹ç®€ä»‹/1.webp" alt=""></p><p>ä¸‹é¢çš„ç¨‹åºä»¥åŠ æ³•ä¸ºä¾‹ï¼Œè®¡ç®—äº†é•¿åº¦ä¸º 1024 çš„æ•°ç»„</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">import</span> pycuda.driver <span class="keyword">as</span> drv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">from</span> pycuda.compiler <span class="keyword">import</span> SourceModule</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">naive_ker = SourceModule(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">__global__ void naive_scan(double *vec, double *out) &#123;</span></span><br><span class="line"><span class="string">     __shared__ double sum_buf[1024];     </span></span><br><span class="line"><span class="string">     int tid = threadIdx.x;</span></span><br><span class="line"><span class="string">     sum_buf[tid] = vec[tid];</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     // begin parallel prefix sum algorithm</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     int iter = 1;</span></span><br><span class="line"><span class="string">     for (int i=0; i &lt; 10; i++) &#123;</span></span><br><span class="line"><span class="string">         __syncthreads();</span></span><br><span class="line"><span class="string">         if (tid &gt;= iter ) &#123;</span></span><br><span class="line"><span class="string">             sum_buf[tid] = sum_buf[tid] + sum_buf[tid - iter];</span></span><br><span class="line"><span class="string">         &#125;</span></span><br><span class="line"><span class="string">         iter *= 2;</span></span><br><span class="line"><span class="string">     &#125;</span></span><br><span class="line"><span class="string">    __syncthreads();</span></span><br><span class="line"><span class="string">    out[tid] = sum_buf[tid];</span></span><br><span class="line"><span class="string">    __syncthreads();</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">naive_gpu = naive_ker.get_function(<span class="string">&quot;naive_scan&quot;</span>)</span><br><span class="line"></span><br><span class="line">testvec = np.random.randn(<span class="number">1024</span>).astype(np.float64)</span><br><span class="line">testvec_gpu = gpuarray.to_gpu(testvec)</span><br><span class="line">    </span><br><span class="line">outvec_gpu = gpuarray.empty_like(testvec_gpu)</span><br><span class="line">naive_gpu( testvec_gpu , outvec_gpu, block=(<span class="number">1024</span>,<span class="number">1</span>,<span class="number">1</span>), grid=(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">total_sum = <span class="built_in">sum</span>( testvec)</span><br><span class="line">total_sum_gpu = outvec_gpu[-<span class="number">1</span>].get()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Does our kernel work correctly? : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.allclose(total_sum_gpu , total_sum)))</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ä½¿ç”¨äº†<code>__syncthreads()</code>å‡½æ•°ï¼Œä¿è¯äº†çº¿ç¨‹å—ä¸­çš„æ‰€æœ‰çº¿ç¨‹åœ¨è¿›å…¥ä¸‹ä¸€æ¬¡è¿­ä»£å‰ï¼Œå½“å‰è¿­ä»£é‡Œæ¯ä¸€ä¸ªçº¿ç¨‹çš„æ‰€æœ‰éƒ¨åˆ†éƒ½è¢«ä¿å­˜åœ¨äº†å…¨å±€å†…å­˜ä¸­</p><h3 id="é«˜æ•ˆå¹¶è¡Œå‰ç¼€ç®—æ³•"><a href="#é«˜æ•ˆå¹¶è¡Œå‰ç¼€ç®—æ³•" class="headerlink" title="é«˜æ•ˆå¹¶è¡Œå‰ç¼€ç®—æ³•"></a>é«˜æ•ˆå¹¶è¡Œå‰ç¼€ç®—æ³•</h3><p>ä¸Šä¸€ä¾‹çš„ç®—æ³•åªèƒ½è®¡ç®—é•¿åº¦ä¸º 1024 çš„æ•°ç»„è¿›è¡Œè®¡ç®—ï¼Œä¸”éœ€è¦ä¸é•¿åº¦ç­‰é‡çš„çº¿ç¨‹æ•°é‡ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å®ç°æ”¯æŒé•¿åº¦è¶…è¿‡ 1024 çš„ä»»æ„æ•°ç»„çš„ç®—æ³•ï¼Œæ­¤ç®—æ³•éœ€è¦ä¸¤ä¸ªå†…æ ¸å‡½æ•°å’Œ python å‡½æ•°ï¼Œåˆ†åŠ è¿›è¡Œä¸Šè¡Œæ‰«æå’Œä¸‹è¡Œæ‰«æã€‚ä¸Šè¡Œæ‰«æé˜¶æ®µç±»ä¼¼äºä¸€æ¬¡è§„çº¦æ“ä½œï¼Œå³$x<em>0 \oplus \cdots \oplus x</em>{n-1}$ï¼Œä¸‹è¡Œæ‰«æé˜¶æ®µå°†å¯¹ä¸Šè¡Œæ‰«æçš„è¿”å›å€¼è¿›è¡Œè®¡ç®—ï¼Œè¿”å›æœ€ç»ˆç»“æœï¼Œå…·ä½“ä»£ç å¦‚ä¸‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">import</span> pycuda.autoinit</span><br><span class="line"><span class="keyword">import</span> pycuda.driver <span class="keyword">as</span> drv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pycuda <span class="keyword">import</span> gpuarray</span><br><span class="line"><span class="keyword">from</span> pycuda.compiler <span class="keyword">import</span> SourceModule</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># this is a work-efficent parallel prefix-sum algorithm.</span></span><br><span class="line"><span class="comment"># written by Brian Tuomanen for &quot;Hands On GPU Programming with Python and CUDA&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kernel for up-sweep phase</span></span><br><span class="line">up_ker = SourceModule(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">__global__ void up_ker(double *x, double *x_old, int k ) &#123;</span></span><br><span class="line"><span class="string">     int tid =  blockIdx.x*blockDim.x + threadIdx.x;</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     int _2k = 1 &lt;&lt; k;</span></span><br><span class="line"><span class="string">     int _2k1 = 1 &lt;&lt; (k+1);</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     int j = tid* _2k1;</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     x[j + _2k1 - 1] = x_old[j + _2k -1 ] + x_old[j + _2k1 - 1];</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">up_gpu = up_ker.get_function(<span class="string">&quot;up_ker&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># implementation of up-sweep phase</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">up_sweep</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="comment"># let&#x27;s typecast to be safe.</span></span><br><span class="line">    x = np.float64(x)</span><br><span class="line">    x_gpu = gpuarray.to_gpu(np.float64(x) )</span><br><span class="line">    x_old_gpu = x_gpu.copy()</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>( <span class="built_in">int</span>(np.log2(x.size) ) ) : </span><br><span class="line">        num_threads = <span class="built_in">int</span>(np.ceil( x.size / <span class="number">2</span>**(k+<span class="number">1</span>)))</span><br><span class="line">        grid_size = <span class="built_in">int</span>(np.ceil(num_threads / <span class="number">32</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> grid_size &gt; <span class="number">1</span>:</span><br><span class="line">            block_size = <span class="number">32</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            block_size = num_threads</span><br><span class="line">            </span><br><span class="line">        up_gpu(x_gpu, x_old_gpu, np.int32(k)  , block=(block_size,<span class="number">1</span>,<span class="number">1</span>), grid=(grid_size,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        x_old_gpu[:] = x_gpu[:]</span><br><span class="line">        </span><br><span class="line">    x_out = x_gpu.get()</span><br><span class="line">    <span class="keyword">return</span>(x_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># kernel for down-sweep phase</span></span><br><span class="line">down_ker = SourceModule(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">__global__ void down_ker(double *y, double *y_old,  int k) &#123;</span></span><br><span class="line"><span class="string">     int tid =  blockIdx.x*blockDim.x + threadIdx.x;</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     int _2k = 1 &lt;&lt; k;</span></span><br><span class="line"><span class="string">     int _2k1 = 1 &lt;&lt; (k+1);</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     int j = tid*_2k1;</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     y[j + _2k - 1 ] = y_old[j + _2k1 - 1];</span></span><br><span class="line"><span class="string">     y[j + _2k1 - 1] = y_old[j + _2k1 - 1] + y_old[j + _2k - 1];</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">down_gpu = down_ker.get_function(<span class="string">&quot;down_ker&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># implementation of down-sweep phase</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">down_sweep</span>(<span class="params">y</span>):</span><br><span class="line">    y = np.float64(y)</span><br><span class="line">    y[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    y_gpu = gpuarray.to_gpu(y)</span><br><span class="line">    y_old_gpu = y_gpu.copy()</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="built_in">int</span>(np.log2(y.size)))):</span><br><span class="line">        num_threads = <span class="built_in">int</span>(np.ceil( y.size / <span class="number">2</span>**(k+<span class="number">1</span>)))</span><br><span class="line">        grid_size = <span class="built_in">int</span>(np.ceil(num_threads / <span class="number">32</span>))</span><br><span class="line">        <span class="keyword">if</span> grid_size &gt; <span class="number">1</span>:</span><br><span class="line">            block_size = <span class="number">32</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            block_size = num_threads</span><br><span class="line">        down_gpu(y_gpu, y_old_gpu, np.int32(k), block=(block_size,<span class="number">1</span>,<span class="number">1</span>), grid=(grid_size,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        y_old_gpu[:] = y_gpu[:]</span><br><span class="line">    y_out = y_gpu.get()</span><br><span class="line">    <span class="keyword">return</span>(y_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># full implementation of work-efficient parallel prefix sum</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">efficient_prefix</span>(<span class="params">x</span>):</span><br><span class="line"><span class="keyword">return</span>(down_sweep(up_sweep(x)))</span><br><span class="line"></span><br><span class="line">testvec = np.random.randn(<span class="number">32</span>*<span class="number">1024</span>).astype(np.float64)</span><br><span class="line">testvec_gpu = gpuarray.to_gpu(testvec)</span><br><span class="line"></span><br><span class="line">outvec_gpu = gpuarray.empty_like(testvec_gpu)</span><br><span class="line"></span><br><span class="line">prefix_sum = np.roll(np.cumsum(testvec), <span class="number">1</span>)</span><br><span class="line">prefix_sum[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">prefix_sum_gpu = efficient_prefix(testvec)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Does our work-efficient prefix work? &#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.allclose(prefix_sum_gpu, prefix_sum)))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDA Cç¼–ç¨‹ç®€ä»‹</title>
      <link href="/p/55d1319f/"/>
      <url>/p/55d1319f/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è®²è§£ CUDA C ç¼–ç¨‹ä¸­çš„ç®€å•çš„å†…å­˜ç®¡ç†ï¼Œçº¿ç¨‹æ“ä½œï¼Œå¦‚ä½•ç¼–å†™æ ¸å‡½æ•°ï¼Œä½¿ç”¨ Thrust åº“ï¼Œå¹¶è¡Œè®¡ç®—ï¼Œæ€§èƒ½åˆ†æå·¥å…·ã€‚</p><span id="more"></span><h2 id="è·å–-GPU-ä¿¡æ¯"><a href="#è·å–-GPU-ä¿¡æ¯" class="headerlink" title="è·å– GPU ä¿¡æ¯"></a>è·å– GPU ä¿¡æ¯</h2><p>CUDA  æä¾›äº†å‡ ç§è·å– GPU ä¿¡æ¯çš„æ–¹æ³•ï¼Œè¿™é‡Œä»‹ç»ä¸€ä¸‹é€šè¿‡è°ƒç”¨ <code>cuda_runtime.h</code>ä¸­çš„ API å¾—åˆ° GPU çš„ä¸€äº›å±æ€§ã€‚</p><blockquote><p>åœ¨ç¼–å†™ CUDA C ç¨‹åºæ—¶ï¼Œ è¦å°†æ–‡ä»¶å‘½åä¸º <code>*.cu</code>ï¼Œä¸€èˆ¬ä½¿ç”¨ nvcc å‘½ä»¤ç¼–è¯‘è¿è¡Œï¼Œä¸º CUDAç¨‹åºæ–‡ä»¶ï¼Œæ”¯æŒ C/C++ è¯­æ³•ã€‚</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">    cudaDeviceProp devProp;</span><br><span class="line">    <span class="built_in">cudaGetDeviceProperties</span>(&amp;devProp, dev);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;GPU Device Name&quot;</span> &lt;&lt; dev &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; devProp.name &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;SM Count: &quot;</span> &lt;&lt; devProp.multiProcessorCount &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Shared Memory Size per Thread Block: &quot;</span> &lt;&lt; devProp.sharedMemPerBlock / <span class="number">1024.0</span> &lt;&lt; <span class="string">&quot; KB&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Threads per Thread Block: &quot;</span> &lt;&lt; devProp.maxThreadsPerBlock &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Threads per SM: &quot;</span> &lt;&lt; devProp.maxThreadsPerMultiProcessor &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Warps per SM: &quot;</span> &lt;&lt; devProp.maxThreadsPerMultiProcessor / <span class="number">32</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ç¼–è¯‘å‘½ä»¤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc checkDeviceInfor.cu -o checkDeviceInfor</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹ï¼ŒSM æ•°é‡ä¸º 30ï¼Œæ¯ä¸ªçº¿ç¨‹å—çš„å…±äº«å†…å­˜ä¸º 48KBï¼Œæ¯ä¸ªçº¿ç¨‹å—æœ‰ 1024 ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ª SM æœ‰ 1536 ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ª SM æœ‰ 48 ä¸ªçº¿ç¨‹æŸ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GPU Device Name0: NVIDIA GeForce RTX 3060 Laptop GPU</span><br><span class="line">SM Count: 30</span><br><span class="line">Shared Memory Size per Thread Block: 48 KB</span><br><span class="line">Threads per Thread Block: 1024</span><br><span class="line">Threads per SM: 1536</span><br><span class="line">Warps per SM: 48</span><br></pre></td></tr></table></figure><h2 id="åˆæ­¥å†…å­˜ç®¡ç†"><a href="#åˆæ­¥å†…å­˜ç®¡ç†" class="headerlink" title="åˆæ­¥å†…å­˜ç®¡ç†"></a>åˆæ­¥å†…å­˜ç®¡ç†</h2><p>ä¸»æœºå’Œè®¾å¤‡å„è‡ªæ‹¥æœ‰ç‹¬ç«‹çš„å†…å­˜ï¼ŒC æ‹¥æœ‰æ ‡å‡†åº“å¯ä»¥ç®¡ç†ä¸»æœºçš„å†…å­˜ï¼ŒCUDA æä¾›çš„ API ç®¡ç†è®¾å¤‡çš„å†…å­˜ï¼Œä¸‹é¢æ˜¯ C å’Œ CUDA çš„éƒ¨åˆ†å†…å­˜ç®¡ç†å‡½æ•°</p><div class="table-container"><table><thead><tr><th>C</th><th>CUDA</th><th>åŠŸèƒ½</th></tr></thead><tbody><tr><td>malloc</td><td>cudaMalloc</td><td>åˆ†é…å†…å­˜</td></tr><tr><td>memcpy</td><td>cudaMemcpy</td><td>å¤åˆ¶å†…å­˜</td></tr><tr><td>memset</td><td>cudaMemset</td><td>è®¾ç½®å†…å­˜</td></tr><tr><td>free</td><td>cudaFree</td><td>é‡Šæ”¾å†…å­˜</td></tr></tbody></table></div><h3 id="ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´"><a href="#ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´" class="headerlink" title="ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´"></a>ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´</h3><p>ä¸‹é¢çš„ç¨‹åºä¸¾ä¾‹äº†å¦‚ä½•ä½¿ç”¨è¿›è¡Œä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´ï¼Œä½¿ç”¨äº† <code>cudaMalloc</code>ï¼Œ<code>cudaMemcpy</code> å’Œ <code>cudaFree</code> å‡½æ•°ï¼Œå‡½æ•°å½¢å‚å¦‚ä¸‹</p><ul><li><p><code>__host__ cudaError_t cudaMalloc (void** devPtr, size_t size)</code></p><ul><li><code>devPtr</code>: å¼€è¾Ÿæ•°æ®çš„é¦–æŒ‡é’ˆ</li><li><code>size</code>: å¼€è¾Ÿçš„è®¾å¤‡å†…å­˜ç©ºé—´é•¿åº¦</li></ul></li><li><p><code>__host__ cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)</code></p><ul><li><code>dst</code>: ç›®çš„æ•°æ®å†…å­˜é¦–æŒ‡é’ˆ</li><li><code>src</code>: æºæ•°æ®é¦–æŒ‡é’ˆ</li><li><code>count</code>: æ•°æ®é•¿åº¦</li><li><code>kind</code>: æ‹·è´ç±»å‹ï¼Œ<code>cudaMemcpyDeviceToHost</code>: ä»è®¾å¤‡å‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToHost</code>: ä»ä¸»æœºå‘è®¾å¤‡æ‹·è´ | <code>cudaMemcpyHostToHost</code>: ä»ä¸»æœºå‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToDevice</code>: ä»è®¾å¤‡å‘è®¾å¤‡æ‹·è´</li></ul></li><li><p><code>__host__ cudaError_t cudaFree (void* devPtr)</code></p></li><li><code>devPtr</code>: è®¾å¤‡å˜é‡æŒ‡é’ˆ</li></ul><p>ä¸Šè¿°å‡½æ•°çš„è¿”å›å€¼ç±»å‹éƒ½æ˜¯ <code>cudaError_t</code>ï¼Œä»¥æšä¸¾å½¢å¼ä¿å­˜å„ç§é”™è¯¯ç±»å‹</p><p>æ›´å¤šè¿è¡Œæ—¶å‡½æ•°è¯¦è§£è§<a href="https://docs.nvidia.com/cuda/cuda-runtime-api/">å®˜æ–¹æ–‡æ¡£</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> dets[<span class="number">6</span>][<span class="number">4</span>] = &#123;</span><br><span class="line">        &#123;<span class="number">23</span>, <span class="number">34</span>, <span class="number">56</span>, <span class="number">76</span>&#125;,</span><br><span class="line">        &#123;<span class="number">11</span>, <span class="number">23</span>, <span class="number">45</span>, <span class="number">45</span>&#125;,</span><br><span class="line">        &#123;<span class="number">12</span>, <span class="number">22</span>, <span class="number">47</span>, <span class="number">47</span>&#125;,</span><br><span class="line">        &#123;<span class="number">9</span>, <span class="number">45</span>, <span class="number">56</span>, <span class="number">65</span>&#125;,</span><br><span class="line">        &#123;<span class="number">20</span>, <span class="number">37</span>, <span class="number">55</span>, <span class="number">75</span>&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// copy data to gpu</span></span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(dets) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *dev_dets;</span><br><span class="line">    cudaError_t err = cudaSuccess;</span><br><span class="line">    err = <span class="built_in">cudaMalloc</span>((<span class="type">void</span> **)&amp;dev_dets, <span class="built_in">sizeof</span>(dets));</span><br><span class="line">    <span class="keyword">if</span> (err != cudaSuccess) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;cudaMalloc failed!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(dev_dets, dets, <span class="built_in">sizeof</span>(dets), cudaMemcpyHostToDevice);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied data to GPU.\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get back copied cuda data</span></span><br><span class="line">    <span class="type">float</span> host_dets[<span class="built_in">sizeof</span>(dets)/<span class="built_in">sizeof</span>(<span class="type">float</span>)];</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(&amp;host_dets, dev_dets, <span class="built_in">sizeof</span>(dets), cudaMemcpyDeviceToHost);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied from cuda back to host.\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;host_dets size: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(host_dets) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="built_in">sizeof</span>(dets)/<span class="built_in">sizeof</span>(<span class="type">float</span>);i++) &#123;</span><br><span class="line">        std::cout &lt;&lt; host_dets[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">cudaFree</span>(dev_dets);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;done.\n&quot;</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">96</span></span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: <span class="number">96</span></span><br><span class="line"><span class="number">23</span> <span class="number">34</span> <span class="number">56</span> <span class="number">76</span> <span class="number">11</span> <span class="number">23</span> <span class="number">45</span> <span class="number">45</span> <span class="number">12</span> <span class="number">22</span> <span class="number">47</span> <span class="number">47</span> <span class="number">9</span> <span class="number">45</span> <span class="number">56</span> <span class="number">65</span> <span class="number">20</span> <span class="number">37</span> <span class="number">55</span> <span class="number">75</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> </span><br><span class="line">done.</span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç¨‹åºä½¿ç”¨<code>cudaMalloc</code>æ¥ç”³è¯·è®¾å¤‡å†…å­˜ï¼Œä½†äºŒç»´æ•°ç»„ä¸æ¨èè¿™ä¹ˆåšï¼Œåœ¨ kernel è¿ç®—æ—¶è¾ƒé«˜çš„æ€§èƒ½æŸå¤±ï¼ŒCUDA ç»™å‡ºäº†äºŒç»´æ•°ç»„ä¸“ç”¨çš„å†…å­˜ç”³è¯·å‡½æ•°<code>cudaMallocPitch</code>ï¼Œåœ¨è®¾å¤‡é—´å†…å­˜æ‹·è´æ—¶ï¼Œä¹Ÿè¦ä½¿ç”¨<code>cudaMemcpy2D</code>å‡½æ•°ï¼Œå½¢å‚å¦‚ä¸‹</p><ul><li><code>__host__cudaError_t cudaMallocPitch ( void** devPtr, size_t* pitch, size_t width, size_t height )</code><ul><li><code>devPtr</code>: å¼€è¾ŸçŸ©é˜µçš„æ•°æ®çš„é¦–æŒ‡é’ˆ</li><li><code>pitch</code>: åˆ†é…å­˜å‚¨å™¨çš„å®½åº¦</li><li><code>width</code>: äºŒç»´æ•°ç»„åˆ—æ•°</li><li><code>height</code>: äºŒç»´æ•°ç»„è¡Œæ•°</li></ul></li><li><code>__host__ cudaError_t cudaMemcpy2D ( void* dst, size_t dpitch, const void* src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind )</code><ul><li><code>dst</code>: ç›®çš„çŸ©é˜µå†…å­˜é¦–æŒ‡é’ˆ</li><li><code>dpitch</code>:  dstæŒ‡å‘çš„ 2D æ•°ç»„ä¸­çš„å†…å­˜å®½åº¦ï¼Œä»¥å­—èŠ‚ä¸ºå•ä½ï¼Œæ˜¯cudaä¸ºäº†è¯»å–æ–¹ä¾¿ï¼Œå¯¹é½è¿‡çš„å†…å­˜å®½åº¦ï¼Œå¯èƒ½å¤§äºä¸€è¡Œå…ƒç´ å æ®çš„å®é™…å†…å­˜</li><li><code>src</code>: æºçŸ©é˜µå†…å­˜é¦–æŒ‡é’ˆ</li><li><code>spitch</code>: src æŒ‡å‘çš„ 2D æ•°ç»„ä¸­çš„å†…å­˜å®½åº¦</li><li><code>width</code>: srcæŒ‡å‘çš„2Dæ•°ç»„ä¸­ä¸€è¡Œå…ƒç´ å æ®çš„å®é™…å®½åº¦ï¼Œä¸º <code>width*sizeof(type)</code></li><li><code>height</code>: srcæŒ‡å‘çš„2Dæ•°ç»„çš„è¡Œæ•°</li><li><code>kind</code>: æ‹·è´ç±»å‹ï¼Œ<code>cudaMemcpyDeviceToHost</code>: ä»è®¾å¤‡å‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToHost</code>: ä»ä¸»æœºå‘è®¾å¤‡æ‹·è´ | <code>cudaMemcpyHostToHost</code>: ä»ä¸»æœºå‘ä¸»æœºæ‹·è´ | <code>cudaMemcpyDeviceToDevice</code>: ä»è®¾å¤‡å‘è®¾å¤‡æ‹·è´</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> dets[<span class="number">6</span>][<span class="number">4</span>] = &#123;</span><br><span class="line">        &#123;<span class="number">23</span>, <span class="number">34</span>, <span class="number">56</span>, <span class="number">76</span>&#125;,</span><br><span class="line">        &#123;<span class="number">11</span>, <span class="number">23</span>, <span class="number">45</span>, <span class="number">45</span>&#125;,</span><br><span class="line">        &#123;<span class="number">12</span>, <span class="number">22</span>, <span class="number">47</span>, <span class="number">47</span>&#125;,</span><br><span class="line">        &#123;<span class="number">9</span>, <span class="number">45</span>, <span class="number">56</span>, <span class="number">65</span>&#125;,</span><br><span class="line">        &#123;<span class="number">20</span>, <span class="number">37</span>, <span class="number">55</span>, <span class="number">75</span>&#125;,</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="type">size_t</span> width = <span class="number">4</span>;</span><br><span class="line">    <span class="type">size_t</span> height = <span class="number">6</span>;</span><br><span class="line">    <span class="type">size_t</span> pitch;</span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sizeof</span>(dets) &lt;&lt; std::endl;</span><br><span class="line">    <span class="type">float</span> *dev_dets;</span><br><span class="line">    cudaError_t err = cudaSuccess;</span><br><span class="line">    err = <span class="built_in">cudaMallocPitch</span>((<span class="type">void</span> **)&amp;dev_dets, &amp;pitch, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, height);</span><br><span class="line">    <span class="keyword">if</span> (err != cudaSuccess) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;cudaMalloc failed!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// copy data to gpu</span></span><br><span class="line">    <span class="built_in">cudaMemcpy2D</span>(dev_dets, pitch, dets, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, height,cudaMemcpyHostToDevice);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied data to GPU.\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get back copied cuda data</span></span><br><span class="line">    <span class="type">float</span> host_dets[<span class="built_in">sizeof</span>(dets)/<span class="built_in">sizeof</span>(<span class="type">float</span>)];</span><br><span class="line">    <span class="built_in">cudaMemcpy2D</span>(&amp;host_dets, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, dev_dets, pitch, <span class="built_in">sizeof</span>(<span class="type">float</span>)*width, height,cudaMemcpyDeviceToHost);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Copied from cuda back to host.\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;host_dets size: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(host_dets) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;width*height;i++) &#123;</span><br><span class="line">        std::cout &lt;&lt; host_dets[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">cudaFree</span>(dev_dets);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;done.\n&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">96</span></span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: <span class="number">96</span></span><br><span class="line"><span class="number">23</span> <span class="number">34</span> <span class="number">56</span> <span class="number">76</span> <span class="number">11</span> <span class="number">23</span> <span class="number">45</span> <span class="number">45</span> <span class="number">12</span> <span class="number">22</span> <span class="number">47</span> <span class="number">47</span> <span class="number">9</span> <span class="number">45</span> <span class="number">56</span> <span class="number">65</span> <span class="number">20</span> <span class="number">37</span> <span class="number">55</span> <span class="number">75</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> </span><br><span class="line">done.</span><br></pre></td></tr></table></figure><p>è¿™ä¸¤ä¸ªå‡½æ•°åº”è¯¥ä¼šä½¿ kernel çš„è¿è¡Œæ—¶é—´å˜çŸ­ï¼Œå› ä¸º pitch å¯¹é½åå¯å®ç° global å†…å­˜è”åˆè®¿é—®ï¼Œä½†<code>cudaMallocPitch</code>å’Œ<code>cudaMemcpy2D</code>ä¼šå˜æ…¢ï¼Œå› ä¸ºæ¯”ä¸€ç»´çš„æ“ä½œå¤šäº†å¯¹é½çš„è€ƒè™‘</p><h2 id="Kernel-å‡½æ•°"><a href="#Kernel-å‡½æ•°" class="headerlink" title="Kernel å‡½æ•°"></a>Kernel å‡½æ•°</h2><h3 id="kernel-é™å®šè¯"><a href="#kernel-é™å®šè¯" class="headerlink" title="kernel é™å®šè¯"></a>kernel é™å®šè¯</h3><ul><li><code>__device__</code>: åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œåªèƒ½åœ¨è®¾å¤‡ä¸Šè°ƒç”¨ï¼›</li><li><code>__global__</code>: åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œåªèƒ½åœ¨ä¸»æœºä¸Šè°ƒç”¨ï¼›</li><li><code>__host__</code>: åœ¨ä¸»æœºä¸Šæ‰§è¡Œï¼Œåªèƒ½åœ¨ä¸»æœºä¸Šè°ƒç”¨ã€‚</li></ul><p><code>__device__</code>å’Œ<code>__global__</code>ä»£è¡¨å‡½æ•°åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œä¸æ”¯æŒé€’å½’ï¼Œä¸èƒ½åœ¨å‡½æ•°ä½“å†…å£°æ˜é™æ€å˜é‡ï¼Œé™æ€å˜é‡å¯¹åº”äºCPUçš„æ•´ä¸ªç¨‹åºç”Ÿå‘½è¿‡ç¨‹ï¼Œä¸èƒ½æœ‰å¯å˜é•¿å‚æ•°ï¼›</p><p><code>__global__</code>å’Œ<code>__host__</code>ä¸èƒ½ä¸€èµ·ä½¿ç”¨ï¼Œè€Œ<code>__device__</code>å’Œ<code>__host__</code>å¯ä»¥ä¸€èµ·ä½¿ç”¨ï¼Œç¼–è¯‘å™¨ä¼šåœ¨ CPU å’Œ GPU å„å¤åˆ¶ä¸€ä»½å‡½æ•°ã€‚</p><p>ä¸æ·»åŠ é™å®šè¯æ—¶ï¼Œå‡½æ•°é»˜è®¤ä¸º<code>__host__</code>ï¼Œä¹Ÿå°±æ˜¯åœ¨ä¸»æœºä¸Šæ‰§è¡Œã€‚</p><p>æ‰€æœ‰çš„ kernel å‡½æ•°è¿”å›ç±»å‹éƒ½æ˜¯ voidï¼Œä¸” kernel å‡½æ•°éƒ½æ˜¯å¼‚æ­¥æ‰§è¡Œã€‚</p><h3 id="kernel-è°ƒç”¨æ–¹å¼"><a href="#kernel-è°ƒç”¨æ–¹å¼" class="headerlink" title="kernel è°ƒç”¨æ–¹å¼"></a>kernel è°ƒç”¨æ–¹å¼</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_func</span> <span class="params">(param list)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line">kernel_func &lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt; (param list);</span><br></pre></td></tr></table></figure><ul><li><code>&lt;&lt;&lt;Dg, Db, Ns, S&gt;&gt;&gt;</code>: æ˜¯è¿ç®—ç¬¦å†…æ˜¯æ ¸å‡½æ•°çš„æ‰§è¡Œå‚æ•°ï¼Œå‘Šè¯‰ç¼–è¯‘å™¨è¿è¡Œæ—¶å¦‚ä½•å¯åŠ¨æ ¸å‡½æ•°</li><li><code>Dg</code>: grid çš„ç»´åº¦å’Œå°ºå¯¸ï¼Œdim3 ç±»å‹ï¼Œæ„ä¸ºä¸€ä¸ª grid æœ‰å¤šå°‘ä¸ª block</li><li><code>Db</code>: block çš„ç»´åº¦å’Œå°ºå¯¸ï¼Œ dim3 ç±»å‹ï¼Œæ„ä¸ºä¸€ä¸ª block æœ‰å¤šå°‘ä¸ª thread</li><li><code>Ns</code>: ï¼ˆå¯é€‰ï¼‰ç”¨äºè®¾ç½®æ¯ä¸ªblocké™¤äº†é™æ€åˆ†é…çš„ shared Memory ä»¥å¤–ï¼Œæœ€å¤šèƒ½åŠ¨æ€åˆ†é…çš„ shared Memory å¤§å°ï¼Œå•ä½ä¸º byte ä¸éœ€è¦åŠ¨æ€åˆ†é…æ—¶è¯¥å€¼ä¸º0æˆ–çœç•¥ä¸å†™</li><li><code>S</code>: ï¼ˆå¯é€‰ï¼‰ cudastream ç±»å‹çš„å‚æ•°ï¼Œè¡¨ç¤ºè¯¥æ ¸å‡½æ•°å¤„åœ¨å“ªä¸ªæµä¹‹ä¸­</li></ul><p>è¿™é‡Œæˆ‘ä»¬å®ç°ä¸€ä¸‹ç¬¬äºŒç« æœ€åçš„ä¾‹å­ï¼Œä¸‹é¢çš„ç¨‹åºä½¿ç”¨äº†<code>cudaDeviceSynchronize</code>å’Œ<code>cudaDeviceReset</code>å‡½æ•°ï¼Œè§£é‡Šå¦‚ä¸‹</p><ul><li><code>__host__ __device__ cudaDeviceSynchronize</code>: ä½¿è®¾å¤‡é˜»å¡åˆ°å®Œæˆæ‰€æœ‰å‰é¢è¯·æ±‚çš„ä»»åŠ¡ï¼ŒCUDA 11.6 åå·²å¼ƒç”¨</li><li><code>__host__ cudaDeviceReset</code>: æ˜¾å¼é”€æ¯å¹¶æ¸…é™¤å½“å‰è¿›ç¨‹ä¸­ä¸è®¾å¤‡å…³è”çš„æ‰€æœ‰èµ„æºï¼Œèµ„æºä¸èƒ½å†è¢«è®¿é—®ï¼Œå¯èƒ½å¯¼è‡´æœªå®šä¹‰çš„è¡Œä¸º</li></ul><p>ç”±äº CUDA printf çš„è¾“å‡ºå­˜å‚¨åœ¨ç¼“å†²ä¸­ï¼Œåå°åŒæ­¥æœºåˆ¶ä¼šæœ‰å»¶æ—¶ï¼Œéœ€è¦ä½¿ç”¨ä¸Šé¢ä¸¤ä¸ªåŒæ­¥å‡½æ•°ä¸­ä»»æ„ä¸€ä¸ªä½¿ printf å‡½æ•°çš„å†…å®¹ä¸ä¸»æœºåŒæ­¥ï¼Œå³å¯è¾“å‡º</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">printThreadIndex</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx = iy*blockDim.x * gridDim.x + ix;</span><br><span class="line">    <span class="keyword">if</span>(threadIdx.x == <span class="number">3</span> &amp;&amp; threadIdx.y == <span class="number">1</span> &amp;&amp; blockIdx.x == <span class="number">0</span> &amp;&amp; blockIdx.y == <span class="number">1</span>)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;thread_id (%d,%d) block_id (%d,%d) coordinate (%d, %d), global index %2d \n&quot;</span>, threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y, ix, iy, idx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span>, <span class="title">block</span><span class="params">(<span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    printThreadIndex&lt;&lt;&lt;grid, block&gt;&gt;&gt;();</span><br><span class="line">    <span class="comment">// cudaDeviceSynchronize(); </span></span><br><span class="line">    <span class="built_in">cudaDeviceReset</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="built_in">thread_id</span> (<span class="number">3</span>,<span class="number">1</span>) <span class="built_in">block_id</span> (<span class="number">0</span>,<span class="number">1</span>) <span class="built_in">coordinate</span> (<span class="number">3</span>, <span class="number">3</span>), global index <span class="number">27</span></span><br></pre></td></tr></table></figure><blockquote><p>åœ¨è¾“å‡ºæ—¶ä¸èƒ½ä½¿ç”¨ std::cout, std å‘½åç©ºé—´ä¸èƒ½ä½¿ç”¨åˆ° GPU ä¸Š</p></blockquote><h2 id="CUDA-çš„-Thrust-åº“"><a href="#CUDA-çš„-Thrust-åº“" class="headerlink" title="CUDA çš„ Thrust åº“"></a>CUDA çš„ Thrust åº“</h2><p>CUDA çš„ Thrust åº“æ˜¯åŸºäºæ ‡å‡†æ¨¡æ¿åº“ STL çš„ CUDA çš„ C++ æ¨¡æ¿åº“ï¼Œ é€šè¿‡ä¸ CUDA C é…åˆä½¿ç”¨ï¼ŒèŠ‚çœäº†å¤§é‡ä¼˜åŒ–ç®—æ³•çš„æ—¶é—´ï¼Œä¿è¯äº†æ€§èƒ½ä¸å¼€å‘æ•ˆç‡ï¼Œåœ¨ CUDA Toolkit ä¸­åŒ…å« Thrustï¼Œæ— éœ€é¢å¤–å®‰è£…ï¼Œåªéœ€å¯¼å…¥ç›¸åº”å¤´æ–‡ä»¶ï¼Œåœ¨è°ƒç”¨æ—¶ä½¿ç”¨ <code>thrust</code> å‘½åç©ºé—´ï¼Œå¹¶å°½é‡ä¸è¦ä½¿ç”¨ <code>using namespace std;</code> è¯­å¥ï¼Œå› ä¸º thrust åº“å’Œ STL åº“éå¸¸å¤šçš„é‡å</p><h3 id="Vector-å®¹å™¨"><a href="#Vector-å®¹å™¨" class="headerlink" title="Vector å®¹å™¨"></a>Vector å®¹å™¨</h3><p>Thrust ä¸­å®šä¹‰äº†ä¸»æœºç«¯å’Œè®¾å¤‡ç«¯çš„ä¸¤ç§ vectorï¼Œåˆ†åˆ«å®šä¹‰åœ¨ host_vector.h å’Œ device_vector.h ä¸­ï¼Œä¸¾ä¾‹å¦‚ä¸‹</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// H has storage for 4 integers</span></span><br><span class="line">    <span class="function">thrust::host_vector&lt;<span class="type">int</span>&gt; <span class="title">H</span><span class="params">(<span class="number">4</span>)</span></span>;</span><br><span class="line">    <span class="comment">// initialize individual elements</span></span><br><span class="line">    H[<span class="number">0</span>] = <span class="number">14</span>;</span><br><span class="line">    H[<span class="number">1</span>] = <span class="number">20</span>;</span><br><span class="line">    H[<span class="number">2</span>] = <span class="number">38</span>;</span><br><span class="line">    H[<span class="number">3</span>] = <span class="number">46</span>;</span><br><span class="line">    H.<span class="built_in">push_back</span>(<span class="number">52</span>);</span><br><span class="line">    <span class="comment">// H.size() returns the size of vector H</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;H has size &quot;</span> &lt;&lt; H.<span class="built_in">size</span>() &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// print contents of H</span></span><br><span class="line">    <span class="comment">// for(int i = 0; i &lt; H.size(); i++)</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i:H)</span><br><span class="line">        std::cout &lt;&lt; i &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// resize H</span></span><br><span class="line">    H.<span class="built_in">resize</span>(<span class="number">2</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;H now has size &quot;</span> &lt;&lt; H.<span class="built_in">size</span>() &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// Copy host_vector H to device_vector D</span></span><br><span class="line">    thrust::device_vector&lt;<span class="type">int</span>&gt; D = H; </span><br><span class="line">    <span class="comment">// elements of D can be modified</span></span><br><span class="line">    D[<span class="number">0</span>] = <span class="number">99</span>;</span><br><span class="line">    D[<span class="number">1</span>] = <span class="number">88</span>;</span><br><span class="line">    <span class="comment">// print contents of D</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i:D)</span><br><span class="line">        std::cout &lt;&lt; i &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// H and D are automatically deleted when the function returns</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line">H has size <span class="number">5</span></span><br><span class="line"><span class="number">14</span></span><br><span class="line"><span class="number">20</span></span><br><span class="line"><span class="number">38</span></span><br><span class="line"><span class="number">46</span></span><br><span class="line"><span class="number">52</span></span><br><span class="line">H now has size <span class="number">2</span></span><br><span class="line"><span class="number">99</span></span><br><span class="line"><span class="number">88</span></span><br></pre></td></tr></table></figure><p>Thrust å…è®¸ä½¿ç”¨ <code>=</code> è¿ç®—ç¬¦å¯¹ <code>host_vector</code> å’Œ <code>device_vector</code> çš„ç›¸äº’æ‹·è´ï¼Œä¹Ÿå…è®¸ä½¿ç”¨ <code>[i]</code> ä¸‹æ ‡è®¿é—® <code>device_vector</code> çš„å„ä¸ªå…ƒç´ ï¼Œä½†æ˜¯ç”¨è¿™ç§æ–¹æ³•è®¿é—®æ¯ä¸€æ¬¡éƒ½éœ€è¦è°ƒç”¨ <code>cudaMemcpy</code>ï¼Œæ€§èƒ½æŸå¤±è¾ƒå¤§ï¼Œåº”è°¨æ…ä½¿ç”¨ã€‚ ä¸‹é¢æˆ‘ä»¬å°†ä»‹ç»ä¸€äº›æ›´æœ‰æ•ˆçš„æŠ€æœ¯</p><p>ä¸‹é¢å±•ç¤º Thrust æä¾›çš„å‡ ç§å¯¹ vector æ“ä½œçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬åˆå§‹åŒ–ï¼Œèµ‹å€¼ï¼Œ<code>iterator</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/copy.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/fill.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/sequence.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// initialize all ten integers of a device_vector to 1</span></span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">D</span><span class="params">(<span class="number">10</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="comment">// set the first seven elements of a vector to 9</span></span><br><span class="line">    thrust::<span class="built_in">fill</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">begin</span>() + <span class="number">7</span>, <span class="number">9</span>);</span><br><span class="line">    <span class="comment">// initialize a host_vector with the first five elements of D</span></span><br><span class="line">    <span class="function">thrust::host_vector&lt;<span class="type">int</span>&gt; <span class="title">H</span><span class="params">(D.begin(), D.begin() + <span class="number">5</span>)</span></span>;</span><br><span class="line">    <span class="comment">// set the elements of H to 0, 1, 2, 3, ...</span></span><br><span class="line">    thrust::<span class="built_in">sequence</span>(H.<span class="built_in">begin</span>(), H.<span class="built_in">end</span>());</span><br><span class="line">    <span class="comment">// copy all of H back to the beginning of D</span></span><br><span class="line">    thrust::<span class="built_in">copy</span>(H.<span class="built_in">begin</span>(), H.<span class="built_in">end</span>(), D.<span class="built_in">begin</span>());</span><br><span class="line">    <span class="comment">// print D</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i:D)dd</span><br><span class="line">        std::cout &lt;&lt; i &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">9</span> <span class="number">9</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç¨‹åºä½¿ç”¨äº†<code>thrust::fill</code>ï¼Œå½“å®ƒå¯¹ <code>device_vector iterator</code> æ“ä½œæ—¶ï¼Œä¼šåœ¨ç¼–è¯‘æ—¶æ£€æŸ¥ <code>iterator</code> åœ¨ä¸»æœºä¸Šè¿˜æ˜¯åœ¨è®¾å¤‡ä¸Šï¼Œè¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸ºé™æ€è°ƒåº¦ï¼Œæ„å‘³ç€è°ƒåº¦è¿‡ç¨‹æ²¡æœ‰è¿è¡Œæ—¶å¼€é”€</p><h3 id="æŒ‡é’ˆ"><a href="#æŒ‡é’ˆ" class="headerlink" title="æŒ‡é’ˆ"></a>æŒ‡é’ˆ</h3><p>thrust ä¸­å®šä¹‰äº† <code>device_ptr</code> æ•°æ®ç±»å‹ï¼Œå½“ä¼ å…¥å‡½æ•°çš„æŒ‡é’ˆæŒ‡å‘è®¾å¤‡ç«¯å†…å­˜æ—¶ï¼Œéœ€è¦ç”¨<code>device_ptr</code>è¿›è¡Œå°è£…</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> N = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// raw pointer to device memory</span></span><br><span class="line"><span class="type">int</span> * raw_ptr;</span><br><span class="line"><span class="built_in">cudaMalloc</span>((<span class="type">void</span> **) &amp;raw_ptr, N * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"><span class="comment">// wrap raw pointer with a device_ptr </span></span><br><span class="line"><span class="function">thrust::device_ptr&lt;<span class="type">int</span>&gt; <span class="title">dev_ptr</span><span class="params">(raw_ptr)</span></span>;</span><br><span class="line"><span class="comment">// use device_ptr in thrust algorithms</span></span><br><span class="line">thrust::<span class="built_in">fill</span>(dev_ptr, dev_ptr + N, (<span class="type">int</span>) <span class="number">0</span>);</span><br></pre></td></tr></table></figure><h3 id="æ•°å€¼æ“ä½œ"><a href="#æ•°å€¼æ“ä½œ" class="headerlink" title="æ•°å€¼æ“ä½œ"></a>æ•°å€¼æ“ä½œ</h3><h4 id="Transformations"><a href="#Transformations" class="headerlink" title="Transformations"></a>Transformations</h4><p>Transformations æ˜¯å¯¹ä¸€ä¸ªè¾“å…¥èŒƒå›´ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ åº”ç”¨æ“ä½œï¼Œå°†ç»“æœå­˜å‚¨åœ¨ç»™å®šèŒƒå›´ä¸­çš„æ–¹æ³•ï¼Œä¸Šé¢ç¨‹åºä¸­å·²ç» <code>thrust::fill</code> å°±æ˜¯ä¸€ä¸ª Transformationsï¼Œå®ƒå°†èŒƒå›´å†…çš„æ‰€æœ‰å…ƒç´ è®¾ç½®ä¸ºæŒ‡å®šå€¼ã€‚ä¸‹é¢çš„ç¨‹åºç”¨åˆ°äº† <code>thrust::sequence</code>ï¼Œ<code>thrust::replace</code>ï¼Œ<code>thrust::transform</code>ï¼Œæ›´å¤š Transformations è¯·æŸ¥çœ‹<a href="https://thrust.github.io/doc/group__transformations.html">å®˜æ–¹æ–‡æ¡£</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/transform.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/sequence.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/copy.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/fill.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/replace.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/functional.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// allocate three device_vectors with 10 elements</span></span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">X</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">Y</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">int</span>&gt; <span class="title">Z</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="comment">// initialize X to 0,1,2,3, ....</span></span><br><span class="line">    thrust::<span class="built_in">sequence</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>());</span><br><span class="line">    <span class="comment">// compute Y = -X</span></span><br><span class="line">    thrust::<span class="built_in">transform</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>(), Y.<span class="built_in">begin</span>(), thrust::<span class="built_in">negate</span>&lt;<span class="type">int</span>&gt;());</span><br><span class="line">    <span class="comment">// fill Z with twos</span></span><br><span class="line">    thrust::<span class="built_in">fill</span>(Z.<span class="built_in">begin</span>(), Z.<span class="built_in">end</span>(), <span class="number">2</span>);</span><br><span class="line">    <span class="comment">// compute Y = X mod 2</span></span><br><span class="line">    thrust::<span class="built_in">transform</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>(), Z.<span class="built_in">begin</span>(), Y.<span class="built_in">begin</span>(), thrust::<span class="built_in">modulus</span>&lt;<span class="type">int</span>&gt;());</span><br><span class="line">    <span class="comment">// replace all the ones in Y with tens</span></span><br><span class="line">    thrust::<span class="built_in">replace</span>(Y.<span class="built_in">begin</span>(), Y.<span class="built_in">end</span>(), <span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">    <span class="comment">// print Y</span></span><br><span class="line">    thrust::<span class="built_in">copy</span>(Y.<span class="built_in">begin</span>(), Y.<span class="built_in">end</span>(), std::<span class="built_in">ostream_iterator</span>&lt;<span class="type">int</span>&gt;(std::cout, <span class="string">&quot; &quot;</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> <span class="number">0</span> <span class="number">10</span> </span><br></pre></td></tr></table></figure><h4 id="SAXPY"><a href="#SAXPY" class="headerlink" title="SAXPY"></a>SAXPY</h4><p>SAXPYï¼ˆScalar Alpha X Plus Yï¼‰æ˜¯ä¸€ä¸ªåœ¨ BLASï¼ˆBasic Linear Algebra Subprogramsï¼‰å‡½æ•°åº“æä¾›ä¸­çš„å‡½æ•°ï¼Œå¹¶ä¸”æ˜¯ä¸€ä¸ªå¹¶è¡Œå‘é‡å¤„ç†æœºï¼ˆvector processorï¼‰ä¸­å¸¸ç”¨çš„è®¡ç®—æ“ä½œæŒ‡ä»¤ï¼Œä¸ºæ ‡é‡ä¹˜æ³•å’Œå‘é‡åŠ æ³•çš„ç»„åˆï¼Œå¦‚ $y = a*x + y$ï¼Œå…¶ä¸­ $x$ å’Œ $y$ ä¸ºå‘é‡ï¼Œ$a$ ä¸ºæ ‡é‡å¸¸æ•°ã€‚ä¸‹é¢çš„ç¨‹åºå®šä¹‰äº†ä¸€ä¸ª functor å®ç° SAXPY</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">saxpy_functor</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> a;</span><br><span class="line">    <span class="built_in">saxpy_functor</span>(<span class="type">float</span> _a) : <span class="built_in">a</span>(_a) &#123;&#125;</span><br><span class="line">    <span class="function">__host__ __device__</span></span><br><span class="line"><span class="function">        <span class="type">float</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> <span class="type">float</span>&amp; x, <span class="type">const</span> <span class="type">float</span>&amp; y)</span> <span class="type">const</span> </span>&#123; </span><br><span class="line">            <span class="keyword">return</span> a * x + y;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">saxpy</span><span class="params">(<span class="type">float</span> A, thrust::device_vector&lt;<span class="type">float</span>&gt;&amp; X, thrust::device_vector&lt;<span class="type">float</span>&gt;&amp; Y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// y = a * x + y</span></span><br><span class="line">    thrust::<span class="built_in">transform</span>(X.<span class="built_in">begin</span>(), X.<span class="built_in">end</span>(), Y.<span class="built_in">begin</span>(), Y.<span class="built_in">begin</span>(), <span class="built_in">saxpy_functor</span>(A));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Reductions"><a href="#Reductions" class="headerlink" title="Reductions"></a>Reductions</h4><p>ä½¿ç”¨ <code>thrust::reduce</code> å‡½æ•°å¯¹ä¸€ç»„æ•°æ®è¿›è¡Œæ“ä½œï¼Œè¿”å›å€¼ä¸ºä¸€ä¸ªå…·ä½“æ•°å€¼ï¼Œä¸‹ä¾‹å°±æ˜¯å¯¹ä¸€ç»„æ•°æ®æ±‚å’Œ</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum = thrust::<span class="built_in">reduce</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">end</span>(), (<span class="type">int</span>) <span class="number">0</span>, thrust::<span class="built_in">plus</span>&lt;<span class="type">int</span>&gt;());</span><br></pre></td></tr></table></figure><p>ä¸Šåˆ—ä¸­<code>(int) 0</code>ä¸ºè®¡ç®—çš„åˆå§‹å€¼ï¼Œ<code>thrust::plus&lt;int&gt;()</code>ä¸ºæ“ä½œç¬¦ï¼Œå½“æ²¡æœ‰å®šä¹‰åˆå§‹å€¼å’Œæ“ä½œç¬¦æ—¶ï¼Œå®ƒä»¬æ˜¯é»˜è®¤å€¼ï¼Œå› æ­¤ä¸‹é¢çš„ä¸¤æ¡è¯­å¥å’Œä¸Šé¢çš„ç­‰ä»·ï¼Œæ›´å¤šæ“ä½œç¬¦è¯·æŸ¥çœ‹<a href="https://nvidia.github.io/thrust/api/groups/group__reductions.html">å®˜æ–¹æ–‡æ¡£</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum = thrust::<span class="built_in">reduce</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">end</span>(), (<span class="type">int</span>) <span class="number">0</span>);</span><br><span class="line"><span class="type">int</span> sum = thrust::<span class="built_in">reduce</span>(D.<span class="built_in">begin</span>(), D.<span class="built_in">end</span>());</span><br></pre></td></tr></table></figure><p><code>thrust::transform_reduce</code>å…è®¸æ¥å—å¤šä¸ªæ“ä½œç¬¦æ¥å¯¹ä¸€ç»„æ•°æ®æ±‚å€¼</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/transform_reduce.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/functional.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/device_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/host_vector.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// square&lt;T&gt; computes the square of a number f(x) -&gt; x*x</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">square</span> &#123;</span><br><span class="line">    <span class="function">__host__ __device__</span></span><br><span class="line"><span class="function">        T <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> T&amp; x)</span> <span class="type">const</span> </span>&#123; </span><br><span class="line">            <span class="keyword">return</span> x * x;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// initialize host array</span></span><br><span class="line">    <span class="type">float</span> x[<span class="number">4</span>] = &#123;<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>&#125;;</span><br><span class="line">    <span class="comment">// transfer to device</span></span><br><span class="line">    <span class="function">thrust::device_vector&lt;<span class="type">float</span>&gt; <span class="title">d_x</span><span class="params">(x, x + <span class="number">4</span>)</span></span>;</span><br><span class="line">    <span class="comment">// setup arguments</span></span><br><span class="line">    square&lt;<span class="type">float</span>&gt; unary_op;</span><br><span class="line">    thrust::plus&lt;<span class="type">float</span>&gt; binary_op;</span><br><span class="line">    <span class="type">float</span> init = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// compute norm</span></span><br><span class="line">    <span class="type">float</span> norm = std::<span class="built_in">sqrt</span>( thrust::<span class="built_in">transform_reduce</span>(d_x.<span class="built_in">begin</span>(), d_x.<span class="built_in">end</span>(), unary_op, init, binary_op));</span><br><span class="line">    std::cout &lt;&lt; norm &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line"><span class="number">5.47723</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„ç¨‹åºå¯¹ä¸€ç»„æ•°æ®è®¡ç®—å¹³æ–¹å’Œå†å¼€æ–¹ï¼Œè¿™ç§å†™æ³•ä¼šå¤§å¤§ä¼˜åŒ–æ€§èƒ½ã€‚</p><h4 id="Sorting"><a href="#Sorting" class="headerlink" title="Sorting"></a>Sorting</h4><p>å¯¹æ•°æ®è¿›è¡Œæ’åºï¼Œå¾ˆå¸¸ç”¨çš„æ’åºåŠŸèƒ½ï¼Œä¸¾ä¾‹å¦‚ä¸‹</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/sort.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/functional.h&gt;</span></span></span><br><span class="line">...</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">6</span>;</span><br><span class="line"><span class="type">int</span> A[N] = &#123;<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">7</span>&#125;;</span><br><span class="line">thrust::<span class="built_in">sort</span>(A, A + N);</span><br><span class="line"><span class="comment">// A is now &#123;1, 2, 4, 5, 7, 8&#125;</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">6</span>;</span><br><span class="line"><span class="type">int</span>    keys[N] = &#123;  <span class="number">1</span>,   <span class="number">4</span>,   <span class="number">2</span>,   <span class="number">8</span>,   <span class="number">5</span>,   <span class="number">7</span>&#125;;</span><br><span class="line"><span class="type">char</span> values[N] = &#123;<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>&#125;;</span><br><span class="line">thrust::<span class="built_in">sort_by_key</span>(keys, keys + N, values);</span><br><span class="line"><span class="comment">// keys is now   &#123;  1,   2,   4,   5,   7,   8&#125;</span></span><br><span class="line"><span class="comment">// values is now &#123;&#x27;a&#x27;, &#x27;c&#x27;, &#x27;b&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;d&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">6</span>;</span><br><span class="line"><span class="type">int</span> A[N] = &#123;<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">7</span>&#125;;</span><br><span class="line">thrust::<span class="built_in">stable_sort</span>(A, A + N, thrust::<span class="built_in">greater</span>&lt;<span class="type">int</span>&gt;());</span><br><span class="line"><span class="comment">// A is now &#123;8, 7, 5, 4, 2, 1&#125;</span></span><br></pre></td></tr></table></figure><p>ä¸Šä¾‹ä¸­çš„ <code>thrust::stable_sort</code>æ¥å—ç”¨æˆ·è‡ªå®šä¹‰æ¯”è¾ƒè¿ç®—ç¬¦</p><h4 id="max-element-min-element"><a href="#max-element-min-element" class="headerlink" title="max_element(min_element)"></a>max_element(min_element)</h4><p>æ±‚æœ€å¤§ï¼ˆå°ï¼‰å€¼</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/extrema.h&gt;</span></span></span><br><span class="line">...</span><br><span class="line">thrust::device_vector&lt;type&gt;::iterator iter = thrust::<span class="built_in">max_element</span>(dvec.<span class="built_in">begin</span>()ï¼Œdvec.<span class="built_in">end</span>());</span><br><span class="line"><span class="type">int</span> position = iter - dvec.<span class="built_in">begin</span>();</span><br><span class="line">type max_val = *iter;</span><br></pre></td></tr></table></figure><p>å…¶è¿”å›å€¼æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œéœ€è¦è·å–æœ€å¤§ï¼ˆå°ï¼‰å€¼æ‰€åœ¨ä½ç½®ï¼Œå†å¾—åˆ°ç»“æœ</p><h4 id="unique"><a href="#unique" class="headerlink" title="unique"></a>unique</h4><p>å°†ä¸€ç»„æ•°æ®ä¸­æ»¡è¶³æ¡ä»¶çš„æ•°æ®ç­›é€‰å‡ºæ¥ï¼Œå¯è‡ªå®šä¹‰ç­›é€‰æ¡ä»¶</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thrust/unique.h&gt;</span></span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_same</span> &#123;</span><br><span class="line"><span class="function">__host__ __device__</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> float3 &amp;p1, <span class="type">const</span> float3 &amp;p2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> (p1.x==p2.x) &amp;&amp; (p1.y==p2.y) &amp;&amp; (p1.z==p2.z);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">thrust::<span class="built_in">unique</span>(p.<span class="built_in">begin</span>(), p.<span class="built_in">end</span>(),<span class="built_in">is_same</span>()),p.<span class="built_in">end</span>();</span><br><span class="line">p.<span class="built_in">erase</span>(thrust::<span class="built_in">unique</span>(p.<span class="built_in">begin</span>(), p.<span class="built_in">end</span>(),<span class="built_in">is_sam</span>()),p.<span class="built_in">end</span>());</span><br></pre></td></tr></table></figure><p>unique å‡½æ•°çš„åŠŸèƒ½åªæ˜¯å°†æ»¡è¶³æ¡ä»¶çš„æ•°æ®ç­›é€‰å‡ºæ¥ï¼Œæ— æ³•ç›´æ¥åˆ é™¤ï¼Œéœ€è¦ç»“åˆ vector çš„ erase å‡½æ•°è¿›è¡Œåˆ é™¤</p><h2 id="å»ºç«‹-CUDA-çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—"><a href="#å»ºç«‹-CUDA-çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—" class="headerlink" title="å»ºç«‹ CUDA çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—"></a>å»ºç«‹ CUDA çš„å¹¶è¡Œçº¿ç¨‹è®¡ç®—</h2><p>ä¸‹é¢çš„ç¨‹åºä¸ºå¤§å®¶æ¼”ç¤ºä»¥ç»“æ„ä½“ç±»å‹å­˜å‚¨çš„çŸ©é˜µè®¡ç®—ï¼Œåç»­ç« èŠ‚ä¼šæ•™å¤§å®¶ä½¿ç”¨ cuBLAS åº“è¿›è¡Œå¹¶è¡Œè®¡ç®—</p><h3 id="çŸ©é˜µåŠ æ³•"><a href="#çŸ©é˜µåŠ æ³•" class="headerlink" title="çŸ©é˜µåŠ æ³•"></a>çŸ©é˜µåŠ æ³•</h3><p>ä¸‹é¢çš„ç¨‹åºè¿›è¡Œäº† $C = A + B$ çŸ©é˜µåŠ æ³•è¿ç®—ï¼Œä¸‹é¢çš„ç¨‹åºä¸­ä½¿ç”¨äº†<code>cudaMallocManaged</code>å‡½æ•°ï¼Œç®€å•æ¥è¯´ï¼Œå°±æ˜¯ç»“åˆäº†ä¹‹å‰è®²åˆ°çš„<code>cudaMalloc</code>å’Œ<code>cudaMemcpy</code>ç­‰å†…å­˜è¿ç§»æ‹·è´çš„æ“ä½œï¼Œè‡ªåŠ¨å†…å­˜ç®¡ç†ï¼Œæ–¹ä¾¿ä»£ç ç¼–å†™ï¼Œå¼Šç«¯æ˜¯åœ¨ kernel æ‰§è¡Œæ—¶ä¼šé™ä½ kernel çš„æ‰§è¡Œæ•ˆç‡ï¼Œåœ¨åç»­ç« èŠ‚ï¼Œæˆ‘ä»¬ä¼šè¯¦ç»†è®²è§£æœ‰å…³ CUDA çš„å†…å­˜ç®¡ç†</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Matrix</span> &#123;</span><br><span class="line">    <span class="type">int</span> w;</span><br><span class="line">    <span class="type">int</span> h;</span><br><span class="line">    <span class="type">float</span> *v;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">float</span> <span class="title">getValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> A-&gt;v[row * A-&gt;w + col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">setValue</span><span class="params">(Matrix *A, <span class="type">int</span> row, <span class="type">int</span> col, <span class="type">float</span> v)</span> </span>&#123;</span><br><span class="line">        A-&gt;v[row * A-&gt;w + col] = v;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatrixAdd</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, <span class="built_in">getValue</span>(A, row, col) + <span class="built_in">getValue</span>(B, row, col));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    Matrix *A, *B, *C;</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="type">int</span> nBytes = w * h * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C-&gt;v, nBytes);</span><br><span class="line"></span><br><span class="line">    A-&gt;h = h;</span><br><span class="line">    A-&gt;w = w;</span><br><span class="line">    B-&gt;h = h;</span><br><span class="line">    B-&gt;w = w;</span><br><span class="line">    C-&gt;h = h;</span><br><span class="line">    C-&gt;w = w;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; w * h; ++i) &#123;</span><br><span class="line">        A-&gt;v[i] = <span class="number">1.0</span>;</span><br><span class="line">        B-&gt;v[i] = <span class="number">2.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">gridSize</span><span class="params">((w + blockSize.x - <span class="number">1</span>) / blockSize.x, (h + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line">    MatrixAdd &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A, B, C);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="çŸ©é˜µä¹˜æ³•"><a href="#çŸ©é˜µä¹˜æ³•" class="headerlink" title="çŸ©é˜µä¹˜æ³•"></a>çŸ©é˜µä¹˜æ³•</h3><p>ä¸‹é¢çš„ç¨‹åºè¿›è¡Œäº† $C = A * B$ çŸ©é˜µä¹˜æ³•è¿ç®—</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatrixMul</span><span class="params">(Matrix *A, Matrix *B, Matrix *C)</span> </span>&#123;</span><br><span class="line">        <span class="type">float</span> k = <span class="number">0.0</span>;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;A-&gt;w; i++)</span><br><span class="line">                k += <span class="built_in">getValue</span>(A, row, i) * <span class="built_in">getValue</span>(B, i, col);</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, k);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">    MatrixMul &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A, B, C);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶"><a href="#ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶" class="headerlink" title="ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶"></a>ä¸ºè¿è¡Œç¨‹åºè®¡æ—¶</h2><h3 id="nvprof"><a href="#nvprof" class="headerlink" title="nvprof"></a>nvprof</h3><p>nvprof æ˜¯è¿‡å»æ¯”è¾ƒå¸¸ç”¨çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œä½†åœ¨ç»ˆç«¯ç›´æ¥è¾“å…¥<code>nvprof ./*.o</code>ä¼šå¾—åˆ°ä»¥ä¸‹ Warning</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">======== Warning: nvprof is not supported on devices with compute capability 8.0 and higher.</span><br><span class="line">                  Use NVIDIA Nsight Systems for GPU tracing and CPU sampling and NVIDIA Nsight Compute for GPU profiling.</span><br><span class="line">                  Refer https://developer.nvidia.com/tools-overview for more details.</span><br></pre></td></tr></table></figure><p>ç›®å‰ä¸»æµçš„ CUDA é©±åŠ¨ä¸å†æ”¯æŒ<code>nvprof</code>å‘½ä»¤ï¼Œä½†æˆ‘ä»¬ä»å¯ä»¥åœ¨ NVIDIA Nsight Systems ä¸­ä½¿ç”¨ï¼Œåœ¨ç»ˆç«¯è¾“å…¥ <code>nsys nvprof ./*.o</code>å°±å¯ä»¥çœ‹åˆ°CUDA ç¨‹åºæ‰§è¡Œçš„å…·ä½“å†…å®¹</p><p>è¿™é‡Œæˆ‘ä»¬ä»¥ä¸»æœºä¸è®¾å¤‡çš„æ•°æ®æ‹·è´çš„ä¸¤ä¸ªç¨‹åºä¸ºä¾‹</p><p>ä½¿ç”¨<code>cudaMalloc</code>å‡½æ•°çš„ç¨‹åº</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">WARNING: 1d.o and any of its children processes will be profiled.</span><br><span class="line"></span><br><span class="line">96</span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: 96</span><br><span class="line">23 34 56 76 11 23 45 45 12 22 47 47 9 45 56 65 20 37 55 75 0 0 0 0 </span><br><span class="line">done.</span><br><span class="line">Generating &#x27;/tmp/nsys-report-01f4.qdstrm&#x27;</span><br><span class="line">[1/7] [========================100%] report5.nsys-rep</span><br><span class="line">[2/7] [========================100%] report5.sqlite</span><br><span class="line">[3/7] Executing &#x27;nvtxsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report5.sqlite does not contain NV Tools Extension (NVTX) data.</span><br><span class="line">[4/7] Executing &#x27;cudaapisum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)     Name   </span><br><span class="line"> --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ----------</span><br><span class="line">     99.9        137542088          1  137542088.0  137542088.0  137542088  137542088          0.0  cudaMalloc</span><br><span class="line">      0.1           163239          1     163239.0     163239.0     163239     163239          0.0  cudaFree  </span><br><span class="line">      0.0            36460          2      18230.0      18230.0      18070      18390        226.3  cudaMemcpy</span><br><span class="line"></span><br><span class="line">[5/7] Executing &#x27;gpukernsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report5.sqlite does not contain CUDA kernel data.</span><br><span class="line">[6/7] Executing &#x27;gpumemtimesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     </span><br><span class="line"> --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">     51.6             1504      1    1504.0    1504.0      1504      1504          0.0  [CUDA memcpy HtoD]</span><br><span class="line">     48.4             1408      1    1408.0    1408.0      1408      1408          0.0  [CUDA memcpy DtoH]</span><br><span class="line"></span><br><span class="line">[7/7] Executing &#x27;gpumemsizesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     </span><br><span class="line"> ----------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoH]</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy HtoD]</span><br><span class="line"></span><br><span class="line">Generated:</span><br><span class="line">    /root/report5.nsys-rep</span><br><span class="line">    /root/report5.sqlite</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨<code>cudaMallocPitch</code>å‡½æ•°çš„ç¨‹åº</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">WARNING: 2d.o and any of its children processes will be profiled.</span><br><span class="line"></span><br><span class="line">96</span><br><span class="line">Copied data to GPU.</span><br><span class="line">Copied from cuda back to host.</span><br><span class="line">host_dets size: 96</span><br><span class="line">23 34 56 76 11 23 45 45 12 22 47 47 9 45 56 65 20 37 55 75 0 0 0 0 </span><br><span class="line">done.</span><br><span class="line">Generating &#x27;/tmp/nsys-report-6614.qdstrm&#x27;</span><br><span class="line">[1/7] [========================100%] report6.nsys-rep</span><br><span class="line">[2/7] [========================100%] report6.sqlite</span><br><span class="line">[3/7] Executing &#x27;nvtxsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report6.sqlite does not contain NV Tools Extension (NVTX) data.</span><br><span class="line">[4/7] Executing &#x27;cudaapisum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)       Name      </span><br><span class="line"> --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ---------------</span><br><span class="line">    100.0        745692893          1  745692893.0  745692893.0  745692893  745692893          0.0  cudaMallocPitch</span><br><span class="line">      0.0           161820          1     161820.0     161820.0     161820     161820          0.0  cudaFree       </span><br><span class="line">      0.0            39090          2      19545.0      19545.0      16590      22500       4179.0  cudaMemcpy2D   </span><br><span class="line"></span><br><span class="line">[5/7] Executing &#x27;gpukernsum&#x27; stats report</span><br><span class="line">SKIPPED: /root/report6.sqlite does not contain CUDA kernel data.</span><br><span class="line">[6/7] Executing &#x27;gpumemtimesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     </span><br><span class="line"> --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">     64.8             2880      1    2880.0    2880.0      2880      2880          0.0  [CUDA memcpy HtoD]</span><br><span class="line">     35.2             1567      1    1567.0    1567.0      1567      1567          0.0  [CUDA memcpy DtoH]</span><br><span class="line"></span><br><span class="line">[7/7] Executing &#x27;gpumemsizesum&#x27; stats report</span><br><span class="line"></span><br><span class="line"> Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     </span><br><span class="line"> ----------  -----  --------  --------  --------  --------  -----------  ------------------</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoH]</span><br><span class="line">      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy HtoD]</span><br><span class="line"></span><br><span class="line">Generated:</span><br><span class="line">    /root/report6.nsys-rep</span><br><span class="line">    /root/report6.sqlite</span><br></pre></td></tr></table></figure><p>è¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°<code>Total Time</code>ä¸­<code>cudaMallocPitch</code>å‡½æ•°ç”¨æ—¶å‡ ä¹æ˜¯<code>cudaMalloc</code>çš„ 5 å€ï¼Œæ›´åŠ è‚¯å®šäº†æˆ‘ä»¬çš„è¯´æ³•ï¼Œ<code>cudaMallocPitch</code>å’Œ<code>cudaMemcpy2D</code>éœ€è¦é¢å¤–å¯¹äºŒç»´æ•°æ®è¿›è¡Œå¯¹é½æ“ä½œ</p><h3 id="cudaEvent-è®¡æ—¶å‡½æ•°"><a href="#cudaEvent-è®¡æ—¶å‡½æ•°" class="headerlink" title="cudaEvent è®¡æ—¶å‡½æ•°"></a>cudaEvent è®¡æ—¶å‡½æ•°</h3><p>ä»¥å‰é¢çš„çŸ©é˜µä¹˜æ³•ä¸ºä¾‹ï¼Œåˆ†åˆ«è®¡ç®— CUDA å¼€è¾Ÿå†…å­˜æ—¶é—´å’ŒçŸ©é˜µä¹˜æ³•è¿ç®—æ—¶é—´</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> w = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    <span class="type">int</span> h = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line">    Matrix *A, *B, *C;</span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="type">float</span> elapsedTime = <span class="number">0.0</span>;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C, <span class="built_in">sizeof</span>(Matrix));</span><br><span class="line">    <span class="type">int</span> nBytes = w * h * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;A-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;B-&gt;v, nBytes);</span><br><span class="line">    <span class="built_in">cudaMallocManaged</span>((<span class="type">void</span>**)&amp;C-&gt;v, nBytes);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;cudaMalloc cost: &quot;</span> &lt;&lt; elapsedTime &lt;&lt; <span class="string">&quot;s&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    </span><br><span class="line">    A-&gt;h = h;</span><br><span class="line">    A-&gt;w = w;</span><br><span class="line">    B-&gt;h = h;</span><br><span class="line">    B-&gt;w = w;</span><br><span class="line">    C-&gt;h = h;</span><br><span class="line">    C-&gt;w = w;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; w * h; ++i) &#123;</span><br><span class="line">        A-&gt;v[i] = <span class="number">1.0</span>;</span><br><span class="line">        B-&gt;v[i] = <span class="number">2.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">blockSize</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">gridSize</span><span class="params">((w + blockSize.x - <span class="number">1</span>) / blockSize.x, (h + blockSize.y - <span class="number">1</span>) / blockSize.y)</span></span>;</span><br><span class="line"></span><br><span class="line">    elapsedTime = <span class="number">0.0</span>;</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    MatrixMul &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(A, B, C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Matrix multiplication cost: &quot;</span> &lt;&lt; elapsedTime &lt;&lt; <span class="string">&quot;s&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(stop);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¾“å‡ºä¸º</span></span><br><span class="line">cudaMalloc cost: <span class="number">0.161696</span>s</span><br><span class="line">Matrix multiplication cost: <span class="number">0</span>s</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: CUDAæ¨¡å‹æ¦‚è¿°</title>
      <link href="/p/e07c9171/"/>
      <url>/p/e07c9171/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è®¨è®º GPU çš„å¹¶è¡Œè®¡ç®—æ˜¯å¦‚ä½•åœ¨ç¡¬ä»¶ä¸Šå®ç°çš„ï¼ŒCUDA ä¸­çš„æ¨¡å—ç†è§£ä»¥åŠ CPUå’Œ GPU ä¹‹é—´çš„äº¤äº’ï¼ŒæŒ‡ä»¤çš„åŒæ­¥ã€‚</p><span id="more"></span><h2 id="GPU-æ¶æ„ä¸å¼‚æ„å¹¶è¡Œè®¡ç®—"><a href="#GPU-æ¶æ„ä¸å¼‚æ„å¹¶è¡Œè®¡ç®—" class="headerlink" title="GPU æ¶æ„ä¸å¼‚æ„å¹¶è¡Œè®¡ç®—"></a>GPU æ¶æ„ä¸å¼‚æ„å¹¶è¡Œè®¡ç®—</h2><h3 id="ä»€ä¹ˆæ˜¯å¼‚æ„å¹¶è¡Œè®¡ç®—"><a href="#ä»€ä¹ˆæ˜¯å¼‚æ„å¹¶è¡Œè®¡ç®—" class="headerlink" title="ä»€ä¹ˆæ˜¯å¼‚æ„å¹¶è¡Œè®¡ç®—"></a>ä»€ä¹ˆæ˜¯å¼‚æ„å¹¶è¡Œè®¡ç®—</h3><p>æœ€åˆçš„è®¡ç®—æœºåªåŒ…å«ä¸­å¤®å¤„ç†å™¨ï¼Œä¸ºäº†å¤„ç†è¶Šæ¥è¶Šå¤æ‚çš„å›¾å½¢è®¡ç®—ï¼ŒGPU è¥è¿è€Œç”Ÿï¼Œå› å…¶æ•°æ®ä¼—å¤šçš„è½»é‡çº§çº¿ç¨‹ï¼Œéå¸¸é€‚åˆå¤„ç†å¤§è§„æ¨¡å¼‚æ„å¹¶è¡Œè®¡ç®—ã€‚</p><p>ä¸‹å›¾æ‰€ç¤ºæ˜¯ä¸€ä¸ªå…¸å‹çš„å¼‚æ„å¹¶è¡Œæ¶æ„ï¼ŒåŒ…æ‹¬ä¸€ä¸ª CPUåŠå…¶å†…å­˜ å’Œä¸€ä¸ª GPUåŠå…¶å†…å­˜ï¼ŒGPU è®¾å¤‡ç«¯é€šè¿‡ PCIe æ€»çº¿ä¸åŸºäº CPU ä¸»æœºç«¯è¿›è¡Œäº¤äº’ã€‚ä¸€ä¸ªå¼‚æ„å¹¶è¡Œåº”ç”¨åŒ…æ‹¬ä¸»æœºä»£ç å’Œè®¾å¤‡ä»£ç ï¼Œåˆ†åˆ«è¿è¡Œåœ¨ä¸»æœºç«¯å’Œè®¾å¤‡ç«¯ã€‚åº”ç”¨ç”± CPU åˆå§‹åŒ–ï¼Œåœ¨è®¾å¤‡ç«¯è¿›è¡Œæ•°æ®è¿ç®—å‰ï¼ŒCPU è´Ÿè´£ç®¡ç†è®¾å¤‡ç«¯çš„ç¯å¢ƒï¼Œä»£ç å’Œæ•°æ®ã€‚æˆ‘ä»¬ç§° host ä¸º CPU åŠå…¶å†…å­˜ï¼Œdevice ä¸º GPU åŠå…¶å†…å­˜ã€‚</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/0.webp" alt=""></p><p>CPU è®¡ç®—é€‚åˆå¤„ç†æ§åˆ¶å¯†é›†å‹ä»»åŠ¡ï¼ŒGPU è®¡ç®—é€‚åˆå¤„ç†åŒ…å«æ•°æ®å¹¶è¡Œçš„è®¡ç®—å¯†é›†å‹ä»»åŠ¡ã€‚åœ¨ CPU ä¸Šæ‰§è¡Œä¸²è¡Œéƒ¨åˆ†æˆ–ä»»åŠ¡å¹¶è¡Œéƒ¨åˆ†ï¼Œåœ¨ GPU ä¸Šæ‰§è¡Œæ•°æ®å¯†é›†å‹å¹¶è¡Œéƒ¨åˆ†ï¼Œè¿™ç§å¼‚æ„å¹¶è¡Œæ¶æ„ä½¿å¾—è®¡ç®—èƒ½åŠ›å¯ä»¥å……åˆ†è¢«åˆ©ç”¨ã€‚</p><h3 id="NVIDIA-GPU-æ˜¾å¡æ¶æ„å‘å±•å†ç¨‹"><a href="#NVIDIA-GPU-æ˜¾å¡æ¶æ„å‘å±•å†ç¨‹" class="headerlink" title="NVIDIA GPU æ˜¾å¡æ¶æ„å‘å±•å†ç¨‹"></a>NVIDIA GPU æ˜¾å¡æ¶æ„å‘å±•å†ç¨‹</h3><ul><li><strong>Tesla</strong>ï¼ˆç‰¹æ–¯æ‹‰ï¼‰2008å¹´ï¼Œåº”ç”¨äºæ—©æœŸçš„ CUDA ç³»åˆ—æ˜¾å¡èŠ¯ç‰‡ä¸­ï¼Œå¹¶ä¸æ˜¯çœŸæ­£æ„ä¹‰ä¸Šçš„ GPU èŠ¯ç‰‡ã€‚</li><li><strong>Fermi</strong>ï¼ˆè´¹ç±³ï¼‰2010å¹´ï¼Œæ˜¯ç¬¬ä¸€ä¸ªå®Œæ•´çš„ GPU è®¡ç®—æ¶æ„ã€‚é¦–æ¬¾å¯æ”¯æŒä¸å…±äº«å­˜å‚¨ç»“åˆçº¯ cache å±‚æ¬¡çš„ GPU æ¶æ„ï¼Œæ”¯æŒ ECC(Error Correcting Code) çš„ GPU æ¶æ„ã€‚</li><li><strong>Kepler</strong>ï¼ˆå¼€æ™®å‹’ï¼‰2012å¹´ï¼ŒFermi çš„ä¼˜åŒ–ç‰ˆã€‚</li><li><strong>Maxwell</strong>ï¼ˆéº¦å…‹æ–¯éŸ¦ï¼‰2014å¹´ï¼Œé¦–æ¬¡æ”¯æŒå®æ—¶çš„åŠ¨æ€å…¨å±€å…‰ç…§æ•ˆæœï¼Œ</li><li><strong>Pascal</strong>ï¼ˆå¸•æ–¯å¡ï¼‰2016å¹´ï¼ŒGPU å°†å¤„ç†å™¨å’Œæ•°æ®é›†æˆåœ¨åŒä¸€ä¸ªç¨‹åºåŒ…å†…ï¼Œä»¥å®ç°æ›´é«˜çš„è®¡ç®—æ•ˆç‡ã€‚</li><li><strong>Volta</strong>ï¼ˆä¼æ‰“ï¼‰2017å¹´ï¼Œé¦–æ¬¡å°†ä¸€ä¸ª CUDA å†…æ ¸æ‹†åˆ†ä¸ºFP32 å’Œ INT32 ä¸¤éƒ¨åˆ†ï¼Œé¦–æ¬¡æ”¯æŒæ··åˆç²¾åº¦è¿ç®—ï¼Œæé«˜äº†5å€äº Pascal è®¡ç®—é€Ÿåº¦ï¼Œè¿˜å¢åŠ äº†ä¸“ç”¨äºæ·±åº¦å­¦ä¹ çš„ Tensor Core å¼ é‡å•å…ƒã€‚</li><li><strong>Turing</strong>ï¼ˆå›¾çµï¼‰2018å¹´ï¼Œå¢åŠ äº† RT Core ä¸“ç”¨å…‰çº¿è¿½è¸ªå¤„ç†å™¨ï¼Œå°†å®æ—¶å…‰çº¿è¿½è¸ªè¿ç®—åŠ é€Ÿè‡³ä¸Šä¸€ä»£æ¶æ„çš„ 25 å€ï¼Œå¹¶èƒ½ä»¥é«˜å‡º CPU 30 å¤šå€çš„é€Ÿåº¦è¿›è¡Œç”µå½±æ•ˆæœçš„æœ€ç»ˆå¸§æ¸²æŸ“ã€‚å»æ‰äº†å¯¹ FP64 è®¡ç®—çš„æ”¯æŒã€‚</li><li><strong>Ampere</strong>ï¼ˆå®‰åŸ¹ï¼‰2020å¹´ï¼Œé‡æ–°æ”¯æŒ FP64ï¼Œæ–°å¢å¼‚æ­¥æ‹·è´æŒ‡ä»¤èƒ½å¤Ÿä» global memory ä¸­å°†æ•°æ®ç›´æ¥åŠ è½½åˆ° SM shared memoryï¼Œé™ä½ä¸­é—´å¯„å­˜å™¨å †ï¼ˆRFï¼‰çš„éœ€æ±‚ã€‚æ–°å¢ BF16 æ•°æ®ç±»å‹ï¼Œä¸“ä¸ºæ·±åº¦å­¦ä¹ ä¼˜åŒ–ã€‚</li></ul><h2 id="CUDA-ç¼–ç¨‹æ¨¡å‹"><a href="#CUDA-ç¼–ç¨‹æ¨¡å‹" class="headerlink" title="CUDA ç¼–ç¨‹æ¨¡å‹"></a>CUDA ç¼–ç¨‹æ¨¡å‹</h2><p>CUDA æ˜¯ä¸€ä¸ªé€šç”¨å¹¶è¡Œè®¡ç®—å¹³å°å’Œç¼–ç¨‹æ¨¡å‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒCUDA å¹³å°å¯ä»¥é€šè¿‡ CUDA åŠ é€Ÿåº“ã€ç¼–è¯‘å™¨æŒ‡ä»¤ã€åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£æˆ–ç¼–ç¨‹è¯­è¨€æ¥å£æ¥ä½¿ç”¨ã€‚åé¢çš„ç« èŠ‚æˆ‘ä»¬ä¼šé‡ç‚¹è®²è§£ CUDA C ä»¥åŠ PyCUDA çš„ç¼–ç¨‹ã€‚</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/1.webp" alt=""></p><h3 id="CUDA-è½¯ä»¶ä½“ç³»"><a href="#CUDA-è½¯ä»¶ä½“ç³»" class="headerlink" title="CUDA è½¯ä»¶ä½“ç³»"></a>CUDA è½¯ä»¶ä½“ç³»</h3><p>CUDA æä¾›äº†ä¸¤å±‚ API æ¥è°ƒç”¨åº•å±‚ GPU ç¡¬ä»¶</p><ul><li><p>CUDA é©±åŠ¨ API (CUDA Driver API)</p><p>æ˜¯ä¸€ç§åŸºäºå¥æŸ„çš„åº•å±‚æ¥å£,å¤§å¤šæ•°å¯¹è±¡é€šè¿‡å¥æŸ„è¢«å¼•ç”¨,å…¶å‡½æ•°å‰ç¼€å‡ä¸º<code>cu</code>ï¼Œåœ¨è°ƒç”¨ Driver API å‰å¿…é¡»è¿›è¡Œåˆå§‹åŒ–ï¼Œå†åˆ›å»º CUDA  ä¸Šä¸‹æ–‡ï¼Œè¯¥ä¸Šä¸‹æ–‡å…³è”åˆ°ç‰¹å®šè®¾å¤‡å¹¶æˆä¸ºä¸»æœºçº¿ç¨‹çš„å½“å‰ä¸Šä¸‹æ–‡ï¼Œé€šè¿‡åŠ è½½ PTX æ±‡ç¼–å½¢å¼ æˆ– äºŒè¿›åˆ¶å¯¹è±¡å½¢å¼ çš„å†…æ ¸ï¼Œç„¶åå¯åŠ¨å†…æ ¸è®¡ç®—ã€‚Driver API å¯ä»¥é€šè¿‡ç›´æ¥æ“ä½œç¡¬ä»¶æ‰§è¡Œä¸€äº›å¤æ‚çš„åŠŸèƒ½ï¼Œä½†å…¶ç¼–ç¨‹è¾ƒä¸ºå¤æ‚ï¼Œéš¾åº¦è¾ƒå¤§ã€‚</p></li><li><p>CUDA è¿è¡Œæ—¶ API (CUDA Runtime API)</p><p>Runtime API å¯¹ Driver API è¿›è¡Œäº†ä¸€å®šçš„å°è£…ï¼Œéšè—äº†éƒ¨åˆ†å®ç°ç»†èŠ‚ï¼Œå› æ­¤ä½¿ç”¨èµ·æ¥æ›´ä¸ºæ–¹ä¾¿ï¼Œå› æ­¤æˆ‘ä»¬æ›´å¤šä½¿ç”¨çš„æ˜¯ Runtime APIã€‚Runtime API æ²¡æœ‰ä¸“é—¨çš„åˆå§‹åŒ–å‡½æ•°ï¼Œå®ƒå°†åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨è¿è¡Œæ—¶å‡½æ•°æ—¶è‡ªåŠ¨å®Œæˆåˆå§‹åŒ–ã€‚ä½¿ç”¨æ—¶ï¼Œé€šå¸¸éœ€è¦åŒ…å«å¤´æ–‡ä»¶ <code>cuda_runtime.h</code>ï¼Œå…¶å‡½æ•°å‰ç¼€å‡ä¸ºcudaã€‚</p></li></ul><p>å¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/2.webp" alt=""></p><p>Runtime API å’Œ Driver API ä¹‹é—´æ²¡æœ‰æ˜æ˜¾çš„æ€§èƒ½å·®è·ï¼Œè¿™ä¸¤ç§ API ä¸èƒ½æ··åˆä½¿ç”¨ï¼Œåªç”¨å•ç‹¬ä½¿ç”¨å…¶ä¸€ã€‚</p><h3 id="CUDA-å‡½æ•°åº“-CUDA-Libraries"><a href="#CUDA-å‡½æ•°åº“-CUDA-Libraries" class="headerlink" title="CUDA å‡½æ•°åº“ (CUDA Libraries)"></a>CUDA å‡½æ•°åº“ (CUDA Libraries)</h3><p>CUDA æä¾›äº†å‡ ä¸ªè¾ƒä¸ºæˆç†Ÿçš„é«˜æ•ˆå‡½æ•°åº“ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨è¿™äº›åº“å‡½æ•°è¿›è¡Œè®¡ç®—ï¼Œå¸¸è§çš„åŒ…æ‹¬</p><ul><li><p>CUFFTï¼šåˆ©ç”¨ CUDA è¿›è¡Œå‚…ç«‹å¶å˜æ¢çš„å‡½æ•°åº“</p></li><li><p>CUBLASï¼šåˆ©ç”¨ CUDA è¿›è¡ŒåŠ é€Ÿçš„å®Œæ•´æ ‡å‡†çŸ©é˜µä¸å‘é‡çš„è¿ç®—åº“</p></li><li><p>CUDPPï¼šå¹¶è¡Œæ“ä½œå‡½æ•°åº“</p></li><li><p>CUDNNï¼šåˆ©ç”¨CUDAè¿›è¡Œæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ</p></li></ul><h3 id="CUDA-åº”ç”¨ç¨‹åº-CUDA-Application"><a href="#CUDA-åº”ç”¨ç¨‹åº-CUDA-Application" class="headerlink" title="CUDA åº”ç”¨ç¨‹åº (CUDA Application)"></a>CUDA åº”ç”¨ç¨‹åº (CUDA Application)</h3><p>CUDA ç¨‹åºåŒ…å«åœ¨ host ä¸Šè¿è¡Œçš„ä¸»æœºä»£ç å’Œåœ¨ device ä¸Šè¿è¡Œçš„è®¾å¤‡ä»£ç ï¼Œè®¾å¤‡ä»£ç ä¼šåœ¨ç¼–è¯‘æ—¶é€šè¿‡ CUDA  nvcc ç¼–è¯‘å™¨ä»ä¸»æœºä»£ç ä¸­åˆ†ç¦»ï¼Œå†è½¬æ¢æˆ PTX(ParallelThread Execution) æ±‡ç¼–è¯­è¨€ï¼Œç”± GPU å¹¶è¡Œçº¿ç¨‹æ‰§è¡Œï¼Œä¸»æœºä»£ç ç”± CPU æ‰§è¡Œã€‚å¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/3.webp" alt=""></p><p>æ‰§è¡Œæµç¨‹å¦‚ä¸‹</p><ul><li><p>åˆ†é… host å†…å­˜ï¼Œå¹¶è¿›è¡Œæ•°æ®åˆå§‹åŒ–ï¼ˆCPUåˆå§‹åŒ–ï¼‰</p></li><li><p>åˆ†é… device å†…å­˜ï¼Œå¹¶ä» host å°†æ•°æ®æ‹·è´åˆ° device ä¸Šï¼ˆGPUåˆå§‹åŒ–ï¼‰</p></li><li><p>è°ƒç”¨ CUDA çš„æ ¸å‡½æ•°åœ¨ device ä¸Šå®ŒæˆæŒ‡å®šçš„è¿ç®—ï¼ˆGPUå¹¶è¡Œè¿ç®—ï¼‰</p></li><li><p>å°† deviceä¸Šçš„è¿ç®—ç»“æœæ‹·è´åˆ° host ä¸Šï¼ˆå°†GPUç»“æœä¼ å›CPUï¼‰</p></li><li><p>é‡Šæ”¾ device å’Œ host ä¸Šåˆ†é…çš„å†…å­˜ï¼ˆåˆå§‹åŒ–æ¸…ç©ºï¼‰</p></li></ul><h3 id="CUDA-ç¡¬ä»¶ç»“æ„"><a href="#CUDA-ç¡¬ä»¶ç»“æ„" class="headerlink" title="CUDA ç¡¬ä»¶ç»“æ„"></a>CUDA ç¡¬ä»¶ç»“æ„</h3><ul><li><p>SPï¼ˆStreaming Processorï¼‰ä¹Ÿç§°ä¸º CUDA coreï¼Œæ˜¯æœ€åŸºæœ¬çš„å¤„ç†å•å…ƒï¼Œæœ€åå…·ä½“çš„æŒ‡ä»¤å’Œä»»åŠ¡éƒ½æ˜¯åœ¨ SP ä¸Šå¤„ç†çš„ã€‚GPU è¿›è¡Œå¹¶è¡Œè®¡ç®—ï¼Œä¹Ÿå°±æ˜¯å¾ˆå¤šä¸ª SP åŒæ—¶åšå¤„ç†ã€‚</p></li><li><p>SMï¼ˆStreaming Multiprocessorï¼‰å¤šä¸ª SP åŠ ä¸Šå…¶ä»–èµ„æºç»„æˆä¸€ä¸ª SMï¼Œä¹Ÿå« GPU å¤§æ ¸ï¼Œå…¶ä»–èµ„æºå¦‚åŒ…æ‹¬warp schedulerï¼Œregisterï¼Œshared memory ç­‰ã€‚SMå¯ä»¥çœ‹åšGPUçš„å¿ƒè„ï¼ˆç±»ä¼¼ CPU æ ¸å¿ƒï¼‰ã€‚æ¯ä¸ª SM éƒ½æ‹¥æœ‰ register å’Œ shared memoryï¼ŒCUDA å°†è¿™äº›èµ„æºåˆ†é…ç»™æ‰€æœ‰é©»ç•™åœ¨ SM ä¸­çš„çº¿ç¨‹ï¼Œä½†èµ„æºéå¸¸æœ‰é™ï¼ŒSM ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p></li></ul><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/5.webp" alt=""></p><p>æ¯ä¸ª SM åŒ…å«çš„ SP æ•°é‡ä¾æ® GPU æ¶æ„è€Œä¸åŒï¼Œå¦‚ Fermi æ¶æ„ GF100 æ˜¯ 32 ä¸ªï¼ŒGF10X æ˜¯ 48 ä¸ªï¼ŒKepler æ¶æ„éƒ½æ˜¯ 192 ä¸ªï¼ŒMaxwell éƒ½æ˜¯128 ä¸ªã€‚</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/6.webp" alt=""></p><p>åœ¨è½¯ä»¶é€»è¾‘ä¸Šæ˜¯æ‰€æœ‰ SP æ˜¯å¹¶è¡Œè®¡ç®—çš„ï¼Œä½†æ˜¯ç‰©ç†ä¸Šå¹¶ä¸æ˜¯ï¼Œæ¯”å¦‚åªæœ‰ 8 ä¸ª SM å´æœ‰ 1024 ä¸ªçº¿ç¨‹å—éœ€è¦è°ƒåº¦å¤„ç†ï¼Œå› ä¸ºæœ‰äº›ä¼šå¤„äºæŒ‚èµ·ï¼Œå°±ç»ªç­‰å…¶ä»–çŠ¶æ€ï¼Œè¿™æœ‰å…³ GPU çš„çº¿ç¨‹è°ƒåº¦ï¼Œåç»­ç« èŠ‚ä¼šå±•å¼€è®¨è®ºã€‚</p><h2 id="ä¸‰-ç†è§£-kernel-thread-block-grid-ä¸-warp"><a href="#ä¸‰-ç†è§£-kernel-thread-block-grid-ä¸-warp" class="headerlink" title="ä¸‰ ç†è§£ kernel, thread, block , grid ä¸ warp"></a>ä¸‰ ç†è§£ kernel, thread, block , grid ä¸ warp</h2><h3 id="CUDA-çº¿ç¨‹æ¨¡å‹"><a href="#CUDA-çº¿ç¨‹æ¨¡å‹" class="headerlink" title="CUDA çº¿ç¨‹æ¨¡å‹"></a>CUDA çº¿ç¨‹æ¨¡å‹</h3><p>çº¿ç¨‹æ˜¯ç¨‹åºæ‰§è¡Œçš„æœ€åŸºæœ¬å•å…ƒï¼ŒCUDA çš„å¹¶è¡Œè®¡ç®—é€šè¿‡æˆåƒä¸Šä¸‡ä¸ªçº¿ç¨‹çš„å¹¶è¡Œæ‰§è¡Œæ¥å®ç°ã€‚ä¸‹å›¾ä¸º GPU çš„çº¿ç¨‹ç»“æ„</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/7.webp" alt=""></p><p>CUDAçš„çº¿ç¨‹æ¨¡å‹ä»å°å¾€å¤§ä¾æ¬¡æ˜¯</p><ul><li><p>Threadï¼Œçº¿ç¨‹ï¼Œå¹¶è¡Œçš„åŸºæœ¬å•ä½</p></li><li><p>Blockï¼Œçº¿ç¨‹å—ï¼Œäº’ç›¸åˆä½œçš„çº¿ç¨‹ç»„ï¼Œçº¿ç¨‹å—æœ‰å¦‚ä¸‹å‡ ä¸ªç‰¹ç‚¹ï¼š</p><ul><li><p>ä»¥1ç»´ã€2ç»´æˆ–3ç»´ç»„ç»‡</p></li><li><p>å…è®¸å½¼æ­¤åŒæ­¥</p></li><li>å¯ä»¥é€šè¿‡å…±äº«å†…å­˜å¿«é€Ÿäº¤æ¢æ•°æ®</li></ul></li><li><p>Gridï¼Œç½‘æ ¼ï¼Œç”±ä¸€ç»„ Block ç»„æˆ</p><ul><li>ä»¥1ç»´ã€2ç»´ç»„ç»‡</li></ul><ul><li>å…±äº«å…¨å±€å†…å­˜</li></ul></li></ul><h3 id="kernel"><a href="#kernel" class="headerlink" title="kernel"></a>kernel</h3><p>kernel æ˜¯åœ¨ device ä¸Šçº¿ç¨‹ä¸­å¹¶è¡Œæ‰§è¡Œçš„å‡½æ•°ï¼Œæ˜¯è½¯ä»¶æ¦‚å¿µï¼Œæ ¸å‡½æ•°ç”¨<code>__global__</code>ç¬¦å·å£°æ˜ï¼Œå¹¶ç”¨ <code>&lt;&lt;&lt;grid, block&gt;&gt;&gt;</code> æ‰§è¡Œé…ç½®è¯­æ³•æŒ‡å®šå†…æ ¸è°ƒç”¨çš„ CUDA çº¿ç¨‹æ•°ï¼Œæ¯ä¸ª kernel çš„ thread éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„çº¿ç¨‹ IDï¼Œå¯ä»¥é€šè¿‡å†…ç½®å˜é‡åœ¨å†…æ ¸ä¸­è®¿é—®ã€‚block ä¸€æ—¦è¢«åˆ†é…å¥½ SMï¼Œè¯¥ block å°±ä¼šä¸€ç›´é©»ç•™åœ¨è¯¥ SM ä¸­ï¼Œç›´åˆ°æ‰§è¡Œç»“æŸã€‚ä¸€ä¸ª SM å¯ä»¥åŒæ—¶æ‹¥æœ‰å¤šä¸ª blocksã€‚</p><h3 id="warp"><a href="#warp" class="headerlink" title="warp"></a>warp</h3><p>warp æ˜¯ SM çš„åŸºæœ¬æ‰§è¡Œå•å…ƒï¼Œä¹Ÿç§°çº¿ç¨‹æŸï¼Œä¸€ä¸ª warp æœ‰ 32 ä¸ªå¹¶è¡Œçš„ threadï¼Œ SM æ—¨åœ¨åŒæ—¶æ‰§è¡Œæ•°ç™¾ä¸ª threadï¼Œä¸ºäº†ç®¡ç†å¦‚æ­¤å¤§é‡çš„çº¿ç¨‹ï¼Œé‡‡ç”¨äº† SIMT ï¼ˆSingle-Instruction, Multiple-Threadï¼šå•æŒ‡ä»¤ï¼Œå¤šçº¿ç¨‹ï¼‰çš„æ¶æ„ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ª warp ä¸­çš„æ‰€æœ‰ thread ä¸€æ¬¡æ‰§è¡Œä¸€æ¡å…¬å…±æŒ‡ä»¤ï¼Œå¹¶ä¸”æ¯ä¸ªthreadä¼šä½¿ç”¨å„è‡ªçš„dataæ‰§è¡Œè¯¥æŒ‡ä»¤ã€‚</p><p>ä¸€ä¸ªå—ä¸­çš„ warp æ€»æ•°è®¡ç®—å¦‚ä¸‹</p><script type="math/tex; mode=display">WarpsPerBlock = ceil(\frac{ThreadsPerBlock}{WarpSize}, 1)</script><p>å¯¹åº”ä¸‹å›¾</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/8.webp" alt=""></p><p>ä»ç¡¬ä»¶è§’åº¦æ¥çœ‹ï¼Œæ‰€æœ‰çš„ thread ä»¥ä¸€ç»´å½¢å¼ç»„ç»‡ï¼Œæ¯ä¸ª thread éƒ½æœ‰ä¸ªå”¯ä¸€çš„ IDï¼Œäºæ˜¯ä½œä¸ºè¡¥å…¨æ•´æ•°å€çš„ thread åœ¨æ‰€åœ¨çš„ warp ä¸­ä¸º inactive çŠ¶æ€ï¼Œä¼šé¢å¤–æ¶ˆè€— SM èµ„æºï¼Œæ‰€ä»¥è¦è®¾å®š block ä¸­çš„ thread ä¸€èˆ¬ä¸º32çš„å€æ•°ã€‚</p><p>ä¸‹é¢ä»ç¡¬ä»¶è§’åº¦å’Œè½¯ä»¶è§’åº¦è§£é‡Š CUDA çš„çº¿ç¨‹æ¨¡å‹</p><div class="table-container"><table><thead><tr><th>è½¯ä»¶</th><th>ç¡¬ä»¶</th><th>æè¿°</th></tr></thead><tbody><tr><td>Thread</td><td>SP</td><td>æ¯ä¸ªçº¿ç¨‹ç”±æ¯ä¸ªçº¿ç¨‹å¤„ç†å™¨ï¼ˆSPï¼‰æ‰§è¡Œ</td></tr><tr><td>Block</td><td>SM</td><td>çº¿ç¨‹å—ç”±å¤šæ ¸å¤„ç†å™¨ï¼ˆSMï¼‰æ‰§è¡Œ</td></tr><tr><td>Grid</td><td>Device</td><td>ä¸€ä¸ª kernel ç”±ä¸€ä¸ª grid æ¥æ‰§è¡Œï¼Œä¸€æ¬¡åªèƒ½åœ¨ä¸€ä¸ª GPU ä¸Šæ‰§è¡Œ</td></tr></tbody></table></div><h3 id="çº¿ç¨‹ç´¢å¼•"><a href="#çº¿ç¨‹ç´¢å¼•" class="headerlink" title="çº¿ç¨‹ç´¢å¼•"></a>çº¿ç¨‹ç´¢å¼•</h3><p>ç¡®å®šçº¿ç¨‹çš„å”¯ä¸€ç´¢å¼•ï¼Œä»¥ 2D grid å’Œ 2D block çš„æƒ…å†µä¸ºä¾‹ã€‚</p><p>æˆ‘ä»¬è¦è®¡ç®—çš„æ•°å€¼çŸ©é˜µåœ¨å†…å­˜ä¸­æ˜¯ row-majorï¼ˆè¡Œä¸»åºï¼‰ çº¿æ€§å­˜å‚¨çš„ï¼Œå¦‚ä¸‹å›¾</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/9.webp" alt=""></p><p>å°† thread å’Œ block ç´¢å¼•æ˜ å°„åˆ°çŸ©é˜µåæ ‡</p><p>ix = threadIdx.x + blockIdx.x * blockDim.x</p><p>iy = threadIdx.y + blockIdx.y * blockDim.y</p><p>idx = iy * nx + ix</p><p>ä¸‹å›¾ä¸º block å’Œ thread ç´¢å¼•ï¼ŒçŸ©é˜µåæ ‡ä»¥åŠçº¿æ€§åœ°å€ä¹‹é—´çš„å…³ç³»</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/10.webp" alt=""></p><p>åœ¨å®è·µåº”ç”¨ä¸­ï¼Œå¸¸å¸¸ä¼šå¤šä¸€ç»´ gridï¼Œ é‚£å°±æ˜¯ä¸‰ç»´æƒ…å†µçš„ç´¢å¼•ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè®¾  (gridDim.x,gridDim.y) = (2,3), (blockDim.x,blockDim.y) = (4,2)ï¼Œæˆ‘ä»¬ä»¥ thread_id(3,1) block_id(0,1) ä¸ºä¾‹</p><p><img src="/image/CUDAç¼–ç¨‹-CUDAæ¨¡å‹æ¦‚è¿°/11.webp" alt=""></p><p>å¯ä»¥å¾—åˆ°</p><p>ix = threadIdx.x + blockIdx.x <em> blockDim.x = 3 + 0 </em> 4 = 3</p><p>iy = threadIdx.y + blockIdx.y <em> blockDim.y = 1 + 1 </em> 2 = 3</p><p>coordinate(3,3)</p><p>global index: idx = iy <em> blockDim.x </em> gridDim.x + ix = 3 <em> 4 </em> 2 + 3 = 27</p>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹: GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º</title>
      <link href="/p/b3409785/"/>
      <url>/p/b3409785/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æ¨¡å‹å˜å¾—è¶Šæ¥è¶Šæ·±ï¼Œå‚æ•°æ„ˆåŠ åºå¤§ï¼Œè™½ç„¶å‡†ç¡®ç‡ä¸æ–­å¢é•¿ï¼Œç”±äºç¡¬ä»¶å—é™ï¼Œå¯¹å®é™…åœºæ™¯éƒ¨ç½²çš„è¦æ±‚ä¹Ÿè¶Šæ¥è¶Šé«˜ï¼ŒCUDA ç¼–ç¨‹æˆä¸ºäº†ä¸€é—¨å¿…å¤‡çš„æ­¦æ—ç»å­¦ã€‚</p><span id="more"></span><h2 id="CUDAç®€ä»‹"><a href="#CUDAç®€ä»‹" class="headerlink" title="CUDAç®€ä»‹"></a>CUDAç®€ä»‹</h2><p>é¦–å…ˆä»‹ç»ä¸€ä¸‹ GPUï¼Œåœ¨è®¡ç®—æœºä¸­ï¼ŒGPU ç›¸æ¯” CPUï¼Œæ‹¥æœ‰éå¸¸å¤šçš„å†…æ ¸ï¼Œè¿™æ„å‘³ç€ GPU å¯ä»¥ä»¥éå¸¸é«˜çš„ååé‡æ‰§è¡Œç¨‹åºï¼Œå¦‚åŒä¸€æ¡éå¸¸å®½é˜”çš„é“è·¯å¯ä»¥åŒæ—¶è®©å¾ˆå¤šè½¦è¾†åŒæ—¶é€šè¡Œï¼Œä¾‹å¦‚æœ€æ–°çš„ RTX 3090 çš„æ ¸å¿ƒæ•°è¾¾åˆ°äº†ææ€–çš„ 10496 ä¸ªï¼Œè€Œå½“å‰çš„é¡¶çº§ CPU é€šå¸¸åªæœ‰ä¸è¶…è¿‡ 32 æ ¸å¿ƒã€‚å› æ­¤æˆ‘ä»¬éœ€è¦æ­£ç¡®åœ°è®¾è®¡å¹¶è¡ŒåŒ–åŠ é€Ÿç®—æ³•ï¼Œå°±å¯ä»¥å‘æŒ¥ GPU çš„å¼ºå¤§ä¼˜åŠ¿ã€‚</p><p>CUDA æ˜¯ç”±è‹±ä¼Ÿè¾¾ NVIDIA äº 2007 å¹´æ‰€æ¨å‡ºé’ˆå¯¹ NVIDIA GPU ä¸“æœ‰ç³»ç»Ÿï¼Œé€šè¿‡ CUDAï¼Œç”¨æˆ·å¯æ–¹ä¾¿åœ°ä½¿ç”¨å°é—­å¥½çš„ SDK å¯¹ GPU è¿›è¡Œå¤æ‚çš„æ•°å€¼è®¡ç®—ï¼Œåœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼ŒCUDA æä¾›äº†ä¸€å¥—å¼ºå¤§çš„åŠ é€Ÿå¹¶è¡Œè®¡ç®—å’Œäººå·¥æ™ºèƒ½ç›¸å…³çš„ä»£ç åº“ï¼ŒåŒæ—¶ï¼ŒNVIDIA å®˜æ–¹æä¾›äº†éå¸¸å®Œå–„çš„å®‰è£…ç¨‹åºã€‚</p><h2 id="CUDA-å®‰è£…"><a href="#CUDA-å®‰è£…" class="headerlink" title="CUDA å®‰è£…"></a>CUDA å®‰è£…</h2><h3 id="Linux-å®‰è£…"><a href="#Linux-å®‰è£…" class="headerlink" title="Linux å®‰è£…"></a>Linux å®‰è£…</h3><p>é¦–å…ˆæ£€æŸ¥æœ¬æœºæ˜¯å¦æœ‰ nvidia çš„æ˜¾å¡</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i <span class="string">&quot;nvidia&quot;</span></span><br></pre></td></tr></table></figure><blockquote><p>è¯·ä¸è¦åœ¨vmè™šæ‹Ÿæœºä¸­å®‰è£… CUDA</p></blockquote><p>ä»¥ç¬”ä¸»çš„ç”µè„‘ä¸ºä¾‹ï¼Œæœ‰ä¸€å¼  RTX 3060 çš„ç§»åŠ¨æ˜¾å¡</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">01:00.0 VGA compatible controller: NVIDIA Corporation GA106M [GeForce RTX 3060 Mobile / Max-Q] (rev a1)</span><br><span class="line">01:00.1 Audio device: NVIDIA Corporation Device 228e (rev a1)</span><br></pre></td></tr></table></figure><p>ä¹‹åå» NVIDIA å®˜ç½‘ ä¸‹è½½å¯¹åº”å‘è¡Œç‰ˆçš„ <a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit</a>ï¼Œè¿™é‡Œæ ¹æ®è‡ªå·±çš„æ·±åº¦å­¦ä¹ æ¡†æ¶é€‰æ‹©ç‰ˆæœ¬ï¼Œåœ¨å®‰è£… Toolkit æ—¶ä¼šè‡ªå¸¦ CUDA Driver</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/1.webp" alt=""></p><p>ä¸‹è½½æ–‡ä»¶æ¨èé€‰æ‹© runfile æ ¼å¼</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/2.webp" alt=""></p><p>æ–‡ä»¶æ¯”è¾ƒå¤§ï¼Œç­‰å¾…æ—¶ç¡®ä¿æœºå™¨ä¸Šæœ‰ç›¸åº”çš„ä¾èµ–åº“ï¼Œå¯ä»¥è¿è¡Œä¸‹é¢å‘½ä»¤å®‰è£…ä¾èµ–åº“</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install gcc g++ make</span><br><span class="line">sudo apt install libglu1-mesa libxi-dev libxmu-dev libglu1-mesa-dev freeglut3-dev</span><br></pre></td></tr></table></figure><p>å¦‚æœç³»ç»Ÿä¸ºå›¾å½¢ç•Œé¢ï¼Œéœ€è¦æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦è‡ªå¸¦å¼€æº NVIDIA Nouveau é©±åŠ¨</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep -i <span class="string">&quot;nouveau&quot;</span></span><br></pre></td></tr></table></figure><p>å¦‚æœæœ‰è¾“å‡ºï¼Œéœ€è¦ç¦ç”¨ Nouveau é©±åŠ¨</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></table></figure><p>åœ¨æ–‡ä»¶ä¸­è¿½åŠ å¦‚ä¸‹å†…å®¹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">blacklist lbm-nouveau</span><br><span class="line">options nouveau modeset=0</span><br><span class="line">alias nouveau off</span><br><span class="line">alias lbm-nouveau off</span><br></pre></td></tr></table></figure><p>åŒæ—¶å¸è½½ nvidia ç›¸å…³åŒ…</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt purge nvidia-*</span><br></pre></td></tr></table></figure><p>é‡å¯ç³»ç»Ÿ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><p>é‡å¯åä½¿ç”¨<code>Ctrl + Alt + F2</code>è¿›å…¥ tt2ï¼Œå†æ¬¡æ£€æŸ¥å¼€æºé©±åŠ¨æ˜¯å¦å¯åŠ¨</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep -i <span class="string">&quot;nouveau&quot;</span></span><br></pre></td></tr></table></figure><p>ç„¶åå…³é—­æ˜¾ç¤ºæœåŠ¡ï¼Œå¹¶ä¿®æ”¹å®‰è£…æ–‡ä»¶æƒé™</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm stop</span><br><span class="line"><span class="built_in">chmod</span> 777 cuda_10.2.89_440.33.01_linux.run</span><br></pre></td></tr></table></figure><p>ä¹‹åè¿è¡Œ CUDA å®‰è£…è„šæœ¬ï¼Œåœ¨å®‰è£…æ—¶</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh cuda_*_linux.run</span><br></pre></td></tr></table></figure><p>å®‰è£…å®Œæˆåè„šæœ¬ä¼šè‡ªåŠ¨åœ¨<code>/usr/local</code>åˆ›å»º <code>cuda -&gt; /usr/local/cuda-11.8/</code> è½¯é“¾æ¥ï¼Œåœ¨ <code>~/.bashrc</code>å†™å…¥</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">export</span> CUDA_HOME=/usr/local/cuda</span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure><p>åœ¨ç»ˆç«¯ä¸­è¾“å…¥ <code>nvcc -V</code> ï¼Œå¦‚æœ‰ç±»ä¼¼ä¸‹é¢çš„è¾“å‡ºï¼Œåˆ™å®‰è£…æˆåŠŸ</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2022 NVIDIA Corporation</span><br><span class="line">Built on Wed_Sep_21_10:33:58_PDT_2022</span><br><span class="line">Cuda compilation tools, release 11.8, V11.8.89</span><br><span class="line">Build cuda_11.8.r11.8/compiler.31833905_0</span><br></pre></td></tr></table></figure><p>å®‰è£…å®Œæˆåé‡å¯å›¾å½¢ç•Œé¢</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm restart</span><br></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥å®‰è£… cuDNN</p><p><a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a></p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/9.webp" alt=""></p><p>ä¸‹è½½å®Œæˆåè§£å‹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xf cudnn-linux-x86_64-8.6.0.163_cuda11-archive.tar.xz</span><br></pre></td></tr></table></figure><p>å°†è§£å‹åçš„æ–‡ä»¶æ‹·è´åˆ° CUDA å¯¹åº”çš„å®‰è£…ç›®å½•ä¸‹ï¼Œå¹¶æ·»åŠ æƒé™</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">cp</span> cudnn-linux-x86_64-8.6.0.163_cuda11-archive/include/cudnn.h /usr/local/cuda/include</span><br><span class="line">sudo <span class="built_in">cp</span> cudnn-linux-x86_64-8.6.0.163_cuda11-archive/lib/libcudnn* /usr/local/cuda/lib64*</span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda-11.7/include/cudnn.h </span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda-11.7/lib64/libcudnn*</span><br></pre></td></tr></table></figure><p>å³å®‰è£…å®Œæˆ</p><h3 id="Windows-å®‰è£…"><a href="#Windows-å®‰è£…" class="headerlink" title="Windows å®‰è£…"></a>Windows å®‰è£…</h3><p>æ‰“å¼€è®¾å¤‡ç®¡ç†å™¨ï¼ŒæŸ¥çœ‹å½“å‰æ˜¾å¡å‹å·</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/3.webp" alt=""></p><p>ä»¥ç¬”ä¸»çš„ç”µè„‘ä¸ºä¾‹ï¼Œæœ‰ä¸€å¼  RTX 3060 çš„ç§»åŠ¨æ˜¾å¡</p><p>å†åœ¨æ¡Œé¢å³å‡»æˆ–æ‰“å¼€ç³»ç»Ÿå°æ‰˜ç›˜ï¼Œæ‰“å¼€ NVIDIA æ§åˆ¶é¢æ¿</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/4.webp" alt=""></p><p>è¿™é‡Œæ¨è Studio é©±åŠ¨ç¨‹åºï¼Œä¸å»ºè®® Game Ready é©±åŠ¨ç¨‹åºï¼Œå¯ä»¥åœ¨ <a href="https://www.nvidia.cn/Download/index.aspx">NVIDIA é©±åŠ¨ç¨‹åºä¸‹è½½</a> æ‰¾åˆ°å¯¹åº”æ˜¾å¡çš„é©±åŠ¨ç¨‹åºã€‚å®‰è£…å®Œæˆåå¦‚å›¾æ‰€ç¤º</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/5.webp" alt=""></p><p>ä¹‹åæ ¹æ®ç³»ç»Ÿé©±åŠ¨ç¨‹åºç‰ˆæœ¬<a href="https://developer.nvidia.com/cuda-toolkit-archive">ä¸‹è½½ CUDA å®‰è£…ç¨‹åº</a>ï¼Œ<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-major-component-versions">ç‚¹å‡»æŸ¥çœ‹ç³»ç»Ÿé©±åŠ¨ç¨‹åºç‰ˆæœ¬å’Œ CUDA ç‰ˆæœ¬å¯¹åº”å…³ç³»</a>ï¼Œæ¨è exe(local)</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/16.webp" alt=""></p><p>ä¸‹è½½å®ŒæˆååŒå‡»æ‰“å¼€ï¼Œè¿™é‡Œä½¿ç”¨é»˜è®¤ä½ç½®</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/6.webp" alt=""></p><p>ä½¿ç”¨è‡ªå®šä¹‰å®‰è£…</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/7.webp" alt=""></p><p>è¿™é‡Œè¦è®°ä½å®‰è£…ä½ç½®ï¼Œæ¨èé»˜è®¤</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/11.webp" alt=""></p><p>å®‰è£…åä¼šè‡ªåŠ¨æ·»åŠ ç¯å¢ƒå˜é‡ï¼Œæ‰“å¼€ Powershell / CMDï¼Œè¾“å…¥<code>nvcc -V</code></p><p>å¦‚æœ‰ç±»ä¼¼ä¸‹é¢çš„è¾“å‡ºï¼Œåˆ™å®‰è£…æˆåŠŸ</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2022 NVIDIA Corporation</span><br><span class="line">Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022</span><br><span class="line">Cuda compilation tools, release 11.8, V11.8.89</span><br><span class="line">Build cuda_11.8.r11.8/compiler.31833905_0</span><br></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥å®‰è£… cuDNN</p><p><a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a></p><p>ä¸‹è½½å®Œæˆè§£å‹åå¦‚ä½•ä¸‹å›¾</p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/10.webp" alt=""></p><p>æŠŠè¿™ä¸‰ä¸ªæ–‡ä»¶å¤¹æ‹·è´åˆ° CUDA çš„å®‰è£…ç›®å½•ä¸‹ï¼ŒåŒåæ–‡ä»¶å¤¹ä¼šè‡ªåŠ¨åˆå¹¶ã€‚</p><p>å°†å¦‚ä¸‹è·¯å¾„æ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\bin</span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\include</span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\lib</span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\libnvvp</span><br></pre></td></tr></table></figure><p>å³å®‰è£…å®Œæˆ</p><h2 id="PyCUDA"><a href="#PyCUDA" class="headerlink" title="PyCUDA"></a>PyCUDA</h2><p>PyCUDA æ˜¯ NVIDIA é’ˆå¯¹ python ç¼–å†™çš„ CUDA APIï¼Œåº•å±‚ä½¿ç”¨ C++ï¼Œ ä½¿ç”¨ PyCUDA å¯ä»¥æ›´æ–¹ä¾¿åœ°ç¼–å†™ä»£ç ã€‚åŒæ · CUDA é”™è¯¯éƒ½ä¼šè‡ªåŠ¨è½¬æ¢ä¸º Python å¼‚å¸¸ã€‚</p><h3 id="Linux-å®‰è£…-1"><a href="#Linux-å®‰è£…-1" class="headerlink" title="Linux å®‰è£…"></a>Linux å®‰è£…</h3><p>ç¡®ä¿ç”µè„‘ä¸­å®‰è£…äº† python ç¯å¢ƒå’Œ pipï¼Œå®‰è£…å‘½ä»¤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pycuda</span><br></pre></td></tr></table></figure><h3 id="Windows-å®‰è£…-1"><a href="#Windows-å®‰è£…-1" class="headerlink" title="Windows å®‰è£…"></a>Windows å®‰è£…</h3><p>æ ¹æ®è‡ªå·±çš„ CUDA ç‰ˆæœ¬ å’Œ Python ç‰ˆæœ¬ä¸‹è½½ whl æ–‡ä»¶ <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#pycuda">http://www.lfd.uci.edu/~gohlke/pythonlibs/#pycuda</a></p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/17.webp" alt=""></p><p>å®‰è£…å‘½ä»¤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pycuda*.whl</span><br></pre></td></tr></table></figure><h2 id="Nvidia-Nsight-Systems"><a href="#Nvidia-Nsight-Systems" class="headerlink" title="Nvidia Nsight Systems"></a>Nvidia Nsight Systems</h2><p>ç®€ç§° <code>nsys</code>ï¼Œæ˜¯ä¸€æ¬¾ä½å¼€é”€æ€§èƒ½åˆ†æå·¥å…·ï¼Œæ—¨åœ¨ä¸ºå¼€å‘äººå‘˜æä¾›ä¼˜åŒ–è½¯ä»¶æ‰€éœ€çš„æ´å¯ŸåŠ›ã€‚æ— åå·®çš„æ´»åŠ¨æ•°æ®å¯åœ¨å·¥å…·ä¸­å¯è§†åŒ–ï¼Œå¯å¸®åŠ©ç”¨æˆ·è°ƒæŸ¥ç“¶é¢ˆï¼Œé¿å…æ¨æ–­è¯¯æŠ¥ï¼Œå¹¶ä»¥æ›´é«˜çš„æ€§èƒ½æå‡æ¦‚ç‡å®ç°ä¼˜åŒ–ã€‚ç”¨æˆ·å°†èƒ½å¤Ÿè¯†åˆ«é—®é¢˜ï¼Œä¾‹å¦‚ GPU é—²ç½®ã€ä¸å¿…è¦çš„ GPU åŒæ­¥ã€CPU å¹¶è¡ŒåŒ–ä¸è¶³ã€‚</p><p>æ ¹æ®ç³»ç»Ÿå¹³å°é€‰æ‹©åˆé€‚çš„å®‰è£…åŒ…</p><p><a href="https://developer.nvidia.cn/gameworksdownload#?dn=nsight-systems-2022-4">https://developer.nvidia.cn/gameworksdownload#?dn=nsight-systems-2022-4</a></p><p><img src="/image/CUDAç¼–ç¨‹-GPUç¼–ç¨‹æ¦‚è¿°å’ŒCUDAç¯å¢ƒæ­å»º/18.webp" alt=""></p><p>å®‰è£…å®Œæˆåè¾“å…¥å‘½ä»¤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nsys --version</span><br></pre></td></tr></table></figure><p>å¦‚æœ‰è¿”å›ï¼Œå³å®‰è£…å®Œæˆ</p>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®°å½•ç¬¬næ¬¡åˆ›å»ºå¯ç”¨å¹¶æ¸…ç†ä¸´æ—¶swap</title>
      <link href="/p/f3209fd4/"/>
      <url>/p/f3209fd4/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æ—¶å¸¸è¦ç”¨ chatgpt è¾…åŠ©ç”Ÿæˆ swapï¼Œè®°å½•ä¸‹æ¥æ–¹ä¾¿</p><span id="more"></span><h2 id="è„šæœ¬"><a href="#è„šæœ¬" class="headerlink" title="è„šæœ¬"></a>è„šæœ¬</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">function create_swap &#123;</span><br><span class="line">    SWAPFILE=$1</span><br><span class="line">    SIZE=$2</span><br><span class="line"></span><br><span class="line">    mkdir -p $(dirname &quot;$SWAPFILE&quot;)</span><br><span class="line"></span><br><span class="line">    sudo dd if=/dev/zero of=&quot;$SWAPFILE&quot; bs=1G count=&quot;$SIZE&quot; status=progress</span><br><span class="line"></span><br><span class="line">    sudo chmod 600 &quot;$SWAPFILE&quot;</span><br><span class="line"></span><br><span class="line">    sudo mkswap &quot;$SWAPFILE&quot;</span><br><span class="line">    sudo swapon &quot;$SWAPFILE&quot;</span><br><span class="line"></span><br><span class="line">    echo &quot;Swap file created and enabled at $SWAPFILE with size $&#123;SIZE&#125;G&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function clean_swap &#123;</span><br><span class="line">    SWAPFILE=$1</span><br><span class="line"></span><br><span class="line">    if [ -f &quot;$SWAPFILE&quot; ]; then</span><br><span class="line">        sudo swapoff &quot;$SWAPFILE&quot;</span><br><span class="line">        sudo rm -f &quot;$SWAPFILE&quot;</span><br><span class="line">        echo &quot;Swap file at $SWAPFILE has been removed.&quot;</span><br><span class="line">    else</span><br><span class="line">        echo &quot;Swap file at $SWAPFILE does not exist.&quot;</span><br><span class="line">    fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">CLEAN_MODE=0</span><br><span class="line"></span><br><span class="line">while getopts &quot;c&quot; opt; do</span><br><span class="line">    case $opt in</span><br><span class="line">        c)</span><br><span class="line">            CLEAN_MODE=1</span><br><span class="line">            ;;</span><br><span class="line">        \?)</span><br><span class="line">            echo &quot;Invalid option: -$OPTARG&quot; &gt;&amp;2</span><br><span class="line">            exit 1</span><br><span class="line">            ;;</span><br><span class="line">    esac</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">shift $((OPTIND -1))</span><br><span class="line"></span><br><span class="line">if [ &quot;$CLEAN_MODE&quot; -eq 1 ]; then</span><br><span class="line">    if [ &quot;$#&quot; -ne 1 ]; then</span><br><span class="line">        echo &quot;Usage: $0 -c [swap file path]&quot;</span><br><span class="line">        exit 1</span><br><span class="line">    fi</span><br><span class="line">    clean_swap $1</span><br><span class="line">else</span><br><span class="line">    if [ &quot;$#&quot; -ne 2 ]; then</span><br><span class="line">        echo &quot;Usage: $0 [swap file path] [size in GB]&quot;</span><br><span class="line">        exit 1</span><br><span class="line">    fi</span><br><span class="line">    create_swap $1 $2</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h2 id="è¿è¡Œ"><a href="#è¿è¡Œ" class="headerlink" title="è¿è¡Œ"></a>è¿è¡Œ</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">chmod +x create_swap.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">åˆ›å»º swap æ–‡ä»¶</span></span><br><span class="line">./create_swap.sh [swap file path] [size in GB]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">æ¸…ç† swap æ–‡ä»¶</span></span><br><span class="line">./create_swap.sh -c [swap file path]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> swap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»: ZeRO++: Extremely Eficient Collective Communication for Giant Model Training</title>
      <link href="/p/82ab1321/"/>
      <url>/p/82ab1321/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>åŸæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/pdf/2306.10209.pdf">https://arxiv.org/pdf/2306.10209.pdf</a></p><p>å¼€æºä»£ç ï¼š<a href="https://github.com/microsoft/deepspeed">https://github.com/microsoft/deepspeed</a></p><span id="more"></span><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>é¢å¯¹ LLMï¼Œ3Då¹¶è¡Œå·¥ç¨‹å®ç°å¤æ‚</p><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>é€šè¿‡ä»¥ä¸‹ 3 ç§æ–¹æ³•å‡å°‘é€šä¿¡</p><ul><li>åŸºäºå—é‡åŒ–çš„ all-gather</li><li>é€šè¿‡æ•°æ®é‡æ˜ å°„ç”¨é€šä¿¡å‡å°‘å†…å­˜å¼€é”€</li><li>åŸºäº all-to-all çš„é‡åŒ–æ¢¯åº¦å¹³å‡æ–¹æ³•ï¼Œæ›¿ä»£ reduce-scatter</li></ul><p>ZeRO++å°† ZeRO çš„é€šä¿¡é‡å‡å°‘äº† 4 å€ï¼Œå¹¶åœ¨ä½ç²¾åº¦ä¸‹ä¿æŒå‡†ç¡®æ€§ï¼Œä½¿å¾—åœ¨ 384 å¼  GPUä¸‹ï¼Œååé‡å¯ä»¥æé«˜ 2.16 å€</p><h3 id="Limitations-of-ZeRO"><a href="#Limitations-of-ZeRO" class="headerlink" title="Limitations of ZeRO"></a>Limitations of ZeRO</h3><p>åœ¨ä½å¸¦å®½é›†ç¾¤ä¸­ï¼Œå•å¡çš„ååé‡åªæœ‰é«˜å¸¦å®½é›†ç¾¤çš„ä¸€åŠï¼Œå³ä½¿åœ¨é«˜å¸¦å®½é›†ç¾¤ä¸­ï¼Œä½¿ç”¨æ•°åƒä¸ª GPU è¿›è¡Œè®­ç»ƒï¼Œå•å¡çš„ batch size ä¹Ÿå—åˆ° global batch size çš„é™åˆ¶ï¼ˆglobal batch size ä¸èƒ½æ— é™å¢åŠ ï¼Œå¦åˆ™ä¼šé™ä½æ¨¡å‹æ”¶æ•›æ•ˆç‡ï¼‰</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/1.webp" width="500" /></p><p>æ‰€ä»¥åœ¨åƒå¡è®­ç»ƒæ—¶ï¼Œå•å¡çš„ batch size å¿…é¡»éå¸¸å°ï¼Œè¿™ä¼šé™ä½è®¡ç®—ä¸é€šä¿¡çš„æ¯”ç‡</p><p>ZeRO ç”±äºå¯¹æ¨¡å‹çŠ¶æ€è¿›è¡Œåˆ†åŒºï¼Œæ— æ³•ç›´æ¥å¯¹æ¨¡å‹çŠ¶æ€å¤åˆ¶ï¼Œæ‰€ä»¥ä¸ä¹‹å‰çš„èŠ‚çœé€šä¿¡å·¥ä½œä¸å…¼å®¹</p><h3 id="ZeRO"><a href="#ZeRO" class="headerlink" title="ZeRO++"></a>ZeRO++</h3><p>å‡è®¾æ¨¡å‹å‚æ•°é‡ä¸º M</p><p>FWDï¼šå‚æ•° all gather</p><p>BWDï¼šå‚æ•° all gatherï¼Œæ¢¯åº¦ reduce scatter</p><p>é€šä¿¡é‡æ€»è®¡ 3M</p><h4 id="Quantized-Weight-Communication-qwZ"><a href="#Quantized-Weight-Communication-qwZ" class="headerlink" title="Quantized Weight Communication (qwZ)"></a>Quantized Weight Communication (qwZ)</h4><p>é€šä¿¡å‰ï¼Œå°†å‚æ•°ä» fp16 é‡åŒ–ä¸º int8ï¼Œä¸ºäº†ä¿è¯è®­ç»ƒå‡†ç¡®ç‡ï¼Œä½¿ç”¨ block-based é‡åŒ–çš„æ€æƒ³ï¼Œå¹¶ä½¿ç”¨ CUDA kernel ä¿è¯é«˜æ€§èƒ½</p><h4 id="Hierarchical-Weight-Partition-hpZ"><a href="#Hierarchical-Weight-Partition-hpZ" class="headerlink" title="Hierarchical Weight Partition (hpZ)"></a>Hierarchical Weight Partition (hpZ)</h4><p>åœ¨å•ä¸ªèŠ‚ç‚¹ä¸­ä¿å­˜æ•´ä¸ªæ¨¡å‹å‚æ•°çš„å‰¯æœ¬ï¼Œé€šè¿‡èŠ‚ç‚¹å†…çš„ all gather ä»£æ›¿èŠ‚ç‚¹é—´é€šä¿¡ï¼Œç‰ºç‰²æ˜¾å­˜ï¼ŒèŠ‚çœé€šä¿¡</p><h4 id="Quantized-Gradient-Communication-qgZ"><a href="#Quantized-Gradient-Communication-qgZ" class="headerlink" title="Quantized Gradient Communication  (qgZ)"></a>Quantized Gradient Communication  (qgZ)</h4><p>ç›´æ¥åœ¨ reduce scatter ä¹‹å‰é‡åŒ–ä¼šå½±å“ç²¾åº¦ï¼Œå¯ä»¥åœ¨é€šä¿¡è¿‡ç¨‹ä¸­ä½¿ç”¨ block-based INT4 é‡åŒ–å‹ç¼©æ¢¯åº¦ï¼Œå¹¶åœ¨å‘é€åæ¢å¤ä¿è¯è®­ç»ƒç²¾åº¦</p><p>ä¸¤æ­¥é€šä¿¡ï¼Œå…ˆèŠ‚ç‚¹å†…é€šä¿¡ï¼Œå†èŠ‚ç‚¹é—´é€šä¿¡</p><p>èŠ‚ç‚¹é—´é€šä¿¡ä½¿ç”¨æµæ°´çº¿ç­–ç•¥ï¼Œèåˆ CUDA Kernel</p><h4 id="Communication-Volume-Reduction"><a href="#Communication-Volume-Reduction" class="headerlink" title="Communication Volume Reduction"></a>Communication Volume Reduction</h4><p>qwZ: 1M â†’ 0.5</p><p>hpZ: 1M â†’ 0M</p><p>qgZ: 1M â†’ 0.25M</p><p>all: 3M â†’ 0.75M</p><h2 id="å…ˆå‰å·¥ä½œ"><a href="#å…ˆå‰å·¥ä½œ" class="headerlink" title="å…ˆå‰å·¥ä½œ"></a>å…ˆå‰å·¥ä½œ</h2><h3 id="3D-å¹¶è¡Œ"><a href="#3D-å¹¶è¡Œ" class="headerlink" title="3D å¹¶è¡Œ"></a>3D å¹¶è¡Œ</h3><p>3D å¹¶è¡Œè®­ç»ƒæµç¨‹</p><ol><li>all gather å‚æ•°</li><li>FWD</li><li>partition</li><li>all gather</li><li>BWD</li><li>partition</li><li>reduce scatter</li><li>ä¼˜åŒ–å™¨æ›´æ–°</li></ol><h4 id="ZeRO-ä¼˜åŒ–å™¨"><a href="#ZeRO-ä¼˜åŒ–å™¨" class="headerlink" title="ZeRO ä¼˜åŒ–å™¨"></a>ZeRO ä¼˜åŒ–å™¨</h4><p>ZeRO-3 æœ€é«˜æ•ˆåˆ©ç”¨å†…å­˜ï¼Œä½†éœ€è¦å¤šæ¬¡é€šä¿¡è§£å†³åˆ†åŒºé—®é¢˜</p><h4 id="Communication-Reduction-Techniques"><a href="#Communication-Reduction-Techniques" class="headerlink" title="Communication Reduction Techniques"></a>Communication Reduction Techniques</h4><p>é‡åŒ–é—®é¢˜ï¼šfp32/16 å¯¹æ¯” int8 æœ‰æ•°æ®èŒƒå›´å’Œç²’åº¦çš„å·®å¼‚</p><p>æ”¹è¿›æ–¹æ³•ï¼š</p><p>è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œç¼©å°æ•°å€¼èŒƒå›´å·®è·ï¼Œä½†å‡†ç¡®æ€§è¢«æ»¤æ³¢ç®—æ³•å½±å“ï¼Œä¸”æœ‰æ—¶é—´å¼€é”€<br>åˆ†å—é‡åŒ–ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œä½†éœ€è¦ä¿®æ”¹æ¨¡å‹ç»“æ„</p><p>æ¢¯åº¦å‹ç¼©ï¼š1-bit adam/lamb å¯ä»¥å®ç°é«˜æ•ˆçš„é€šä¿¡ï¼Œä½†å¿…é¡»ä¿è¯æ¯ä¸ª GPU ä¸Šéƒ½æœ‰æ¢¯åº¦å‰¯æœ¬ï¼Œç”±äº ZeRO-3 çš„åˆ†åŒºç­–ç•¥ï¼Œä¸èƒ½åº”ç”¨</p><h4 id="ZeRO-Communication-Reduction"><a href="#ZeRO-Communication-Reduction" class="headerlink" title="ZeRO Communication Reduction"></a>ZeRO Communication Reduction</h4><p>MiCS (åŸºäº DeepSpeed-v0.4.9 å’Œ PyTorch-v1.11)ï¼šå¯¹èŠ‚ç‚¹åˆ†ç»„ï¼Œæ¯ä¸ªç»„ä¿å­˜æ¨¡å‹çŠ¶æ€çš„å®Œæ•´å‰¯æœ¬ã€‚åœ¨æ¯ä¸ªç»„å†…ï¼Œæ¨¡å‹çŠ¶æ€è¢«åˆ†åŒºï¼Œä½¿æœ€é¢‘ç¹çš„å‚æ•° all gatheræ“ä½œåœ¨æ¯ä¸ªç»„ä¸Šè¿›è¡Œï¼Œä¸”å¹¶è¡Œå¤šä¸ªèŠ‚ç‚¹é—´çš„é›†ä½“é€šä¿¡ï¼Œåœ¨ç»„å†…çš„æ¢¯åº¦è¾¾åˆ°è¾¹ç•Œï¼Œåˆ™è¿›è¡Œç»„é—´é€šä¿¡ï¼Œæ­¤å¤–ï¼Œè¿˜é‡‡ç”¨äº†ç»†ç²’åº¦åŒæ­¥ã€åˆå¹¶é€šä¿¡ API å’Œå†…å­˜ç¢ç‰‡æ•´ç†ç­‰ä¼˜åŒ–</p><p>hpZ ä¸ MiCS ç±»ä¼¼ï¼Œä½†åªå¯¹æƒé‡åˆ†ç»„ï¼Œåœ¨æ¯ä¸ª gpu ä¸Šä¿ç•™å¯¹æ¨¡å‹çŠ¶æ€çš„åˆ†åŒºï¼Œç›¸æ¯” MiCS èŠ‚çœäº†å†…å­˜</p><h2 id="è®¾è®¡"><a href="#è®¾è®¡" class="headerlink" title="è®¾è®¡"></a>è®¾è®¡</h2><h3 id="qwZ"><a href="#qwZ" class="headerlink" title="qwZ"></a>qwZ</h3><p>ä¸ºäº†è§£å†³ç²¾åº¦ä¸‹é™ä¸¥é‡çš„é—®é¢˜ï¼Œä½¿ç”¨å—é‡åŒ–çš„æ€æƒ³ï¼Œå°†æ¯ä¸ªæƒé‡å¼ é‡è¢«åˆ’åˆ†ä¸ºæ›´å°çš„å—ï¼Œç„¶åä½¿ç”¨ç‹¬ç«‹çš„é‡åŒ–ç¼©æ”¾ç³»æ•°è¿›è¡Œå¯¹ç§°é‡åŒ–ä¸º INT8ï¼Œå‡å°‘äº† 3 å€é‡åŒ–è¯¯å·®</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/2.webp" width="500" /></p><h3 id="hpZ"><a href="#hpZ" class="headerlink" title="hpZ"></a>hpZ</h3><p>é‡‡ç”¨ä¸¤çº§åˆ†åŒºç­–ç•¥</p><ul><li>å…¨å±€ä¸»åˆ†åŒºï¼šæ‰€æœ‰æ¨¡å‹çŠ¶æ€åœ¨æ‰€æœ‰è®¾å¤‡ä¸Šå…¨å±€åˆ†åŒºï¼ˆå¦‚ZeRO-3ï¼‰</li><li>æ¬¡çº§åˆ†åŒºï¼šåœ¨æ¬¡å…¨å±€çº§åˆ«ï¼ˆä¾‹å¦‚ï¼Œè®¡ç®—èŠ‚ç‚¹ï¼‰åˆ›å»º FP16 å‚æ•°çš„æ¬¡çº§å‰¯æœ¬ï¼Œå¹¶åœ¨å¤šä¸ªæ¬¡çº§åˆ†åŒºä¸­å¤åˆ¶</li></ul><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/3.webp" width="500" /></p><p>åœ¨ FWD é˜¶æ®µï¼Œå¯¹æƒé‡åœ¨ä¸»åˆ†åŒºä¸Š all gatherã€‚æƒé‡åœ¨ FWD åï¼Œæ ¹æ®æ¬¡çº§åˆ†åŒºè¿›è¡Œåˆ†åŒºã€‚ç”±äº FWD/BWD ä¹‹é—´æ¨¡å‹å‚æ•°çš„å­˜åœ¨æ—¶åºä¸€è‡´æ€§ï¼Œåœ¨ BWD ä¸­å†æ¬¡éœ€è¦æƒé‡æ—¶ï¼ŒåŸºäºæ¬¡çº§åˆ†ç»„è¿›è¡Œ all gather</p><p>å½“æ¬¡çº§åˆ†åŒºè®¾ç½®ä¸ºè®¡ç®—èŠ‚ç‚¹æ—¶ï¼Œé¿å…äº† all gather è¿‡ç¨‹ä¸­çš„è·¨èŠ‚ç‚¹é€šä¿¡</p><p>åœ¨è¿­ä»£ç»“æŸæ—¶ï¼Œåœ¨ä¼˜åŒ–å™¨æ­¥éª¤ä¸­ï¼Œæ‰€æœ‰æ¨¡å‹çŠ¶æ€ä»¥åŠ FP16 å‚æ•°çš„ä¸»å‰¯æœ¬éƒ½æ ¹æ®ä¸»åˆ†åŒºæ›´æ–°</p><p>æ”¯æŒä»»ä½•æ¬¡çº§åˆ†åŒºå¤§å°ï¼Œå¹¶æ§åˆ¶æ¬¡çº§åˆ†åŒºä¸­çš„GPUæ•°é‡</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/4.webp" width="500" /></p><h3 id="qgZ"><a href="#qgZ" class="headerlink" title="qgZ"></a>qgZ</h3><p>åŸºäº all-to-all çš„é‡åŒ–æ¢¯åº¦é€šä¿¡ç­–ç•¥ï¼Œåªåœ¨é€šä¿¡ä¹‹å‰é‡åŒ–æ¢¯åº¦ï¼Œä½†åœ¨ä»»ä½• reduce æ“ä½œä¹‹å‰å°†å®ƒä»¬åé‡åŒ–åˆ°åŸæœ‰ç²¾åº¦ ï¼ŒåŠŸèƒ½ä¸Šç­‰åŒäºå‹ç¼©çš„ reduce-scatter æ“ä½œ</p><p>è§£å†³äº†ä¸¤ä¸ªé—®é¢˜ï¼š</p><ol><li>ç®€å•åœ°åœ¨ INT4/INT8 ä¸­å®æ–½ reduce-scatter ä¼šå¯¼è‡´æ˜¾è‘—ç²¾åº¦æŸå¤±</li><li>åœ¨ä¼ ç»Ÿ tree æˆ– ring-based reduce-scatter ä¸­ä½¿ç”¨é‡åŒ–éœ€è¦ä¸€é•¿ä¸²é‡åŒ–å’Œåé‡åŒ–æ­¥éª¤ï¼Œè¿™ç›´æ¥å¯¼è‡´è¯¯å·®ç§¯ç´¯å’Œæ˜¾è‘—çš„å»¶è¿Ÿ</li></ol><p>qgZ ä¸ä½¿ç”¨treeæˆ–ring-based reduce-scatterç®—æ³•ï¼Œè€Œæ˜¯åŸºäºä¸€ç§æ–°çš„åˆ†å±‚ all-to-all æ–¹æ³•</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/5.webp" width="500" /></p><p>qgZ ä¸­æœ‰ä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š</p><ol><li>æ¢¯åº¦åˆ‡ç‰‡é‡æ–°æ’åºï¼Œåœ¨ä»»ä½•é€šä¿¡å‘ç”Ÿä¹‹å‰ï¼Œå¯¹æ¢¯åº¦è¿›è¡Œåˆ‡ç‰‡å¹¶å¯¹å¼ é‡åˆ‡ç‰‡é‡æ–°æ’åºï¼Œä»¥ä¿è¯é€šä¿¡ç»“æŸæ—¶æ¯ä¸ª GPU ä¸Šçš„æœ€ç»ˆæ¢¯åº¦ä½ç½®æ˜¯æ­£ç¡®çš„</li><li>èŠ‚ç‚¹å†…é€šä¿¡å’Œ reduceï¼Œé‡åŒ–é‡æ–°æ’åºçš„æ¢¯åº¦åˆ‡ç‰‡ï¼Œåœ¨æ¯ä¸ªèŠ‚ç‚¹å†…è¿›è¡Œ all-to-all é€šä¿¡ï¼Œä» all-to-all ä¸­å¯¹æ¥æ”¶åˆ°çš„æ¢¯åº¦åˆ‡ç‰‡è¿›è¡Œåé‡åŒ–ï¼Œå¹¶è¿›è¡Œå±€éƒ¨ reduce</li><li>èŠ‚ç‚¹é—´é€šä¿¡å’Œ reduceï¼Œå†æ¬¡é‡åŒ–å±€éƒ¨reduceåçš„æ¢¯åº¦ï¼Œè¿›è¡ŒèŠ‚ç‚¹é—´çš„all-to-allé€šä¿¡ï¼Œå†æ¬¡å¯¹æ¥æ”¶åˆ°çš„æ¢¯åº¦è¿›è¡Œåé‡åŒ–ï¼Œå¹¶è®¡ç®—æœ€ç»ˆçš„é«˜ç²¾åº¦æ¢¯åº¦ reduce</li></ol><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/6.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/7.webp" width="500" /></p><p>ç»™å®šæ¯ä¸ªèŠ‚ç‚¹ N ä¸ª GPUã€M çš„æ¨¡å‹å¤§å°å’Œ Z çš„é‡åŒ–æ¯”ç‡ï¼ŒNCCL all-to-all å°†ç”Ÿæˆ M*N/Z è·¨èŠ‚ç‚¹æµé‡</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/8.webp" width="1000" /></p><p>ç›¸æ¯”ä¹‹ä¸‹ï¼Œé€šè¿‡ qgZï¼Œå°†æ¯ä¸ª GPU çš„è·¨èŠ‚ç‚¹æµé‡ä» M/Z å‡å°‘åˆ° M/(Z<em>N)ã€‚ å› æ­¤ï¼Œæ€»é€šä¿¡é‡ä» M</em>N/Z å‡å°‘åˆ° M<em>N/(Z</em>N) = M/Z</p><p>æ­¤å¤–ï¼Œé€šè¿‡é‡å èŠ‚ç‚¹å†…å’ŒèŠ‚ç‚¹é—´é€šä¿¡ä»¥åŠèåˆ CUDA å†…æ ¸æ¥è¿›ä¸€æ­¥ä¼˜åŒ– qgZ çš„ç«¯åˆ°ç«¯å»¶è¿Ÿ</p><ul><li>å¼ é‡åˆ‡ç‰‡é‡æ–°æ’åº (Tensor Slice Reordering)</li><li>èŠ‚ç‚¹å†…é‡åŒ– (Intra-node quantization)</li><li>èŠ‚ç‚¹å†…åé‡åŒ– (Intra-node Dequantization)</li><li>èŠ‚ç‚¹å†…æ¢¯åº¦æ•´åˆ (Intra-node Reduction)</li><li>èŠ‚ç‚¹é—´é‡åŒ– (inter-node quantization)</li></ul><h2 id="ä¼˜åŒ–å®ç°"><a href="#ä¼˜åŒ–å®ç°" class="headerlink" title="ä¼˜åŒ–å®ç°"></a>ä¼˜åŒ–å®ç°</h2><h3 id="Overlap-Compute-and-Communication"><a href="#Overlap-Compute-and-Communication" class="headerlink" title="Overlap Compute and Communication"></a>Overlap Compute and Communication</h3><ul><li>æ ¹æ®æ¨¡å‹å±‚çš„æ‰§è¡Œé¡ºåº</li><li>ä¿è¯é‡åŒ–å¼‚æ­¥æ‰§è¡Œ</li></ul><p>è·å–æ¯ä¸€å±‚çš„å‚æ•°ï¼Œåœ¨ä¸åŒçš„ CUDA æµä¸ŠåŒæ—¶å¯åŠ¨å½“å‰å±‚çš„é€šä¿¡å’Œä¸‹ä¸€å±‚çš„é‡åŒ–ã€‚å½“ä¸‹ä¸€å±‚éœ€è¦é‡åŒ–æ•°æ®æ—¶ï¼ŒZeRO++åŒæ­¥é‡åŒ–æµä»¥ç¡®ä¿é‡åŒ–æ•°æ®å‡†å¤‡å°±ç»ª</p><p>è¿™å¯ä»¥åœ¨å½“å‰å±‚çš„é€šä¿¡æ—¶é—´è·¨åº¦ä¸‹éšè—äº†ä¸‹ä¸€å±‚çš„é‡åŒ–æˆæœ¬ï¼Œéšè—äº†é‡åŒ–å¼€é”€</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/9.webp" width="500" /></p><p>åŸºäº all to all çš„æ¢¯åº¦é€šä¿¡åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šèŠ‚ç‚¹å†…é€šä¿¡å’ŒèŠ‚ç‚¹é—´é€šä¿¡</p><p>ä¸ºäº†åˆ©ç”¨èŠ‚ç‚¹é—´é€šä¿¡æ‰§è¡Œæ—¶ï¼ŒèŠ‚ç‚¹å†…é€šä¿¡çš„ç©ºé—²ï¼Œå®ç°äº†è¾“å…¥æ¢¯åº¦å¼ é‡çš„åˆ†å—å’Œ pipeline ä¼ è¾“</p><p>pipeline é˜¶æ®µè¶Šå¤šï¼Œé‡æ–°æ’åºæ‰€éœ€çš„ç»†ç²’åº¦å¼ é‡åˆ‡ç‰‡å°±è¶Šå¤š</p><p>æå‡ºäº†ä¸€ç§å¹¿ä¹‰å¼ é‡åˆ‡ç‰‡é‡æ–°æ’åºç®—æ³•ï¼Œæ¶µç›–äº† w/ å’Œ w/o pipeline æ•°æ®ä¼ è¾“çš„æƒ…å†µ</p><p>è¿™é‡Œçš„ stages æ˜¯æŒ‡æ‹¥æœ‰çš„ pipeline stage çš„æ•°é‡ï¼ŒnodeSize æ˜¯æ¯ä¸ªèŠ‚ç‚¹çš„ GPU æ•°é‡ï¼Œnodes æ˜¯èŠ‚ç‚¹çš„æ•°é‡</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/10.webp" width="500" /></p><h3 id="CUDA-Kernels"><a href="#CUDA-Kernels" class="headerlink" title="CUDA Kernels"></a>CUDA Kernels</h3><p>ä¸ºäº†æœ€å¤§åŒ–å¸¦å®½åˆ©ç”¨å’Œæœ€å°åŒ–å†…æ ¸å¼€é”€ï¼Œè®ºæ–‡ä¸­å®ç°å¹¶ä¼˜åŒ–äº†è‡ªå®šä¹‰CUDAæ ¸å¿ƒï¼Œç”¨äºå®ç°é‡åŒ–æ“ä½œ</p><p>å¼€å‘äº†ä¸€ä¸ªå¯ç»„åˆè¿ç®—ç¬¦çš„æ ¸å¿ƒé‡åŒ–å’Œåé‡åŒ–åº“ï¼Œåˆ©ç”¨é«˜æ•ˆçš„å‘é‡åŒ–å†…å­˜è®¿é—®æ¥æ»¡è¶³ç»™å®šGPUæ¶æ„æ”¯æŒçš„æœ€å¤§ç²’åº¦ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨æŒ‡ä»¤çº§å¹¶è¡Œæ€§é‡å å¤šä¸ªå†…å­˜äº‹åŠ¡</p><p>ä½¿ç”¨å¤šç§æŠ€æœ¯å‡å°‘é‡åŒ–å†…æ ¸çš„æ€»å†…å­˜æµé‡ã€‚ä¾‹å¦‚ï¼Œè°ƒæ•´æ¯ä¸ªé‡åŒ–å—çš„å¤§å°ï¼Œå°†å¼ é‡é‡å¡‘å’Œé‡åŒ–èåˆåˆ°åŒä¸€å†…æ ¸ä¸­ï¼Œé¿å…ä»å…¨å±€å†…å­˜ä¸­é‡å¤åŠ è½½æ•°æ®</p><p>æ­¤å¤–ï¼Œå°†è¿ç»­çš„åé‡åŒ–ã€å‡å°‘å’Œé‡åŒ–æ“ä½œèåˆåˆ°å•ä¸€å†…æ ¸å®ç°ä¸­</p><p>å‡å°‘äº† 9 å€çš„å†…å­˜æµé‡</p><h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><h3 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h3><ul><li>ç¡¬ä»¶é…ç½®ï¼šä½¿ç”¨åŒ…å«16ä¸ªV100 SXM3 32 GB GPUçš„24ä¸ªNVIDIA DGX-2èŠ‚ç‚¹ã€‚è¿™äº›èŠ‚ç‚¹é€šè¿‡å…·æœ‰NVIDIA SHARPæ”¯æŒçš„InfiniBandï¼ˆIBï¼‰è¿æ¥ï¼Œå®ç°è¶…è¿‡800 Gbpsçš„èŠ‚ç‚¹é—´å¸¦å®½</li><li>æµ‹è¯•ç¯å¢ƒï¼šä¸ºäº†è¯„ä¼°ZeRO++åœ¨ä¸åŒç½‘ç»œç¯å¢ƒä¸‹çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†é€šè¿‡å¯ç”¨1åˆ°8ä¸ªIBè¿æ¥ï¼ˆå³100 Gbpsåˆ°800 Gbpsï¼‰çš„ZeRO++è¿è¡Œæ€§èƒ½</li><li>åŸºå‡†è®¾ç½®ï¼šä½¿ç”¨ZeRO-3ä½œä¸ºåŸºå‡†ï¼Œå› å…¶ä¾¿äºå¤§è§„æ¨¡è®­ç»ƒå·¨å‹æ¨¡å‹ã€‚åŒæ—¶ï¼Œä¸ºäº†è¯„ä¼°ä¼˜åŒ–å†…æ ¸çš„æ€§èƒ½ï¼Œè¿˜ä½¿ç”¨äº†PyTorché‡åŒ–å’Œéèåˆå†…æ ¸å®ç°çš„ZeRO++ä½œä¸ºæ¶ˆèç ”ç©¶çš„åŸºçº¿</li><li>æ¨¡å‹é…ç½®ï¼šåŸºäºMegatron-Turing-NLGè®­ç»ƒ530Bæ¨¡å‹åœ¨2000ä¸ªGPUä¸Šä½¿ç”¨æ¯GPU 2000 tokençš„è®¾ç½®ï¼Œå¯¹ZeRO++ä½¿ç”¨ç›¸åŒçš„2000 tokenè®¾ç½®è¿›è¡Œè¯„ä¼°ã€‚è¿˜è¯„ä¼°äº†æ¯ GPU 1000 tokençš„è®¾ç½®ï¼Œä»¥æµ‹è¯•ZeRO++åœ¨æ›´æç«¯è§„æ¨¡çš„åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚è°ƒæ•´å±‚æ•°å’Œéšè—å±‚å¤§å°ä»¥æ„å»ºä¸åŒå¤§å°çš„æ¨¡å‹</li></ul><h3 id="ç»“æœ"><a href="#ç»“æœ" class="headerlink" title="ç»“æœ"></a>ç»“æœ</h3><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/11.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/12.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/13.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/14.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/15.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/16.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/17.webp" width="500" /></p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Extremely-Eficient-Collective-Communication-for-Giant-Model-Training/18.webp" width="500" /></p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>åˆå¹¶ä¸Šè¿°ä¸‰é¡¹ä¼˜åŒ–ï¼Œä½¿ç”¨ 384 V100 GPU è¿›è¡Œå¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒæ—¶ç³»ç»Ÿååé‡æé«˜ 2.16 å€</p>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¼€ä¸ªæ–°å‘: ç²¾è¯»pytorchæºç </title>
      <link href="/p/d343b623/"/>
      <url>/p/d343b623/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æ¯•è®¾æ‰“ç®—åšä¸ªç®€å•çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè°ƒç ”äº†å‡ ç§è¯­è¨€ç›®å‰çš„å®ç°ï¼Œå„æœ‰ä¼˜åŠ£ï¼Œå…ˆä»æœ€ç»å…¸çš„ torch è¯»èµ·ã€‚æ¬¢è¿æœ‹å‹ä»¬æå‡ºå»ºè®®</p><span id="more"></span><h2 id="mixed"><a href="#mixed" class="headerlink" title="mixed"></a>mixed</h2><p><a href="https://github.com/pytorch/pytorch">https://github.com/pytorch/pytorch</a></p><p><a href="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</a></p><p><a href="https://github.com/PaddlePaddle/Paddle">https://github.com/PaddlePaddle/Paddle</a></p><p><a href="https://github.com/mindspore-ai/mindspore">https://github.com/mindspore-ai/mindspore</a></p><h2 id="C"><a href="#C" class="headerlink" title="C"></a>C</h2><p><a href="https://github.com/ggerganov/ggml">https://github.com/ggerganov/ggml</a></p><h2 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h2><p><a href="https://github.com/huggingface/candle">https://github.com/huggingface/candle</a></p><p><a href="https://github.com/burn-rs/burn">https://github.com/burn-rs/burn</a></p><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p><a href="https://github.com/tensorlayer/TensorLayer">https://github.com/tensorlayer/TensorLayer</a></p><p><a href="https://github.com/alibaba/TinyNeuralNetwork">https://github.com/alibaba/TinyNeuralNetwork</a></p><h2 id="C-1"><a href="#C-1" class="headerlink" title="C++"></a>C++</h2><p><a href="https://github.com/xylcbd/EasyCNN">https://github.com/xylcbd/EasyCNN</a></p>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»: ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</title>
      <link href="/p/fc5b020/"/>
      <url>/p/fc5b020/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ZeRO-Infinity æ˜¯åŸºäº ZeRO çš„æ‰©å±•ï¼ŒInfinity ç¦»çº¿å¼•æ“å¯ä»¥åŒæ—¶åˆ©ç”¨ GPUã€CPU å’Œ NVMe å†…å­˜ï¼Œè¿˜æå‡ºäº†å…¶ä»–çš„ä¼˜åŒ–æŠ€æœ¯ã€‚</p><span id="more"></span><p>åŸæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/pdf/2104.07857.pdf">https://arxiv.org/pdf/2104.07857.pdf</a></p><p>å¼€æºä»£ç ï¼š<a href="https://github.com/microsoft/deepspeed">https://github.com/microsoft/deepspeed</a></p><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>GPU å†…å­˜å¢™ï¼šæ¨¡å‹è§„æ¨¡æˆé•¿äº† 1000 å€ï¼Œä½† GPU å†…å­˜åªå¢é•¿äº† 5 å€</p><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>ZeRO-Infinity æ˜¯åŸºäº ZeRO çš„æ‰©å±•ï¼ŒInfinity ç¦»çº¿å¼•æ“å¯ä»¥åŒæ—¶åˆ©ç”¨ GPUã€CPU å’Œ NVMe å†…å­˜ï¼Œè¿˜æå‡ºäº†ä»¥ä¸‹ä¸‰ä¸ªæŠ€æœ¯</p><ul><li>Memory-Centric Tilingï¼šå‡å°‘å¤§è§„æ¨¡æ“ä½œçš„GPUå†…å­˜éœ€æ±‚ï¼Œè€Œæ— éœ€ MP</li><li>Bandwidth-Centric Partitioningï¼šæŠ€æœ¯åˆ©ç”¨æ‰€æœ‰å¹¶è¡Œè®¾å¤‡çš„èšåˆå†…å­˜å¸¦å®½</li><li>Ease-Inspired Implementationï¼šé¿å…æ¨¡å‹ä»£ç é‡æ„</li></ul><h2 id="å…ˆå‰å·¥ä½œ"><a href="#å…ˆå‰å·¥ä½œ" class="headerlink" title="å…ˆå‰å·¥ä½œ"></a>å…ˆå‰å·¥ä½œ</h2><p>ZeROï¼š<a href="https://arxiv.org/abs/1910.02054">https://arxiv.org/abs/1910.02054</a></p><p>ZeRO-Offloadï¼š<a href="https://arxiv.org/pdf/2101.06840.pdf">https://arxiv.org/pdf/2101.06840.pdf</a></p><h2 id="æ˜¾å­˜éœ€æ±‚"><a href="#æ˜¾å­˜éœ€æ±‚" class="headerlink" title="æ˜¾å­˜éœ€æ±‚"></a>æ˜¾å­˜éœ€æ±‚</h2><blockquote><p>è¿™ä¸€èŠ‚æ²¡æœ‰æ ¹æ®è®ºæ–‡çš„å†…å®¹å†™ï¼Œè®ºæ–‡è®²çš„å¤ªç®€ç•¥äº†ï¼Œçœ‹çš„ç³Šé‡Œç³Šæ¶‚</p></blockquote><p>å†…å­˜å¯ä»¥ä»ä¸¤ä¸ªæ–¹é¢ä¼˜åŒ–</p><ul><li>æ¨¡å‹çŠ¶æ€ï¼šæ¢¯åº¦ï¼Œå‚æ•°ï¼Œä¼˜åŒ–å™¨çŠ¶æ€</li><li>å‰©ä½™çŠ¶æ€ï¼šä¸­é—´æ¿€æ´»å€¼ã€ä¸´æ—¶bufferã€æ˜¾å­˜ç¢ç‰‡ç­‰ã€‚ä¸‹é¢æˆ‘ä»¬åªè®¨è®ºä¸­é—´æ¿€æ´»å€¼çš„æ˜¾å­˜å ç”¨</li></ul><h2 id="æ¨¡å‹çŠ¶æ€å†…å­˜"><a href="#æ¨¡å‹çŠ¶æ€å†…å­˜" class="headerlink" title="æ¨¡å‹çŠ¶æ€å†…å­˜"></a>æ¨¡å‹çŠ¶æ€å†…å­˜</h2><h3 id="æ¨¡å‹å‚æ•°é‡"><a href="#æ¨¡å‹å‚æ•°é‡" class="headerlink" title="æ¨¡å‹å‚æ•°é‡"></a>æ¨¡å‹å‚æ•°é‡</h3><p>ä¸ºäº†æ–¹ä¾¿åˆ†æï¼Œå®šä¹‰ transformer æ¨¡å‹çš„å±‚æ•°ä¸º lï¼Œéšè—å±‚ç»´åº¦ä¸º hï¼Œæ³¨æ„åŠ›å¤´æ•°ä¸º aã€‚</p><p>è¯è¡¨å¤§å°ä¸º vï¼Œè®­ç»ƒæ•°æ®çš„æ‰¹æ¬¡å¤§å°ä¸º bï¼Œåºåˆ—é•¿åº¦ä¸º s</p><p>transformeræ¨¡å‹ç”± l ä¸ªç›¸åŒçš„å±‚ç»„æˆï¼Œæ¯ä¸ªå±‚åˆ†ä¸º self-attention å—å’Œ MLP å—</p><ul><li><p>self-attentionï¼šå‚æ•°æœ‰ q, k, v çš„æƒé‡çŸ©é˜µå’Œ wq, wk, wv çš„åç½® bq, bk, bvï¼Œè¾“å‡ºæƒé‡çŸ©é˜µ wo å’Œåç½® boï¼Œ4 ä¸ªæƒé‡çŸ©é˜µçš„å½¢çŠ¶ä¸º [h, h]ï¼Œ4ä¸ªåç½®çš„å½¢çŠ¶ä¸º [h]ã€‚æ‰€ä»¥ self-attention å—çš„å‚æ•°é‡ä¸º  4h^2 + 4h</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/1.webp" width="800" /></p></li><li><p>MLPï¼šç”± 2 ä¸ªçº¿æ€§å±‚ç»„æˆï¼Œä¸€èˆ¬ç¬¬ä¸€ä¸ªçº¿æ€§å±‚æ˜¯å…ˆå°†ç»´åº¦ä» h æ˜ å°„åˆ° 4h ï¼Œç¬¬äºŒä¸ªçº¿æ€§å±‚å†å°†ç»´åº¦ä» 4h æ˜ å°„åˆ° hã€‚ç¬¬ä¸€ä¸ªçº¿æ€§å±‚çš„æƒé‡çŸ©é˜µ  çš„å½¢çŠ¶ä¸º [h,4h] ï¼Œåç½®çš„å½¢çŠ¶ä¸º [4h] ã€‚ç¬¬äºŒä¸ªçº¿æ€§å±‚æƒé‡çŸ©é˜µçš„å½¢çŠ¶ä¸º [4h,h] ï¼Œåç½®å½¢çŠ¶ä¸º [h] ã€‚æ‰€ä»¥ MLP å—çš„å‚æ•°é‡ä¸º 8h^2+5h</p></li><li><p>layer normalizationï¼šself-attention å—å’Œ MLP å—å„æœ‰ä¸€ä¸ª layer normalizationï¼ŒåŒ…å«å¯è®­ç»ƒçš„ç¼©æ”¾å‚æ•°å’Œå¹³ç§»å‚æ•°ï¼Œå½¢çŠ¶éƒ½æ˜¯ [h] ã€‚2ä¸ªlayer normalizationçš„å‚æ•°é‡ä¸º 4h</p></li></ul><p>æ‰€ä»¥æ¯ä¸ª transformer å±‚çš„å‚æ•°é‡ä¸º 12h^2+13hï¼Œæ­¤å¤–è¿˜æœ‰</p><ul><li>embdding å±‚ï¼šç»´åº¦é€šå¸¸ç­‰äºéšè—å±‚ç»´åº¦ hï¼Œå‚æ•°é‡ä¸º vhã€‚æœ€åçš„è¾“å‡ºå±‚çš„æƒé‡çŸ©é˜µé€šå¸¸ä¸ embdding å±‚æ˜¯å‚æ•°å…±äº«çš„</li><li>ä½ç½®ç¼–ç ï¼šå¦‚æœé‡‡ç”¨å¯è®­ç»ƒå¼çš„ä½ç½®ç¼–ç ï¼Œä¼šæœ‰ä¸€äº›å¯è®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œæ•°é‡æ¯”è¾ƒå°‘ã€‚å¦‚æœé‡‡ç”¨ç›¸å¯¹ä½ç½®ç¼–ç ï¼Œä¾‹å¦‚ RoPE å’Œ ALiBiï¼Œåˆ™ä¸åŒ…å«å¯è®­ç»ƒçš„æ¨¡å‹å‚æ•°ã€‚è¿™é‡Œå¿½ç•¥è¿™éƒ¨åˆ†å‚æ•°</li></ul><p>ç»¼ä¸Šï¼Œl å±‚ transformer æ¨¡å‹çš„å¯è®­ç»ƒæ¨¡å‹å‚æ•°é‡ä¸º l(12h^2+13h)+vhã€‚å½“éšè—ç»´åº¦ h è¾ƒå¤§æ—¶ï¼Œå¯ä»¥å¿½ç•¥ä¸€æ¬¡é¡¹ï¼Œè¿‘ä¼¼ä¸º 12lh^2</p><p>ç›®å‰ä¸»æµçš„å¤§æ¨¡å‹è®­ç»ƒæ–¹æ³•æ˜¯ä½¿ç”¨ Adam ä¼˜åŒ–å™¨è¿›è¡Œæ··åˆç²¾åº¦è®­ç»ƒï¼Œå‚æ•°å’Œæ¢¯åº¦å­˜å‚¨ä¸º FP16ï¼Œä¼˜åŒ–å™¨çŠ¶æ€åŒ…æ‹¬ FP32 çš„åŠ¨é‡ã€æ–¹å·®ã€å‚æ•°å’Œæ¢¯åº¦ï¼Œå› æ­¤æ¯ä¸ªå‚æ•°éœ€è¦ 20bï¼ˆ2<em>2b + 4</em>4bï¼‰ çš„æ˜¾å­˜ï¼Œæ€»æ˜¾å­˜å ç”¨å°±æ˜¯ 240 lh^2 å­—èŠ‚</p><h2 id="å‰©ä½™çŠ¶æ€å†…å­˜"><a href="#å‰©ä½™çŠ¶æ€å†…å­˜" class="headerlink" title="å‰©ä½™çŠ¶æ€å†…å­˜"></a>å‰©ä½™çŠ¶æ€å†…å­˜</h2><h3 id="ä¸­é—´æ¿€æ´»å€¼"><a href="#ä¸­é—´æ¿€æ´»å€¼" class="headerlink" title="ä¸­é—´æ¿€æ´»å€¼"></a>ä¸­é—´æ¿€æ´»å€¼</h3><p>å¯ä»¥ç†è§£ä¸ºå‰å‘ä¼ é€’è¿‡ç¨‹ä¸­è®¡ç®—å¾—åˆ°çš„ï¼Œå¹¶åœ¨åå‘ä¼ é€’è¿‡ç¨‹ä¸­éœ€è¦ç”¨åˆ°çš„æ‰€æœ‰ tensor</p><ul><li>layer normalization å±‚ï¼šè®¡ç®—æ¢¯åº¦æ—¶éœ€è¦ç”¨åˆ°å±‚çš„è¾“å…¥ bsh å­—èŠ‚ï¼Œè¾“å…¥çš„å‡å€¼å’Œæ–¹å·® bs å­—èŠ‚ï¼Œç”±äº h ä¸€èˆ¬æ˜¯åƒä½ï¼Œæ‰€ä»¥ layer normalization æ˜¾å­˜è¿‘ä¼¼ä¸º bsh å­—èŠ‚</li><li>dropout å±‚ï¼šåœ¨è®­ç»ƒä¸­å­˜å‚¨ä¸º mask çŸ©é˜µï¼Œæ¯ä¸ªå…ƒç´ åªå  1 å­—èŠ‚</li></ul><p>æ¯ä¸ª transformer å±‚åŒ…å«äº†ä¸€ä¸ª self-attention å—å’Œ MLP å—ï¼Œå¹¶åˆ†åˆ«å¯¹åº”ä¸€ä¸ª layer normalization è¿æ¥</p><h4 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h4><p>è®¡ç®—å…¬å¼ä¸º</p><script type="math/tex; mode=display">Q=xW_q,K=xW_k,V=xW_v \\x_{out} = softmax(\frac{QK^T}{\sqrt{h}})\cdot V\cdot W_o +x</script><ul><li><p>Q, K, Vï¼šéœ€è¦ä¿å­˜å…±åŒè¾“å…¥ xï¼Œè¿™å°±æ˜¯ä¸­é—´æ¿€æ´»ï¼Œx shape ä¸º [b, s, h]ï¼Œå…ƒç´ ä¸ªæ•°ä¸º bshï¼Œå ç”¨æ˜¾å­˜ä¸º 2bsh å­—èŠ‚</p><blockquote><p>è¿™é‡Œçš„ shape ä¸­æ²¡æœ‰ a æ˜¯å› ä¸ºåœ¨è®¡ç®—æ—¶ï¼Œæ¯ä¸ª head å¯¹åº”çš„ hidden size è¢«é™¤ä»¥äº† headï¼Œä¸€ä¹˜ä¸€é™¤ï¼ŒåŒ–ç®€äº†</p></blockquote></li><li><p>QK^Tï¼šéœ€è¦ä¿å­˜ Q, Kï¼Œshape éƒ½æ˜¯ [b, s, h]ï¼Œå ç”¨æ˜¾å­˜å¤§å°ä¸º 4bsh<br>softmax()ï¼šéœ€è¦ä¿å­˜å‡½æ•°è¾“å…¥ QK^Tï¼ŒQ shape [b, a, s, h]ï¼ŒK^T shape [b, a, h, s]ï¼ŒQK^T shape [b, a, s, s]ï¼Œå ç”¨æ˜¾å­˜ä¸º 2bs^2a</p></li><li><p>dropoutï¼šè®¡ç®—å®Œ softmax åå¾—åˆ° scoreï¼Œéœ€è¦è®¡ç®— dropoutï¼Œä¿å­˜ mask çŸ©é˜µï¼Œshape ä¸ QK^T ç›¸åŒï¼Œå ç”¨æ˜¾å­˜ä¸º bs^2a</p></li><li><p>è®¡ç®— v ä¸Šçš„ attention ï¼Œscore * vï¼Œéœ€è¦ä¿å­˜ scoreï¼š2bs^2a ï¼Œvï¼š2bshï¼Œæ€»åˆ 2bs^2a+2bsh</p></li><li><p>è®¡ç®—è¾“å‡ºæ˜ å°„å’Œä¸€ä¸ª dropoutï¼Œè¾“å‡ºæ˜ å°„éœ€è¦ä¿å­˜å…¶è¾“å…¥ï¼Œ2bsh å­—èŠ‚ï¼Œç»“åˆ dropout 3bsh</p></li></ul><p>ç»¼ä¸Šæ‰€è¿°ï¼Œself-attention å—ä¸­é—´æ¿€æ´»å ç”¨æ˜¾å­˜ä¸º 11bsh + 5bs^2a å­—èŠ‚</p><h4 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h4><p>è®¡ç®—å…¬å¼ä¸º</p><script type="math/tex; mode=display">x = f_{gelu} (x_{out}W_1)W_2 + x_{out}</script><ul><li>linear_1ï¼š2bsh</li><li>æ¿€æ´»å‡½æ•°ï¼š8bsh</li><li>linear_2ï¼š8bsh</li><li>dropoutï¼šbsh</li></ul><p>ç»¼ä¸Šæ‰€è¿°ï¼ŒMLP å—ä¸­é—´æ¿€æ´»å ç”¨æ˜¾å­˜ä¸º 19bsh å­—èŠ‚</p><p>å¦å¤–ï¼Œself-attention å—å’Œ MLP å—å…±å¯¹åº”ä¸¤ä¸ª layer normalizationï¼Œå…¶è¾“å…¥åˆè®¡ä¸º 2bshï¼Œä¸­é—´æ¿€æ´» 4bsh</p><p>æ¯ä¸ª transformer å±‚ä¸­é—´æ¿€æ´»å ç”¨æ˜¾å­˜ä¸º 34bsh + 5bs^2a å­—èŠ‚</p><p>ä»¥ GPT3-175B æ¨¡å‹ä¸ºä¾‹ï¼Œæ¨¡å‹é…ç½®å¦‚ä¸‹</p><ul><li>layerï¼ˆlï¼‰ï¼š96</li><li>hidden sizeï¼ˆhï¼‰ï¼š12288</li><li>attention headï¼ˆaï¼‰ï¼š96</li><li>sequence lengthï¼ˆsï¼‰ï¼š2048</li></ul><p>å‡è®¾é‡‡ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œéƒ½é‡‡ç”¨ bf16 æˆ– fp16 å­˜å‚¨ï¼Œæ¯ä¸ªå…ƒç´ å 2ä¸ªbytesï¼Œåˆ™æ¨¡å‹å‚æ•°å ç”¨æ˜¾å­˜ä¸º 350 GB</p><div class="table-container"><table><thead><tr><th>batch sizeï¼ˆbï¼‰</th><th>ä¸­é—´æ¿€æ´»æ˜¾å­˜ (34bsh + 5bs^2a)*l</th><th>ä¸­é—´æ¿€æ´»æ˜¾å­˜/æ¨¡å‹å‚æ•°æ˜¾å­˜</th></tr></thead><tbody><tr><td>1</td><td>275 GB</td><td>79%</td></tr><tr><td>64</td><td>17.6 TB</td><td>5000%</td></tr><tr><td>128</td><td>35.3 TB</td><td>10100%</td></tr></tbody></table></div><p>å¯ä»¥çœ‹åˆ°ä¸­é—´æ¿€æ´»å ç”¨æ˜¾å­˜ï¼Œå¯ä»¥é€šè¿‡æ¿€æ´»å€¼ checkpoint æŠ€æœ¯æ˜¾è‘—å‡å°‘æ¿€æ´»æ‰€éœ€çš„å†…å­˜ï¼Œä½†ä»£ä»·æ˜¯å¢åŠ äº† 0.33 å€é‡è®¡ç®—</p><p>å®šä¹‰ c ä¸ºä¸¤ä¸ªæ¿€æ´»å€¼ checkpoint ä¹‹é—´çš„ Transformer å—æ•°é‡</p><p>å¤§å‹æ¨¡å‹å¦‚ Turing-NLG 17.2B å’Œ GPT-3 175B éƒ½æ˜¯ä½¿ç”¨è¯¥æ–¹æ³•è¿›è¡Œè®­ç»ƒçš„ã€‚å­˜å‚¨æ¿€æ´»å€¼ checkpoint æ‰€éœ€çš„å†…å­˜è¿‘ä¼¼ä¼°è®¡ä¸º 2bsh * l/c</p><p>ä¸‹å›¾ a ç¬¬ 7 åˆ—æ˜¯å­˜å‚¨æ¿€æ´»å€¼ checkpoint æ‰€éœ€çš„å†…å­˜</p><p>å‡è®¾ bï¼š32ï¼Œsï¼š1024ï¼Œcï¼š1ï¼Œè™½ç„¶ç”Ÿæˆçš„æ¿€æ´»å€¼ checkpoint æ¯”å®Œæ•´çš„ä¸­é—´æ¿€æ´»å°å‡ ä¸ªæ•°é‡çº§ï¼Œä½†åœ¨è¶…è¿‡ä¸‡äº¿å‚æ•°æ—¶ï¼ŒGPU å†…å­˜ä»ç„¶æ— æ³•å­˜å‚¨æ‰€æœ‰ä¸­é—´æ¿€æ´»å€¼</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/2.webp" width="800" /></p><h3 id="æ¨¡å‹çŠ¶æ€å·¥ä½œå†…å­˜-MSWM"><a href="#æ¨¡å‹çŠ¶æ€å·¥ä½œå†…å­˜-MSWM" class="headerlink" title="æ¨¡å‹çŠ¶æ€å·¥ä½œå†…å­˜ (MSWM)"></a>æ¨¡å‹çŠ¶æ€å·¥ä½œå†…å­˜ (MSWM)</h3><p>æ˜¯åœ¨æ‰€æœ‰æ¨¡å‹çŠ¶æ€è¢« offload è‡³ CPU æˆ– NVMe åï¼Œåœ¨æ¨¡å‹ä¸­æ‰§è¡Œå‰å‘æˆ– BWD æ‰€éœ€çš„æœ€å° GPU å†…å­˜å ç”¨</p><p>ä»ä¸Šå›¾ (a) å€’æ•°ç¬¬ 2 åˆ—å¾—çŸ¥ï¼Œåœ¨è¶…è¿‡ 1k äº¿ä¸ªå‚æ•°åï¼Œæ˜¾å­˜éœ€æ±‚æ¿€å¢ï¼Œåœ¨é‡åˆ° MLP ä¸­çš„ linear ç”³è¯·å­˜å‚¨ 8h^2+5h ä¸ªå‚æ•°çš„è¿ç»­å†…å­˜æ—¶ï¼Œæ²¡æœ‰è¶³å¤Ÿçš„è¿ç»­ç©ºé—´ï¼Œä¸‹æ–‡æå‡ºäº†ä¸€ç§æœ‰åˆ«äº MP çš„æ–¹æ³•è§£å†³è¿™ä¸ªé—®é¢˜</p><h3 id="æ¿€æ´»å€¼å·¥ä½œå†…å­˜-AWM"><a href="#æ¿€æ´»å€¼å·¥ä½œå†…å­˜-AWM" class="headerlink" title="æ¿€æ´»å€¼å·¥ä½œå†…å­˜ (AWM)"></a>æ¿€æ´»å€¼å·¥ä½œå†…å­˜ (AWM)</h3><p>æ˜¯åœ¨è¿›è¡Œ BWD ä¹‹å‰ï¼Œåœ¨ BWD ä¸­é‡è®¡ç®—æ¿€æ´»æ‰€éœ€çš„å†…å­˜ã€‚è¿™å–å†³äºä¸¤ä¸ªè¿ç»­æ¿€æ´»å€¼ checkpoint ä¹‹é—´çš„æ¿€æ´»å¤§å°</p><p>ç»“åˆä¸Šå›¾ (a) æœ€å 1 åˆ—ï¼ŒAWM ç”±å‡ åä¸ªä¸­é—´æ¿€æ´»å±‚å‚æ•°ç»„æˆï¼Œåªè¦æ€»çš„ AWM å ç”¨æ»¡è¶³æ˜¾å­˜ï¼Œä¸ä¼šé‡åˆ°è¿ç»­ç©ºé—´ä¸è¶³çš„é—®é¢˜</p><h3 id="å¸¦å®½éœ€æ±‚"><a href="#å¸¦å®½éœ€æ±‚" class="headerlink" title="å¸¦å®½éœ€æ±‚"></a>å¸¦å®½éœ€æ±‚</h3><p>åŠ è½½ CPU å’Œ NVMe å†…å­˜å…³é”®æ˜¯æœ‰é™çš„å¸¦å®½æ˜¯å¦ä¼šå½±å“è®­ç»ƒæ•ˆç‡ã€‚æ–‡ä¸­æè¿°äº†å¸¦å®½å¯¹è®­ç»ƒæ•ˆç‡çš„å½±å“ã€‚å®šä¹‰äº†æ•ˆç‡ efficiency</p><p>å‡è®¾æ²¡æœ‰è®¡ç®—é€šä¿¡é‡å ï¼Œæ‰§è¡Œå·¥ä½œè´Ÿè½½ï¼Œä½¿ç”¨å³°å€¼è®¡ç®—ååé‡ penk_tpï¼Œæ•°æ®ç§»åŠ¨å¸¦å®½ bwï¼Œç®—æœ¯å¼ºåº¦ ait è¯„ä¼°è®­ç»ƒæ•ˆç‡</p><p>ait æ˜¯æ€»è®¡ç®—é‡ä¸è®¡ç®—éœ€è¦ç§»åŠ¨çš„æ•°æ®ä¹‹é—´çš„æ¯”ç‡ï¼Œæè¿°äº†æ¯æ¬¡æ•°æ®ç§»åŠ¨çš„è®¡ç®—é‡ï¼Œæ›´é«˜çš„ ait è¡¨ç¤ºå¯¹å¸¦å®½çš„è¦æ±‚æ›´ä½</p><p>æ•ˆç‡ efficiency æ¨å¯¼å¦‚ä¸‹</p><script type="math/tex; mode=display">\begin{align}compute\_time & = \frac{total\_computation}{peak_{tp}} \\\\ait & = \frac{total\_computation}{total\_data\_mouement} \\\\communication\_time & = \frac{total\_data\_mouement}{bw} \\& = \frac{total\_computation}{ait \times bw} \\\\efficiency & = \frac{compute\_time}{compute\_time + communication\_time} \\& = \frac{ait \times bw}{ait \times bw + peak_{tp}}\end{align}</script><h3 id="Quantifying-AIT-in-DL-training"><a href="#Quantifying-AIT-in-DL-training" class="headerlink" title="Quantifying AIT in DL training"></a>Quantifying AIT in DL training</h3><p>æ¨¡å‹çŠ¶æ€å’Œæ¿€æ´»å€¼ checkpoint æœ‰ä¸åŒçš„ ait å€¼ï¼Œæ–‡ä¸­é€šè¿‡æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­çš„æ€»è®¡ç®—é‡ï¼Œè®¡ç®—æ¯ä¸ªæ¨¡å‹çŠ¶æ€å’Œæ¿€æ´»å€¼çš„æ•°æ®ç§»åŠ¨é‡è¿›è¡Œ ait é‡åŒ–</p><ul><li>æ€»è®¡ç®—é‡ï¼šæ¯æ¬¡è¿­ä»£çš„æ€»è®¡ç®—é‡ä¸»è¦å–å†³äº Transformer ä¸­çš„å‚æ•° pï¼Œåºåˆ—é•¿åº¦ s å’Œ batch sizeï¼Œå³ 2bspï¼ŒBWD çš„è®¡ç®—é‡å¤§çº¦æ˜¯ FWD çš„ä¸¤å€ã€‚æ­¤å¤–ï¼Œæ¿€æ´»å€¼ checkpoint åœ¨ BWD æœŸé—´éœ€è¦è¿›è¡Œé¢å¤–çš„æ­£å‘è®¡ç®—ï¼Œæ‰€ä»¥æ¯æ¬¡è¿­ä»£çš„æ€»è®¡ç®—é‡ä¸º 8 bsp</li><li>å‚æ•°å’Œæ¢¯åº¦ï¼šå‚æ•°åœ¨ FWD å’Œ BWD æœŸé—´è‡³å°‘éœ€è¦ä» CPU åŠ è½½åˆ° GPU ä¸¤æ¬¡ï¼Œå­˜åœ¨ 2p çš„æ•°æ®ç§»åŠ¨é‡ï¼Œåœ¨ä½¿ç”¨æ¿€æ´»å€¼ checkpoint æ—¶ï¼Œå‚æ•°å¯èƒ½éœ€è¦åœ¨ BWD æœŸé—´è¿›è¡Œé¢å¤–çš„åŠ è½½ï¼Œå¢åŠ äº†é¢å¤– 1p çš„æ•°æ®ç§»åŠ¨é‡ã€‚æ­¤å¤–ï¼Œæ¢¯åº¦å¿…é¡»è‡³å°‘ä» GPU å­˜å‚¨åˆ°å…¶ç›®æ ‡ä½ç½®ä¸€æ¬¡ï¼Œå¢åŠ äº†æœ€å1p çš„æ•°æ®ç§»åŠ¨é‡ï¼Œå‡è®¾å‚æ•°å’Œæ¢¯åº¦å­˜å‚¨åœ¨ç›¸åŒçš„ç›®æ ‡ä½ç½®ï¼ŒFWD å’Œ BWD æœŸé—´çš„æ€»æ•°æ®ç§»åŠ¨é‡ä¸º 4pï¼Œå³ 8p å­—èŠ‚ã€‚æ¯æ¬¡è¿­ä»£çš„æ€»è®¡ç®—é‡ï¼Œå› æ­¤ ait ä¸å‚æ•°å’Œæ¢¯åº¦çš„å…³ç³»ä¸º bs</li><li>ä¼˜åŒ–å™¨çŠ¶æ€ï¼šä¼˜åŒ–å™¨çŠ¶æ€è‡³å°‘éœ€è¦è¯»å–å’Œå†™å…¥ä¸€æ¬¡ GPUï¼Œæ€»æ•°æ®ç§»åŠ¨é‡ä¸º 2osï¼Œçº¦ä¸º 2<em>16p å­—èŠ‚ï¼ˆç»“åˆä¸Šæ–‡çš„ adamï¼Œç¬”è€…è®¤ä¸ºæ˜¯ 2</em>20p å­—èŠ‚ï¼‰ï¼Œå› æ­¤åœ¨å®Œæ•´çš„è®­ç»ƒè¿­ä»£è¿‡ç¨‹ä¸­ï¼Œait ä¸ä¼˜åŒ–å™¨çŠ¶æ€å…³ç³»ä¸º bs/4<br>æ¿€æ´»å€¼ checkpointï¼šåœ¨ FWD ä¸­ï¼Œæ¿€æ´»å€¼ checkpoint å¿…é¡»ä¿å­˜åˆ°ç›®æ ‡ä½ç½®ï¼Œå¹¶åœ¨ BWD æœŸé—´æ£€ç´¢ã€‚æ€»æ•°æ®ç§»åŠ¨é‡ä¸æ¿€æ´»å€¼ checkpoint çš„å…³ç³»ä¸º 2 <em> bsh </em> l/cï¼Œait ä¸æ¿€æ´»å€¼ checkpoint çš„å…³ç³»ä¸º 24hc</li></ul><h3 id="Bandwidth-Requirements"><a href="#Bandwidth-Requirements" class="headerlink" title="Bandwidth Requirements"></a>Bandwidth Requirements</h3><p>ç”±äº ait çš„å˜åŒ–ï¼Œæ¨¡å‹çŠ¶æ€å’Œæ¿€æ´» checkpoint æœ‰éå¸¸ä¸åŒçš„å¸¦å®½è¦æ±‚ã€‚æ¨¡å‹çŠ¶æ€ä»…å–å†³äº bsï¼Œæ¿€æ´» checkpoint å–å†³äº ch</p><p>ç”±ä¸Šé¢çš„å…¬å¼å¾—çŸ¥ï¼Œefficiency çš„å¸¦å®½éœ€æ±‚è¿˜å–å†³äº peak_tpï¼Œä½œè€…ä½¿ç”¨ NVIDIA V100 DGX-2 SuperPOD é›†ç¾¤è¿›è¡Œäº†å¦‚ä¸‹å®éªŒ</p><p>å®éªŒå‡è®¾äº†ä¸åœ¨å®éªŒå˜é‡ä¸­çš„å…¶ä»–é€šä¿¡å¸¦å®½æ— é™ï¼Œä¸” peak_tp æ˜¯ç†è®ºå³°å€¼</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/3.webp" width="800" /></p><ul><li>aï¼šå‚æ•°å’Œæ¢¯åº¦çš„å¸¦å®½è¶…è¿‡70 GB/sï¼Œå³ä½¿æ˜¯æœ€å°çš„ batch sizeï¼Œä¹Ÿå¯ä»¥å®ç°50%ä»¥ä¸Šçš„æ•ˆç‡ï¼Œåœ¨è¿™ä¸ªå¸¦å®½ä¸‹ï¼Œåªè¦ bz è¶³å¤Ÿå¤§ï¼Œæ•°æ®ç§»åŠ¨å¯ä»¥ä¸è®¡ç®—å®Œå…¨é‡å ï¼Œä»¥å®ç°100%çš„æ•ˆç‡</li><li>bï¼šç›¸æ¯” aï¼Œä¼˜åŒ–å™¨çŠ¶æ€éœ€è¦é«˜å‡ºè¿‘ 4 å€çš„å¸¦å®½æ‰èƒ½è¾¾åˆ° 50% æ•ˆç‡ã€‚æ­¤å¤–ï¼Œä¼˜åŒ–å™¨çŠ¶æ€åœ¨ FWD å’Œ BWD ç»“æŸæ—¶æ›´æ–°ï¼Œå¹¶ä¸”ä¸èƒ½ä¸è®¡ç®—é‡å </li><li>cï¼šå¯ç”¨æ¿€æ´»å€¼ checkpoint åï¼Œå³ä½¿ h ä¸º 2kï¼Œ2GB/s çš„å¸¦å®½ä¹Ÿèƒ½ç»´æŒ 50% ä»¥ä¸Šçš„æ•ˆç‡ã€‚ä¸€æ—¦ h è¶…è¿‡ 8kï¼Œå¸¦å®½éœ€æ±‚å°†é™è‡³ 1 GB/s ä»¥ä¸‹</li></ul><h2 id="ZeRO-Infinity-è®¾è®¡æ¦‚è§ˆ"><a href="#ZeRO-Infinity-è®¾è®¡æ¦‚è§ˆ" class="headerlink" title="ZeRO-Infinity è®¾è®¡æ¦‚è§ˆ"></a>ZeRO-Infinity è®¾è®¡æ¦‚è§ˆ</h2><p>GPU é›†ç¾¤åœ¨å­˜å‚¨å™¨æ–¹é¢å…·æœ‰é«˜åº¦å¼‚æ„æ€§ã€‚é™¤äº†GPUå†…å­˜å¤–ï¼Œè¿˜æœ‰ CPU å†…å­˜ä»¥åŠæ— é™å¤§ï¼ˆInfinityï¼‰çš„ NVMe ç£ç›˜ç©ºé—´ã€‚ZeRO-Infinity é€šè¿‡åˆ©ç”¨è¿™äº›å¼‚æ„å­˜å‚¨å™¨ï¼Œçªç ´äº† GPU å†…å­˜å£å’ã€‚ä¸‹å›¾æ¯”è¾ƒäº† 3D å¹¶è¡Œå’Œ ZeRO-Infinity æ‰€èƒ½è¾¾åˆ°çš„æœ€å¤§æ¨¡å‹è§„æ¨¡ï¼Œå…¶æ”¯æŒæ¯ä¸ª NVIDIA V100 DGX-2 èŠ‚ç‚¹ 1 ä¸‡äº¿ä¸ªå‚æ•°ï¼Œç›¸æ¯” 3D å¹¶è¡Œå¢åŠ äº† 50 å€</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/4.webp" width="500" /></p><p>ç¤ºæ„å›¾</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/5.webp" width="500" /></p><h3 id="Design-for-Unprecedented-Scale"><a href="#Design-for-Unprecedented-Scale" class="headerlink" title="Design for Unprecedented Scale"></a>Design for Unprecedented Scale</h3><ul><li>Infinity offload engine for model statesï¼šZeRO Infinity åŸºäº ZeRO-3 è®¾è®¡ï¼Œå¯¹æ‰€æœ‰æ¨¡å‹çŠ¶æ€è¿›è¡Œåˆ†åŒºï¼Œæ¶ˆé™¤å†…å­˜å†—ä½™ï¼Œè®¾è®¡äº† Infinity offload engineï¼Œå°†æ‰€æœ‰åˆ†åŒºæ¨¡å‹çŠ¶æ€ offload åˆ° CPU æˆ– NVMeï¼Œæˆ–è€…æ ¹æ®å†…å­˜éœ€æ±‚ä¿ç•™åœ¨ GPU ä¸Šã€‚è¯·æ³¨æ„ï¼Œä¸Šé¢å›¾ 2a å’Œå›¾ 2b ä¸­ï¼Œ96 ä¸ªèŠ‚ç‚¹ï¼ˆ1536ä¸ªGPUï¼‰çš„ DGX-2 é›†ç¾¤çš„æ€» NVMe å†…å­˜è¶³å¤Ÿå­˜å‚¨ 100  ä¸‡äº¿å‚æ•°æ¨¡å‹çš„æ¨¡å‹çŠ¶æ€</li><li>CPU Offload for activationsï¼šå°†æ¿€æ´»å€¼å†…å­˜ offload åˆ° CPU å†…å­˜ä¸­</li><li>Memory-centric tiling for working memoryï¼šZeRO-Infinity å¯ä»¥æ”¯æŒä»»æ„å¤§å°çš„ç®—å­ï¼Œä¸ä¾èµ– MPï¼Œå°†å¤§å‹ç®—å­åˆ†è§£ä¸ºç”±åŸå§‹ç®—å­çš„å‚æ•°åˆ‡ç‰‡ç»„æˆçš„æ•°å­¦ä¸Šç­‰ä»·çš„è¾ƒå°çº¿æ€§ç®—å­åºåˆ—ï¼Œé€ä¸ªè·å–å’Œé‡Šæ”¾æ¯ä¸ªåˆ‡ç‰‡çš„å‚æ•°å’Œæ¢¯åº¦</li></ul><h3 id="Design-for-Excellent-Training-Efficiency"><a href="#Design-for-Excellent-Training-Efficiency" class="headerlink" title="Design for Excellent Training Efficiency"></a>Design for Excellent Training Efficiency</h3><p>é—®é¢˜ï¼šå¸¦å®½ä¸åŒ¹é…ï¼šGPU &gt; CPU &gt; NVMe</p><p>å¿…è¦å¸¦å®½ï¼š</p><ul><li>å‚æ•°å’Œæ¢¯åº¦ï¼š70GB/s</li><li>ä¼˜åŒ–å™¨çŠ¶æ€ï¼š1.5TB/s</li><li>æ¿€æ´»å€¼ checkpointï¼š1-4 GB/s</li></ul><h4 id="ä¼˜åŒ–å‚æ•°å’Œæ¢¯åº¦æ•ˆç‡"><a href="#ä¼˜åŒ–å‚æ•°å’Œæ¢¯åº¦æ•ˆç‡" class="headerlink" title="ä¼˜åŒ–å‚æ•°å’Œæ¢¯åº¦æ•ˆç‡"></a>ä¼˜åŒ–å‚æ•°å’Œæ¢¯åº¦æ•ˆç‡</h4><p>æå‡ºäº†ä¼˜åŒ–ä¸¤ç§æ–¹æ¡ˆ</p><ul><li>åŸºäºå¸¦å®½çš„åˆ’åˆ†ç­–ç•¥ï¼ˆæ²¡æ˜ç™½ï¼Œçœ‹æ‡‚ä»£ç åå†æ¥æ›´ï¼‰</li><li>é‡å è®¡ç®—é€šä¿¡</li></ul><h4 id="æé«˜ä¼˜åŒ–å™¨çŠ¶æ€æ•ˆç‡"><a href="#æé«˜ä¼˜åŒ–å™¨çŠ¶æ€æ•ˆç‡" class="headerlink" title="æé«˜ä¼˜åŒ–å™¨çŠ¶æ€æ•ˆç‡"></a>æé«˜ä¼˜åŒ–å™¨çŠ¶æ€æ•ˆç‡</h4><p>åŸºäº ZeRO-Offload ï¼Œå¯ä»¥åˆ©ç”¨èšåˆçš„ GPU å’Œ CPU å†…å­˜å¸¦å®½ä»¥åŠèšåˆçš„ CPU è®¡ç®—æ¥è¿›è¡Œä¼˜åŒ–å™¨æ›´æ–°ï¼Œä¸åŒæ˜¯çš„ï¼Œåœ¨ NVMe offload æ—¶ï¼Œéœ€è¦å°†æ•°æ®ä» NVMe ä¼ è¾“åˆ° CPU å†…å­˜ï¼Œå¹¶ä»¥é€‚åˆ CPU å†…å­˜çš„å—å¤§å°è¿›è¡Œä¼˜åŒ–å™¨æ›´æ–°ï¼Œä¸€æ¬¡ä¸€ä¸ªå—åœ°è¿›è¡Œï¼Œè¿™ä¼šå—åˆ° NVMe â†’ CPU å¸¦å®½çš„é™åˆ¶ï¼Œå¯ä»¥å¤šä¸ªèŠ‚ç‚¹èšåˆ NVMe å¸¦å®½</p><p>ä¸è¶³ï¼šå¯èƒ½ä¼šå¯¼è‡´ CPU å†…å­˜ç¢ç‰‡åŒ–ï¼ˆPyTorch 2.0 æå‡ºäº†æ–°çš„å†…å­˜ç¢ç‰‡æ•´ç†ç­–ç•¥ï¼Œåé¢æœ‰æ—¶é—´çœ‹çœ‹ï¼‰</p><h4 id="ä¼˜åŒ–æ¿€æ´»å€¼æ•ˆç‡"><a href="#ä¼˜åŒ–æ¿€æ´»å€¼æ•ˆç‡" class="headerlink" title="ä¼˜åŒ–æ¿€æ´»å€¼æ•ˆç‡"></a>ä¼˜åŒ–æ¿€æ´»å€¼æ•ˆç‡</h4><p>æ¯ä¸ª GPU é€šè¿‡ PCIe ä»¥ 3GB/s çš„é€Ÿåº¦å¹¶è¡Œè¯»å†™æ•°æ®åˆ° CPUï¼Œå¯ä»¥è¶…è¿‡ 80% çš„æ•ˆç‡ï¼ˆå¯¹äºéšè—å¤§å°å¤§äº8Kï¼‰ï¼Œå‡å°‘æ¿€æ´»å€¼ checkpoint é¢‘ç‡ä¹Ÿå¯ä»¥æé«˜æ•ˆç‡</p><h3 id="Design-for-Ease-of-Use"><a href="#Design-for-Ease-of-Use" class="headerlink" title="Design for Ease of Use"></a>Design for Ease of Use</h3><p>ä¸åŒäº MPï¼Œç”¨æˆ·ä¸éœ€è¦åœ¨è®¾è®¡æ¨¡å‹æ—¶è€ƒè™‘èƒ½å¦å¹¶è¡Œ</p><p>æå‡ºäº†ä¸¤ä¸ªä¼˜åŒ–ç­–ç•¥ï¼Œåé¢å†…å®¹æœ‰å®ç°ç»†èŠ‚</p><ul><li>automated data movementï¼šé€šè¿‡å‘ PyTorch å­æ¨¡å—æ³¨å…¥ FWD/BWD hooks è§¦å‘å‚æ•°çš„æ”¶é›†å’Œåˆ†åŒºæ“ä½œã€‚åœ¨ FWD/BWD ä¹‹å‰ï¼Œè¿›è¡Œ allgather æ”¶é›†æ•°æ®ã€‚è€Œåœ¨ FWD/BWD ä¹‹åï¼Œé€šè¿‡ hooks è§¦å‘å‚æ•°å’Œæ¢¯åº¦çš„åˆ†åŒºï¼Œå¯é€‰æ‹©å°†å®ƒä»¬è½¬ç§»åˆ° CPU æˆ– NVMe</li><li>automated model partitoiningï¼šé€šè¿‡åŒ…è£…æ‰€æœ‰æ¨¡å—ç±»çš„æ„é€ å‡½æ•°ï¼Œä½¿æ¯ä¸ªå­æ¨¡å—çš„å‚æ•°åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­è¿›è¡Œåˆ†åŒºå’Œç§»åŠ¨</li></ul><h2 id="æ•ˆç‡ä¼˜åŒ–"><a href="#æ•ˆç‡ä¼˜åŒ–" class="headerlink" title="æ•ˆç‡ä¼˜åŒ–"></a>æ•ˆç‡ä¼˜åŒ–</h2><p>ä¸‹é¢ä¼˜åŒ–ä¸Šä¸€èŠ‚æå‡ºçš„æ”¹è¿›ç‚¹</p><h3 id="Bandwidth-Centric-Partitioning"><a href="#Bandwidth-Centric-Partitioning" class="headerlink" title="Bandwidth-Centric Partitioning"></a>Bandwidth-Centric Partitioning</h3><p>ZeRO-Infinity æå‡ºäº†æ–°çš„æ•°æ®æ˜ å°„å’Œæ£€ç´¢ç­–ç•¥ï¼Œä»¥è§£å†³ NVMe å’Œ CPU å†…å­˜å¸¦å®½é™åˆ¶çš„é—®é¢˜</p><p>ä¸ ZeRO å’Œ ZeRO-Offload ä¸åŒçš„æ˜¯ï¼ŒZeRO-Infinity å°†æ¯ä¸ªå±‚çš„å‚æ•°åˆ’åˆ†åˆ°æ‰€æœ‰çš„ DP è¿›ç¨‹ä¸­ï¼Œå¹¶ä¸”åœ¨è®¿é—®å‚æ•°æ—¶ä½¿ç”¨ allgather è€Œä¸æ˜¯ broadcastï¼ŒåŸå› å¦‚ä¸‹ï¼š</p><p>å½“æ•°æ®ä½äº GPU ä¸Šæ—¶ï¼Œ broadcast å’Œ allgather é€šä¿¡æˆæœ¬ç›¸åŒï¼Œ</p><p>ä½†å½“æ•°æ®ä½äº NVMe æˆ– CPU æ—¶ï¼Œ</p><ul><li>å¦‚æœä½¿ç”¨ braodcastï¼Œç”±äºæ¯ä¸ªå‚æ•°å®Œå…¨ç”±ä¸€ä¸ª DP è¿›ç¨‹æ‹¥æœ‰ï¼Œå‚æ•°å¿…é¡»å…ˆé€šè¿‡ PCIe ä»å…¶æºä½ç½®ä¼ è¾“åˆ° GPU å†…å­˜ï¼Œç„¶åæ‰èƒ½ broadcastï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­åªæœ‰ä¸€ä¸ª PCIe å¯ä»¥å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œè€Œè¿æ¥åˆ°å…¶ä»–æ‰€æœ‰ GPU çš„ PCIe é“¾è·¯éƒ½å¤„äºé—²ç½®çŠ¶æ€</li><li>å¦‚æœä½¿ç”¨ allgatherï¼Œæ‰€æœ‰ PCIe é“¾è·¯éƒ½åŒæ—¶å¤„äºæ´»åŠ¨çŠ¶æ€ï¼Œæ¯ä¸ªé“¾è·¯ä¼ è¾“ 1/dp çš„å‚æ•°ï¼Œè¿™æ · CPU/NVMe ä¸ GPU ä¹‹é—´çš„é€šä¿¡å¸¦å®½ä¼šéšç€ dp çº¿æ€§å¢é•¿</li></ul><p>åœ¨å¤§è§„æ¨¡è®­ç»ƒæ—¶ï¼Œè¯¥æ–¹æ³•å¯ä»¥æä¾› Infinity çš„å¼‚æ„å†…å­˜å¸¦å®½ï¼Œä¾‹å¦‚åœ¨ 64 ä¸ª DGX-2 èŠ‚ç‚¹ä¸Šï¼ŒZeRO-Infinity å¯ä»¥è·å¾—è¶…è¿‡ 3TB/s çš„ CPU å†…å­˜å¸¦å®½å’Œè¶…è¿‡ 1.5TB/s çš„ NVMe å¸¦å®½</p><h3 id="Overlap-Centric-Design"><a href="#Overlap-Centric-Design" class="headerlink" title="Overlap Centric Design"></a>Overlap Centric Design</h3><p>è§£å†³åœ¨å•ä¸ª GPU æˆ–å•ä¸ªèŠ‚ç‚¹ä¸­ï¼Œå¸¦å®½ä»ç„¶å¯èƒ½æˆä¸ºç“¶é¢ˆçš„é—®é¢˜ã€‚</p><p>å³ä½¿æ˜¯ GPU ä¹‹é—´çš„ allgather é€šä¿¡åœ¨å° batch size ï¼ˆå›¾3ï¼‰ä¸‹ä¹Ÿä¼šå¯¹æ•ˆç‡äº§ç”Ÿé‡å¤§å½±å“</p><p>æ­¤å¤–ï¼Œè®¿é—® NVMe å†…å­˜éœ€è¦è¿›è¡Œä¸‰ä¸ªæ­¥éª¤</p><ul><li>NVMe â†’ CPU</li><li>CPU â†’ GPU</li><li>GPU â†’ GPU (allgather)</li></ul><p>å¦‚æœé¡ºåºæ‰§è¡Œä¸Šé¢æ­¥éª¤ï¼Œæ•ˆç‡ä¼šå¾ˆå·®ã€‚ ZeRO-Infinity æå‡ºäº† overlap engineï¼ŒåŒ…æ‹¬</p><p>dynamic prefetcherï¼šåœ¨ FWD/BWD æ—¶ï¼Œè¦ä½¿ç”¨å‚æ•°ä¹‹å‰ï¼Œå¹¶è¡Œæ‰§è¡Œå‚æ•°çš„ç§»åŠ¨ã€‚å®æ—¶è·Ÿè¸ª FWD/BWDWï¼Œæ„å»ºæ¯æ¬¡è¿­ä»£çš„ç®—å­åºåˆ—çš„å†…éƒ¨æ˜ å°„ï¼Œï¼Œè·Ÿè¸ªç®—å­åºåˆ—çš„ä½ç½®ï¼Œå¹¶è¡ŒåŠ è½½å³å°†æ‰§è¡Œç®—å­çš„å‚æ•°ï¼Œå¦‚åœ¨æ‰§è¡Œç®—å­çš„è®¡ç®—æ—¶ï¼Œå¯¹å³å°†æ‰§è¡Œçš„ 3 ä¸ªç®—å­ä¾æ¬¡å¹¶è¡Œæ‰§è¡Œ NVMe â†’ CPUï¼ŒCPU â†’ GPU å’Œ GPU â†’ GPUã€‚å½“ FWD/BWD å‘ç”Ÿå˜åŒ–æ—¶ï¼Œä¹Ÿå¯ä»¥æ›´æ–°ç®—å­åºåˆ—æ˜ å°„</p><p>communication and offload overlapping mechanismï¼šå¹¶è¡Œæ‰§è¡Œ BWD ä¸æ¢¯åº¦æ›´æ–°ç§»åŠ¨ã€‚ç±»ä¼¼ä¸Šé¢ï¼Œåœ¨è®¡ç®— BWD ç®—å­æ—¶ï¼Œå¯¹å·²ç»æ‰§è¡Œçš„ 2 ä¸ªç®—å­ä¾æ¬¡å¹¶è¡Œæ‰§è¡Œæ¢¯åº¦æ›´æ–°ä¸ GPU â†’ CPU æ¢¯åº¦ä¼ è¾“</p><h3 id="Infinity-Offload-Engine"><a href="#Infinity-Offload-Engine" class="headerlink" title="Infinity Offload Engine"></a>Infinity Offload Engine</h3><h4 id="DeepNVMe"><a href="#DeepNVMe" class="headerlink" title="DeepNVMe"></a>DeepNVMe</h4><p>C++ NVMe è¯»/å†™åº“ï¼Œå¼‚æ­¥å®Œæˆçš„æ‰¹é‡è¯»/å†™è¯·æ±‚ï¼Œï¼Œåˆ·æ–°æ­£åœ¨è¿›è¡Œçš„è¯»/å†™çš„æ˜¾å¼åŒæ­¥è¯·æ±‚ã€‚å…è®¸å°†è¿™äº›è¯·æ±‚ä¸ GPU â†’ GPU æˆ– GPU â†’ CPU é€šä¿¡è®¡ç®—é‡å </p><p>å®ç°äº†æ¥è¿‘å³°å€¼çš„ NVMe é¡ºåºè¯»å†™å¸¦å®½ï¼ŒåŒ…æ‹¬å¯¹ I/O è¯·æ±‚çš„å¹¶è¡ŒåŒ–ï¼Œæ™ºèƒ½å·¥ä½œè°ƒåº¦ï¼Œé¿å…æ•°æ®å¤åˆ¶å’Œå†…å­˜å›ºå®š</p><h4 id="Pinned-memory-management-layer"><a href="#Pinned-memory-management-layer" class="headerlink" title="Pinned memory management layer"></a>Pinned memory management layer</h4><p>ç¡®ä¿ NVMe â†’ CPU è¯»/å†™ é«˜æ€§èƒ½çš„æ•°æ®ï¼Œæ•°æ®å¿…é¡»ä¿å­˜åœ¨å›ºå®šå†…å­˜ç¼“å†²åŒºä¸­ã€‚è¯¥å±‚é€šè¿‡é‡å¤ä½¿ç”¨å°‘é‡ï¼ˆæ•°åGBï¼‰çš„å†…å­˜æ¥ç®¡ç†æœ‰é™çš„å›ºå®šå†…å­˜ä¾›åº”ï¼Œä»¥å°†æ•´ä¸ªæ¨¡å‹çŠ¶æ€ï¼ˆæ•°åTBï¼‰ offload åˆ° CPU/NVMeã€‚</p><p>å†…å­˜ç¼“å†²åŒºé‡å¤ä½¿ç”¨å¯é˜²æ­¢ CPU/GPU å†…å­˜ç¢ç‰‡åŒ–ï¼Œè¿˜ä¸º PyTorch æ•°æ®æä¾›å…·æœ‰å›ºå®šå†…å­˜æ•°æ®çš„åŠŸèƒ½ï¼Œå…è®¸åœ¨åŸå§‹åœ°å€è®¡ç®—ï¼Œç„¶åå°†å…¶å†™å…¥ NVMeï¼Œæ— éœ€è¿›ä¸€æ­¥å¤åˆ¶ä»¥æé«˜å¸¦å®½</p><h2 id="å®ç°ç»†èŠ‚"><a href="#å®ç°ç»†èŠ‚" class="headerlink" title="å®ç°ç»†èŠ‚"></a>å®ç°ç»†èŠ‚</h2><p>ZeRO Infinity åŸºäº PyTorch ä»£ç å®ç°ï¼Œå¹¶ä¸”ä¸ç”¨é‡æ„ä»»ä½•æ¨¡å‹ä»£ç </p><h3 id="Automating-Data-Movement"><a href="#Automating-Data-Movement" class="headerlink" title="Automating Data Movement"></a>Automating Data Movement</h3><p>ZeRO-Infinity éœ€è¦åè°ƒæ¨¡å‹å‚æ•°ã€æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€æ•°æ®ç§»åŠ¨ï¼Œå¿…é¡»ç¡®ä¿è¿™äº›æ•°æ®åœ¨è¢«ä½¿ç”¨å‰ç§»åŠ¨åˆ° GPU å†…å­˜ä¸­ï¼Œå¹¶åœ¨ä½¿ç”¨ä¹‹åé‡æ–°åˆ†é…ä½ç½®</p><p>PyTorch æ¨¡å‹ä»¥å±‚çº§æ¨¡å—çš„å½¢å¼è¡¨ç¤ºï¼Œä»£è¡¨ç€ç¥ç»ç½‘ç»œçš„å„ä¸ªå±‚æ¬¡ã€‚ä¾‹å¦‚ï¼ŒTransformer æ¶æ„ä¸­åŒ…å«äº†è¯¸å¦‚è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç½‘ç»œç­‰å­æ¨¡å—ã€‚è‡ªæ³¨æ„åŠ›å­æ¨¡å—åˆåŒ…å«äº†çº¿æ€§å±‚å’Œå…¶ä»–å­æ¨¡å—</p><p>ZeRO-Infinity ä¼šé€’å½’åœ°å‘æ¨¡å‹çš„å­æ¨¡å—ä¸­æ’å…¥ hooks ï¼Œä»¥è‡ªåŠ¨åŒ–æ‰€éœ€çš„æ•°æ®ç§»åŠ¨ã€‚åœ¨å­æ¨¡å—çš„ FWD å¼€å§‹æ—¶ï¼Œè¿™äº› hooks ä¼šç¡®ä¿å­æ¨¡å—çš„å‚æ•°å¯ç”¨äºè®¡ç®—ï¼Œå¦åˆ™å®ƒä»¬å°†æ‰§è¡Œ allgather æ“ä½œï¼Œå¹¶é˜»å¡åˆ°å‚æ•°å¯ç”¨</p><p>ç±»ä¼¼ä¸Šæ–‡ä»‹ç»çš„åŸºäºé‡å çš„è®¾è®¡ï¼Œåœ¨å­æ¨¡å—çš„ FWD/BWD ç»“æŸæ—¶ï¼Œå†æ¬¡å¯¹å‚æ•°è¿›è¡Œåˆ†åŒºï¼Œå¹¶å¯é€‰æ‹©å°†å…¶è½¬ç§»ï¼Œå‡å°‘å‚æ•°é€šä¿¡æ—¶çš„é˜»å¡</p><h3 id="Auto-Registration-of-External-Parameters"><a href="#Auto-Registration-of-External-Parameters" class="headerlink" title="Auto Registration of External Parameters"></a>Auto Registration of External Parameters</h3><p>åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œä¸€ä¸ªå­æ¨¡å—çš„å‚æ•°å’Œæ¢¯åº¦åªåœ¨è‡ªå·±çš„ FWD/BWD ä¸­ä½¿ç”¨ï¼Œè¿™æ ·å¯ä»¥å¾ˆå®¹æ˜“åœ°è¯†åˆ«å¹¶è‡ªåŠ¨åŒ–æ•°æ®ç§»åŠ¨ï¼Œä½†æŸäº›æ¨¡å‹æ¶æ„ä¾‹å¤–ï¼Œå…¶ä¸­åœ¨ä¸€ä¸ªå­æ¨¡å—ä¸­å®šä¹‰å’Œåˆ†é…çš„å‚æ•°åœ¨ä¸åŒå­æ¨¡å—çš„ FWD/BWD ä¸­éƒ½è¢«ä½¿ç”¨</p><p>ä¾‹å¦‚ï¼ŒGPT ç­‰æ¨¡å‹åœ¨ç½‘ç»œçš„å¼€å¤´å’Œç»“å°¾éƒ½å…±äº« embedding å±‚çš„æƒé‡</p><p>å°†ä¸Šé¢è¿™ç§è·¨æ¨¡å—è¾¹ç•Œä½¿ç”¨çš„å‚æ•°ç§°ä¸ºå¤–éƒ¨å‚æ•°ï¼Œè¿™å¾ˆéš¾çŸ¥é“åœ¨ä¸€ä¸ªå­æ¨¡å—çš„ FWD/BWD çš„å¼€å§‹æ—¶åº”è¯¥æ”¶é›†å“ªäº›å‚æ•°</p><p>äºæ˜¯æå‡ºäº†å°†å¤–éƒ¨å‚æ•°æ‰‹åŠ¨æ³¨å†Œåˆ° ZeRO-Infinity ä¸­ï¼Œä»¥ä¾¿åœ¨è®¿é—®å®ƒä»¬çš„å­æ¨¡å—çš„ FWD/BWD ä¸­è¿›è¡Œ gatherï¼Œæ³¨å†Œåï¼Œå¤–éƒ¨å‚æ•°å°†åƒå…¶ä»–å‚æ•°ä¸€æ ·ï¼Œå°†è¢«åŒ…å«åœ¨ dynamic prefetcher ä¸­</p><p>æ­¤å¤–è¿˜æä¾›äº†æ£€æµ‹è¿™äº›åœºæ™¯å¹¶è‡ªåŠ¨æ³¨å†Œå¤–éƒ¨å‚æ•°æœºåˆ¶ï¼Œä¸ç”¨æ›´æ”¹ä»»ä½•ä»£ç </p><ul><li>æˆªè·åˆ†åŒºå‚æ•°è®¿é—®ï¼šPyTorch æ¨¡å—å°†å…¶æ•°æ®å‚æ•°å­˜å‚¨åœ¨å“ˆå¸Œè¡¨ä¸­ã€‚åœ¨åˆå§‹åŒ–æ—¶ï¼Œä½¿ç”¨å­ç±»ç±»å‹æ›¿æ¢å“ˆå¸Œè¡¨ï¼Œè¦†ç›–æ•°æ®çš„è®¿é—®æ–¹æ³•ã€‚å½“è®¿é—®ä¸€ä¸ªåˆ†åŒºå‚æ•°æ—¶ï¼Œå¯¹è¯¥å‚æ•°è¿›è¡Œé˜»å¡çš„ allgatherï¼Œå°†å…¶æ³¨å†Œä¸ºå¤–éƒ¨å‚æ•°ï¼Œç„¶åè¿”å›æ”¶é›†åˆ°çš„å‚æ•°</li><li>æ¿€æ´»ä¿¡æ¯æ£€æµ‹ï¼šå­æ¨¡å—çš„ FWD å¯èƒ½ä¼šè¿”å›ä¸€ä¸ªå‚æ•°ï¼Œä¾›å¦ä¸€ä¸ªå­æ¨¡å—çš„ FWD/BWD ä½¿ç”¨ã€‚ä¾‹å¦‚ï¼ŒMegatron-LM ä¸­çº¿æ€§å±‚ FWD åè¿”å› biasï¼Œåœ¨çˆ¶ Transformer å±‚æ¨¡å—ä¸­ä½¿ç”¨ï¼Œå†æ£€æŸ¥æ¯ä¸ªå­æ¨¡å— FWD è¿”å›çš„æ¿€æ´»å€¼è¾“å‡ºä¸­æ˜¯å¦åŒ…å«åˆ†åŒºå‚æ•°ï¼Œå¦‚æœåŒ…å«ï¼Œåˆ™å¯¹å…¶è¿›è¡Œæ”¶é›†å’Œæ³¨å†Œï¼Œä½œä¸ºå¤–éƒ¨å‚æ•°</li></ul><h3 id="Automatic-Model-Partitioning-during-Initialization"><a href="#Automatic-Model-Partitioning-during-Initialization" class="headerlink" title="Automatic Model Partitioning during Initialization"></a>Automatic Model Partitioning during Initialization</h3><p>éœ€è¦åœ¨åˆå§‹åŒ–æ—¶åˆ’åˆ†æ¨¡å‹çš„æ¯ä¸ªå±‚å¯¹åº”çš„å‚æ•°ï¼Œè€Œä¸æ˜¯åœ¨æ•´ä¸ªæ¨¡å‹åˆå§‹åŒ–ä¹‹åå†è¿›è¡Œåˆ’åˆ†ï¼Œä»¥èŠ‚çœå³°å€¼å†…å­˜</p><p>æä¾›äº†ä¸€ä¸ª Python ZeRO-Infinity ä¸Šä¸‹æ–‡ï¼Œç”¨äºä¿®é¥° torch.nn.Module çš„ <strong>init</strong> æ–¹æ³•ï¼Œåœ¨æ¯ä¸ªæ¨¡å—åˆå§‹åŒ–ä¹‹åï¼Œç«‹å³å°†å…¶åˆ†é…çš„å‚æ•°åˆ’åˆ†åœ¨æ‰€åœ¨è¿›ç¨‹ç»„ä¸­</p><p>åªæœ‰å•ç‹¬çš„å­æ¨¡å—åœ¨å®Œå…¨åˆå§‹åŒ–ä¹‹åæ‰ä¼šè¢«åˆ’åˆ†ï¼Œæ•´ä¸ªæ¨¡å‹ä¸ä¼šåœ¨æ‰€æœ‰å¹¶è¡Œè¿›ç¨‹ä¸Šå¤åˆ¶ã€‚ä¸€ä¸ªæ‹¥æœ‰ 5 åƒäº¿ä¸ªå‚æ•°çš„æ¨¡å‹åªéœ€è¦ 1TB çš„èšåˆ CPU å†…å­˜å°±å¯ä»¥åœ¨åˆå§‹åŒ–æœŸé—´å®Œå…¨åˆ’åˆ†</p><h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><h3 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h3><p>é›†ç¾¤ï¼šV100 SXM3 32 GB GPU * 512</p><p>é€šä¿¡å¸¦å®½ï¼š800 Gbps</p><p>no MP benchmarkï¼štorch DDP</p><p>MP benchmarkï¼šMegatron-LM</p><p>æ¨¡å‹ï¼šGPTï¼ˆs = 1024ï¼‰</p><p>æ¨¡å‹é…ç½®å¦‚ä¸‹</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/6.webp" width="800" /></p><h3 id="Model-Size"><a href="#Model-Size" class="headerlink" title="Model Size"></a>Model Size</h3><p>Infinityï¼š32 ä¸‡äº¿å‚æ•°</p><p>3D å¹¶è¡Œï¼š6500 äº¿å‚æ•°</p><p>å›¾5aï¼Œæå‡ 50 å€</p><h3 id="Model-Speed"><a href="#Model-Speed" class="headerlink" title="Model Speed"></a>Model Speed</h3><p>Infinity è®­ç»ƒ 20 ä¸‡äº¿å‚æ•°æ—¶ï¼Œä¸ 3D å¹¶è¡Œæœ‰å‡ ä¹ç›¸åŒçš„ååé‡</p><p>è¿›ä¸€æ­¥å¢åŠ æ¨¡å‹å¤§å°ï¼Œç”±äº3Då¹¶è¡Œçš„å†…å­˜é™åˆ¶ï¼Œä¼š OOMï¼Œè€Œ Infinity ååé‡ä¸º 49 TFlops/GPU</p><p>åœ¨æé™æƒ…å†µä¸‹ï¼Œç”±äº CPU å†…å­˜æœ‰é™ï¼Œå¯¼è‡´æ¯ä¸ª GPU çš„ batch size éå¸¸å°ï¼Œå›¾5aæ˜¾ç¤ºæ€§èƒ½ä¸‹é™ï¼Œå¯ä»¥é€šè¿‡å¢åŠ  CPU å†…å­˜æˆ–è€…å°†æ¿€æ´»å€¼ checkpoint è½¬ç§»åˆ° NVMe ä¸­æ”¹å–„</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/7.webp" width="800" /></p><h3 id="Superlinear-Scalability"><a href="#Superlinear-Scalability" class="headerlink" title="Superlinear Scalability"></a>Superlinear Scalability</h3><p>é€šè¿‡æœ‰æ•ˆåˆ©ç”¨èšåˆ PCIe å’Œ NVMe å¸¦å®½çš„çº¿æ€§å¢åŠ åŠ é€Ÿå‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„ offloadï¼Œå¹¶åˆ©ç”¨é¢å¤–èŠ‚ç‚¹çš„ CPU è®¡ç®—è¿›è¡Œå‚æ•°æ›´æ–°ï¼Œå®ç°è¶…çº¿æ€§æ‰©å±•ï¼ˆå›¾5bï¼‰</p><p>å³ä½¿è§„æ¨¡è¾ƒå°æ—¶ï¼ŒZeRO-Infinity ä¹Ÿåªéœ€ 4 ä¸ªèŠ‚ç‚¹å°±å®ç°äº†è¶…è¿‡ 2.8 petaflopsï¼Œ44 Tflops/GPUï¼Œèšåˆ NVMe ä¸é«˜çš„å¸¦å®½è¶³å¤Ÿç”¨äº Infinity</p><h3 id="Democratizing-Large-Model-Training"><a href="#Democratizing-Large-Model-Training" class="headerlink" title="Democratizing Large Model Training"></a>Democratizing Large Model Training</h3><p>å›¾5c åœ¨å•ä¸ªèŠ‚ç‚¹ï¼Œ16ä¸ª GPU ä¸Šï¼Œä½¿ç”¨ Infinity å¯ä»¥è®­ç»ƒè¶…è¿‡1ä¸‡äº¿å‚æ•°ï¼Œ27 TFlops/GPUï¼Œ3Då¹¶è¡Œå’Œ ZeRO-Offload æ— æ³•è®­ç»ƒè¶…è¿‡ 200 äº¿å‚æ•°</p><h3 id="Impact-of-System-Features-on-Model-Scale"><a href="#Impact-of-System-Features-on-Model-Scale" class="headerlink" title="Impact of System Features on Model Scale"></a>Impact of System Features on Model Scale</h3><p>å›¾6a å¯¹æ¯”äº†ä¸åŒç­–ç•¥ï¼Œåˆ©ç”¨ä¸åŒè®¾å¤‡åœ¨å•èŠ‚ç‚¹è®­ç»ƒæ—¶èƒ½è¾¾åˆ°çš„æœ€å¤§å‚æ•°é‡</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/8.webp" width="500" /></p><p>åˆ©ç”¨ CPUï¼š70B</p><p>åˆ©ç”¨ CPU + NVMeï¼š1T</p><p>é€šè¿‡å°†æ€» GPU å†…å­˜é¢„å…ˆåˆ†å‰²æˆ 2GB çš„è¿ç»­å—ï¼Œä½¿å¾—æ‰€æœ‰å¤§äº2GBçš„å†…å­˜åˆ†é…è¯·æ±‚éƒ½å°†å¤±è´¥ï¼Œä»¥æ­¤æµ‹è¯•æœ€å¤§ hidden size</p><p>å›¾6b memory-centric tiling ç³»æ•°ä¸º 16 æ—¶å¯è®­ç»ƒ 64k çš„æœ€å¤§ hidden size</p><h3 id="Impact-of-System-Features-on-Performance"><a href="#Impact-of-System-Features-on-Performance" class="headerlink" title="Impact of System Features on Performance"></a>Impact of System Features on Performance</h3><p>å›¾6c æ¯”è¾ƒäº†ä½¿ç”¨ Infinity å’Œ Offload å°†æ¢¯åº¦å¸è½½åˆ° CPU å†…å­˜å¯¹ 8B æ¨¡å‹çš„ BWD æ—¶é—´çš„å½±å“ï¼ŒOffload å—é™äºå•ä¸ª PCIe å¸¦å®½ï¼Œåœ¨ 64 GPUæ—¶ï¼Œåªæœ‰ Infinity 50% çš„é€Ÿåº¦</p><p>å›¾6d æ¯”è¾ƒäº†é‡å é€šä¿¡ä¸å¦å¯¹é€Ÿåº¦çš„å½±å“ï¼Œbz è¶Šå¤§ï¼Œé‡å é€šä¿¡çš„å½±å“è¶Šå°</p><p>å›¾6e æ¯”è¾ƒäº† offload ä¸åŒè§„æ¨¡çš„ hidden å±‚ checkpoint åˆ° CPU çš„æ”¶ç›Šï¼Œhidden size è¶Šå¤§æ”¶ç›Šè¶Šå°</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/9.webp" width="800" /></p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>å¸¦å®½æ˜¯åˆ¶çº¦è®¡ç®—èƒ½åŠ›çš„ä¸€å¤§å…³é”®å› ç´ ï¼ŒInfinity åœ¨åˆ©ç”¨ CPU å’Œ NVMe è®¾å¤‡çš„åŒæ—¶ï¼Œèšåˆæ‰€æœ‰é€šä¿¡è®¾å¤‡çš„å¸¦å®½æé€Ÿ</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Infinity-Breaking-the-GPU-Memory-Wall-for-Extreme-Scale-Deep-Learning/10.webp" width="500" /></p>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»: ZeRO-Offload: Democratizing Billion-Scale Model Training</title>
      <link href="/p/17582ba3/"/>
      <url>/p/17582ba3/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ZeRO-Offload ä¸»è¦ä¼˜åŒ–åœ¨äºå°½é‡å‡å°‘æ•°æ®åœ¨ GPU ä¸ CPU ä¹‹é—´çš„ç§»åŠ¨ï¼Œå¹¶å‡å°‘ CPU è®¡ç®—æ—¶é—´ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°èŠ‚çœ GPU ä¸Šçš„å†…å­˜ã€‚</p><span id="more"></span><p>åŸæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/pdf/2101.06840.pdf">https://arxiv.org/pdf/2101.06840.pdf</a></p><p>å¼€æºä»£ç ï¼š<a href="https://github.com/microsoft/deepspeed">https://github.com/microsoft/deepspeed</a></p><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>ä½¿ç”¨ Pytorch è®­ç»ƒå†…å­˜ä¸å¤Ÿï¼Œå•ä¸ª V100 ä¸Šæ€§èƒ½ä¸º 30 TFlops</p><p>ç›®å‰çš„åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶åŠ¨è¾„éœ€è¦è¶…è¿‡ 10w åˆ€çš„è®¾å¤‡ï¼Œéš¾ä»¥åœ¨å•å¡ä¸Šå‘æŒ¥ä½œç”¨</p><p>å¯¹äºåŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ LLM è®­ç»ƒï¼Œå†…å­˜ç“¶é¢ˆä¸»è¦åœ¨æ¨¡å‹çŠ¶æ€ä¸Š</p><p>ç°æœ‰çš„å¼‚æ„è®­ç»ƒæ–¹æ³•ä¸»è¦åˆ©ç”¨ CPU å†…å­˜ï¼Œè€Œå¿½ç•¥äº† CPU çš„è®¡ç®—æ½œåŠ›</p><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>ZeRO-Offload ä¼˜åŒ–ï¼šå°½é‡å‡å°‘æ•°æ®åœ¨ GPU ä¸ CPU ä¹‹é—´çš„ç§»åŠ¨ï¼Œå¹¶å‡å°‘ CPU è®¡ç®—æ—¶é—´ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°èŠ‚çœ GPU ä¸Šçš„å†…å­˜</p><p>å•ä¸ª V100 ä¸Šæ€§èƒ½æé«˜åˆ° 40 TFlopsï¼Œåœ¨ 128 å¡ä¸Šå®ç°æ¥è¿‘çº¿æ€§åŠ é€Ÿï¼Œå¯¹æ¯”MPï¼Œæ¨¡å‹è§„æ¨¡å¢åŠ äº† 4.5 å€</p><p>ZeRO-Offload åˆ©ç”¨äº†CPUå†…å­˜å’Œè®¡ç®—èµ„æºè¿›è¡Œ Offloadï¼Œå¹¶ä¸ ZeRO-DP ç›¸ç»“åˆ</p><h3 id="Efficiency"><a href="#Efficiency" class="headerlink" title="Efficiency"></a>Efficiency</h3><p>è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºEfficiencyçš„offloadç­–ç•¥ï¼Œé€šè¿‡åˆ†æç¡®å®šäº†CPUå’ŒGPUè®¾å¤‡ä¹‹é—´çš„æœ€ä½³è®¡ç®—å’Œæ•°æ®åˆ’åˆ†ç­–ç•¥ï¼Œä»¥åœ¨ä¸‰ä¸ªå…³é”®æ–¹é¢è¾¾åˆ°æœ€ä¼˜åŒ–ï¼š</p><ul><li>åœ¨CPUä¸Šçš„è®¡ç®—é‡æ¯”GPUå°‘å¤šä¸ªæ•°é‡çº§ï¼Œé˜²æ­¢CPUæ€§èƒ½ç“¶é¢ˆï¼›</li><li>æœ€å°åŒ–CPUå’ŒGPUä¹‹é—´çš„é€šä¿¡é‡ï¼Œé˜²æ­¢é€šä¿¡ç“¶é¢ˆï¼›</li><li>åœ¨å®ç°æœ€å°é€šä¿¡é‡çš„åŒæ—¶ï¼Œå¯è¯æ˜åœ°æœ€å¤§åŒ–èŠ‚çº¦GPUå†…å­˜ã€‚ </li></ul><p>åˆ†æè¡¨æ˜ï¼Œè¦åœ¨ä¸Šè¿°æ–¹é¢è¾¾åˆ°æœ€ä¼˜ï¼Œå¿…é¡»å°†æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œä¼˜åŒ–å™¨è®¡ç®—å¸è½½åˆ°CPUä¸Šï¼ŒåŒæ—¶åœ¨ GPU ä¸Šä¿ç•™å‚æ•°ã€å‰å‘å’Œåå‘è®¡ç®—ã€‚è¿™ç§ç­–ç•¥ä½¿æ¨¡å‹è§„æ¨¡å¢åŠ äº†10å€ï¼Œå¹¶ä¸”é€šä¿¡é‡æœ€å°ã€‚èƒ½å¤Ÿåœ¨ä¸€å— V100 GPUä¸Šè®­ç»ƒ130äº¿å‚æ•°æ¨¡å‹ï¼Œæ€§èƒ½ä¸º 40 TFLOPSï¼Œè€Œæ²¡æœ‰ CPU offload çš„æƒ…å†µä¸‹åªèƒ½è®­ç»ƒ12äº¿å‚æ•°æ¨¡å‹ï¼Œä¸”æ€§èƒ½åªæœ‰30 TFLOPSã€‚</p><p>offload ä¼˜åŒ–å™¨è®¡ç®—è¦æ±‚CPUè¿›è¡ŒO(M)æ¬¡è®¡ç®—ï¼Œè€ŒGPUéœ€è¿›è¡ŒO(MB)æ¬¡è®¡ç®—ï¼Œå…¶ä¸­Må’ŒBåˆ†åˆ«ä¸ºæ¨¡å‹è§„æ¨¡å’Œ batch size ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œ batch size è¾ƒå¤§ï¼ŒCPUè®¡ç®—é‡å¹¶ä¸æ˜¯ç“¶é¢ˆï¼Œä½†å¯¹äºå° batch sizeï¼ŒCPUè®¡ç®—é‡å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé‡‡å–äº†ä¸¤ç§ä¼˜åŒ–æªæ–½ï¼š</p><ul><li>é«˜æ•ˆçš„CPUä¼˜åŒ–å™¨ï¼Œå…¶é€Ÿåº¦æ¯”ç°æœ‰æŠ€æœ¯å¿«6å€ï¼›</li><li>å»¶è¿Ÿä¸€æ­¥çš„å‚æ•°æ›´æ–°ï¼Œå…è®¸å°†CPUä¼˜åŒ–å™¨æ­¥éª¤ä¸GPUè®¡ç®—é‡å ï¼ŒåŒæ—¶ç¡®ä¿å‡†ç¡®æ€§ã€‚è¿™ä¸¤ç§æªæ–½å…±åŒä¿è¯äº†ZeRO-Offloadåœ¨å° batch size ä¸‹ä¹Ÿèƒ½ä¿æŒæ•ˆç‡ã€‚</li></ul><h3 id="Unique-Optimal-Offload-Strategy"><a href="#Unique-Optimal-Offload-Strategy" class="headerlink" title="Unique Optimal Offload Strategy"></a>Unique Optimal Offload Strategy</h3><p>ä¸ºäº†ç¡®å®šæœ€ä½³çš„ä¸‹è½½ç­–ç•¥ï¼ŒZeRO-Offloadå°†æ·±åº¦å­¦ä¹ è®­ç»ƒå»ºæ¨¡ä¸ºæ•°æ®æµå›¾ï¼Œå¹¶ä½¿ç”¨åŸºäºç¬¬ä¸€åŸç†çš„åˆ†ææ–¹æ³•å°†è¯¥å›¾åˆ†å‰²ä¸ºCPUå’ŒGPUè®¾å¤‡ä¹‹é—´çš„éƒ¨åˆ†ã€‚</p><p>ZeRO-Offload åœ¨ä»¥ä¸‹ä¸‰ä¸ªå…³é”®æ–¹é¢ä¼˜åŒ–äº†å›¾çš„åˆ†å‰²ç­–ç•¥</p><ul><li>è¦æ±‚æ›´å°‘æ•°é‡çº§çš„CPUè®¡ç®—ï¼Œä»¥é˜²æ­¢CPUæˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼›</li><li>ç¡®ä¿æœ€å°åŒ–CPUå’ŒGPUå†…å­˜ä¹‹é—´çš„é€šä¿¡é‡ï¼›</li><li>å¯è¯æ˜åœ°å®ç°æœ€å°é€šä¿¡é‡çš„åŒæ—¶æœ€å¤§åŒ–å†…å­˜èŠ‚çœã€‚</li></ul><p>è®­ç»ƒçš„è®¡ç®—å¤æ‚åº¦é€šå¸¸ä¸ºO(MB)ï¼Œå…¶ä¸­Mä¸ºæ¨¡å‹å¤§å°ï¼ŒBä¸ºæœ‰æ•ˆbatch sizeã€‚ä¸ºé¿å…CPUè®¡ç®—æˆä¸ºç“¶é¢ˆï¼Œåªæœ‰é‚£äº›è®¡ç®—å¤æ‚åº¦ä½äºO(MB)çš„è®¡ç®—æ‰èƒ½è½¬ç§»åˆ°CPUä¸Š</p><p>FWD å’Œ BWD çš„è®¡ç®—å¤æ‚åº¦éƒ½æ˜¯O(MB)ï¼Œå¿…é¡»åœ¨GPUä¸Šè¿›è¡Œï¼Œè€Œå…¶ä½™çš„è®¡ç®—ï¼Œå¦‚èŒƒæ•°è®¡ç®—ã€æƒé‡æ›´æ–°ç­‰ï¼Œå…¶å¤æ‚åº¦ä¸ºO(M)ï¼Œå¯ä»¥è½¬ç§»åˆ°CPUä¸Š</p><p>åŸºäºæ­¤ï¼Œæ•°æ®æµå›¾ä¸­çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­èŠ‚ç‚¹åˆå¹¶ä¸ºä¸€ä¸ª FWD-BWD Super Node å¹¶åˆ†é…åˆ° GPU ä¸Š</p><p>è¿˜éœ€è¦æœ€å°åŒ– CPU ä¸ GPU çš„é€šä¿¡å¸¦å®½ï¼Œå¦‚å›¾ä¸­æ‰€ç¤ºï¼Œæœ€å°é€šä¿¡é‡ä¸º BWDå GPU å‘é€åˆ° CPU çš„ 2M æ¢¯åº¦ä¸ CPU å‘é€åˆ° GPU çš„ 2M å‚æ•°ï¼Œåªæœ‰å°† fp32 æ¨¡å‹çŠ¶æ€ï¼ˆmomentum 32ã€variance 32å’Œp32ï¼‰ï¼ŒParam Update å’Œ float2half è®¡ç®—æ”¾ç½®åœ¨ä¸€èµ·ï¼Œä¸ºä¸€ä¸ª CPU ä¸Šçš„ Update Super Nodeï¼Œæ‰èƒ½è¾¾æˆæœ€å°é€šä¿¡é‡ç­–ç•¥</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/1.webp" width="800"/></p><p>å¦å¤–ï¼Œä¸Šå›¾ä¸­ 2M å¤§å°çš„ parameter 16 ä¸ºä»€ä¹ˆåˆ†åˆ«åˆ° FWD ä¸ BWD æœ‰æ€»å’Œ 4M çš„æ•°æ®ä¼ è¾“ï¼Œè¿™ä¸ªé—®é¢˜å¦‚æœ‰æœ‹å‹çŸ¥é“ï¼Œæ¬¢è¿è¯„è®ºåŒºè®¨è®º</p><p>å®éªŒä¾æ®å¦‚ä¸‹</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/2.webp" width="500"/></p><p>æ€»ä¹‹ï¼ŒZeRO-Offload ç­–ç•¥å°±æ˜¯å°†æ‰€æœ‰çš„ fp32 æ¨¡å‹çŠ¶æ€å’Œ fp16 æ¢¯åº¦å­˜å‚¨åœ¨ CPU å†…å­˜ä¸­ï¼Œå¹¶åœ¨ CPU ä¸Šè®¡ç®—å‚æ•°æ›´æ–°ã€‚è€Œ fp16 å‚æ•°åˆ™ä¿ç•™åœ¨GPUä¸Šï¼Œå‰å‘å’Œåå‘è®¡ç®—åœ¨GPUä¸Šè¿›è¡Œ</p><h2 id="ZeRO-Offload-Schedule"><a href="#ZeRO-Offload-Schedule" class="headerlink" title="ZeRO-Offload Schedule"></a>ZeRO-Offload Schedule</h2><h3 id="å•å¡ç­–ç•¥"><a href="#å•å¡ç­–ç•¥" class="headerlink" title="å•å¡ç­–ç•¥"></a>å•å¡ç­–ç•¥</h3><p>ZeRO-Offloadå°†æ•°æ®è¿›è¡Œåˆ†åŒºï¼Œå°†fp16å‚æ•°å­˜å‚¨åœ¨GPUä¸Šï¼Œfp16æ¢¯åº¦å’Œæ‰€æœ‰ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå¦‚fp32åŠ¨é‡ã€æ–¹å·®å’Œå‚æ•°ï¼‰å­˜å‚¨åœ¨CPUä¸Šã€‚</p><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆé€šè¿‡ FWD è®¡ç®—æŸå¤±ã€‚ç”±äºfp16å‚æ•°å·²ç»ä½äºGPUä¸Šï¼Œå› æ­¤è¿™éƒ¨åˆ†è®¡ç®—ä¸éœ€è¦ä¸CPUè¿›è¡Œé€šä¿¡ã€‚</p><p>åœ¨ BWD è¿‡ç¨‹ä¸­ï¼Œä¸åŒå‚æ•°çš„æ¢¯åº¦åœ¨åå‘è°ƒåº¦çš„ä¸åŒä½ç½®è®¡ç®—ã€‚ZeRO-Offloadå¯ä»¥ç«‹å³å°†è¿™äº›æ¢¯åº¦é€ä¸ªæˆ–åˆ‡åˆ†ä¼ è¾“åˆ° CPU å†…å­˜ä¸­ã€‚</p><p>å› æ­¤ï¼Œåœ¨å°†æ¢¯åº¦ä¼ è¾“åˆ°CPUå†…å­˜ä¹‹å‰ï¼Œåªéœ€è¦åœ¨GPUå†…å­˜ä¸­ä¸´æ—¶ä¿å­˜å°‘é‡çš„æ¢¯åº¦ã€‚æ­¤å¤–ï¼Œæ¯ä¸ªæ¢¯åº¦ä¼ è¾“å¯ä»¥ä¸åå‘è®¡ç®—é‡å ï¼Œæ¶ˆé™¤å¤§éƒ¨åˆ†é€šä¿¡æˆæœ¬ã€‚</p><p>åœ¨ BWD ä¹‹åï¼ŒZeRO-Offloadåœ¨CPUä¸Šç›´æ¥æ›´æ–°fp32å‚æ•°å’Œå‰©ä½™çš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå¦‚åŠ¨é‡å’Œæ–¹å·®ï¼‰ï¼Œå¹¶å°†æ›´æ–°åçš„ fp32 å‚æ•°ä» CPU å†…å­˜å¤åˆ¶åˆ° GPU å†…å­˜ä¸­çš„fp16å‚æ•°ä¸­ã€‚</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/3.webp" width="800"/></p><p>ä¸Šå›¾å±•ç¤ºäº† ZeRO-Offload æ¯ä¸ªæ­¥éª¤ä¸­çš„è®¡ç®—é€šä¿¡è¿‡ç¨‹ï¼Œä¸‹å›¾ä¼ªä»£ç å±•ç¤ºäº†å…·ä½“çš„è°ƒåº¦è¿‡ç¨‹</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/4.webp" width="500"/></p><h3 id="å¤šå¡ç­–ç•¥"><a href="#å¤šå¡ç­–ç•¥" class="headerlink" title="å¤šå¡ç­–ç•¥"></a>å¤šå¡ç­–ç•¥</h3><p>ZeRO-Offload å°†æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€åœ¨ä¸åŒçš„ GPU ä¹‹é—´è¿›è¡Œ partitionï¼Œå¹¶ä¸”æ¯ä¸ª GPU å°†è‡ªå·±çš„ part offload åˆ° CPU å†…å­˜ä¸­ï¼Œå­˜å‚¨æŒç»­æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹</p><p>BWD è¿‡ç¨‹ä¸­ï¼Œåœ¨ GPU ä¸Š reduce-scatter è®¡ç®—æ¢¯åº¦å¹¶å¹³å‡ï¼Œæ¯ä¸ª GPU ä»…å°†å±äºå…¶ part çš„å¹³å‡æ¢¯åº¦ offload åˆ° CPU å†…å­˜ä¸­</p><p>ä¸€æ—¦æ¢¯åº¦åœ¨ CPU ä¸Šå¯ç”¨ï¼Œä¼˜åŒ–å™¨çŠ¶æ€ part å¯¹åº”çš„æ¯ä¸ª DP è¿›ç¨‹ç›´æ¥åœ¨ CPU ä¸Šå¹¶è¡Œæ›´æ–°å¯¹åº”çš„å‚æ•° part</p><p>æ›´æ–°å®Œæˆåï¼Œå‚æ•° part å‘é€åˆ° GPUï¼Œåœ¨ GPU ä¸Šå¯¹å‚æ•°è¿›è¡Œç±»ä¼¼ ZeRO-2 çš„ all-gather æ“ä½œ</p><p>ä¸‹é¢æ˜¯ ZeRO-Offload çš„å¤šå¡æ•°æ®å¸ƒå±€ç¤ºæ„å›¾</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/5.webp" width="800"/></p><p>æ­¤å¤–ï¼ŒZeRO-Offload è¿˜å¯ä»¥ä¸ MP å’Œ Megatron-LM åŒæ—¶ä½¿ç”¨ï¼Œé€šè¿‡ offload MP è¿›ç¨‹å¯¹åº”çš„æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œä¼˜åŒ–å™¨è®¡ç®—å®ç°</p><h2 id="Optimized-CPU-Execution"><a href="#Optimized-CPU-Execution" class="headerlink" title="Optimized CPU Execution"></a>Optimized CPU Execution</h2><h3 id="Implementing-the-CPU-Optimizer"><a href="#Implementing-the-CPU-Optimizer" class="headerlink" title="Implementing the CPU Optimizer"></a>Implementing the CPU Optimizer</h3><p>ä¼˜åŒ– CPU Optimizer æ€§èƒ½</p><ul><li>ä½¿ç”¨SIMDå‘é‡æŒ‡ä»¤</li><li>å¾ªç¯å±•å¼€</li><li>OMP å¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—</li><li>æ··åˆç²¾åº¦è®­ç»ƒ</li></ul><p>åœ¨æ··åˆç²¾åº¦è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œå†…å­˜ä¸­çš„å‚æ•°æœ‰ä¸¤ä¸ªç‰ˆæœ¬</p><ul><li>FP32 ç‰ˆæœ¬ï¼Œç”¨äºä¼˜åŒ–å™¨åœ¨ CPU ä¸Šè¿›è¡Œæ›´æ–°</li><li>æµ®ç‚¹è½¬æ¢ FP32  åç”¨äºåœ¨ FWD ä¸­è®¡ç®—æ¿€æ´»çš„ FP16ï¼Œç”¨äºGPU</li></ul><p>æ­¤å¤–ï¼Œæ¢¯åº¦çš„åŠ¨é‡å’Œæ–¹å·®ä¹Ÿä»¥ FP32 ä¿å­˜åœ¨ CPU ä¸Šï¼Œé˜²æ­¢åœ¨æ›´æ–°å‚æ•°æ—¶å‡ºç°ç²¾åº¦ä¸¢å¤±</p><p>è®ºæ–‡ä¸­çš„ adam å®ç°ä½¿ç”¨äº† SIMDï¼Œé€šè¿‡å°†æ•°æ®è¯»å…¥å‘é‡å¯„å­˜å™¨å¹¶ä½¿ç”¨å¤šä¸ªèåˆä¹˜åŠ æ“ä½œï¼ˆFMAï¼‰æ„æˆä¸»æ‰§è¡Œæµæ°´çº¿ï¼ŒSIMD çŸ¢é‡å®½åº¦ç”± simd_width æŒ‡å®šï¼Œå¹¶ç»“åˆå¾ªç¯å±•å¼€ï¼Œè‡ªåŠ¨è°ƒä¼˜çš„ unroll_width ä¸º 8</p><p>åŒæ—¶ï¼Œå¯¹è®¡ç®—çš„æ•°æ®æŒ‰ tile_width åˆ†åŒºï¼Œå°† CPUä¸Šè®¡ç®—å¥½çš„ FP32 æ•°æ® part è½¬æ¢ä¸º FP16 æ‹·è´åˆ° GPU ä¸­ï¼ŒåŒæ—¶åœ¨ CPU ä¸Šè®¡ç®—ä¸‹ä¸€ä¸ª æ•°æ® partï¼Œå®ç°é€šä¿¡è®¡ç®— overlap</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/6.webp" width="600"/></p><h3 id="One-Step-Delayed-Parameter-Updateï¼ˆDPUï¼‰"><a href="#One-Step-Delayed-Parameter-Updateï¼ˆDPUï¼‰" class="headerlink" title="One-Step Delayed Parameter Updateï¼ˆDPUï¼‰"></a>One-Step Delayed Parameter Updateï¼ˆDPUï¼‰</h3><p>åœ¨ DPU è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆåœ¨å‰ N-1 ä¸ªæ­¥éª¤ä¸­è¿›è¡Œè®­ç»ƒï¼Œé¿å…åœ¨è®­ç»ƒçš„æ—©æœŸé˜¶æ®µæ¢¯åº¦å˜åŒ–è¾ƒå¿«æ—¶ç ´åè®­ç»ƒçš„ç¨³å®šæ€§ã€‚</p><p>åœ¨ç¬¬Næ­¥ï¼Œä» GPU è·å–æ¢¯åº¦ï¼Œä½†è·³è¿‡ CPU ä¼˜åŒ–å™¨æ­¥éª¤ï¼Œä¹Ÿä¸æ›´æ–° GPU ä¸Šçš„ fp16 å‚æ•°ã€‚</p><p>åœ¨ç¬¬ N+1 æ­¥ï¼Œä½¿ç”¨ç¬¬Næ­¥çš„æ¢¯åº¦åœ¨CPUä¸Šè®¡ç®—å‚æ•°æ›´æ–°ï¼Œåœ¨GPUä¸Šå¹¶è¡Œè®¡ç®—å‰å‘å’Œåå‘ä¼ æ’­ï¼Œä½¿ç”¨ç¬¬ N-1 æ­¥æ›´æ–°çš„å‚æ•°ã€‚</p><p>ä»è¿™ä¸€æ­¥å¼€å§‹ï¼Œæ¯ä¸ªæ­¥éª¤çš„æ¨¡å‹å°†ä½¿ç”¨ä» i-1 æ­¥æ›´æ–°çš„å‚æ•°è¿›è¡Œè®­ç»ƒï¼Œå®ç°äº† CPU ä¸ GPU çš„è®¡ç®—é‡å </p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/7.webp" width="1000"/></p><p>ä½œè€…é€šè¿‡å¯¹å¤šä¸ªè®­ç»ƒå·¥ä½œè¯„ä¼°å‘ç°ï¼Œå¦‚æœåœ¨å‡ åæ¬¡è¿­ä»£ä¹‹åå¼•å…¥ DPUï¼Œä¸ä¼šå¯¹æ”¶æ•›äº§ç”Ÿå½±å“</p><h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><h3 id="å®éªŒæ–¹æ³•"><a href="#å®éªŒæ–¹æ³•" class="headerlink" title="å®éªŒæ–¹æ³•"></a>å®éªŒæ–¹æ³•</h3><p>ç¡¬ä»¶é…ç½®</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/8.webp" width="500"/></p><p>å®éªŒæ¨¡å‹ï¼šGPT-2ã€BERT</p><p>å®éªŒæ•°æ®é›†ï¼šSQuAD</p><p>å¯¹æ¯”æ¡†æ¶ï¼šPyTorch DDPã€Megatronã€L2Lã€ZeRO</p><p>æ¨¡å‹é…ç½®</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/9.webp" width="500"/></p><h3 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h3><p>å›¾7 åœ¨å•ä¸ªGPUï¼Œ4ä¸ªGPUå’Œ16ä¸ªGPUï¼ˆä¸€ä¸ªDGX-2èŠ‚ç‚¹ï¼‰ä¸Šå¯è®­ç»ƒçš„æœ€å¤§æ¨¡å‹å‚æ•°é‡å¯¹æ¯”</p><p>å›¾8 åœ¨ batch size ä¸º 512 çš„å•ä¸ªGPUä¸Šä½¿ç”¨ PyTorchï¼ŒL2L å’Œ ZeRO-Offload è®­ç»ƒçš„ TFLOPS å¯¹æ¯”</p><p>å›¾9 ä½¿ç”¨ DPU å’Œä¸ä½¿ç”¨ DPU çš„æƒ…å†µä¸‹ï¼Œä¸ GPT-2 è®­ç»ƒçš„ TFLOPSï¼ˆbatch_size = 8ï¼‰ å¯¹æ¯”</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/10.webp" width="800"/></p><p>å›¾10 é’ˆå¯¹ä¸åŒæ¨¡å‹å¤§å°ï¼Œä½¿ç”¨PyTorchã€ZeRO-2ã€MegatronLMã€ZeRO-Offloadï¼ˆæ—  MPï¼‰ä»¥åŠZeRO-Offloadï¼ˆæœ‰ MPï¼‰è®­ç»ƒçš„ TFLOPS å¯¹æ¯”</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/11.webp" width="600"/></p><p>å›¾11 é’ˆå¯¹ä¸åŒ GPU æ•°é‡ï¼ŒZeRO-2 å’Œ ZeRO-Offload çš„ TFLOPS å¯¹æ¯”ï¼Œä» 64 å¡å¼€å§‹ ZeRO-2 ä¼˜äº ZeRO-Offload æ˜¯å› ä¸º ZeRO-2 æ²¡æœ‰ CPU-GPU é€šä¿¡çš„é¢å¤–å¼€é”€</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/12.webp" width="600"/></p><p>æœ¬æ–‡ä¼˜åŒ–è¿‡çš„ CPU-Adam ä¸ PT-GPU æ€§èƒ½å·®è·å¹¶ä¸å¤§ï¼Œä¸ä¼šæˆä¸ºæ€§èƒ½ç“¶é¢ˆ</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/13.webp" width="600"/></p><p>å®éªŒè¡¨æ˜ DPU ç­–ç•¥åœ¨è®­ç»ƒä¸å¾®è°ƒä¸Šä¸ä¼šå½±å“ç²¾åº¦ï¼Œæœ€ç»ˆçš„ F1 åˆ†æ•°éƒ½æ˜¯ 0.92</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/14.webp" width="600"/></p>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®°å½•ç¬¬næ¬¡ä¿®å¤USBè®¾å¤‡æ— æ³•è¯†åˆ«æŒ‚è½½</title>
      <link href="/p/bddb5e0d/"/>
      <url>/p/bddb5e0d/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>archlinux æ»šç€æ»šç€å°±ä¸èƒ½è¯†åˆ« USB è®¾å¤‡äº†ï¼Œè®°å½•ä¸€ä¸‹ä¿®å¤è¿‡ç¨‹</p><span id="more"></span><h2 id="å‡†å¤‡"><a href="#å‡†å¤‡" class="headerlink" title="å‡†å¤‡"></a>å‡†å¤‡</h2><p>ä¸€ä¸ªUç›˜</p><h2 id="è¿‡ç¨‹"><a href="#è¿‡ç¨‹" class="headerlink" title="è¿‡ç¨‹"></a>è¿‡ç¨‹</h2><p>ä½¿ç”¨ <code>lsusb</code> å¯ä»¥è¯†åˆ«åˆ°<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Bus 004 Device 006: ID 0dd8:2004 Netac Technology Co., Ltd OnlyDisk</span><br></pre></td></tr></table></figure></p><p><code>sudo dmesg | grep USB</code> æ˜¾ç¤ºå¦‚ä¸‹ï¼Œå¯ä»¥è¯†åˆ«åˆ°</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[418536.174864] usb 4-2: New USB device found, idVendor=0dd8, idProduct=2004, bcdDevice= 1.10</span><br><span class="line">[418536.174868] usb 4-2: New USB device strings: Mfr=2, Product=3, SerialNumber=4</span><br></pre></td></tr></table></figure><p><code>lsblk</code> æ˜¾ç¤ºå¦‚ä¸‹ï¼Œæ²¡æœ‰USBè®¾å¤‡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">nvme0n1     259:0    0 931.5G  0 disk </span><br><span class="line">â”œâ”€nvme0n1p1 259:1    0   260M  0 part /boot</span><br><span class="line">â””â”€nvme0n1p2 259:2    0 931.3G  0 part /</span><br></pre></td></tr></table></figure><p><code>sudo fdisk -l</code>  æ˜¾ç¤ºå¦‚ä¸‹ï¼Œæ²¡æœ‰USBè®¾å¤‡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Disk /dev/nvme0n1ï¼š931.51 GiBï¼Œ1000204886016 å­—èŠ‚ï¼Œ1953525168 ä¸ªæ‰‡åŒºç£ç›˜å‹å·ï¼šCT1000P2SSD8                            </span><br><span class="line">å•å…ƒï¼šæ‰‡åŒº / 1 * 512 = 512 å­—èŠ‚æ‰‡åŒºå¤§å°(é€»è¾‘/ç‰©ç†)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚I/O å¤§å°(æœ€å°/æœ€ä½³)ï¼š512 å­—èŠ‚ / 512 å­—èŠ‚ç£ç›˜æ ‡ç­¾ç±»å‹ï¼šgpt</span><br><span class="line">ç£ç›˜æ ‡è¯†ç¬¦ï¼šC23A898B-ABD0-4208-9AF0-6BB0F443BD75</span><br><span class="line"></span><br><span class="line">è®¾å¤‡             èµ·ç‚¹       æœ«å°¾       æ‰‡åŒº   å¤§å° ç±»å‹/dev/nvme0n1p1   2048     534527     532480   260M EFI ç³»ç»Ÿ/dev/nvme0n1p2 534528 1953525134 1952990607 931.3G Linux æ–‡ä»¶ç³»ç»Ÿ</span><br></pre></td></tr></table></figure><p><code>df -h</code> æ˜¾ç¤ºå¦‚ä¸‹ï¼Œæ²¡æœ‰usbè®¾å¤‡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dev             6.8G     0  6.8G    0% /dev</span><br><span class="line">run             6.8G  1.8M  6.8G    1% /run</span><br><span class="line">/dev/nvme0n1p2  931G  433G  499G   47% /</span><br><span class="line">tmpfs           6.8G  144M  6.7G    3% /dev/shm</span><br><span class="line">tmpfs           6.8G   31M  6.8G    1% /tmp</span><br><span class="line">/dev/nvme0n1p1  256M  255M  1.7M  100% /boot</span><br><span class="line">tmpfs           1.4G  5.8M  1.4G    1% /run/user/1000</span><br></pre></td></tr></table></figure><p>æ€»ç»“ <code>lsusb</code>ï¼Œ<code>sudo dmesg | grep USB</code> å¯ä»¥è¯†åˆ«ï¼Œ<code>lsblk</code>ï¼Œ<code>fdisk -l</code>ï¼Œ<code>df -h</code> ä¸èƒ½è¯†åˆ«åˆ°ï¼Œæ¨æµ‹æ˜¯å› ä¸ºç³»ç»Ÿæ²¡æœ‰è‡ªåŠ¨æŒ‚è½½</p><h2 id="è§£å†³"><a href="#è§£å†³" class="headerlink" title="è§£å†³"></a>è§£å†³</h2><p>å®‰è£… <code>udisks2</code> å’Œ <code>udevil</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S udisks2 udevil</span><br></pre></td></tr></table></figure><p>å¯ç”¨<code>devmon</code>æœåŠ¡</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable devmon@$(whoami).service</span><br></pre></td></tr></table></figure><p><code>reboot</code> åå³å¯ç”Ÿæ•ˆ</p>]]></content>
      
      
      <categories>
          
          <category> archlinux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> USB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»: ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</title>
      <link href="/p/706a94b5/"/>
      <url>/p/706a94b5/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ZeRO æ˜¯ä¸€ç§ç”¨äºå¤§è§„æ¨¡æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å†…å­˜ä¼˜åŒ–è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡æ¶ˆé™¤æ•°æ®å’Œæ¨¡å‹å¹¶è¡Œè®­ç»ƒä¸­çš„å†…å­˜å†—ä½™ï¼ŒåŒæ—¶ä¿æŒäº†ä½é€šä¿¡é‡å’Œé«˜è®¡ç®—ç²’åº¦ã€‚</p><span id="more"></span><p>paper: <a href="https://arxiv.org/abs/1910.02054">https://arxiv.org/abs/1910.02054</a></p><p>code: <a href="https://github.com/microsoft/DeepSpeed">https://github.com/microsoft/DeepSpeed</a></p><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>æ¨¡å‹è®­ç»ƒçš„æŒ‘æˆ˜ï¼š</p><p>ä¼ ç»Ÿçš„ DP æ–¹æ³•ä¸èƒ½å‡å°‘æ¯ä¸ªè®¾å¤‡çš„å†…å­˜ä½¿ç”¨é‡ï¼Œå¯¼è‡´åœ¨å½“æ—¶ 32G æ˜¾å­˜çš„ GPU ä¸Šæ— æ³•è®­ç»ƒè¶…è¿‡ 14 äº¿ä¸ªå‚æ•°çš„æ¨¡å‹</p><p>ç°æœ‰çš„æ–¹æ³•ï¼šæµæ°´çº¿å¹¶è¡Œï¼Œæ¨¡å‹å¹¶è¡Œï¼Œ CPU offloadingï¼Œåœ¨åŠŸèƒ½æ€§ï¼Œå†…å­˜ä½¿ç”¨ï¼Œè®¡ç®—é€šä¿¡æ•ˆç‡ä¹‹é—´åšå‡ºäº†å–èˆ</p><p>ä½œè€…æåˆ°æ¨¡å‹å¹¶è¡Œæœ€æœ‰æ½œåŠ›ï¼Œéœ€è¦å°†æ¨¡å‹åœ¨å‚ç›´æ–¹å‘ä¸Šè¿›è¡Œåˆ‡åˆ†ï¼Œå¹¶å°†æ¯ä¸ªå±‚çš„è®¡ç®—å’Œå‚æ•°åœ¨å¤šä¸ªè®¾å¤‡ä¹‹é—´è¿›è¡Œåˆ’åˆ†ï¼Œå½“æ—¶çš„ 11B å‚æ•°çš„ T5ï¼Œ8.3B çš„ Megatron-LM éƒ½ä½¿ç”¨äº†æ¨¡å‹å¹¶è¡Œã€‚ä½†æ˜¯è¿™éœ€è¦å¤§é‡çš„å±‚é—´é€šä¿¡ï¼Œè™½ç„¶åœ¨å•ä¸ªèŠ‚ç‚¹å†…è¡¨ç°è‰¯å¥½ï¼Œä½œè€…åœ¨ä¸¤ä¸ª DGX-2 èŠ‚ç‚¹ä¸Šä½¿ç”¨ Megatron-LM æµ‹è¯•äº† 40B çš„æ¨¡å‹ï¼Œæ¯ä¸ª V100 GPU çš„è®¡ç®—æ€§èƒ½ä»…ä¸º 5 TFLOPS</p><p>ä½œè€…å‘ç°å†…å­˜æ¶ˆè€—ä¸»è¦é›†ä¸­åœ¨</p><ul><li>æ¨¡å‹çŠ¶æ€ï¼šä¼˜åŒ–å™¨ï¼Œæ¢¯åº¦ï¼Œå‚æ•°</li><li>residual statesï¼šæ¿€æ´»å€¼ï¼Œbufferï¼Œå†…å­˜ç¢ç‰‡</li></ul><p>é’ˆå¯¹è¿™ä¸¤ä¸ªéƒ¨åˆ†æå‡ºäº† ZeROï¼ˆZero Redundancy Optimizerï¼‰ </p><h2 id="å¼•è®º"><a href="#å¼•è®º" class="headerlink" title="å¼•è®º"></a>å¼•è®º</h2><h3 id="ä¼˜åŒ–æ¨¡å‹çŠ¶æ€å†…å­˜"><a href="#ä¼˜åŒ–æ¨¡å‹çŠ¶æ€å†…å­˜" class="headerlink" title="ä¼˜åŒ–æ¨¡å‹çŠ¶æ€å†…å­˜"></a>ä¼˜åŒ–æ¨¡å‹çŠ¶æ€å†…å­˜</h3><p>æ•°æ®å¹¶è¡Œ ï¼ˆDPï¼‰ä¸è¶³ï¼šä¸éœ€è¦é¢‘ç¹åœ°é€šä¿¡ï¼Œä½†éœ€è¦åœ¨æ¯ä¸ªè¿›ç¨‹ä¸­å¤åˆ¶æ•´ä¸ªæ¨¡å‹çŠ¶æ€ï¼Œæµªè´¹å†…å­˜</p><p>æ¨¡å‹å¹¶è¡Œï¼ˆMPï¼‰ä¸è¶³ï¼šå¯¹æ¨¡å‹çŠ¶æ€åˆ†åŒºä»¥é«˜æ•ˆç‡ä½¿ç”¨å†…å­˜ï¼Œä½†ä¼šå¯¼è‡´è¿‡ç»†çš„è®¡ç®—ç²’åº¦ï¼Œéœ€è¦é¢‘ç¹é€šä¿¡</p><p>æ•´ä½“æ¥çœ‹ï¼Œä¸Šè¿°æ–¹æ³•éœ€è¦åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­é™æ€åœ°ç»´æŠ¤æ‰€æœ‰æ¨¡å‹çŠ¶æ€ï¼Œä½†åœ¨è®­ç»ƒæ—¶ä¸æ€»æ˜¯éœ€è¦æ‰€æœ‰çš„æ¨¡å‹çŠ¶æ€</p><p>æ”¹è¿›ï¼š</p><p>æå‡ºäº†  ZeRO-DPï¼ŒZeRO-powered  DP ï¼Œé€šè¿‡åˆ†åŒºæ¨¡å‹çŠ¶æ€è€Œä¸æ˜¯å¤åˆ¶æ¥æ¶ˆé™¤ DP æ—¶çš„å†…å­˜å†—ä½™ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€é€šä¿¡è°ƒåº¦ç­–ç•¥ä¼˜åŒ–è®¡ç®—é€šä¿¡æ•ˆç‡ï¼Œæå‡ºäº†ä¸‰ä¸ªä¼˜åŒ–é˜¶æ®µ</p><ul><li>ä¼˜åŒ–å™¨åˆ†åŒºï¼ˆPosï¼‰ï¼šå†…å­˜å‡å°‘4å€ï¼Œä¸DPå…·æœ‰ç›¸åŒçš„é€šä¿¡é‡</li><li>æ¢¯åº¦åˆ†åŒºï¼ˆPos+gï¼‰ï¼šå†…å­˜å‡å°‘8å€ï¼Œä¸DPå…·æœ‰ç›¸åŒçš„é€šä¿¡é‡</li><li>æ¨¡å‹å‚æ•°åˆ†åŒºï¼ˆPos+g+pï¼‰ï¼šå†…å­˜å‡å°‘é‡ä¸ DP çš„ä»½æ•°æˆçº¿æ€§å…³ç³»ã€‚å¦‚åœ¨ 64 ä¸ª GPU ä¸Šæ‹†åˆ†å°†å‡å°‘64å€å†…å­˜ã€‚é€šä¿¡ä»…å¢åŠ  50%</li></ul><p>å›¾ä¸­ Î¨ è¡¨ç¤ºæ¨¡å‹å‚æ•°é‡ï¼ŒK è¡¨ç¤ºä¼˜åŒ–å™¨çŠ¶æ€çš„å†…å­˜å€æ•°ï¼ŒNd è¡¨ç¤º DP ä»½æ•°ã€‚åœ¨è¯¥ç¤ºä¾‹ä¸­ï¼Œå‡è®¾åŸºäº Adam ä¼˜åŒ–å™¨çš„æ··åˆç²¾åº¦è®­ç»ƒï¼ŒÎ¨=7.5Bï¼ŒNd=64ï¼ŒK=12ï¼Œå…¶ä¸­çš„è¯¦ç»†è®¡ç®—æ–¹æ³•åé¢ä¼šä»‹ç»</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/1.webp" width="800" /></p><p>ä½œè€…åœ¨è¿™é‡Œè®¡ç®—äº†é€šè¿‡ä¸Šè¿°ä¼˜åŒ–åœ¨ 1024 å¼  GPU ä¸Šè®­ç»ƒä¸‡äº¿å‚æ•°æ¨¡å‹ï¼Œä½¿ç”¨ fp16ï¼Œéœ€è¦ 16TB ç©ºé—´å­˜å‚¨ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¢¯åº¦å’Œå‚æ•°ï¼Œæ¯å¼ å¡å ç”¨ 16GB æ˜¾å­˜</p><h3 id="ä¼˜åŒ–-residual-states-å†…å­˜"><a href="#ä¼˜åŒ–-residual-states-å†…å­˜" class="headerlink" title="ä¼˜åŒ– residual states å†…å­˜"></a>ä¼˜åŒ– residual states å†…å­˜</h3><p>ä¸ºäº†ä¼˜åŒ–æ¿€æ´»å€¼ï¼Œbufferï¼Œå†…å­˜ç¢ç‰‡çš„å ç”¨ï¼Œæå‡ºäº† ZeRO-Rï¼Œæœ‰ä»¥ä¸‹å‡ ä¸ªä¼˜åŒ–ç‚¹</p><ul><li>ä½¿ç”¨å¯¹æ¿€æ´»å€¼çš„ checkpointing æ¥èŠ‚çœå†…å­˜ï¼Œè¿˜å¯¹æ¿€æ´»å€¼åˆ‡ç‰‡ï¼Œæ ¹æ®éœ€è¦å°†æ¿€æ´»æ•°æ®è½¬ç§»è‡³ CPU æ¥ä¼˜åŒ–æ¿€æ´»å€¼çš„å†…å­˜å ç”¨</li><li>ZeRO-R å®šä¹‰äº†é€‚å½“çš„ä¸´æ—¶ç¼“å†²åŒºå¤§å°ï¼Œä½¿å†…å­˜å’Œè®¡ç®—æ•ˆç‡å¹³è¡¡</li><li>æ ¹æ®ä¸åŒ tensor çš„ç”Ÿå‘½å‘¨æœŸï¼Œä¸»åŠ¨ç®¡ç†å†…å­˜ï¼Œé¢„é˜²å†…å­˜ç¢ç‰‡åŒ–</li></ul><p>ç»¼ä¸Šï¼ŒZeRO ä¸»è¦æ˜¯ç”± ZeRO-DP å’Œ ZeRO-R ä¸¤ç§ä¼˜åŒ–ç»“åˆ</p><h2 id="ZeRO-æ­é…æ¨¡å‹å¹¶è¡Œï¼ˆMPï¼‰"><a href="#ZeRO-æ­é…æ¨¡å‹å¹¶è¡Œï¼ˆMPï¼‰" class="headerlink" title="ZeRO æ­é…æ¨¡å‹å¹¶è¡Œï¼ˆMPï¼‰"></a>ZeRO æ­é…æ¨¡å‹å¹¶è¡Œï¼ˆMPï¼‰</h2><p>è™½ç„¶ä½¿ç”¨ ZeRO çš„ç­–ç•¥åï¼ŒMP çš„ç­–ç•¥å˜å¾—ä¸é‚£ä¹ˆé‡è¦äº†ï¼ŒMP åœ¨ä½¿ç”¨æ—¶è¿˜éœ€è¦ä¿®æ”¹æ¨¡å‹ï¼Œç›¸æ¯” DPï¼Œæœ‰è¯¸å¤šé™åˆ¶</p><p>ä½†åœ¨æ¿€æ´»å†…å­˜å ç”¨éå¸¸å¤§æ—¶ï¼Œè¿™æ—¶ ZeRO-R çš„ç­–ç•¥ä¹Ÿä¸èƒ½æ»¡è¶³è®­ç»ƒä¼˜åŒ–ï¼Œå¯ä»¥æ­é… MP å‡å°‘æ¿€æ´»å†…å­˜å ç”¨ã€‚å¹¶ä¸”ï¼Œåœ¨ç»“åˆ ZeRO å’Œ MP æ—¶ï¼Œç†è®ºä¸Šå¯ä»¥ä¼˜åŒ–åˆ° Nd * Nmï¼ˆMP ä»½æ•°ï¼‰ å€çš„å†…å­˜å ç”¨</p><p>åœ¨å°æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå•ç‹¬ä½¿ç”¨ DP ä¼šå¯¼è‡´ batch size è¿‡å¤§å¯èƒ½æ— æ³•æ”¶æ•›ï¼Œä½¿ç”¨ MP å¯ä»¥åœ¨åŠ é€Ÿçš„åŒæ—¶å‡å° batch size åˆ°åˆé€‚çš„å€¼ï¼Œå¸®åŠ©æ¨¡å‹æ”¶æ•›</p><h3 id="Implementation-amp-Evaluation"><a href="#Implementation-amp-Evaluation" class="headerlink" title="Implementation &amp; Evaluation"></a>Implementation &amp; Evaluation</h3><p>ä½œè€…è¿›è¡Œäº†ä¸€äº›ä¸Šè¿°å·¥ä½œçš„å®éªŒï¼Œå¾—å‡ºå¦‚ä¸‹ç»“è®º</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/2.webp" width="800" /></p><ul><li><p>æ¨¡å‹å¤§å°ï¼šå°† Megatron ä¸ MP ç›¸ç»“åˆï¼ŒZeRO-100B å¯ä»¥é«˜æ•ˆåœ°è¿è¡Œ 1700 äº¿å‚æ•°çš„æ¨¡å‹ï¼Œè€Œå•ç‹¬ä½¿ç”¨ Megatron ç­‰ç°æœ‰ç³»ç»Ÿåœ¨ 40 äº¿å‚æ•°ä»¥ä¸Šçš„è§„æ¨¡ä¸Šæ— æ³•é«˜æ•ˆæ‰©å±•ã€‚ç›¸æ¯”äºSOTAï¼Œæ¨¡å‹å¤§å°å¢åŠ äº†8å€ä»¥ä¸Š</p></li><li><p>è®­ç»ƒé€Ÿåº¦ï¼šæ”¹è¿›çš„å†…å­˜æ•ˆç‡æé«˜äº†ååé‡å’Œè®­ç»ƒé€Ÿåº¦ã€‚é€šè¿‡åœ¨ 400 å° Nvidia V100 GPU ä¸Šè¿è¡Œï¼ŒZeRO å¯ä»¥ä»¥æ¯ä¸ª GPU 38 TFlops çš„é€Ÿåº¦è®­ç»ƒ 1000 äº¿å‚æ•°çš„æ¨¡å‹ï¼Œæ€»æ€§èƒ½è¶…è¿‡ 15 Petaflopsã€‚ä¸ SOTA ç›¸æ¯”ï¼Œå¯¹äºç›¸åŒæ¨¡å‹å¤§å°ï¼Œè®­ç»ƒé€Ÿåº¦æé«˜äº† 10 å€ä»¥ä¸Š</p></li><li><p>å¯æ‰©å±•æ€§ï¼šå½“ä½¿ç”¨64-400ä¸ªGPUæ—¶ï¼Œæ€§èƒ½å‘ˆç°è¶…çº¿æ€§åŠ é€Ÿï¼Œå³å½“GPUæ•°é‡åŠ å€æ—¶ï¼Œæ€§èƒ½å¢åŠ äº†ä¸€å€ä»¥ä¸Šã€‚è¿™æ˜¯ ZeRO-DP çš„ç‰¹æ€§ï¼Œå®ƒéšç€DPåº¦æ•°çš„å¢åŠ å‡å°‘äº†æ¨¡å‹çŠ¶æ€çš„å†…å­˜å ç”¨ï¼Œä½¿å¾—æ¯ä¸ªGPUèƒ½å¤Ÿæ‰¿è½½æ›´å¤§çš„ batch_size ï¼Œä»è€Œæé«˜æ€§èƒ½</p></li><li><p>å¤§è§„æ¨¡è®­ç»ƒå¯è¡Œæ€§ï¼šZeRO-100B ä½¿å¾— 130äº¿å‚æ•°çš„æ¨¡å‹åªéœ€é‡æ„å³å¯è®­ç»ƒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç°æœ‰ç³»ç»Ÿï¼ˆå¦‚PyTorch Distributed Data Parallelï¼‰åœ¨ 14 äº¿å‚æ•°çš„è§„æ¨¡ä¸Šå°±ä¼šå‡ºç°å†…å­˜ä¸è¶³çš„æƒ…å†µ</p></li><li><p>SOTAï¼šZeRO æ”¯æŒæ‹¥æœ‰ 170 äº¿å‚æ•°çš„ Turing-NLG æ¨¡å‹ï¼Œå¹¶å–å¾—äº† SOTA çš„æˆç»©</p></li></ul><h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><h3 id="DP-TP-and-PP"><a href="#DP-TP-and-PP" class="headerlink" title="DP, TP and PP"></a>DP, TP and PP</h3><p>å…ˆäº†è§£ä¸€ä¸‹ 3 ç§å¹¶è¡Œçš„æ¦‚å¿µ</p><h4 id="DPï¼ˆæ•°æ®å¹¶è¡Œï¼‰"><a href="#DPï¼ˆæ•°æ®å¹¶è¡Œï¼‰" class="headerlink" title="DPï¼ˆæ•°æ®å¹¶è¡Œï¼‰"></a>DPï¼ˆæ•°æ®å¹¶è¡Œï¼‰</h4><p>å°†æ¯æ‰¹è¾“å…¥çš„è®­ç»ƒæ•°æ®éƒ½åœ¨ DP çš„ worker ä¹‹é—´è¿›è¡Œå¹³åˆ†ã€‚åå‘ä¼ æ’­ä¹‹åï¼Œéœ€è¦è¿›è¡Œé€šä¿¡æ¥è§„çº¦æ¢¯åº¦ï¼Œä»¥ä¿è¯ä¼˜åŒ–å™¨åœ¨å„ä¸ª worker ä¸Šå¯ä»¥å¾—åˆ°ç›¸åŒçš„æ›´æ–°</p><p>ä¼˜åŠ¿ï¼Œè®¡ç®—æ•ˆç‡é«˜ï¼Œå·¥ç¨‹ä¸Šæ˜“äºå®ç°</p><p>ä¸è¶³ï¼šä¼šåœ¨æ‰€æœ‰ worker ä¹‹é—´å¤åˆ¶æ¨¡å‹å’Œä¼˜åŒ–å™¨ï¼Œå› æ­¤æ˜¾å­˜æ•ˆç‡ä¸é«˜ã€‚ä¸”éšç€å¹¶è¡Œåº¦çš„æé«˜ï¼Œæ¯ä¸ª worker æ‰§è¡Œçš„è®¡ç®—é‡æ˜¯æ’å®šçš„ã€‚ DP å¯ä»¥åœ¨å°è§„æ¨¡ä¸Šå®ç°è¿‘ä¹çº¿æ€§æ‰©å±•ã€‚ä½†æ˜¯ï¼Œå› ä¸ºåœ¨ worker ä¹‹é—´è§„çº¦æ¢¯åº¦çš„é€šä¿¡æˆæœ¬è·Ÿæ¨¡å‹å¤§å°æˆæ­£ç›¸å…³ï¼Œæ‰€ä»¥å½“æ¨¡å‹å¾ˆå¤§æˆ–é€šä¿¡å¸¦å®½å¾ˆä½æ—¶ï¼Œè®¡ç®—æ•ˆç‡ä¼šå—åˆ°é™åˆ¶</p><p>æ”¹è¿›ï¼šæ¢¯åº¦ç´¯ç§¯å¯ä»¥å¢åŠ  batch sizeï¼Œåœ¨æœ¬åœ°ä½¿ç”¨ micro-batch è¿›è¡Œå¤šæ¬¡æ­£å‘å’Œåå‘ä¼ æ’­ï¼Œåœ¨è¿›è¡Œä¼˜åŒ–å™¨æ›´æ–°ä¹‹å‰å†è§„çº¦æ¢¯åº¦ï¼Œä»è€Œåˆ†æ‘Šé€šä¿¡æˆæœ¬</p><h4 id="TPï¼ˆæ¨¡å‹å¹¶è¡Œï¼‰"><a href="#TPï¼ˆæ¨¡å‹å¹¶è¡Œï¼‰" class="headerlink" title="TPï¼ˆæ¨¡å‹å¹¶è¡Œï¼‰"></a>TPï¼ˆæ¨¡å‹å¹¶è¡Œï¼‰</h4><p>åœ¨å¤šä¸ª worker ä¹‹é—´åˆ’åˆ†æ¨¡å‹çš„å„ä¸ªå±‚ã€‚æ¨¡å‹å¹¶è¡Œçš„è®¡ç®—å’Œé€šä¿¡å› æ¨¡å‹ç»“æ„è€Œå¼‚ï¼Œå› æ­¤éœ€è¦å¾ˆå¤§çš„å·¥ä½œé‡æ¥å®ç°ã€‚DeepSpeed åˆ©ç”¨äº† Megatron-LM æ¥æ„å»ºåŸºäº Transformerçš„å¤§è§„æ¨¡æ¨¡å‹å¹¶è¡Œè¯­è¨€æ¨¡å‹</p><p>ä¼˜åŠ¿ï¼šä¼šæ ¹æ® worker æ•°é‡æˆæ¯”ä¾‹åœ°å‡å°‘æ˜¾å­˜ä½¿ç”¨ï¼Œè¿™æ˜¯è¿™ä¸‰ç§å¹¶è¡Œæ¨¡å¼ä¸­æ˜¾å­˜æ•ˆç‡æœ€é«˜çš„ã€‚ä¸”å¯ä»¥é€šè¿‡åœ¨æ¨¡å‹å¹¶è¡Œ worker ä¹‹é—´åˆ’åˆ†æ¿€æ´»æ˜¾å­˜ï¼Œå‡å°‘æ˜¾å­˜å ç”¨</p><p>ä¸è¶³ï¼šæ¯æ¬¡å‰å‘å’Œåå‘ä¼ æ’­ä¸­éƒ½éœ€è¦é¢å¤–é€šä¿¡æ¥ä¼ é€’æ¿€æ´»ï¼Œæ¨¡å‹å¹¶è¡Œçš„è®¡ç®—æ•ˆç‡å¾ˆä½ã€‚æ¨¡å‹å¹¶è¡Œéœ€è¦é«˜é€šä¿¡å¸¦å®½ï¼Œå¹¶ä¸”ä¸èƒ½å¾ˆå¥½åœ°æ‰©å±•åˆ°é€šä¿¡å¸¦å®½å—é™çš„å•ä¸ªèŠ‚ç‚¹ä¹‹å¤–ã€‚æ­¤å¤–ï¼Œæ¯ä¸ªæ¨¡å‹å¹¶è¡Œworkeréƒ½ä¼šå‡å°‘æ¯ä¸ªé€šä¿¡é˜¶æ®µä¹‹é—´æ‰§è¡Œçš„è®¡ç®—é‡ï¼Œä»è€Œå½±å“è®¡ç®—æ•ˆç‡</p><h4 id="PPï¼ˆæµæ°´çº¿å¹¶è¡Œï¼‰"><a href="#PPï¼ˆæµæ°´çº¿å¹¶è¡Œï¼‰" class="headerlink" title="PPï¼ˆæµæ°´çº¿å¹¶è¡Œï¼‰"></a>PPï¼ˆæµæ°´çº¿å¹¶è¡Œï¼‰</h4><p>å°†æ¨¡å‹çš„å„å±‚åˆ’åˆ†ä¸ºå¯ä»¥å¹¶è¡Œå¤„ç†çš„é˜¶æ®µã€‚å½“ä¸€ä¸ªé˜¶æ®µå®Œæˆä¸€ä¸ª micro-batch çš„æ­£å‘ä¼ æ’­æ—¶ï¼Œæ¿€æ´»å†…å­˜å°†è¢«å‘é€ç»™æµæ°´çº¿çš„ä¸‹ä¸€ä¸ªé˜¶æ®µã€‚ç±»ä¼¼åœ°ï¼Œå½“ä¸‹ä¸€é˜¶æ®µå®Œæˆåå‘ä¼ æ’­æ—¶ï¼Œå°†é€šè¿‡æµæ°´çº¿æŠŠæ¢¯åº¦åå‘ä¼ é€’å›æ¥ã€‚ä¸ºäº†ç¡®ä¿æµæ°´çº¿çš„å„ä¸ªé˜¶æ®µèƒ½å¹¶è¡Œè®¡ç®—ï¼Œå¿…é¡»åŒæ—¶è®¡ç®—å¤šä¸ª micro-batch</p><p>åœ¨ PipeDream çš„å®ç°ä¸­ï¼Œé€šè¿‡ä¿ç•™å¤šä»½æ—§å‚æ•°æ¥éšè—æµæ°´çº¿æ³¡æ²«ï¼Œè€Œä¸”ä¸ä¼šè¿‡å¤šå¢åŠ  batch sizeï¼Œæœ¬æ–‡é€šè¿‡æ¢¯åº¦ç´¯ç§¯æ¥å®ç°å¹¶è¡Œçš„æ–¹æ³•ï¼Œåœ¨ç›¸åŒçš„ batch sizeä¸‹å¯ä»¥è¾¾åˆ°ä¸ä¼ ç»Ÿ DP å’Œæ¨¡å‹å¹¶è¡Œç›¸åŒçš„è®­ç»ƒæ•ˆæœ</p><p>ä¼˜åŠ¿ï¼šæµæ°´çº¿å¹¶è¡Œå‡å°‘çš„æ˜¾å­˜ä¸æµæ°´çº¿çš„é˜¶æ®µæ•°æˆæ­£æ¯”ï¼Œè¿™ä½¿æ¨¡å‹çš„å¤§å°å¯ä»¥éš worker çš„æ•°é‡çº¿æ€§æ‰©å±•ï¼Œå¹¶ä¸”é€šè¿‡ micro-batch å¯ä»¥æœ‰æ•ˆå‡å°‘ bubbleã€‚æ­¤å¤–ï¼Œæµæ°´çº¿çš„é€šä¿¡é‡åªå’Œé˜¶æ®µè¾¹ç•Œçš„å„å±‚çš„æ¿€æ´»å€¼å¤§å°æˆæ­£æ¯”ï¼Œæ‰€ä»¥æµæ°´çº¿å¹¶è¡Œçš„é€šä¿¡é‡æœ€ä½</p><p>ä¸è¶³ï¼šæ¯ä¸ª worker å¿…é¡»åŒæ—¶å­˜å‚¨å¹¶è¿è¡Œçš„å„ä¸ª micro-batch çš„æ¿€æ´»å€¼ï¼Œå¯¼è‡´æµæ°´çº¿ç¬¬ä¸€é˜¶æ®µçš„æ¿€æ´»å†…å­˜ä¸å•ä¸ª mirco-batch çš„æ€»æ¿€æ´»å†…å­˜å¤§è‡´ç›¸åŒã€‚ä¸æ–­å¢åŠ æµæ°´çº¿å¤§å°ä¼šå‡å°‘æ¯ä¸ªæµæ°´çº¿é˜¶æ®µçš„è®¡ç®—é‡ï¼Œé™ä½è®¡ç®—é€šä¿¡æ•ˆç‡ã€‚æµæ°´çº¿å¹¶è¡Œè¿˜å¯¹æ¯ä¸ªé˜¶æ®µçš„è´Ÿè½½å‡è¡¡æœ‰å¾ˆé«˜çš„è¦æ±‚ã€‚æ­¤å¤–ï¼Œç”±äºæ°´å¹³æ‹†åˆ†å’Œ micro-batchï¼Œå¦‚tied-weight å’Œ batch-normalization ç­‰åŠŸèƒ½éš¾ä»¥å®ç°</p><h3 id="éå¹¶è¡ŒåŒ–æ–¹æ³•èŠ‚çœå†…å­˜"><a href="#éå¹¶è¡ŒåŒ–æ–¹æ³•èŠ‚çœå†…å­˜" class="headerlink" title="éå¹¶è¡ŒåŒ–æ–¹æ³•èŠ‚çœå†…å­˜"></a>éå¹¶è¡ŒåŒ–æ–¹æ³•èŠ‚çœå†…å­˜</h3><h4 id="å‡å°‘æ¿€æ´»å†…å­˜"><a href="#å‡å°‘æ¿€æ´»å†…å­˜" class="headerlink" title="å‡å°‘æ¿€æ´»å†…å­˜"></a>å‡å°‘æ¿€æ´»å†…å­˜</h4><p>ä½œè€…å¼•ç”¨äº†å‡ ç¯‡æ–‡çŒ®ä¸¾ä¾‹å¦‚ä½•ä¼˜åŒ–æ¿€æ´»å†…å­˜</p><h5 id="å‹ç¼©å†…å­˜"><a href="#å‹ç¼©å†…å­˜" class="headerlink" title="å‹ç¼©å†…å­˜"></a>å‹ç¼©å†…å­˜</h5><p>è®ºæ–‡ä¸»è¦ç ”ç©¶äº†åœ¨æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰çš„è®­ç»ƒä¸­ï¼ŒGPUä¸»å†…å­˜é™åˆ¶å¯¼è‡´è®­ç»ƒæ›´æ·±å±‚æ¬¡çš„ç½‘ç»œæ—¶å‡ºç°ç“¶é¢ˆçš„é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œä¸»è¦çš„å†…å­˜å ç”¨é—®é¢˜æ¥è‡ªäºä¸­é—´å±‚çš„è¾“å‡ºï¼ˆç‰¹å¾å›¾ï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§DNNå±‚ç‰¹å®šçš„ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡å¯¹ç‰¹å®šå±‚ï¼ˆå¦‚å·ç§¯ã€ReLUã€æ± åŒ–ï¼‰è¿›è¡Œç¼–ç å’Œè§£ç ï¼Œä»¥æ˜¾è‘—é™ä½GPUä¸»å†…å­˜çš„å‹åŠ›ã€‚å…¶æ ¸å¿ƒæ–¹æ³•æ˜¯åœ¨ä¸¤ä¸ªæ—¶é—´ç‚¹ä¹‹é—´å­˜å‚¨ç‰¹å¾å›¾çš„ç¼–ç è¡¨ç¤ºï¼Œå¹¶åœ¨åå‘ä¼ æ’­æ—¶è§£ç ï¼Œè€Œåœ¨å‰å‘ä¼ æ’­æ—¶ä½¿ç”¨å®Œæ•´çš„ç‰¹å¾å›¾ã€‚ä½œè€…è¿˜ä»‹ç»äº†åä¸ºGistçš„ç³»ç»Ÿï¼Œå®ƒé‡‡ç”¨ä¸¤ç±»å±‚ç‰¹å®šçš„ç¼–ç æ–¹æ¡ˆï¼ˆæ— æŸå’Œæœ‰æŸï¼‰ï¼Œåˆ©ç”¨DNNè®­ç»ƒä¸­ç°æœ‰çš„æ•°å€¼å†—ä½™ï¼Œæ˜¾è‘—å‡å°‘äº†ç›®æ ‡ç‰¹å¾å›¾çš„å†…å­˜æ¶ˆè€—ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡å……åˆ†åˆ©ç”¨ä»æ± åŒ–åˆ°ReLUå±‚çš„åå‘ä¼ æ’­çš„è®¡ç®—ç‰¹æ€§ï¼Œå¯ä»¥å°†ä¸­é—´ç‰¹å¾å›¾çš„å­˜å‚¨ç²¾ç®€è‡³æ¯ä¸ªå€¼ä»…ä½¿ç”¨1ä½è€Œä¸æ˜¯32ä½ã€‚é€šè¿‡åœ¨ä¸€æµçš„DNNæ¡†æ¶ï¼ˆCNTKï¼‰ä¸­éƒ¨ç½²è¿™äº›æœºåˆ¶ï¼ŒGiståœ¨5ä¸ªæœ€å…ˆè¿›çš„å›¾åƒåˆ†ç±»DNNä¸Šå°†å†…å­˜å ç”¨é™ä½äº†æœ€å¤š2å€ï¼Œå¹³å‡é™ä½äº†1.8å€ï¼Œä»…å¸¦æ¥4%çš„æ€§èƒ½å¼€é”€ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è¡¨æ˜ï¼Œè¿›ä¸€æ­¥çš„è½¯ä»¶ï¼ˆä¾‹å¦‚CuDNNï¼‰å’Œç¡¬ä»¶ï¼ˆä¾‹å¦‚åŠ¨æ€åˆ†é…ï¼‰ä¼˜åŒ–å¯ä»¥è¿›ä¸€æ­¥é™ä½å†…å­˜å ç”¨ï¼Œæœ€å¤šå¯å‡å°‘4.1å€</p><h5 id="æ¿€æ´»å†…å­˜-checkpoint"><a href="#æ¿€æ´»å†…å­˜-checkpoint" class="headerlink" title="æ¿€æ´»å†…å­˜ checkpoint"></a>æ¿€æ´»å†…å­˜ checkpoint</h5><p>è®ºæ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿæ€§æ–¹æ³•ï¼Œæ—¨åœ¨å‡å°‘æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒçš„å†…å­˜æ¶ˆè€—ã€‚ä¸»è¦å…³æ³¨ç‚¹æ˜¯å‡å°‘å­˜å‚¨ä¸­é—´ç»“æœï¼ˆç‰¹å¾å›¾ï¼‰å’Œæ¢¯åº¦æ‰€éœ€çš„å†…å­˜æˆæœ¬ï¼Œå› ä¸ºä¸è®¸å¤šå¸¸è§çš„æ·±åº¦æ¶æ„ä¸­çš„ä¸­é—´ç‰¹å¾å›¾ç›¸æ¯”ï¼Œå‚æ•°çš„å¤§å°ç›¸å¯¹è¾ƒå°ã€‚è®ºæ–‡ä½¿ç”¨è®¡ç®—å›¾åˆ†æè¿›è¡Œè‡ªåŠ¨åŸåœ°æ“ä½œå’Œå†…å­˜å…±äº«ä¼˜åŒ–ã€‚è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥ä»¥è®¡ç®—ä¸ºä»£ä»·æ¥æ¢å–å†…å­˜ï¼Œç”¨äºç‰¹å¾å›¾è®­ç»ƒnå±‚ç½‘ç»œï¼Œæˆæœ¬ä¸ºO(âˆšn)çš„å†…å­˜ï¼Œä»…éœ€åŒå€çš„å‰å‘ä¼ æ’­è®¡ç®—æˆæœ¬ã€‚åœ¨æç«¯æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨ä»…O(logn)çš„å†…å­˜æ¥è®­ç»ƒnå±‚ç½‘ç»œçš„ç‰¹å¾å›¾</p><p>ä½œè€…è¿™é‡Œå¼•ç”¨äº† Checkmate ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿæ—¨åœ¨è§£å†³å¼ é‡é‡æ–°ç”Ÿæˆè°ƒåº¦çš„æœ€ä½³åŒ–é—®é¢˜ã€‚Checkmate å¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…ï¼ˆä¸åˆ°ä¸€å°æ—¶ï¼‰ä½¿ç”¨ç°æˆçš„MILPï¼ˆMixed Integer Linear Programmingï¼‰æ±‚è§£å™¨æˆ–ä½¿ç”¨è¿‘ä¼¼ç®—æ³•æ‰¾åˆ°æ¥è¿‘æœ€ä¼˜çš„è°ƒåº¦æ–¹æ¡ˆã€‚è¿™äº›è°ƒåº¦æ–¹æ¡ˆå¯ä»¥ç”¨äºåŠ é€Ÿæ•°ç™¾ä¸‡æ¬¡çš„è®­ç»ƒè¿­ä»£ã€‚é™¤äº†å‡å°‘è®­ç»ƒæˆæœ¬å¤–ï¼ŒCheckmateè¿˜å¯ä»¥ä½¿ç°å®ä¸–ç•Œä¸­çš„ç½‘ç»œèƒ½å¤Ÿä½¿ç”¨æ¯”ä»¥å‰å¤§çº¦å¤š5.1å€çš„è¾“å…¥å°ºå¯¸è¿›è¡Œè®­ç»ƒ</p><h5 id="å®æ—¶å†…å­˜ç®¡ç†"><a href="#å®æ—¶å†…å­˜ç®¡ç†" class="headerlink" title="å®æ—¶å†…å­˜ç®¡ç†"></a>å®æ—¶å†…å­˜ç®¡ç†</h5><p>ä½œè€…æå‡ºäº†SuperNeurons åŠ¨æ€çš„GPUå†…å­˜è°ƒåº¦è¿è¡Œæ—¶ç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸‰ç§å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼šLiveness Analysisï¼ˆå­˜æ´»æ€§åˆ†æï¼‰ã€Unified Tensor Poolï¼ˆç»Ÿä¸€å¼ é‡æ± ï¼‰å’Œ Cost-Aware Recomputationï¼ˆæˆæœ¬æ„ŸçŸ¥çš„é‡è®¡ç®—ï¼‰ã€‚è¿™äº›æŠ€æœ¯å…±åŒæœ‰æ•ˆåœ°å°†ç½‘ç»œæ•´ä½“çš„å†…å­˜å³°å€¼ä½¿ç”¨é‡é™ä½åˆ°å„å±‚ä¸­çš„æœ€å¤§å†…å­˜ä½¿ç”¨é‡ã€‚æ­¤å¤–ï¼ŒSuperNeuronsè¿˜è§£å†³äº†è¿™äº›å†…å­˜èŠ‚çœæŠ€æœ¯ä¸­çš„æ€§èƒ½é—®é¢˜ã€‚é‰´äºæœ‰é™çš„GPU DRAMï¼ŒSuperNeuronsä¸ä»…æä¾›äº†è®­ç»ƒæ‰€éœ€çš„å†…å­˜ï¼Œè¿˜åŠ¨æ€åˆ†é…å†…å­˜ç”¨äºå·ç§¯å·¥ä½œç©ºé—´ï¼Œä»¥å®ç°é«˜æ€§èƒ½çš„è®­ç»ƒã€‚SuperNeurons èƒ½å¤Ÿåœ¨ä¸€ä¸ª12GBçš„ K40c GPUä¸Šè®­ç»ƒåŒ…å«104ä¸ªåŸºæœ¬ç½‘ç»œå±‚çš„ ResNet2500</p><p>æœ¬æ–‡çš„ ZeRO-R åŒæ—¶ä½¿ç”¨äº†å‹ç¼©å†…å­˜å’Œ checkpoint æŠ€æœ¯</p><h3 id="CPU-Offload"><a href="#CPU-Offload" class="headerlink" title="CPU Offload"></a>CPU Offload</h3><p>è¿™é‡Œå¼•ç”¨äº†å…¶å®ƒä¸¤ç§å†…å­˜å¸è½½æ–¹æ³•</p><h4 id="ä¼˜åŒ–æ‰§è¡Œç®—æ³•"><a href="#ä¼˜åŒ–æ‰§è¡Œç®—æ³•" class="headerlink" title="ä¼˜åŒ–æ‰§è¡Œç®—æ³•"></a>ä¼˜åŒ–æ‰§è¡Œç®—æ³•</h4><p>è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºâ€L2Lâ€çš„æ–°å‹æ‰§è¡Œç®—æ³•ï¼Œå®ƒé‡‡ç”¨ä¸€ç§ä¸­ç»§å¼æ‰§è¡ŒæŠ€æœ¯ã€‚åœ¨ä»»ä½•ç»™å®šæ—¶åˆ»ï¼Œè®¾å¤‡å†…å­˜ä¸»è¦ä»…å¡«å……äº†æ­£åœ¨æ‰§è¡Œçš„å±‚çš„å ç”¨ç©ºé—´ã€‚æ¨¡å‹é©»ç•™åœ¨DRAMå†…å­˜ä¸­ï¼Œè¿æ¥åˆ°CPUæˆ–FPGAï¼Œä½œä¸ºä¸€ç§ç§°ä¸ºâ€eager param-serverï¼ˆEPSï¼‰â€çš„å®ä½“ã€‚ä¸ºäº†è§£å†³å°†å‚æ•°ä¼ é€’åˆ°EPSçš„å¸¦å®½é—®é¢˜ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨äº†ä¸€ç§é€å±‚æ‰§è¡Œçš„æ–¹å¼ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„å°æ‰¹é‡æ‰§è¡Œæ•´ä¸ªæ¨¡å‹çš„æ–¹æ³•ã€‚è¿™æ„å‘³ç€æ¨¡å‹ä»¥å¤šä¸ªå¾®æ‰¹æ¬¡çš„æ–¹å¼æ‰§è¡Œï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„å°æ‰¹é‡æ–¹å¼ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æ˜¾è‘—å‡å°‘å†…å­˜å ç”¨ï¼Œå¹¶æé«˜ååé‡</p><h4 id="è™šæ‹Ÿå†…å­˜-Offload"><a href="#è™šæ‹Ÿå†…å­˜-Offload" class="headerlink" title="è™šæ‹Ÿå†…å­˜ Offload"></a>è™šæ‹Ÿå†…å­˜ Offload</h4><p>è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸º vDNN çš„è™šæ‹ŸåŒ–DNNï¼Œä¸»è¦æ€æƒ³æ˜¯ä¿å®ˆåœ°åˆ†é…GPUå†…å­˜ï¼Œä»¥ç«‹å³ä½¿ç”¨ç»™å®šå±‚çš„è®¡ç®—ï¼Œä»è€Œå¤§å¹…å‡å°‘æœ€å¤§å’Œå¹³å‡å†…å­˜ä½¿ç”¨ã€‚vDNN åˆ©ç”¨åˆ†é…çš„æ•°æ®ç»“æ„çš„æ•°æ®ä¾èµ–æ€§ï¼Œç‰¹åˆ«æ˜¯å å†…å­˜ä½¿ç”¨é‡å¤§éƒ¨åˆ†çš„ä¸­é—´ç‰¹å¾æ˜ å°„ï¼Œåœ¨ GPU å’Œ CPU å†…å­˜ä¹‹é—´é‡Šæ”¾æˆ–ç§»åŠ¨è¿™äº›ä¸­é—´æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼Œå¦‚æœæ²¡æœ‰è¿›ä¸€æ­¥çš„é‡ç”¨ï¼Œå°±ç§¯æåœ°ä» GPU å†…å­˜ä¸­é‡Šæ”¾è¿™äº›ç‰¹å¾æ˜ å°„ï¼Œå¦‚æœå­˜åœ¨è¿›ä¸€æ­¥çš„é‡ç”¨ï¼Œä½†ä¸æ˜¯ç«‹å³éœ€è¦ï¼Œå°±ä»CPUå†…å­˜å¸è½½/é¢„å–ã€‚é€šè¿‡ DNN ç»œçš„å±‚é—´å†…å­˜è®¿é—®å’Œé‡ç”¨æ¨¡å¼ï¼Œå†…å­˜ç®¡ç†å™¨æ™ºèƒ½åœ°å°†æ­£å¸¸çš„ DNN è®¡ç®—ä¸å¸è½½/é¢„å–/é‡Šæ”¾ æ“ä½œé‡å ï¼Œå‡ ä¹æ²¡æœ‰æ€§èƒ½æŸå¤±</p><p>ä¸Šé¢çš„æ–‡çŒ®åˆ©ç”¨è®¡ç®—èŠ‚ç‚¹çš„å¼‚æ„æ€§ï¼Œåˆ†åˆ«é€šè¿‡ç®—æ³•è®¾è®¡æˆ–è™šæ‹ŸåŒ–å†…å­˜å°†æ¨¡å‹çŠ¶æ€è½¬ç§»åˆ°CPUå†…å­˜ã€‚ä½†æ˜¯è¿™å¯¼è‡´æœ‰50%çš„æ—¶é—´è¢«æµªè´¹åœ¨GPU-CPU-GPUä¼ è¾“ã€‚ZeROçš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œå®ƒæ˜¾è‘—é™ä½äº†å†…å­˜æ¶ˆè€—ï¼Œè€Œæ— éœ€å°†æ¨¡å‹çŠ¶æ€å­˜å‚¨åˆ°CPUå†…å­˜ä¸­ã€‚åœ¨æå°‘æ•°æƒ…å†µä¸‹ï¼ŒZeRO-Rå¯èƒ½åªé’ˆå¯¹éå¸¸å¤§çš„æ¨¡å‹æ‰ offload æ¿€æ´» checkpointï¼Œä»¥æé«˜æ€§èƒ½</p><h3 id="Memory-Efficient-Optimizer"><a href="#Memory-Efficient-Optimizer" class="headerlink" title="Memory Efficient Optimizer"></a>Memory Efficient Optimizer</h3><p>è‡ªé€‚åº”æ¢¯åº¦ä¼˜åŒ–å™¨å¦‚ Adagrad å’Œ Adam æ–¹æ³•åœ¨ NLP ä»»åŠ¡ä¸­å–å¾—äº†ä¸é”™çš„æ€§èƒ½ï¼Œç„¶è€Œè¿™äº›æ–¹æ³•ä¸ºæ¯ä¸ªå‚æ•°ç»´æŠ¤äº†äºŒé˜¶ç»Ÿè®¡ä¿¡æ¯ï¼Œå› æ­¤å¼•å…¥äº†æ˜¾è‘—çš„å†…å­˜å¼€é”€ï¼Œé™åˆ¶äº†å¯ä½¿ç”¨çš„æ¨¡å‹å¤§å°ä»¥åŠæ¯ä¸ªå°æ‰¹é‡ä¸­çš„ç¤ºä¾‹æ•°é‡ã€‚ä¸‹é¢æ˜¯è¿‡å»æå‡ºçš„ä¼˜åŒ–å†…å­˜çš„æ–‡çŒ®</p><h4 id="è‡ªé€‚åº”å­¦ä¹ ç‡"><a href="#è‡ªé€‚åº”å­¦ä¹ ç‡" class="headerlink" title="è‡ªé€‚åº”å­¦ä¹ ç‡"></a>è‡ªé€‚åº”å­¦ä¹ ç‡</h4><p>è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸º Adafactor çš„è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–ç®—æ³•ï¼Œä¸ºäº†å‡å°‘å†…å­˜å ç”¨ï¼Œä»…ç»´æŠ¤æ¯è¡Œå’Œæ¯åˆ—çš„ç§»åŠ¨å¹³å‡å’ŒäºŒé˜¶çŸ©çš„å’Œï¼Œç„¶ååŸºäºè¿™äº›å’Œæ¥ä¼°è®¡æ¯ä¸ªå‚æ•°çš„äºŒé˜¶çŸ©ã€‚è¿™ç§æ–¹æ³•åœ¨å®éªŒä¸­è¡¨ç°å‡ºä¸ä¼ ç»Ÿæ–¹æ³•ç›¸ä¼¼çš„ç»“æœã€‚æœ€åï¼Œä½œè€…è¿˜æå‡ºäº†æ ¹æ®å‚æ•°æœ¬èº«çš„è§„æ¨¡æ¥è°ƒæ•´å‚æ•°æ›´æ–°çš„æ–¹æ³•</p><h4 id="è‡ªé€‚åº”ä¼˜åŒ–å™¨"><a href="#è‡ªé€‚åº”ä¼˜åŒ–å™¨" class="headerlink" title="è‡ªé€‚åº”ä¼˜åŒ–å™¨"></a>è‡ªé€‚åº”ä¼˜åŒ–å™¨</h4><p>ä½œè€…æå‡ºäº†ä¸€ç§è‡ªé€‚åº”ä¼˜åŒ–ç®—æ³• SM3ï¼Œè¯¥ç®—æ³•é€šè¿‡ä½¿ç”¨å‚æ•°çš„è¦†ç›–é›†åˆæ¥å‡å°‘å†…å­˜éœ€æ±‚ï¼Œå…¶ä¸­æ¯ä¸ªé›†åˆéƒ½å¯¹åº”ä¸€ä¸ªå˜é‡ï¼Œé€šè¿‡ç»´æŠ¤ä¸€ç»„è¦†ç›–é›†åˆï¼Œå¹¶å¯¹æ¯ä¸ªé›†åˆçš„æœ€å¤§æ–¹å·®è¿›è¡Œæ±‚å’Œï¼Œç¡®å®šæ¯ä¸ªæ¢¯åº¦æ¡ç›®çš„å­¦ä¹ ç‡ã€‚é€šè¿‡å‡å°‘å†…å­˜éœ€æ±‚å®ç°äº†ä¸¤å€çš„é€Ÿåº¦æå‡</p><p>ä¸Šé¢çš„æ–‡çŒ®é€šè¿‡è·å–æ¨¡å‹å‚æ•°æˆ–æ¢¯åº¦çš„ç²—ç²’åº¦ç»Ÿè®¡æ•°æ®æ¥å‡å°‘è‡ªé€‚åº”ä¼˜åŒ–æ–¹æ³•çš„å†…å­˜æ¶ˆè€—ï¼Œè¿™å¯èƒ½ä¼šå¯¹æ¨¡å‹æ”¶æ•›ä¿è¯äº§ç”Ÿå½±å“ã€‚ZeROä¸è¿™äº›å·¥ä½œä¸åŒï¼Œå®ƒçš„ä¼˜åŒ–ä¸ä¼šæ”¹å˜æ¨¡å‹ä¼˜åŒ–æ–¹æ³•æˆ–å½±å“æ¨¡å‹æ”¶æ•›ï¼Œä½†ä¼šæœ‰æ•ˆåœ°å‡å°‘æ¯ä¸ªè®¾å¤‡çš„ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦çš„å†…å­˜å ç”¨</p><h4 id="è®­ç»ƒä¼˜åŒ–å™¨"><a href="#è®­ç»ƒä¼˜åŒ–å™¨" class="headerlink" title="è®­ç»ƒä¼˜åŒ–å™¨"></a>è®­ç»ƒä¼˜åŒ–å™¨</h4><p>å¯¹äºå¤§å‹æ¨¡å‹ï¼Œè‡ªé€‚åº”ä¼˜åŒ–ï¼ˆAdaptiveï¼‰æ–¹æ³•å¯¹äºè¾¾åˆ° SOTA æ€§èƒ½å’Œç²¾åº¦è‡³å…³é‡è¦ã€‚ä¸ SGD ç›¸æ¯”ï¼Œå®ƒä»¥æ˜¾è‘—çš„å†…å­˜å ç”¨ä¸ºä»£ä»·ï¼Œç»´æŠ¤æ¯ä¸ªæ¨¡å‹å‚æ•°å’Œæ¢¯åº¦çš„ç»†ç²’åº¦ä¸€é˜¶å’ŒäºŒé˜¶ç»Ÿè®¡ä¿¡æ¯ã€‚ZeROå¯ä»¥å°†è¿™äº›ä¼˜åŒ–å™¨çš„å†…å­˜å ç”¨å‡å°‘å‡ ä¸ªæ•°é‡çº§ï¼Œä½¿è¿™äº›å¤æ‚çš„ä¼˜åŒ–æ–¹æ³•åœ¨è®­ç»ƒå¤§æ¨¡å‹æ—¶éå¸¸æœ‰æ•ˆã€‚å®ƒè¿˜å…è®¸å¼€å‘å’Œä½¿ç”¨æ›´å¤æ‚ã€å†…å­˜æ¶ˆè€—æ›´å¤§ã€æ”¶æ•›æ€§æ›´å¥½çš„ä¼˜åŒ–å™¨</p><h2 id="ä¼˜åŒ–å†…å­˜å ç”¨"><a href="#ä¼˜åŒ–å†…å­˜å ç”¨" class="headerlink" title="ä¼˜åŒ–å†…å­˜å ç”¨"></a>ä¼˜åŒ–å†…å­˜å ç”¨</h2><p>å‰é¢æåˆ°å†…å­˜æ¶ˆè€—ä¸»è¦é›†ä¸­åœ¨</p><ul><li>æ¨¡å‹çŠ¶æ€ï¼šä¼˜åŒ–å™¨ï¼Œæ¢¯åº¦ï¼Œå‚æ•°</li><li>residual statesï¼šæ¿€æ´»å€¼ï¼Œbufferï¼Œå†…å­˜ç¢ç‰‡</li></ul><p>ä¸‹é¢å±•å¼€è®¨è®ºä¸ºä½•ä¼šè¿™æ ·</p><h3 id="æ¨¡å‹çŠ¶æ€ï¼šä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¢¯åº¦ä¸å‚æ•°"><a href="#æ¨¡å‹çŠ¶æ€ï¼šä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¢¯åº¦ä¸å‚æ•°" class="headerlink" title="æ¨¡å‹çŠ¶æ€ï¼šä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¢¯åº¦ä¸å‚æ•°"></a>æ¨¡å‹çŠ¶æ€ï¼šä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ¢¯åº¦ä¸å‚æ•°</h3><h4 id="æ··åˆç²¾åº¦è®­ç»ƒ"><a href="#æ··åˆç²¾åº¦è®­ç»ƒ" class="headerlink" title="æ··åˆç²¾åº¦è®­ç»ƒ"></a>æ··åˆç²¾åº¦è®­ç»ƒ</h4><p>åœ¨ä½¿ç”¨adamä¼˜åŒ–å™¨è®­ç»ƒæ—¶ï¼ŒAdamä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡æ¥è®¡ç®—æ¢¯åº¦ï¼Œè¿™éœ€è¦ä¿å­˜æ¢¯åº¦çš„æ‹·è´ï¼Œä»¥ç¨³å®šæ›´æ–°å‚æ•°ã€‚Adamè¿˜ä½¿ç”¨äº†è‡ªé€‚åº”å­¦ä¹ ç‡æœºåˆ¶ï¼Œä¼šä¸ºæ¯ä¸ªå‚æ•°è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡ã€‚å­¦ä¹ ç‡çš„è‡ªé€‚åº”æ€§ä¾èµ–äºæ¯ä¸ªå‚æ•°çš„æ¢¯åº¦æ–¹å·®ã€‚ä¸ºäº†è®¡ç®—æ¢¯åº¦æ–¹å·®ï¼Œå°±éœ€è¦ä¿å­˜æ¢¯åº¦çš„å¹³æ–¹çš„ç§»åŠ¨å¹³å‡å€¼ï¼Œä»¥ä¾¿åœ¨å‚æ•°æ›´æ–°æ—¶æ›´å¥½åœ°é€‚åº”å±€éƒ¨æ¢¯åº¦çš„ç‰¹æ€§</p><p>åœ¨ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒæ—¶ï¼Œå°†å‚æ•°å’Œæ¢¯åº¦å­˜å‚¨ä¸º fp16ï¼Œå¹¶åœ¨å‰åå‘ä¼ æ’­æ—¶éƒ½ä½¿ç”¨ fp16 æ›´æ–°ï¼Œä½†æ˜¯ä¸ºäº†åå‘ä¼ æ’­ç»“æŸåä¿è¯è®¡ç®—çš„ç²¾ç¡®ï¼Œéœ€è¦ä¿å­˜å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„ fp32 å‰¯æœ¬ï¼Œä»¥Adamä¼˜åŒ–å™¨ä¸ºä¾‹ï¼Œä½¿ç”¨Adamå¯¹å…·æœ‰Î¨ä¸ªå‚æ•°çš„æ¨¡å‹è¿›è¡Œæ··åˆç²¾åº¦è®­ç»ƒéœ€è¦è¶³å¤Ÿçš„å†…å­˜æ¥å­˜å‚¨å‚æ•°å’Œæ¢¯åº¦çš„fp16å‰¯æœ¬ï¼Œå†…å­˜éœ€æ±‚åˆ†åˆ«ä¸º 2Î¨ å’Œ 2Î¨ å­—èŠ‚ã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦å­˜å‚¨ä¼˜åŒ–å™¨çŠ¶æ€ï¼šå‚æ•°ã€åŠ¨é‡å’Œæ–¹å·®çš„ fp32 å‰¯æœ¬ï¼Œå†…å­˜éœ€æ±‚åˆ†åˆ«ä¸º 4Î¨ã€4Î¨ å’Œ 4Î¨ å­—èŠ‚ã€‚æ–‡ä¸­ä½¿ç”¨ K æ¥è¡¨ç¤ºä¼˜åŒ–å™¨çŠ¶æ€çš„å†…å­˜ä¹˜æ•°ï¼Œå³å­˜å‚¨å®ƒä»¬æ‰€éœ€çš„é¢å¤–å†…å­˜ä¸º KÎ¨ å­—èŠ‚ã€‚æ··åˆç²¾åº¦ Adam çš„ K å€¼ä¸º 12ã€‚è¿™å¯¼è‡´äº† 2+2+12=16 Î¨ å­—èŠ‚çš„å†…å­˜éœ€æ±‚ã€‚å¯¹äºåƒ GPT-2 è¿™æ ·æœ‰15äº¿å‚æ•°çš„æ¨¡å‹ï¼Œè‡³å°‘éœ€è¦24GBçš„å†…å­˜ï¼Œè¿œè¿œé«˜äº 3GB å†…å­˜æ¥å­˜å‚¨ fp16 å‚æ•°çš„éœ€æ±‚</p><h3 id="Residual-å†…å­˜æ¶ˆè€—"><a href="#Residual-å†…å­˜æ¶ˆè€—" class="headerlink" title="Residual å†…å­˜æ¶ˆè€—"></a>Residual å†…å­˜æ¶ˆè€—</h3><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ä¼šå ç”¨å¤§é‡å†…å­˜ã€‚ä»¥ GPT-2 æ¨¡å‹ä¸ºä¾‹ï¼Œå½“åºåˆ—é•¿åº¦ä¸º 1Kï¼Œbatch_size ä¸º 32æ—¶ï¼Œ1.5B å‚æ•°çš„æ¨¡å‹éœ€è¦å¤§çº¦ 60GB çš„å†…å­˜</p><p>è®¡ç®—å…¬å¼ï¼šæ¿€æ´»å€¼å†…å­˜ = Transformer å±‚æ•° Ã— hidden_dim Ã— batch_size Ã— seq_len Ã— Transformer å±‚æ•°</p><p>ä½¿ç”¨æ¿€æ´»å€¼ checkpoint æ–¹æ³•å¯ä»¥å‡å°‘æ¿€æ´»å‡½æ•°å†…å­˜çš„æ¶ˆè€—ï¼Œä¼šå¢åŠ  33% çš„ recompute å¼€é”€ï¼Œä½†å¯ä»¥å°†æ¿€æ´»å‡½æ•°å†…å­˜æ¶ˆè€—é™ä½åˆ°çº¦ 8GB ä½†å¯¹äºæ›´å¤§çš„æ¨¡å‹ï¼Œæ¿€æ´»å‡½æ•°çš„å†…å­˜æ¶ˆè€—ä»ç„¶å¯èƒ½éå¸¸å¤§ã€‚å¦‚ä¸€ä¸ªæ‹¥æœ‰ 1000 äº¿å‚æ•°çš„ GPT-like æ¨¡å‹ï¼Œåœ¨ batch_size ä¸º32 æ—¶ï¼Œå³ä½¿ä½¿ç”¨äº†æ¿€æ´»å€¼ checkpoint ä»éœ€60GBçš„å†…å­˜ã€‚æ­¤å¤–ï¼Œå¯¹äºå¤§å‹æ¨¡å‹ï¼Œç”¨äºå­˜å‚¨ä¸­é—´ç»“æœçš„ä¸´æ—¶ buffer ä¹Ÿä¼šå ç”¨ç›¸å½“å¤§çš„å†…å­˜ã€‚ä¾‹å¦‚ï¼Œå¯¹æ¢¯åº¦ all_reduce æˆ–æ¢¯åº¦è®¡ç®—æ—¶ä¼šå°†æ‰€æœ‰æ¢¯åº¦èåˆåˆ°ä¸€ä¸ª flattened buffer ä¸­ï¼Œå°½ç®¡æ¢¯åº¦å¯ä»¥ä»¥ fp16 å­˜å‚¨ï¼Œä½† buffer å¯èƒ½è¿˜æ˜¯ fp32ã€‚å¯¹äºä¸€ä¸ªå…·æœ‰ 15 äº¿å‚æ•°çš„æ¨¡å‹ï¼Œä¸€ä¸ª flattened fp32 buffer è¦å ç”¨6GBçš„å†…å­˜</p><p>æ­¤å¤–ï¼Œå†…å­˜ç¢ç‰‡çš„é—®é¢˜ä¹Ÿè¦æ³¨æ„ï¼Œåœ¨æç«¯æƒ…å†µä¸‹ï¼Œå†…å­˜ç¢ç‰‡å¯æµªè´¹ 30% çš„å†…å­˜</p><h2 id="ZeRO"><a href="#ZeRO" class="headerlink" title="ZeRO"></a>ZeRO</h2><p>ZeRO æå‡ºäº†ä¸¤ç»„ä¼˜åŒ–ï¼š</p><ul><li>ZeRO-DPï¼šä¼˜åŒ–æ¨¡å‹çŠ¶æ€å†…å­˜æ¶ˆè€—</li><li>ZeRO-Rï¼šä¼˜åŒ– Residual å†…å­˜æ¶ˆè€—</li></ul><h3 id="ZeRO-DP"><a href="#ZeRO-DP" class="headerlink" title="ZeRO-DP"></a>ZeRO-DP</h3><p>DPï¼šä¼˜ç‚¹ï¼šè®¡ç®—ç²’åº¦é«˜ï¼Œé€šä¿¡ä½ï¼›ä¸è¶³ï¼š DP è¿›ç¨‹ä¹‹é—´å†—ä½™å­˜å‚¨</p><p>MPï¼šä¼˜ç‚¹ï¼šé€šè¿‡åˆ†åŒºæ¨¡å‹åˆ©ç”¨å†…å­˜ï¼›ä¸è¶³ï¼šè®¡ç®—ç²’åº¦é™ä½</p><p>ZeRO-DP é€šè¿‡åˆ†åŒºæ¨¡å‹çŠ¶æ€å¹¶ä½¿ç”¨åŠ¨æ€çš„é€šä¿¡è°ƒåº¦ï¼ŒåŒæ—¶æœ‰ DP å’Œ MP çš„ä¼˜ç‚¹</p><h4 id="Optimizer-State-Partitioning"><a href="#Optimizer-State-Partitioning" class="headerlink" title="Optimizer State Partitioning"></a>Optimizer State Partitioning</h4><p>åœ¨DPä¸­ï¼Œé€šè¿‡å°†ä¼˜åŒ–å™¨çš„çŠ¶æ€åˆ†æˆNä¸ªåˆ†åŒºï¼Œä½¿å¾—æ¯ä¸ªDPè¿›ç¨‹åªæ›´æ–°å¯¹åº”çš„åˆ†åŒºçš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œä¹Ÿå°±æ˜¯1/Nçš„æ€»ä¼˜åŒ–å™¨çŠ¶æ€å‚æ•°é‡</p><h4 id="Gradient-Partitioning"><a href="#Gradient-Partitioning" class="headerlink" title="Gradient Partitioning"></a>Gradient Partitioning</h4><p>æ¢¯åº¦çš„è®¡ç®—è¢«åˆ†ä¸ºä¸åŒçš„åˆ†åŒºï¼Œæ¯ä¸ª DP è¿›ç¨‹åªå¤„ç†å’Œæ›´æ–°å¯¹åº”å‚æ•°åˆ†åŒºçš„æ¢¯åº¦ã€‚æ–‡ä¸­è¿˜é‡‡ç”¨äº†ä¸€ç§ ucketization<br>ç­–ç•¥ï¼Œå°†åŒä¸€å‚æ•°åˆ†åŒºçš„æ¢¯åº¦è¿›è¡Œåˆ†ç»„ï¼Œå¹¶ä¸€æ¬¡æ€§å¯¹æ•´ä¸ªç»„è¿›è¡Œå½’çº¦æ“ä½œã€‚ç±»ä¼¼äºNVIDIAçš„ AMP ä¼˜åŒ–å™¨ä¸­å°†å…¨å±€æ¢¯åº¦è®¡ç®—è¿›è¡Œ bucketization ä»¥é‡å è®¡ç®—é€šä¿¡ã€‚é€šè¿‡åœ¨æœ€åä¸€ä¸ªåˆ†åŒºè¿›è¡Œ all-reduceï¼Œä»¥å‡å°‘å†…å­˜å ç”¨ï¼Œå®ç°è®¡ç®—é€šä¿¡é‡å </p><h4 id="Parameter-Partitioning"><a href="#Parameter-Partitioning" class="headerlink" title="Parameter Partitioning"></a>Parameter Partitioning</h4><p>å‚æ•°åˆ†åŒºæ˜¯åœ¨ DP è®­ç»ƒä¸­å‡å°‘å†…å­˜æ¶ˆè€—çš„ä¸€ç§æ–¹å¼ã€‚æ¯ä¸ªè¿›ç¨‹åªå­˜å‚¨ä¸å…¶åˆ†åŒºç›¸å¯¹åº”çš„å‚æ•°ï¼Œå½“éœ€è¦ä½¿ç”¨åˆ°å…¶ä»–åˆ†åŒºçš„å‚æ•°è¿›è¡Œå‰å‘å’Œåå‘ä¼ æ’­æ—¶ï¼Œé€šè¿‡ broadcast ä»ç›¸åº”çš„ DP è¿›ç¨‹æ¥æ”¶è¿™äº›å‚æ•°</p><h4 id="Implication-on-Model-Size"><a href="#Implication-on-Model-Size" class="headerlink" title="Implication on Model Size"></a>Implication on Model Size</h4><p>åœ¨ 1024 DP çš„æƒ…å†µä¸‹ï¼Œæ­é… Pos+g+pï¼Œå¯ä»¥å®ç° 1.5 ä¸‡äº¿å‚æ•°çš„è®­ç»ƒï¼Œå¦‚æœåªä½¿ç”¨ DP è®­ç»ƒï¼Œä»…èƒ½è®­ç»ƒ 1.5 Billion å‚æ•°é‡</p><h3 id="ZeRO-R"><a href="#ZeRO-R" class="headerlink" title="ZeRO-R"></a>ZeRO-R</h3><p>å°†ä½¿ç”¨çš„å†…å­˜åˆ†ä¸ºä¸¤ç±»ï¼š</p><ul><li>é•¿æœŸå­˜åœ¨ï¼šå‰å‘ä¼ æ’­æ—¶çš„æ¿€æ´»å€¼ checkpointï¼Œåå‘ä¼ æ’­æ—¶çš„å‚æ•°æ¢¯åº¦</li><li>çŸ­æœŸå­˜åœ¨ï¼šå‰å‘ä¼ æ’­æ—¶çš„ recomputeï¼Œåå‘ä¼ æ’­æ—¶çš„æ¿€æ´»å€¼æ¢¯åº¦</li></ul><p>ZeRO-R é€šè¿‡å°†æ¿€æ´»å€¼ checkpoint å’Œ æ¢¯åº¦ ç§»åŠ¨åˆ°é¢„å…ˆåˆ†é…çš„è¿ç»­ buffer ä¸­ï¼Œè¿›è¡Œå®æ—¶å†…å­˜ç¢ç‰‡æ•´ç†ï¼Œè¿˜å‡å°‘äº†æŸ¥æ‰¾ç©ºé—²è¿ç»­å†…å­˜çš„æ—¶é—´</p><h4 id="Partitioned-Activation-Checkpointing"><a href="#Partitioned-Activation-Checkpointing" class="headerlink" title="Partitioned Activation Checkpointing"></a>Partitioned Activation Checkpointing</h4><p>é€šè¿‡æ¿€æ´»å€¼ checkpoint åˆ†åŒºï¼Œæ¶ˆé™¤äº† MP ä¸­çš„å†…å­˜å†—ä½™ï¼Œåªæœ‰åœ¨è®¡ç®—ä¸­éœ€è¦ä½¿ç”¨æ¿€æ´»æ—¶ï¼Œæ‰ä¼šå°†æ¿€æ´»å€¼å¤åˆ¶</p><p>åœ¨æ¨¡å‹ä¸­ä¸€å±‚å®Œæˆå‰å‘å®Œæˆæ—¶ï¼Œä¼šå°†æ¿€æ´»å€¼åˆ†åŒºåˆ°æ‰€æœ‰å¹¶è¡Œè¿›ç¨‹ä¸Šï¼Œå¦‚æœåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­è¢«ä½¿ç”¨æ—¶ï¼Œåˆ™ä½¿ç”¨ all-gather é‡æ–°åˆ›å»ºæ¿€æ´»å€¼çš„ copy</p><h4 id="Constant-Size-Buffers"><a href="#Constant-Size-Buffers" class="headerlink" title="Constant Size Buffers"></a>Constant Size Buffers</h4><p>é€šè¿‡ä¿æŒè¶³å¤Ÿå¤§çš„å¸¸é‡ buffer ï¼Œåœ¨è®¡ç®—ä¹‹å‰å°†æ‰€æœ‰å‚æ•°èåˆåˆ°è¿™ä¸ªå•ç‹¬çš„ buffer ä¸­ï¼Œå¯ä»¥åŠ é€Ÿå†…å­˜è¯»å†™æ•ˆç‡</p><h4 id="Memory-Defragmentation"><a href="#Memory-Defragmentation" class="headerlink" title="Memory Defragmentation"></a>Memory Defragmentation</h4><p>å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­é€šè¿‡æ¿€æ´»å€¼ checkpoint åªä¿ç•™äº†éƒ¨åˆ†æ¿€æ´»å€¼ï¼Œå…¶ä½™çš„æ¿€æ´»å€¼ä¼šè¢«ä¸¢å¼ƒï¼Œå› ä¸ºå®ƒä»¬åœ¨åå‘ä¼ æ’­æ—¶å¯ä»¥é‡æ–°è®¡ç®—ã€‚åŒæ ·ï¼Œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå‚æ•°æ¢¯åº¦æ˜¯é•¿æœŸå­˜åœ¨çš„ï¼Œè€Œæ¿€æ´»æ¢¯åº¦å’Œå…¶ä»–ç”¨äºè®¡ç®—å‚æ•°æ¢¯åº¦çš„ç¼“å†²åŒºæ˜¯çŸ­æœŸå­˜åœ¨çš„ã€‚è¿™ç§é•¿æœŸå’ŒçŸ­æœŸå†…å­˜çš„äº¤ç»‡å¯¼è‡´äº†å†…å­˜ç¢ç‰‡åŒ–çš„é—®é¢˜</p><p>æ–‡ä¸­æå‡ºäº† In-place Activation Reuse çš„æ–¹æ³•ï¼Œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­å¯ä»¥é‡å¤ä½¿ç”¨æ¿€æ´»å€¼çš„å†…å­˜ï¼Œè€Œæ— éœ€æ¯æ¬¡éƒ½é‡æ–°åˆ†é…å†…å­˜ã€‚å°†ä¸å†éœ€è¦çš„æ¿€æ´»å€¼å†…å­˜æ ‡è®°ä¸ºå¯é‡ç”¨ï¼Œå¹¶åœ¨ä¸‹ä¸€æ¬¡éœ€è¦ç›¸åŒå¤§å°å†…å­˜çš„åœ°æ–¹é‡ç”¨å®ƒä»¬ã€‚å‡å°‘äº†å†…å­˜åˆ†é…å’Œé‡Šæ”¾çš„æ¬¡æ•°ï¼Œå‡å°‘äº†ç¢ç‰‡åŒ–</p><h2 id="ZeRO-DP-é€šä¿¡åˆ†æ"><a href="#ZeRO-DP-é€šä¿¡åˆ†æ" class="headerlink" title="ZeRO-DP é€šä¿¡åˆ†æ"></a>ZeRO-DP é€šä¿¡åˆ†æ</h2><h3 id="DP-é€šä¿¡é‡"><a href="#DP-é€šä¿¡é‡" class="headerlink" title="DP é€šä¿¡é‡"></a>DP é€šä¿¡é‡</h3><p>åœ¨æ¯æ¬¡åå‘åæ‰§è¡Œ all-reduce å¹³å‡ï¼Œè¿™ç§ all-reduce ä¼šåœ¨å¤§æ¨¡å‹ä¸Šä¼šå®Œå…¨ä¾èµ–é€šä¿¡å¸¦å®½ï¼Œç°åœ¨çš„ all-reduce é€šè¿‡æµæ°´çº¿æ‰§è¡Œ reduce-scatter å† all-gather è¾¾åˆ° all-reduce çš„æ•ˆæœï¼Œä¼šæœ‰ä¸¤å€çš„æ•°æ®é€šä¿¡é‡</p><h3 id="ZeRO-DP-é€šä¿¡é‡"><a href="#ZeRO-DP-é€šä¿¡é‡" class="headerlink" title="ZeRO-DP é€šä¿¡é‡"></a>ZeRO-DP é€šä¿¡é‡</h3><h4 id="Pos-g"><a href="#Pos-g" class="headerlink" title="Pos+g"></a>Pos+g</h4><p>å› ä¸ºæ¯ä¸ªè¿›ç¨‹åªä¿å­˜å…¶åˆ†åŒºçš„æ¢¯åº¦ï¼Œå¯¹æ¢¯åº¦è¿›ç¨‹è¿›è¡Œ scatter-reduceï¼Œå†æ‰§è¡Œ all-gatherï¼Œé€šä¿¡é‡ä¸ DP ç›¸åŒï¼Œä¸º 2Î¨</p><h4 id="Pos-g-p"><a href="#Pos-g-p" class="headerlink" title="Pos+g+p"></a>Pos+g+p</h4><p>é€šè¿‡å‚æ•°åˆ†åŒºï¼Œæ¯ä¸ªè¿›ç¨‹åªå­˜å‚¨æ›´æ–°çš„å‚æ•°ã€‚åœ¨è®¡ç®—å‰å‘ä¼ æ’­ç»“æœå‰ï¼Œæ¯ä¸ªåˆ†åŒºçš„è¿›ç¨‹å°†æƒé‡ braodcast åˆ°æ‰€æœ‰è¿›ç¨‹ï¼Œåœ¨å‰å‘ä¼ æ’­æ—¶ï¼Œé€šè¿‡æµæ°´çº¿æ‰§è¡Œ all-gather æ¥å—å…¶ä»–åˆ†åŒºçš„å‚æ•°ï¼Œä»¥å‡å°‘å†…å­˜å ç”¨ï¼Œå‰å‘ä¼ æ’­åï¼Œä¸¢å¼ƒæƒé‡ã€‚åœ¨åå‘ä¼ æ’­æ—¶éœ€è¦å†æ¬¡ all-gatherï¼Œå› æ­¤ï¼Œæ€»é€šä¿¡é‡ä¸º (Î¨ * N) / N = Î¨</p><p>ç»¼ä¸Šï¼Œæ€»é€šä¿¡é‡ä¸º 3Î¨ï¼Œä¸º DP çš„ 1.5 å€</p><h2 id="ZeRO-R-é€šä¿¡åˆ†æ"><a href="#ZeRO-R-é€šä¿¡åˆ†æ" class="headerlink" title="ZeRO-R  é€šä¿¡åˆ†æ"></a>ZeRO-R  é€šä¿¡åˆ†æ</h2><p>ä¸‹é¢é€šè¿‡åˆ†æåˆ†åŒºæ¿€æ´»å€¼ checkpointï¼ˆPaï¼‰ä¸MPï¼ŒDPé€šä¿¡é‡å†³å®šä½¿ç”¨Paè¿˜æ˜¯Pa+cpu</p><p>Pa çš„é€šä¿¡é‡æƒè¡¡å–å†³äºæ¨¡å‹å¤§å°ã€checkpoint ç­–ç•¥å’Œ MP ç­–ç•¥ã€‚è®ºæ–‡ä½¿ç”¨ Megatron-LM å®ç°çš„æ¨¡å‹èƒŒæ™¯ä¸‹è¿›è¡Œåˆ†æã€‚ åœ¨å¸¦æœ‰æ¿€æ´»å€¼ checkpoint çš„ Megatron-LM ä¸­ï¼Œæ¯ä¸ªtransformeråœ¨æ­£å‘ä¼ æ’­ä¸­æ‰§è¡Œä¸¤ä¸ªå¤§å°ä¸º batch Ã— seq_length Ã— hidden_dim çš„ all-reduce æ“ä½œç”¨äºæ­£å‘ä¼ æ’­æ—¶çš„é‡è®¡ç®—ï¼Œå¦å¤–ä¸¤ä¸ª all-reduce æ“ä½œç”¨äºåå‘ä¼ æ’­ã€‚æ¯ä¸ªå—çš„æ€»é€šä¿¡é‡ä¸º 12 Ã— seq length Ã— hidden dimï¼Œå› ä¸º all-reduce çš„é€šä¿¡é‡ä¸º 2 Ã— message_sizeã€‚ å½“ ZeRO-R å¯¹æ¿€æ´»å€¼ checkpoint è¿›è¡Œåˆ†åŒºæ—¶ï¼Œåœ¨æ¯ä¸ªæ¿€æ´»å€¼ checkpoint ä¸Šçš„åå‘ä¼ æ’­çš„æ­£å‘é‡æ–°è®¡ç®—ä¹‹å‰éœ€è¦é¢å¤–çš„ all-gather æ“ä½œã€‚ä¼šæ£€æŸ¥æ¯ä¸ªtransformerå—çš„è¾“å…¥æ¿€æ´»ï¼Œéœ€è¦ä¸€ä¸ª all-gatherï¼Œå› æ­¤ï¼ŒPa çš„é€šä¿¡é‡ä¸º seq_length âˆ— hidden_dimã€‚å› ä¸º all-gather çš„é€šä¿¡é‡ä¸º message_sizeï¼Œè®¡ç®— Pa çš„æ€»é€šä¿¡é‡å°äº MP åŸå§‹é€šä¿¡é‡çš„ 10%ã€‚å½“MPä¸DPç»“åˆä½¿ç”¨æ—¶ï¼ŒPaå¯ç”¨äºå°†Paé€šä¿¡é‡å‡å°‘ä¸€ä¸ªæ•°é‡çº§ï¼Œè€Œæ¨¡å‹å¹¶è¡Œé€šä¿¡é‡å¢åŠ 10%ï¼Œå¹¶åœ¨ DP é€šä¿¡æˆä¸ºæ€§èƒ½ç“¶é¢ˆæ—¶æ˜¾è‘—æé«˜æ•ˆç‡ã€‚å¦å¤–ï¼ŒPaå°†æ¿€æ´»å†…å­˜æ¶ˆè€—é™ä½äº† MP å¹¶è¡Œåº¦ï¼Œä»è€Œå…è®¸æŒ‰æ¯”ä¾‹å¢åŠ  batch_sizeã€‚ç”±äº Pa å¯¼è‡´ batch_size å¢åŠ ä¸€ä¸ªæ•°é‡çº§å¯èƒ½å¯¼è‡´ DP é€šä¿¡é‡å‡å°‘ä¸€ä¸ªæ•°é‡çº§ã€‚ å¦‚æœé‡‡ç”¨ Pa+cpuï¼Œåˆ†åŒºæ¿€æ´»å€¼ checkpoint å°†å¸è½½åˆ°cpuï¼Œå°±ä¸å†éœ€è¦æ¿€æ´»å†…å­˜äº†ï¼Œä¸Paç›¸æ¯”ï¼Œcpuå†…å­˜ä¹‹é—´å¢åŠ äº†2å€çš„æ•°æ®ç§»åŠ¨ã€‚åœ¨æç«¯æƒ…å†µä¸‹ï¼ŒDP é€šä¿¡é‡æ˜¯ä¸»è¦ç“¶é¢ˆï¼Œå› ä¸ºå³ä½¿ä½¿ç”¨Paï¼Œbatch_size ä¹Ÿå¾ˆå°ï¼Œåœ¨å°batch_sizeçš„æƒ…å†µä¸‹ï¼Œåªè¦ cpu æ•°æ®ä¼ è¾“å¼€é”€å°äºDPé€šä¿¡é‡å¼€é”€ï¼ŒPa+cpu å°±å¯ä»¥é€šè¿‡å¢åŠ  batch_size æ¥æé«˜æ•ˆç‡ã€‚åœ¨ç»™å®šæ¨¡å‹å’Œç¡¬ä»¶ç‰¹æ€§çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥åˆ©ç”¨ä¸Šè¿°åˆ†ææ¥å†³å®šæ˜¯å¦ä»¥åŠä½•æ—¶ä½¿ç”¨Paè¿˜æ˜¯Pa+cpu</p><h2 id="ä¸‡äº¿å‚æ•°"><a href="#ä¸‡äº¿å‚æ•°" class="headerlink" title="ä¸‡äº¿å‚æ•°"></a>ä¸‡äº¿å‚æ•°</h2><p>ä»…ä½¿ç”¨ DPï¼ŒZeROèƒ½å¤Ÿåœ¨1024ä¸ªGPUä¸Šå®¹çº³è¶…è¿‡1ä¸‡äº¿å‚æ•°çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œå½“ä¸ MP ç»“åˆä½¿ç”¨æ—¶ï¼Œæ¯ä¸ªDGX2èŠ‚ç‚¹å†…ä½¿ç”¨16è·¯MPï¼Œè·¨èŠ‚ç‚¹ä½¿ç”¨64è·¯DPï¼ŒZeROèƒ½å¤Ÿåœ¨1024ä¸ªGPUä¸Šè¿è¡Œè¶…è¿‡1ä¸‡äº¿å‚æ•°çš„æ¨¡å‹ï¼Œä½†è®­ç»ƒæ—¶é•¿ä¼šè¶…è¿‡ä¸€å¹´ï¼ŒæœŸå¾…æœªæ¥ç®—åŠ›æå‡</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/3.webp" width="800" /></p><h2 id="å®éªŒè¯„ä¼°"><a href="#å®éªŒè¯„ä¼°" class="headerlink" title="å®éªŒè¯„ä¼°"></a>å®éªŒè¯„ä¼°</h2><p>å®æ–½ï¼šåŸºäº PyTorch çš„ ZeRO-100Bï¼ŒåŒ…æ‹¬Pos+g å’Œ ZeRO-R ä¸­çš„å…¨éƒ¨ä¼˜åŒ–ç‚¹</p><p>ç¡¬ä»¶ï¼šç”± 400 ä¸ª V100 GPUï¼ˆ25ä¸ªDGX-2èŠ‚ç‚¹ï¼‰ç»„æˆçš„é›†ç¾¤ï¼ŒèŠ‚ç‚¹é—´é€šä¿¡å¸¦å®½ä¸º800 Gbps</p><p>Baselineï¼šæ²¡æœ‰MPçš„å®éªŒä½¿ç”¨äº† torch çš„ DDPï¼ŒMP çš„å®éªŒä½¿ç”¨ Megatron-LM çš„ MP</p><p>ZeROï¼šæ²¡æœ‰MPçš„å®éªŒä½¿ç”¨äº† ZeRO-100B ä¸­åŸºäº ZeRO çš„ DP å®ç°ã€‚MP çš„å®éªŒå°† ZeRO-100B ä¸­çš„ ZeRO-powered DP ä¸ Megatron-LM çš„ MP ç›¸ç»“åˆ</p><p>æ¨¡å‹ï¼šåŸºäºGPT-2çš„ transformer æ¨¡å‹ï¼Œä¸‹è¡¨æ˜¯å‚æ•°é…ç½®</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/5.webp" width="800" /></p><h3 id="Speed-and-Model-size"><a href="#Speed-and-Model-size" class="headerlink" title="Speed and Model size"></a>Speed and Model size</h3><p>Baseline çš„ Megatron MP åœ¨æ¨¡å‹è§„æ¨¡å¢å¤§æ—¶æ€§èƒ½ä¼šå¿«é€Ÿä¸‹é™ï¼Œå› ä¸º MP åœ¨ GPU ä¹‹é—´äº§ç”Ÿäº†é«˜é¢é€šä¿¡é‡ï¼Œè€Œåœ¨è¶…è¿‡å•ä¸ªèŠ‚ç‚¹ä»¥é€‚åº”æ›´å¤§çš„æ¨¡å‹æ—¶ï¼Œæ¯æ¡é“¾è·¯ï¼ˆNVSwitchï¼‰çš„é€šä¿¡å¸¦å®½ä»300GB/ç§’ä¸‹é™ä¸º12.5GB/ç§’ï¼Œå¯¼è‡´æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚å¯¹æ¯”ä¹‹ä¸‹ï¼ŒZeRO-100B ä¼šæœ‰ 10 å€çš„è®­ç»ƒé€Ÿåº¦æå‡</p><h3 id="Super-Linear-Scalability"><a href="#Super-Linear-Scalability" class="headerlink" title="Super-Linear Scalability"></a>Super-Linear Scalability</h3><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä½¿ç”¨ZeRO-100Bå¯ä»¥å®ç°è¶…çº¿æ€§å¯æ‰©å±•æ€§ï¼Œå¹¶é€šè¿‡å¢åŠ  DP å¹¶è¡Œåº¦æ¥æé«˜æ¯ä¸ªGPUçš„ååé‡ï¼Œä»è€Œé€‚åº”æ›´å¤§çš„ batch_size</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/6.webp" width="800" /></p><h3 id="Democratizing-Large-Model-Training"><a href="#Democratizing-Large-Model-Training" class="headerlink" title="Democratizing Large Model Training"></a>Democratizing Large Model Training</h3><p>ä¸‹å›¾ä½¿ç”¨128ä¸ªGPUï¼ŒZeRO-100B å¯ä»¥è®­ç»ƒ13Bå‚æ•°çš„æ¨¡å‹ï¼Œå¹³å‡æ¯ä¸ªGPUååé‡è¶…è¿‡40 TFlopsã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ²¡æœ‰ä½¿ç”¨ZeROï¼Œä»…ä½¿ç”¨DPçš„æœ€å¤§å¯è®­ç»ƒæ¨¡å‹ä»…æœ‰ 1.4B å‚æ•°ï¼Œæ¯ä¸ª GPU çš„ååé‡ä¸åˆ° 20 TFlopsã€‚æ­¤å¤–ï¼Œç”±äºæ²¡æœ‰ MP å¸¦æ¥çš„é€šä¿¡å¼€é”€ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥åœ¨å…·æœ‰è¾ƒä½ç«¯è®¡ç®—èŠ‚ç‚¹ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ— éœ€ NVLINK æˆ– NVSwitch è¿™ç§é«˜é€Ÿäº’è”æ–¹å¼</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/7.webp" width="500" /></p><h3 id="Memory-and-Performance-Analysis"><a href="#Memory-and-Performance-Analysis" class="headerlink" title="Memory and Performance Analysis"></a>Memory and Performance Analysis</h3><p>ä½œè€…è®¨è®ºäº†ä¸åŒä¼˜åŒ–æ–¹æ³•å¯¹æœ€å¤§æ¨¡å‹å¤§å°ã€å†…å­˜æ¶ˆè€—å’Œæ€§èƒ½çš„å½±å“ã€‚ä½œè€…å°†è¿™äº›ä¼˜åŒ–æ–¹æ³•åˆ†ä¸ºé…ç½®1åˆ°5ï¼ˆC1-C5ï¼‰ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œé€šè¿‡ä½¿ç”¨å›ºå®š batch_size å’Œ MP ä¸º16ï¼Œè§‚å¯Ÿå¯ç”¨ä¸åŒZeROä¼˜åŒ–çš„å¯è®­ç»ƒæ¨¡å‹çš„æœ€å¤§å°ºå¯¸</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/8.webp" width="400" /></p><p>åœ¨æœ€å¤§æ¨¡å‹å°ºå¯¸æ–¹é¢ï¼Œå¦‚ Figure 6 æ‰€ç¤ºï¼Œé€šè¿‡ä½¿ç”¨ Pa ä¼˜åŒ–ï¼Œæ¨¡å‹å¤§å°ä»40Bå¢åŠ åˆ°äº†60Bã€‚è€Œé€šè¿‡ä½¿ç”¨Pos+gä¼˜åŒ–ï¼Œåœ¨C2çš„åŸºç¡€ä¸Šï¼Œæ¨¡å‹å¤§å°å¢åŠ åˆ°äº†140Bï¼Œè¿™æ˜¯å› ä¸ºä¸C2ç›¸æ¯”ï¼Œè¯¥ä¼˜åŒ–ä½¿æ¨¡å‹çŠ¶æ€çš„å†…å­˜éœ€æ±‚å‡åŠã€‚ä½¿ç”¨C5è¿›ä¸€æ­¥å‡å°‘äº†æ¿€æ´»å†…å­˜ï¼Œå°†åˆ†åŒºæ¿€æ´»å€¼ checkpoint è½¬ç§»åˆ°CPUå†…å­˜ï¼Œä½¿æ¨¡å‹å¤§å°å¢åŠ åˆ°150B</p><p>å¯¹äºæ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­ PyTorch ç¼“å­˜çš„æœ€å¤§å†…å­˜ï¼Œå¦‚ Figure 7 æ‰€ç¤ºï¼Œä½œè€…è§‚å¯Ÿäº†40Bå’Œ100Bæ¨¡å‹çš„æƒ…å†µã€‚ä»C1åˆ°C2ï¼Œç¼“å­˜çš„å†…å­˜å¤§å°å¦‚æœŸå‡å°‘ã€‚C2åˆ°C3çš„å†…å­˜æ¶ˆè€—å·®å¼‚å–å†³äºæ¨¡å‹çŠ¶æ€ä¸æ¿€æ´»å†…å­˜çš„å¤§å°å…³ç³»ï¼Œå½“æ¿€æ´»å†…å­˜è¾ƒå¤§æ—¶ï¼Œå·®å¼‚å¯èƒ½å¢åŠ ï¼Œå½“æ¨¡å‹çŠ¶æ€è¾ƒå¤§æ—¶ï¼Œå·®å¼‚å¯èƒ½å‡å°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨40Bæ¨¡å‹ä¸­ï¼Œä»C4åˆ°C5æ—¶ï¼Œç¼“å­˜çš„å†…å­˜å¤§å°æ²¡æœ‰å‡å°‘ï¼Œä½†åœ¨100Bæ¨¡å‹ä¸­æœ‰å‡å°‘ã€‚è¿™æ˜¯å› ä¸º100Bçš„æ¿€æ´»å†…å­˜è¾ƒå¤§ï¼Œå‡å°‘ä¸æ˜æ˜¾ã€‚ä½œè€…æŒ‡å‡ºï¼Œå½“æˆ‘ä»¬å¤„ç†éå¸¸å¤§çš„æ¨¡å‹æ—¶ï¼ŒPa+cpuä¼˜åŒ–å¯ç”¨äºé€‚åº”æ›´å¤§çš„ batch_size</p><p>å¯¹äºä¸åŒä¼˜åŒ–è®¾ç½®çš„æœ€ä½³æ€§èƒ½ï¼Œå¦‚ Figure 8 æ‰€ç¤ºï¼Œæ€§èƒ½æå‡ä¸å†…å­˜æ¶ˆè€—çš„å‡å°‘ç›¸å¯¹åº”ã€‚è¾ƒä½çš„å†…å­˜æ¶ˆè€—å¯ä»¥å®ç°æ›´å¤§çš„ batch_sizeï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚å”¯ä¸€çš„ä¾‹å¤–æ˜¯60Bå‚æ•°æ¨¡å‹åœ¨C4å’ŒC5ä¹‹é—´çš„æ€§èƒ½ä¸‹é™ã€‚å°½ç®¡å†…å­˜æ¶ˆè€—è¾ƒä½ï¼Œä½†C5ä¼šå¯¼è‡´æ¿€æ´»åœ¨CPUä¹‹é—´ç§»åŠ¨ï¼Œè¿™é€šå¸¸ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œé™¤éæ¨¡å‹éå¸¸å¤§ä»¥è‡³äºæ— æ³•åœ¨æ²¡æœ‰C5çš„æƒ…å†µä¸‹è¿è¡Œï¼Œæˆ–è€…å¯ä»¥åœ¨æ²¡æœ‰C5çš„æƒ…å†µä¸‹è¿è¡Œçš„ batch_size å¾ˆå°ï¼ˆä¾‹å¦‚åœ¨ Figure 8 ä¸­å…·æœ‰170Bå‚æ•°çš„æ¨¡å‹ï¼‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒPa+cpuä¼˜åŒ–åªåœ¨æœ‰ç›Šæ—¶æ‰å¯ç”¨</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/9.webp" width="800" /></p><h3 id="Turing-NLG-the-SOTA-language-model-with-17B-parameters"><a href="#Turing-NLG-the-SOTA-language-model-with-17B-parameters" class="headerlink" title="Turing-NLG, the SOTA language model with 17B parameters"></a>Turing-NLG, the SOTA language model with 17B parameters</h3><p>ä¸‹å›¾å±•ç¤ºäº†åœ¨300Kæ¬¡è¿­ä»£ä¸­ä¸ä¹‹å‰æœ€å…ˆè¿›çš„Megatron-LM 8.3Bå‚æ•°æ¨¡å‹çš„éªŒè¯ Perplexity å¯¹æ¯”ï¼Œä½¿ç”¨ ZeRO è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹æŒ‡æ ‡ä¼˜äº Megatron-LMï¼Œæ­¤å¤– ZeRO100B è¿˜å®ç°äº†æŒç»­çš„ 41.4 TFlops/GPUçš„ååé‡</p><p><img src="/image/è®ºæ–‡é˜…è¯»-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/10.webp" width="400" /></p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>ZeRO ç‰›é€¼</p>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»: PyTorch Distributed: Experiences on Accelerating Data Parallel Training</title>
      <link href="/p/a8cf276f/"/>
      <url>/p/a8cf276f/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æœ¬æ–‡æå‡ºçš„ DistributedDataParallel åœ¨ä¼˜åŒ–å™¨è¿è¡Œä¹‹å‰è¿›è¡Œæ¢¯åº¦å¹³å‡ï¼Œç”¨ç›¸åŒçš„æ¢¯åº¦é›†æ›´æ–°æ‰€æœ‰æ¨¡å‹å‰¯æœ¬ï¼Œè¿™æ ·åœ¨æ•°å­¦ä¸Šå’Œæœ¬åœ°è®­ç»ƒå®Œå…¨ç­‰ä»·ï¼Œè€Œä¸”å¯ä»¥å®ç°å¼‚æ­¥ï¼Œæ¯”å‚æ•°å¹³å‡æ›´åŠ é«˜æ•ˆã€‚</p><span id="more"></span><p>paper: <a href="https://arxiv.org/abs/2006.15704">https://arxiv.org/abs/2006.15704</a></p><p>code: <a href="https://github.com/pytorch/pytorch/">https://github.com/pytorch/pytorch/</a></p><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><h3 id="PyTorch-è®­ç»ƒæµç¨‹"><a href="#PyTorch-è®­ç»ƒæµç¨‹" class="headerlink" title="PyTorch è®­ç»ƒæµç¨‹"></a>PyTorch è®­ç»ƒæµç¨‹</h3><ul><li>Forward passï¼šè®¡ç®—æŸå¤± </li><li>Backward passï¼šè®¡ç®—æ¢¯åº¦ </li><li>Optimizer stepï¼šæ›´æ–°å‚æ•°</li><li>æ•°æ®å¹¶è¡Œ </li></ul><p>PyTorch æœ‰ä»¥ä¸‹æ–¹å¼è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œå¦‚ </p><ul><li>DataParallelï¼šå•æœºå¤šå¡è¿›è¡Œå•è¿›ç¨‹å¤šçº¿ç¨‹æ•°æ®å¹¶è¡Œè®­ç»ƒ </li><li>DistributedDataParallelï¼šå¤šæœºå¤šå¡è¿›è¡Œå¤šè¿›ç¨‹æ•°æ®å¹¶è¡Œè®­ç»ƒ </li><li>RPCï¼ˆe.g. å‚æ•°æœåŠ¡å™¨ï¼‰ï¼šåˆ†å¸ƒå¼æ¨¡å‹å¹¶è¡Œè®­ç»ƒ </li></ul><p>å¦ä¸€ç§æ–¹æ¡ˆï¼šå‚æ•°å¹³å‡è®¡ç®—æ‰€æœ‰æ¨¡å‹æƒé‡çš„å‡å€¼ï¼Œä½†æ˜¯å½“ä¼˜åŒ–å™¨ä¸­æœ‰ä¾èµ–è¿‡å»å±€éƒ¨æ¢¯åº¦çš„å€¼ï¼ˆå¦‚ Adam ä¸­çš„åŠ¨é‡ï¼‰ï¼Œä¼˜åŒ–å™¨çš„çŠ¶æ€å¯èƒ½ä¼šé€æ¸åç¦»ï¼Œæœ€ç»ˆå¯¼è‡´è®­ç»ƒæ•ˆæœä¸‹é™ã€‚å¦å¤–ï¼Œå‘åä¼ é€’å’Œå‚æ•°å¹³å‡ä¸èƒ½é‡å è¿è¡Œï¼Œæµªè´¹äº†æ€§èƒ½</p><p>æœ¬æ–‡æå‡ºçš„ DistributedDataParallel åœ¨ä¼˜åŒ–å™¨è¿è¡Œä¹‹å‰è¿›è¡Œæ¢¯åº¦å¹³å‡ï¼Œç”¨ç›¸åŒçš„æ¢¯åº¦é›†æ›´æ–°æ‰€æœ‰æ¨¡å‹å‰¯æœ¬ï¼Œè¿™æ ·åœ¨æ•°å­¦ä¸Šå’Œæœ¬åœ°è®­ç»ƒå®Œå…¨ç­‰ä»·ï¼Œè€Œä¸”å¯ä»¥å®ç°å¼‚æ­¥ï¼Œæ¯”å‚æ•°å¹³å‡æ›´åŠ é«˜æ•ˆ </p><h2 id="AllReduce"><a href="#AllReduce" class="headerlink" title="AllReduce"></a>AllReduce</h2><p>æ¬¡çº§å®ç°</p><p>æ¯ä¸ªè¿›ç¨‹å°†å…¶è¾“å…¥å¼ é‡å¹¿æ’­ç»™æ‰€æœ‰å¯¹ç­‰è¿›ç¨‹ï¼Œç„¶åç‹¬ç«‹åœ°åº”ç”¨ç®—æœ¯è¿ç®—ï¼Œç„¶è€Œæ•ˆç‡ä¸é«˜ </p><p>äºæ˜¯ Nvidia åœ¨ NCCL åç«¯ä¸­æå‡ºäº†åŸºäºç¯çš„ AllReduce å’ŒåŸºäºæ ‘çš„ AllReduce </p><p>AllReduce æ“ä½œéœ€è¦ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å°±ç»ªåæ‰èƒ½è¿è¡Œï¼Œæ˜¯åŒæ­¥æ“ä½œï¼Œè€Œå‚æ•°æœåŠ¡å™¨ä¸­ä½¿ç”¨ P2P é€šä¿¡ </p><h2 id="ç³»ç»Ÿè®¾è®¡"><a href="#ç³»ç»Ÿè®¾è®¡" class="headerlink" title="ç³»ç»Ÿè®¾è®¡"></a>ç³»ç»Ÿè®¾è®¡</h2><p>API å®ç°</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/1.webp" width="300" /></p><p>åˆ†å¸ƒå¼è®­ç»ƒæ—¶åªéœ€è¦ä¿®æ”¹å°‘éƒ¨åˆ†è®­ç»ƒè„šæœ¬</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/3.webp" width="500" /></p><p>æš´éœ²æ›´å¤šæ¥å£ä»¥å®ç°æ‹¦æˆªä¿¡å·å’Œè§¦å‘æ“ä½œçš„æœºåˆ¶è¿›è¡Œä¼˜åŒ– </p><h2 id="æ¢¯åº¦è§„çº¦"><a href="#æ¢¯åº¦è§„çº¦" class="headerlink" title="æ¢¯åº¦è§„çº¦"></a>æ¢¯åº¦è§„çº¦</h2><h3 id="æ¬¡çº§å®ç°ï¼ˆAll-Reduceï¼‰"><a href="#æ¬¡çº§å®ç°ï¼ˆAll-Reduceï¼‰" class="headerlink" title="æ¬¡çº§å®ç°ï¼ˆAll Reduceï¼‰"></a>æ¬¡çº§å®ç°ï¼ˆAll Reduceï¼‰</h3><p>DDPæ§åˆ¶æ‰€æœ‰çš„è®­ç»ƒè¿›ç¨‹</p><p>åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶å¹¿æ’­ç½‘ç»œçŠ¶æ€ï¼Œè®©æ‰€æœ‰æ¨¡å‹ä»¥ç›¸åŒçŠ¶æ€å¼€å§‹è®­ç»ƒ<br>æ¯æ¬¡è¿­ä»£æ—¶åœ¨å±€éƒ¨ backward() ä¹‹åå’Œä¼˜åŒ–å™¨ step() ä¹‹å‰æ‰§è¡Œæ¢¯åº¦ï¼Œä»¥ç›¸åŒçš„æ¢¯åº¦æ›´æ–°æƒé‡ </p><p>DDP å¯ä»¥æ³¨å†Œ autograd hooksï¼Œæ¯æ¬¡ backward() åè§¦å‘ä»¥ä¸‹æ“ä½œ</p><ol><li>hooks æ‰«ææ‰€æœ‰å±€éƒ¨æ¨¡å‹å‚æ•°</li><li>ä»æ¯ä¸ªå‚æ•°ä¸­æ£€ç´¢æ¢¯åº¦å¼ é‡</li><li>å†ä½¿ç”¨ AllReduce é›†ä½“é€šä¿¡è®¡ç®—æ‰€æœ‰è¿›ç¨‹ä¸­å‚æ•°çš„å¹³å‡æ¢¯åº¦</li><li>å°†ç»“æœè¿”å›æ¢¯åº¦å¼ é‡</li></ol><p>ä½†æ˜¯æœ‰ä¸¤ä¸ªæ€§èƒ½é—®é¢˜</p><ul><li>åœ¨å° tensor ä¸Šçš„é›†åˆé€šä¿¡æ•ˆç‡éå¸¸ä½</li><li>æŠŠæ¢¯åº¦è®¡ç®—å’ŒåŒæ­¥åˆ†å¼€ä¹‹åï¼Œä¸èƒ½è®©å®ƒä»¬é€šä¿¡é‡å  </li></ul><h3 id="æ¢¯åº¦æ¡¶"><a href="#æ¢¯åº¦æ¡¶" class="headerlink" title="æ¢¯åº¦æ¡¶"></a>æ¢¯åº¦æ¡¶</h3><p>ä¸‹å›¾æ˜¾ç¤ºäº†ä¸åŒçš„å‚æ•°è§„æ¨¡åœ¨æ‰§è¡Œ All Reduce æ—¶çš„æ•ˆç‡ï¼Œå¯ä»¥çœ‹åˆ° tensor è¶Šå¤§ï¼Œæ•ˆç‡è¶Šé«˜</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/2.webp" width="500" /></p><p>æ¢¯åº¦æ¡¶ä¸ºäº†è§£å†³ All Reduce åœ¨å° tensor ä¸Šçš„æ€§èƒ½é—®é¢˜ï¼Œå°†å¤šä¸ªå° tensor æ”¶é›†ä¸ºä¸€ä¸ªæ¡¶ï¼Œåœ¨è¾¾åˆ°ä¸€å®šè§„æ¨¡åè¿›è¡Œ All Reduceï¼Œè¿™å°† All Reduce çš„æ“ä½œè½¬å˜ä¸ºäº†å¼‚æ­¥</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/4.webp" width="500" /></p><h3 id="é€šä¿¡å’Œè®¡ç®—é‡å "><a href="#é€šä¿¡å’Œè®¡ç®—é‡å " class="headerlink" title="é€šä¿¡å’Œè®¡ç®—é‡å "></a>é€šä¿¡å’Œè®¡ç®—é‡å </h3><p>åœ¨æ²¡æœ‰ä½¿ç”¨æ¢¯åº¦æ¡¶æœºåˆ¶ä¹‹å‰ï¼Œé€šä¿¡å’Œæ¢¯åº¦è®¡ç®—å¯ä»¥é‡å ã€‚ </p><p>åœ¨æ¢¯åº¦æ¡¶æœºåˆ¶ä¸‹ï¼Œéœ€è¦ç­‰åœ¨åŒä¸€ä¸ªæ¡¶å†…çš„æ‰€æœ‰æ¢¯åº¦éƒ½è®¡ç®—å®Œæˆåï¼Œæ‰èƒ½è¿›è¡Œé€šä¿¡ã€‚ä¸ºäº†é‡å ï¼ŒPyTorch å¼•å…¥ hook æœºåˆ¶ï¼Œåœ¨åå‘ä¼ æ’­è®¡ç®—å®Œæˆåï¼Œè°ƒç”¨è‡ªå®šä¹‰å‡½æ•°</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/5.webp" width="500" /></p><p>æ¯å½“ä¸€ä¸ªæ¢¯åº¦è®¡ç®—å®Œæˆåï¼Œå¯¹åº”çš„ hook å°†ä¼šè¢«è§¦å‘ï¼Œå½“åœ¨åŒä¸€ä¸ªbucketä¸­çš„æ¢¯åº¦çš„hookéƒ½è¢«fireåï¼Œå°±è°ƒç”¨AllReduceå¯¹è¯¥bucketè¿›è¡Œé€šä¿¡ </p><p>ä½†æ˜¯è¿™ç§ç­–ç•¥ä¼šå¯¼è‡´ä¸¤ä¸ªé—®é¢˜</p><ul><li><p>æ¯ä¸ªè¿›ç¨‹éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œä¸èƒ½ä¿è¯æ‰€æœ‰è¿›ç¨‹å¤„ç†æ¡¶çš„é¡ºåºä¸€è‡´ï¼Œå¦‚ä¸‹å›¾ (a) æ‰€ç¤º </p><p>è§£å†³æ–¹æ³•ï¼šå°†æ¨¡å‹å‚æ•°çš„ååºä½œä¸ºæ¡¶çš„é¡ºåºï¼Œåå‘é¡ºåºå¯ä»¥è¿‘ä¼¼è¡¨ç¤ºåå‘ä¼ é€’ä¸­çš„æ¢¯åº¦è®¡ç®—é¡ºåº</p></li><li><p>åœ¨æŸäº›é˜¶æ®µï¼Œç½‘ç»œä¸­çš„ä¸€äº›å±‚çš„æ¢¯åº¦å¯ä»¥ä¸éœ€è¦ä½¿ç”¨ï¼Œå¦‚ Dropout ç­‰ï¼Œè¿™æ ·è¿™ä¸ªå±‚å¯¹åº”æ¢¯åº¦çš„ hook æ°¸è¿œä¸ä¼šè¢«è§¦å‘ï¼Œå¦‚ä¸‹å›¾ (b) æ‰€ç¤º</p><p>è§£å†³æ–¹æ³•ï¼šåœ¨å‰å‘ä¼ æ’­ç»“æŸåä»è¾“å‡ºå¼€å§‹éå†è®¡ç®—å›¾ï¼Œä½¿ç”¨ bitmapï¼ˆç”¨äºè¡¨ç¤ºäºŒè¿›åˆ¶æ•°æ®çš„æ•°æ®ç»“æ„ï¼‰ è®°å½•å“ªäº›å‚æ•°å‚ä¸è®¡ç®—ï¼Œå“ªäº›å‚æ•°æ²¡æœ‰å‚ä¸è®¡ç®—ï¼Œå¯¹äºæ²¡æœ‰å‚ä¸è®¡ç®—çš„å‚æ•°ï¼Œæ ‡è®°ä¸º ready </p></li></ul><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/6.webp" width="500" /></p><h3 id="æ¢¯åº¦ç´¯ç§¯"><a href="#æ¢¯åº¦ç´¯ç§¯" class="headerlink" title="æ¢¯åº¦ç´¯ç§¯"></a>æ¢¯åº¦ç´¯ç§¯</h3><p>ä¼ ç»Ÿæ¢¯åº¦ä¼ æ’­é¢‘ç‡æ˜¯åœ¨æ¯æ¬¡è®­ç»ƒå®Œæˆåä¼ æ’­ï¼ŒPyTorch é€šè¿‡åœ¨åœ¨å…¨å±€åŒæ­¥æ¢¯åº¦ä¹‹å‰è¿›è¡Œ n æ¬¡å±€éƒ¨è®­ç»ƒè¿­ä»£ï¼Œå‡å°‘æ¢¯åº¦é€šä¿¡çš„æ—¶é—´ï¼Œè¿™ç§æ€è·¯è¿˜å¯ä»¥è§£å†³å¤§ batch size å ç”¨èµ„æºè¿‡å¤§çš„é—®é¢˜ï¼Œå¯ä»¥å°†ä¸€ä¸ªbatchåˆ‡åˆ†ä¸ºå¤šä¸ªmicro<br>batchï¼Œåœ¨æœ€åä¸€ä¸ªmicro batchè®­ç»ƒå®Œæˆåï¼Œè¿›è¡Œæ¢¯åº¦æ›´æ–°</p><p>ä½†æ˜¯è¿™ç§ç­–ç•¥ä¼šå¯¼è‡´æŸäº›è¿­ä»£ä¸­æ²¡æœ‰å‚ä¸è®¡ç®—çš„æ¢¯åº¦ï¼ˆå¦‚ Dropoutï¼‰å’Œæ­£å¸¸è®¡ç®—çš„æ¢¯åº¦æ··åˆåï¼Œä¼šå¯¼è‡´æœ‰éƒ¨åˆ†æ¢¯åº¦åœ¨æŸäº›è¿­ä»£ä¸­è¢«ç´¯åŠ ï¼Œè€Œåœ¨å…¶ä»–è¿­ä»£ä¸­è¢«æ¸…é›¶ï¼ŒPyTorchä¹Ÿæ— æ³•åˆ¤æ–­å“ªäº›æ¢¯åº¦è®¡ç®—å®Œæˆåç«‹å³è¿›è¡ŒåŒæ­¥ï¼Œè¿˜æ˜¯ç­‰<br>ç´¯åŠ è‹¥å¹²ä¸ªè¿­ä»£ä¹‹åå†è¿›è¡ŒåŒæ­¥</p><p>è§£å†³æ–¹æ³•ï¼šæå‡ºäº† â€œno_syncâ€ä¸Šä¸‹æ–‡ã€‚å½“è¿›è¡Œæ¢¯åº¦ç´¯ç§¯å¹¶ä½¿ç”¨ â€œno_syncâ€ä¸Šä¸‹æ–‡æ—¶ï¼Œä¼šæœ‰ä¸€äº›å‚æ•°åœ¨æŸäº›è¿­ä»£ä¸­æœªè¢«ä½¿ç”¨ï¼Œä½†åœ¨å…¶ä»–è¿­ä»£ä¸­è¢«ä½¿ç”¨ã€‚ä¸ºäº†ç¡®ä¿è¿™äº›æœªä½¿ç”¨å‚æ•°çš„æ¢¯åº¦ä¸ä¼šåœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­è¢«è¯¯ç”¨ï¼Œä½¿ç”¨ â€œbitmapâ€<br>æ¥è®°å½•è¿™äº›æœªä½¿ç”¨å‚æ•°çš„ä¿¡æ¯ã€‚åœ¨è¿›å…¥â€no_syncâ€ä¸Šä¸‹æ–‡ä¹‹åï¼Œæ‰€æœ‰çš„ DDP hook éƒ½è¢«ç¦ç”¨ï¼Œè¿™æ„å‘³ç€å‚æ•°çš„æ¢¯åº¦å°†è¢«ç´¯ç§¯è€Œä¸ä¼šåœ¨è¯¥ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œé€šä¿¡ã€‚åŒæ—¶ï¼Œå…¨å±€æœªä½¿ç”¨å‚æ•°çš„ä¿¡æ¯ä¹Ÿä¼šè¢«è®°å½•åœ¨ â€œbitmapâ€ ä¸­ã€‚è¿™æ ·ï¼Œåœ¨ä¸‹<br>ä¸€æ¬¡é€šä¿¡æ—¶ï¼ŒPyTorchä¼šä½¿ç”¨ â€œbitmapâ€ æ¥æŒ‡å¯¼æ¢¯åº¦é€šä¿¡ï¼Œä»¥ç¡®ä¿æœªä½¿ç”¨çš„å‚æ•°ä¸ä¼šè¢«ä¼ è¾“ï¼Œä»è€Œä¿æŒæ¢¯åº¦çš„æ­£ç¡®æ€§ã€‚</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/11.webp" width="500" /></p><h2 id="é›†åˆé€šä¿¡"><a href="#é›†åˆé€šä¿¡" class="headerlink" title="é›†åˆé€šä¿¡"></a>é›†åˆé€šä¿¡</h2><p>PyTorch DDP æ”¯æŒä¸‰ç§é€šè®¯åº“ï¼šNCCLï¼ŒGloo å’Œ MPIã€‚è¿™äº›åº“è¢«åŒ…è£…åˆ°åŒä¸€ä¸ª ProcessGroup API ä¸­ï¼Œåœ¨è¿è¡Œå¤šä¸ª ProcessGroup æ—¶ï¼Œä¼šä½¿ç”¨è½®è¯¢è°ƒåº¦å°†é›†ä½“é€šä¿¡åˆ†æ´¾ç»™å„ä¸ª ProcessGroup å®ä¾‹ï¼Œè·å¾—æ›´é«˜çš„å¸¦å®½åˆ©ç”¨ç‡ </p><h2 id="å·¥ç¨‹å®ç°"><a href="#å·¥ç¨‹å®ç°" class="headerlink" title="å·¥ç¨‹å®ç°"></a>å·¥ç¨‹å®ç°</h2><h3 id="python-å‰åç«¯"><a href="#python-å‰åç«¯" class="headerlink" title="python å‰åç«¯"></a>python å‰åç«¯</h3><p>å¯é…ç½®å‚æ•°</p><ul><li>Process Groupï¼šæŒ‡å®šè¿›ç¨‹ç»„è¿è¡Œ AllReduce</li><li>bucket_cap_mbï¼šè°ƒæ•´æ¡¶å¤§å°ä¼˜åŒ–è®­ç»ƒé€Ÿåº¦ </li><li><p>find_unused_parametersï¼šæ§åˆ¶ DDP æ˜¯å¦åº”è¯¥é€šè¿‡éå†è®¡ç®—å›¾æ¥æ£€æµ‹æœªä½¿ç”¨çš„å‚æ•° </p></li><li><p>Model Buffersï¼šåœ¨æŸäº›å±‚ä¸­ï¼Œä¾‹å¦‚BatchNormå±‚ï¼Œéœ€è¦ç»´æŠ¤ä¸€äº›çŠ¶æ€ï¼Œæ¯”å¦‚running varianceï¼ˆè¿è¡Œæ–¹å·®ï¼‰å’Œrunning meanï¼ˆè¿è¡Œå‡å€¼ï¼‰ã€‚è¿™äº›çŠ¶æ€éœ€è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­æ›´æ–°å’Œä½¿ç”¨ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚ä¸ºäº†æ­£ç¡®å¤„ç†Model Buffersçš„åŒæ­¥å’Œå¹¿æ’­ã€‚DDPé€šè¿‡æŒ‡å®š rank 0 è¿›ç¨‹æ¥å¤„ç†ã€‚åœ¨å¯ç”¨no syncæ¨¡å¼æ—¶ï¼Œç›¸åº”åœ°è°ƒæ•´ç¼“å†²åŒºçš„å¹¿æ’­ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹åœ¨è¿›è¡Œæœ¬åœ°è®¡ç®—ä¹‹å‰ï¼Œéƒ½æ‹¥æœ‰æœ€æ–°çš„Model Buffersçš„å€¼ </p></li></ul><h3 id="æ¢¯åº¦è§„çº¦çš„é‡ç‚¹å®ç°"><a href="#æ¢¯åº¦è§„çº¦çš„é‡ç‚¹å®ç°" class="headerlink" title="æ¢¯åº¦è§„çº¦çš„é‡ç‚¹å®ç°"></a>æ¢¯åº¦è§„çº¦çš„é‡ç‚¹å®ç°</h3><p>å‚æ•°ä¸æ¡¶çš„æ˜ å°„ï¼šç¡®ä¿åŒä¸€ bucket ä¸­çš„ parameter éƒ½æ¥è‡ªåŒä¸€ä¸ªdevice</p><p>Autograd Hookï¼šé€šè¿‡ä¸ºæ¯ä¸ªæ¡¶æ·»åŠ å€¼ä¸ºæ¢¯åº¦æ•°é‡çš„é€’å‡è®¡æ•°å™¨æ¥åˆ¤æ–­å½“å‰ backward åˆ°äº†ç¬¬å‡ å±‚ï¼Œä»è€Œåœ¨åˆé€‚çš„æ—¶å€™ AllReduceï¼Œåœ¨ä¸‹ä¸€æ¬¡å‰å‘ä¼ æ’­æ—¶ï¼Œé‡ç½®è®¡æ•°å™¨</p><p>æ¡¶è§„çº¦ï¼šé»˜è®¤ bucket size ä¸º 25Mï¼Œå®è·µä¸­éœ€è¦å®éªŒå¾—åˆ°æœ€ä½³å¤§å° </p><p>å…¨å±€æœªä½¿ç”¨å‚æ•°ï¼šåœ¨ CPU ä¸Šåˆ›å»º bitmap æ¥ä¿å­˜æœ¬åœ°æ²¡æœ‰ä½¿ç”¨çš„å‚æ•°ä¿¡æ¯ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªé¢å¤–çš„allreduceå¾—åˆ° global bitmap</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/7.webp" width="300" /></p><h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><p>é€šè¿‡ Latency Breakdownï¼ˆå¯¹è®­ç»ƒè¿‡ç¨‹ä¸­ä¸åŒé˜¶æ®µçš„å»¶è¿Ÿè¿›è¡Œç»†åˆ†å’Œåˆ†æï¼‰æ¯”è¾ƒäº†ä¸åŒæ¨¡å‹ã€ä½¿ç”¨ä¸åŒ backendã€æœ‰æ— é€šä¿¡å’Œè®­ç»ƒçš„ overlapï¼Œå¾—åˆ°åå‘ä¼ æ’­æ˜¯æœ€è€—æ—¶æ˜¯é˜¶æ®µï¼ŒAllReduce å°±æ˜¯åœ¨è¿™ä¸€é˜¶æ®µä¸­ï¼Œä»ç„¶éœ€è¦ä¼˜åŒ–é€šä¿¡æ•ˆç‡ </p><p>ä¸‹å›¾å®éªŒäº†ä¸åŒ bucket size</p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/9.webp" width="800" /></p><p>DDPé€šè¿‡ä½¿ç”¨å¤šä¸ªround-robinï¼ˆè½®è¯¢è°ƒåº¦ï¼‰è¿›ç¨‹ç»„ä»è€Œå……åˆ†åˆ©ç”¨å¸¦å®½ã€‚ä¸‹å›¾å®éªŒæ¯”è¾ƒäº†ä½¿ç”¨ä¸åŒæ•°é‡è¿›ç¨‹ç»„å¯¹ latency çš„å½±å“ </p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/10.webp" width="800" /></p><h2 id="è®¨è®º"><a href="#è®¨è®º" class="headerlink" title="è®¨è®º"></a>è®¨è®º</h2><ul><li><p>é€šä¿¡åç«¯ï¼šNCCL ä¼˜äº GLOO </p><p><img src="/image/è®ºæ–‡é˜…è¯»-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/8.webp" width="300" /></p></li><li><p>bucket sizeï¼šå¤§å°éšç€æ¨¡å‹çš„å¢å¤§è€Œå¢å¤§ </p></li><li><p>èµ„æºåˆ†é…ï¼šç”¨ NCCL æ—¶å»ºè®®æŠŠåŒä¸€å°æœºå™¨ä¸Šçš„æ‰€æœ‰è¿›ç¨‹éƒ½æ”¾åˆ°åŒä¸€ä¸ªè¿›ç¨‹ç»„ä¸­ </p></li></ul><h2 id="æ”¹è¿›"><a href="#æ”¹è¿›" class="headerlink" title="æ”¹è¿›"></a>æ”¹è¿›</h2><ul><li>æ¢¯åº¦é¡ºåºé¢„æµ‹ï¼šä½¿ç”¨ autograd hook è®°å½• backward çš„é¡ºåºï¼Œå¹¶ç›¸åº”åœ°æ›´æ–° bucket mapping ä¸­çš„å¯¹åº”å‚æ•°</li><li>Layer droppingï¼šåœ¨forwardçš„è¿‡ç¨‹ä¸­éšæœº drop æ‰å‡ å±‚ç½‘ç»œï¼ŒåŠ é€Ÿè®­ç»ƒçš„åŒæ—¶é¿å…è¿‡æ‹Ÿåˆï¼Œä¸æ­¤åŒæ—¶ç›¸åº”ä¿®æ”¹ parameter-to-bucket mappingï¼Œæˆ–ä» bucket å±‚é¢ drop ç½‘ç»œå±‚</li><li>æ¢¯åº¦å‹ç¼©ï¼šåªé€šä¿¡éœ€è¦é«˜ç²¾åº¦çš„æ¢¯åº¦</li></ul>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»: Horovod: fast and easy distributed deep learning in TensorFlow</title>
      <link href="/p/b353fa5f/"/>
      <url>/p/b353fa5f/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æœ€è¿‘å¿™å®ä¹ å»äº†ï¼Œæ–­æ›´å¤§åŠå¹´ã€‚æ•´ç†äº†ä¸€ä¸‹è®ºæ–‡ï¼Œæœ‰åå‡ ç¯‡æ²¡è¯»ï¼Œåé¢æœ‰æ—¶é—´æ…¢æ…¢æ›´ã€‚</p><p>è¿™ç¯‡è®ºæ–‡ä¸»è¦å·¥ä½œæ˜¯å¯¹ TensorFlow æ¡†æ¶ API çš„é‡å†™ï¼Œä½¿ç”¨ ring-allreduce å’Œ broadcast æ–¹æ³•ï¼Œè¿›è¡Œæ•°æ®å¹¶è¡Œã€‚</p><span id="more"></span><p>paper: <a href="https://arxiv.org/abs/1802.05799">https://arxiv.org/abs/1802.05799</a></p><p>code: <a href="https://github.com/uber/horovod">https://github.com/uber/horovod</a></p><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>è®­ç»ƒæ—¶çš„ GPU é€šä¿¡è€—æ—¶è¿‡å¤§ </p><p>å½“æ—¶åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿéœ€è¦ä¿®æ”¹å¤§é‡ä»£ç ï¼Œæˆæœ¬è¿‡é«˜ </p><h3 id="TensorFlow-ä¸è¶³"><a href="#TensorFlow-ä¸è¶³" class="headerlink" title="TensorFlow ä¸è¶³"></a>TensorFlow ä¸è¶³</h3><p>TensorFlow çš„åˆ†å¸ƒå¼å¼•å…¥äº†è®¸å¤šå¤æ‚çš„æ¦‚å¿µå’Œ APIï¼Œä½¿ç”¨æˆæœ¬å˜é«˜ï¼Œå¾ˆéš¾å‘ç°ä¿®å¤éšè—çš„ bug<br>ä½¿ç”¨ 128 å¼  GPU è¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒæ—¶ï¼Œé€šä¿¡ä¸è®¡ç®—å æ¯”ç›¸å½“ï¼Œå¯æ‰©å±•æ€§å·® </p><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/1.webp" width="800" /></p><p>Facebook é¦–æ¬¡æå‡ºæ•°æ®å¹¶è¡Œï¼Œåœ¨å¤šä¸ªèŠ‚ç‚¹ä¸Šå¹¶è¡Œæ‹†åˆ†æ•°æ®æ¥è®­ç»ƒã€‚ä¸åŒæ‰¹æ¬¡æ•°æ®çš„æ¢¯åº¦åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå•ç‹¬è®¡ç®—ï¼Œä¹‹åæ”¶é›†æ¢¯åº¦æ±‚å¹³å‡åå¹¿æ’­åˆ°æ¯ä¸ªèŠ‚ç‚¹ä¸Šï¼Œä»¥ä¿è¯æ¯ä¸ªèŠ‚ç‚¹ä¸­çš„æ¨¡å‹å‰¯æœ¬å‚æ•°ä¸€è‡´ </p><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/2.webp" width="800" /></p><h3 id="Leveraging-a-different-type-of-algorithm"><a href="#Leveraging-a-different-type-of-algorithm" class="headerlink" title="Leveraging a different type of algorithm"></a>Leveraging a different type of algorithm</h3><p>TensorFlow é€šè¿‡æŒ‡å®šä¸€ä¸ªè¿›ç¨‹ä¸º workerï¼ˆå·¥ä½œè¿›ç¨‹ï¼‰ æˆ– parameter serversï¼ˆå‚æ•°æœåŠ¡å™¨ï¼‰</p><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/3.webp" width="800" /></p><p>worker è´Ÿè´£å‰åå‘ä¼ æ’­ï¼Œå‘é€è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦ï¼Œæ¥æ”¶å¹³å‡åçš„æ¢¯åº¦å’Œæ•°æ®</p><p>æœ‰ä¸¤ä¸ªéš¾ç‚¹ï¼š</p><ul><li>worker å’Œ parameter servers æ¯”ä¾‹éš¾ä»¥ç¡®å®šï¼Œå¤ªå°‘çš„ parameter servers ä¼šå¯¼è‡´è®¡ç®—é¥±å’Œï¼Œå¤ªå¤šçš„ parameter servers ä¼šå¯¼è‡´é€šä¿¡é¥±å’Œ </li><li>å­¦ä¹ æ›²çº¿é™¡å³­ï¼Œå¤§é‡ä»£ç é‡æ„ </li></ul><p>ring allreduce çš„æå‡ºè§£å†³äº†è¿™ä¸ªé—®é¢˜ </p><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/4.webp" width="800" /> </p><p>Nä¸ªèŠ‚ç‚¹ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä¸å…¶ä¸¤ä¸ªå¯¹ç­‰èŠ‚ç‚¹è¿›è¡Œé€šä¿¡ï¼Œå…±è¿›è¡Œäº†2 * (N - 1)æ¬¡é€šä¿¡ï¼ŒèŠ‚ç‚¹å‘é€å’Œæ¥æ”¶æ•°æ®ç¼“å†²åŒºçš„å—ã€‚åœ¨ç¬¬ä¸€æ¬¡ï¼ˆN - 1ï¼‰æ¬¡è¿­ä»£æ—¶ï¼Œæ¥æ”¶åˆ°çš„å€¼ä¼šè¢«æ·»åŠ åˆ°èŠ‚ç‚¹ç¼“å†²åŒºä¸­çš„å€¼ä¸­ã€‚åœ¨ç¬¬äºŒæ¬¡ï¼ˆN - 1ï¼‰æ¬¡è¿­ä»£æ—¶ï¼Œæ¥<br>æ”¶åˆ°çš„å€¼å°†æ›¿æ¢èŠ‚ç‚¹ç¼“å†²åŒºä¸­çš„å€¼ </p><h2 id="Horovod"><a href="#Horovod" class="headerlink" title="Horovod"></a>Horovod</h2><p>åšäº†å¦‚ä¸‹å·¥ä½œ </p><ul><li>å°†ç™¾åº¦çš„ TensorFlow ring-allreduce ç®—æ³•çš„å®ç°è½¬åŒ–ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ Python åŒ…ï¼Œå‘½åä¸º Horovod </li><li>ä½¿ç”¨ NCCL åº“å®ç°äº† TensorFlow ring-allreduceï¼Œå¹¶ä¼˜åŒ–äº†æ€§èƒ½ </li><li>æ·»åŠ äº†å¯¹å•æœºå¤šå¡çš„æ”¯æŒ </li><li>æ”¹è¿›äº† APIï¼Œæ·»åŠ  broadcast æ“ä½œï¼Œä»…éœ€ 4 æ­¥å³å¯ä½¿ç”¨ Horovod </li></ul><h3 id="ä½¿ç”¨æ–¹æ³•"><a href="#ä½¿ç”¨æ–¹æ³•" class="headerlink" title="ä½¿ç”¨æ–¹æ³•"></a>ä½¿ç”¨æ–¹æ³•</h3><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/5.webp" width="800" /></p><p>ä¸‹é¢ä»£ç ä½¿ç”¨ mpirun å‘½ä»¤åœ¨ 4 å¼ å¡çš„ 4 ä¸ª server ä¸Šè¿è¡Œ train.pyï¼Œæ”¯æŒ TensorFlow å’Œ Keras </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mpirun -np 16 -H server1:4,server2:4,server3:4,server4:4 python train.py </span><br></pre></td></tr></table></figure><h3 id="Horovod-Timeline"><a href="#Horovod-Timeline" class="headerlink" title="Horovod Timeline"></a>Horovod Timeline</h3><p>TensorFlow å’Œ CUDA Profiler ä¸è¶³ï¼šåªèƒ½æ˜¾ç¤ºå•ä¸ª server çš„ Profilerï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨äº¤å‰æ¯”å¯¹ </p><p>æ”¹è¿›ï¼šå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå°±å¯ä»¥æŸ¥çœ‹è®­ç»ƒæ—¶æ¯ä¸ªèŠ‚ç‚¹åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­çš„å…·ä½“æ“ä½œï¼Œå¹¶ä¸”å…¼å®¹ chrome://tracing </p><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/6.webp" width="800" /></p><h3 id="Tensor-Fusion"><a href="#Tensor-Fusion" class="headerlink" title="Tensor Fusion"></a>Tensor Fusion</h3><p>è§‚å¯Ÿ Profiler æ—¶å‘ç°ä¸è¶³ï¼šå¤§ Tensor å¯ä»¥å¾ˆå¥½åœ°åˆ©ç”¨å¸¦å®½ï¼Œä½†æ˜¯å° Tensor çš„ ring-allreduce ä¼šå½±å“æ•ˆç‡ </p><p>æ”¹è¿›ï¼š</p><ul><li>æ•´ç†è¦ allreduce çš„ Tensorï¼Œåˆ†é…åˆ°åŒ¹é…çš„åŒæ•°æ®ç±»å‹çš„ bufferï¼Œå¦‚æœæ²¡èƒ½æˆåŠŸåˆ†é…ï¼Œå°±åˆ›å»ºä¸€ä¸ª fusion bufferï¼Œé»˜è®¤ä¸º 64 MBï¼› </li><li>å°† Tensor æ‹·è´åˆ° bufferï¼Œå¯¹ fusion buffer æ‰§è¡Œ broadcastï¼Œå†å°† Tensor æ‹·è´å‡ºæ¥ã€‚é‡å¤ä¸Šè¿°æ­¥éª¤ï¼›</li></ul><p>å¯¹æ¯”å¾—åˆ° 65% çš„æ€§èƒ½æå‡ </p><h2 id="Horovod-Benchmarks"><a href="#Horovod-Benchmarks" class="headerlink" title="Horovod Benchmarks"></a>Horovod Benchmarks</h2><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/7.webp" width="800" /> </p><p>ä¸Šå›¾æ‰€ç¤ºï¼Œä½¿ç”¨ Inception V3å’ŒResNet-101æ¨¡å‹è¿›è¡Œå®éªŒï¼ŒHorovod ç›¸æ¯” TensorFlow æ€§èƒ½æå‡äº† 88% </p><p>ä½¿ç”¨ RDMA ä¸ TCP è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚åœ¨ Inception V3å’Œ ResNet-101 æ¨¡å‹ä¸Šï¼ŒRDMA å¹¶æ²¡æœ‰æ˜¾è‘—æé«˜æ€§èƒ½ï¼Œåªæ¯” TCP ç½‘ç»œå¤šäº† 3% åˆ° 4% çš„å¢é•¿</p><p><img src="/image/è®ºæ–‡é˜…è¯»-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/8.webp" width="800" /></p><p>ä½†æ˜¯åœ¨ VGG-16 æ¨¡å‹ä¸Šï¼Œä½¿ç”¨RDMAç½‘ç»œæ€§èƒ½æé«˜äº†30%ã€‚å¯ä»¥è§£é‡Šä¸º VGG-16 æ¨¡å‹å…·æœ‰å¤§é‡çš„å‚æ•°ï¼Œç»“åˆå…¶è¾ƒå°‘çš„å±‚æ•°ï¼Œä½¿å¾—é€šä¿¡æˆä¸ºå…³é”®è·¯å¾„ï¼Œä½¿å¾—ç½‘ç»œæˆä¸ºç“¶é¢ˆ</p><h2 id="æ”¹è¿›"><a href="#æ”¹è¿›" class="headerlink" title="æ”¹è¿›"></a>æ”¹è¿›</h2><ul><li>ä½¿ MPI å®‰è£…ä½¿ç”¨æ›´æ–¹ä¾¿ </li><li>ç€é‡ç ”ç©¶å¦‚ä½•è°ƒæ•´æ¨¡å‹çš„è¶…å‚ä»¥æé«˜å‡†ç¡®ç‡ </li><li>å¼€å‘æ›´å¤šå¤§æ¨¡å‹è®­ç»ƒç¤ºä¾‹</li></ul>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2023MCM-ICMç¾èµ›Cé¢˜ç¬¬äºŒé—®æ€è·¯</title>
      <link href="/p/c1bfab13/"/>
      <url>/p/c1bfab13/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>åœ¨ç¡äº†åä¸€ä¸ªå°æ—¶åï¼Œè¹¦å‡ºçš„æ€è·¯ï¼Œç›®å‰ç½‘ä¸Šæ²¡æœ‰çœ‹åˆ°ç›¸åŒçš„æ–¹æ³•ï¼ˆä¸çŸ¥é“æ¯”èµ›åˆšç»“æŸå°±å‘æ€è·¯ä¼šä¸ä¼šå‡ºäº‹ï¼‰ï¼Œç¬¬ä¸€é¢˜å’Œç¬¬ä¸‰é¢˜å¤§å®¶å¤§åŒå°å¼‚ï¼Œå°±ä¸è®²è§£äº†ã€‚</p><span id="more"></span><h2 id="é¢˜ç›®"><a href="#é¢˜ç›®" class="headerlink" title="é¢˜ç›®"></a>é¢˜ç›®</h2><p>å¯¹äºç»™å®šçš„æœªæ¥è§£å†³æ–¹æ¡ˆå•è¯ï¼Œåœ¨æœªæ¥çš„æ—¥æœŸï¼Œå¼€å‘ä¸€ä¸ªæ¨¡å‹ï¼Œä½¿æ‚¨èƒ½å¤Ÿé¢„æµ‹æŠ¥å‘Šç»“æœçš„åˆ†å¸ƒã€‚æ¢å¥è¯è¯´ï¼Œé¢„æµ‹æœªæ¥æ—¥æœŸï¼ˆ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6ï¼ŒXï¼‰çš„ç›¸å…³ç™¾åˆ†æ¯”ã€‚ä½ çš„æ¨¡å‹å’Œé¢„æµ‹æœ‰å“ªäº›ä¸ç¡®å®šæ€§ï¼Ÿä¸¾ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œè¯´æ˜ä½ å¯¹2023å¹´3æœˆ1æ—¥<code>EERIE</code>ä¸€è¯çš„é¢„æµ‹ã€‚ä½ å¯¹æ¨¡å‹çš„é¢„æµ‹æœ‰å¤šè‡ªä¿¡ï¼Ÿ</p><h2 id="æ€è·¯"><a href="#æ€è·¯" class="headerlink" title="æ€è·¯"></a>æ€è·¯</h2><p>é¦–å…ˆæ˜¯å•è¯ç‰¹å¾ï¼Œç¬”è€…åœ¨è¿™é‡Œé€‰æ‹©äº† 6 ä¸ªç‰¹å¾</p><ul><li>è¯é¢‘ï¼ˆ</li><li>è¯æ€§ï¼ˆåè¯ï¼ŒåŠ¨è¯ â€¦â€¦ï¼‰</li><li>éŸ³èŠ‚æ•°</li><li>è¯çš„æƒ…æ„Ÿåˆ†ç±»ï¼ˆè´¬ä¹‰ï¼Œä¸­æ€§ï¼Œè¤’ä¹‰ï¼‰</li><li>é‡å¤å­—æ¯æ•°</li><li>å½“å¤©æ˜¯å¦æ˜¯å‡æœŸ</li></ul><p>è¦é¢„æµ‹çš„ 7 ä¸ªç™¾åˆ†æ¯”æ˜¯å¾ˆæ˜æ˜¾å‘ˆæ­£æ€åˆ†å¸ƒï¼Œå¯ä»¥ä½¿ç”¨æ­£æ€åˆ†å¸ƒæ›²çº¿æ‹Ÿåˆï¼Œå¯è§†åŒ–å¦‚ä¸‹</p><p><img src="/image/2023MCM-ICMç¾èµ›Cé¢˜ç¬¬äºŒé¢˜æ€è·¯/std.webp" alt=""></p><p>è¿™æ ·å°±å¯ä»¥å°† 7 ä¸ªè¦é¢„æµ‹çš„ç‰¹å¾è½¬åŒ–ä¸º 2 ä¸ªç‰¹å¾ï¼ˆstdï¼Œmeanï¼‰</p><p>å†æ­å»ºç¥ç»ç½‘ç»œé¢„æµ‹å³å¯ï¼Œç”±äºæ•°æ®é‡è¾ƒå°‘ï¼Œç¬”è€…ä½¿ç”¨å¤šå±‚ Dropout çš„æ–¹æ³•ï¼Œp ç›¸ç»§ä¸‹é™æ¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–ã€‚ç½‘ç»œç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼Œè¶…å‚åœ¨æ–‡æœ«ä»£ç ä¸­</p><p><img src="/image/2023MCM-ICMç¾èµ›Cé¢˜ç¬¬äºŒé¢˜æ€è·¯/net.webp" alt=""></p><p>æœ€åé¢„æµ‹çš„<code>EERIE</code>ç™¾åˆ†æ¯”å¦‚ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/2023MCM-ICMç¾èµ›Cé¢˜ç¬¬äºŒé¢˜æ€è·¯/eerie.webp" alt=""></p><p>ä»£ç æˆ‘æ”¾åœ¨äº† github ä»“åº“</p><p><a href="https://github.com/aeeeeeep/2023MCM-C-Task2">https://github.com/aeeeeeep/2023MCM-C-Task2</a></p><p>æ¬¢è¿ç»™ä¸ª star â­â­â­ï½</p>]]></content>
      
      
      <categories>
          
          <category> æ•°å­¦å»ºæ¨¡ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•°æ®åˆ†æ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HGame_2023_Week3_3ctu4_card_problem</title>
      <link href="/p/f100aba/"/>
      <url>/p/f100aba/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å¹²æ‰°ç‰¹å¾éå¸¸å¤šçš„äºŒåˆ†ç±»é—®é¢˜ï¼Œè§£é¢˜æ­¥éª¤å¦‚ä¸‹</p><span id="more"></span><ul><li>é¦–å…ˆä½¿ç”¨é«˜æ–¯æ¨¡ç³Šå¯¹åŸå›¾ç‰‡é™å™ªï¼Œkernel ä¸º (9,9) ï¼Œå†äºŒå€¼åŒ–å›¾ç‰‡ï¼Œé˜ˆå€¼ä¸º 220ï¼Œä½¿ç”¨å½¢æ€å­¦è…èš€æ¥å¡«å……å­”æ´ï¼Œkernel ä¸º (5,5)ï¼Œå¾—åˆ°æ©ç å›¾åƒ</li><li>è·å–å›¾åƒä¸­æœ€å¤§è½®å»“çš„æ—‹è½¬åŒ…å›´ç›’ï¼ˆä¸­å¿ƒç‚¹ï¼Œå®½é«˜ï¼Œæ—‹è½¬è§’åº¦ï¼‰ä»¥åŠé¡¶ç‚¹ï¼Œç”Ÿæˆé€è§†å˜æ¢çŸ©é˜µï¼Œå¯¹æ©ç å›¾åƒå¯¹åº”çš„éƒ¨åˆ†è¿›è¡Œé€è§†å˜æ¢ï¼Œå¾—åˆ°å¡ç‰‡å›¾åƒï¼Œå¾—åˆ°çš„å¡ç‰‡ä¸åˆ†ä¸Šä¸‹æ–¹å‘</li><li>ç»è¿‡åˆ†æå¾— YGO ç±»åˆ«çš„å¡ç‰‡è¾¹ç¼˜ç‰¹å¾æ¯”è¾ƒç»Ÿä¸€ï¼Œé®ç›–ä¸­å¿ƒæ— ç”¨ç‰¹å¾ï¼Œå°†å¡ç‰‡å›¾åƒ [50:355,22:280] çš„åŒºåŸŸè®¾ä¸ºç™½è‰²ï¼Œç•™ä¸‹è¾¹ç¼˜ç‰¹å¾ï¼Œä»é®ç›–åçš„å›¾åƒä¸­æ‰¾å‘ä¸Šå’Œå‘ä¸‹æ–¹å‘å„ä¸¤å¼ å›¾ç‰‡ä½œä¸ºæ¨¡æ¿å›¾ç‰‡ä¿å­˜åˆ°å½“å‰ç›®å½•ä¸‹ <code>temp1.webp</code>å’Œ <code>temp2.webp</code></li><li>æ¯å¼ å›¾å¯¹ä¸¤ä¸ªæ¨¡æ¿åˆ†åˆ«ä½¿ç”¨ ORB ç®—æ³•è¿›è¡Œç›¸ä¼¼åº¦æ£€æµ‹ï¼Œå¦‚æœä¸ä¸¤ä¸ªæ¨¡æ¿ç›¸ä¼¼åº¦ä¹‹å’Œ &gt; 0.04ï¼Œå°±åˆ¤å®šä¸º YGOï¼Œå¦åˆ™ä¸º PTCG</li></ul><h2 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Img_Outline</span>(<span class="params">original_img</span>):</span><br><span class="line">    gray_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    blurred = cv2.GaussianBlur(gray_img, (<span class="number">9</span>, <span class="number">9</span>), <span class="number">0</span>)                    </span><br><span class="line">    _, RedThresh = cv2.threshold(blurred, <span class="number">220</span>, <span class="number">255</span>, cv2.THRESH_BINARY)  </span><br><span class="line">    h, w = original_img.shape[:<span class="number">2</span>]</span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">5</span>,<span class="number">5</span>))         </span><br><span class="line">    marker = np.zeros_like(gray_img)</span><br><span class="line">    marker[<span class="number">0</span>, :] = <span class="number">255</span></span><br><span class="line">    marker[-<span class="number">1</span>, :] = <span class="number">255</span></span><br><span class="line">    marker[:, <span class="number">0</span>] = <span class="number">255</span></span><br><span class="line">    marker[:, -<span class="number">1</span>] = <span class="number">255</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        marker_pre = marker</span><br><span class="line">        dilation = cv2.dilate(marker, kernel=kernel)</span><br><span class="line">        marker = np.<span class="built_in">min</span>((dilation, RedThresh), axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> (marker_pre == marker).<span class="built_in">all</span>():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    marker = cv2.morphologyEx(marker, cv2.MORPH_OPEN, kernel)</span><br><span class="line">    marker[<span class="number">0</span>:<span class="number">5</span>,:] = <span class="number">255</span></span><br><span class="line">    marker[-<span class="number">5</span>:,:] = <span class="number">255</span></span><br><span class="line">    marker[:,<span class="number">0</span>:<span class="number">5</span>] = <span class="number">255</span></span><br><span class="line">    marker[:,-<span class="number">5</span>:] = <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> original_img, gray_img, marker</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">findContours_img</span>(<span class="params">original_img, marker</span>):</span><br><span class="line">    contours, hierarchy = cv2.findContours(marker, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    c = <span class="built_in">sorted</span>(contours, key=cv2.contourArea, reverse=<span class="literal">True</span>)[<span class="number">1</span>]  </span><br><span class="line">    rect = cv2.minAreaRect(c)                                  </span><br><span class="line">    box = np.int0(cv2.boxPoints(rect))                          </span><br><span class="line">    draw_img = cv2.drawContours(original_img.copy(), [box], -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> box,draw_img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Perspective_transform</span>(<span class="params">box,original_img</span>):</span><br><span class="line">    orignal_W = math.ceil(np.sqrt((box[<span class="number">3</span>][<span class="number">1</span>] - box[<span class="number">2</span>][<span class="number">1</span>])**<span class="number">2</span> + (box[<span class="number">3</span>][<span class="number">0</span>] - box[<span class="number">2</span>][<span class="number">0</span>])**<span class="number">2</span>))</span><br><span class="line">    orignal_H= math.ceil(np.sqrt((box[<span class="number">3</span>][<span class="number">1</span>] - box[<span class="number">0</span>][<span class="number">1</span>])**<span class="number">2</span> + (box[<span class="number">3</span>][<span class="number">0</span>] - box[<span class="number">0</span>][<span class="number">0</span>])**<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    pts1 = np.float32([box[<span class="number">0</span>], box[<span class="number">1</span>], box[<span class="number">2</span>], box[<span class="number">3</span>]])</span><br><span class="line">    pts2 = np.float32([[<span class="built_in">int</span>(orignal_W+<span class="number">1</span>),<span class="built_in">int</span>(orignal_H+<span class="number">1</span>)], [<span class="number">0</span>, <span class="built_in">int</span>(orignal_H+<span class="number">1</span>)], [<span class="number">0</span>, <span class="number">0</span>], [<span class="built_in">int</span>(orignal_W+<span class="number">1</span>), <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    M = cv2.getPerspectiveTransform(pts1, pts2)</span><br><span class="line">    result_img = cv2.warpPerspective(original_img, M, (<span class="built_in">int</span>(orignal_W+<span class="number">3</span>),<span class="built_in">int</span>(orignal_H+<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">if</span> orignal_H &lt; orignal_W:</span><br><span class="line">        result_img = cv2.flip(cv2.transpose(result_img), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result_img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">img_similarity</span>(<span class="params">img1,img2</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">        orb = cv2.ORB_create()</span><br><span class="line">        kp1, des1 = orb.detectAndCompute(img1, <span class="literal">None</span>)</span><br><span class="line">        kp2, des2 = orb.detectAndCompute(img2, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        bf = cv2.BFMatcher(cv2.NORM_HAMMING)</span><br><span class="line"></span><br><span class="line">        matches = bf.knnMatch(des1, trainDescriptors=des2, k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        good = [m <span class="keyword">for</span> (m, n) <span class="keyword">in</span> matches <span class="keyword">if</span> m.distance &lt; <span class="number">0.75</span> * n.distance]</span><br><span class="line">        similary = <span class="built_in">len</span>(good) / <span class="built_in">len</span>(matches)</span><br><span class="line">        <span class="keyword">return</span> similary</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;æ— æ³•è®¡ç®—ä¸¤å¼ å›¾ç‰‡ç›¸ä¼¼åº¦&#x27;</span>)</span><br><span class="line">        exit()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./result&#x27;</span>):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;result&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    final = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    temp1 = cv2.imread(<span class="string">&#x27;./temp1.webp&#x27;</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">    temp2 = cv2.imread(<span class="string">&#x27;./temp2.webp&#x27;</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line">    r = remote(<span class="string">&#x27;week-3.hgame.lwsec.cn&#x27;</span>, <span class="number">30802</span>)</span><br><span class="line">    r.recvuntil(<span class="string">&#x27;...&#x27;</span>)</span><br><span class="line">    r.send(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    b64 = r.recvline()[:-<span class="number">1</span>]</span><br><span class="line">    out = <span class="built_in">open</span>(<span class="string">&#x27;row.zip&#x27;</span>, <span class="string">&quot;wb&quot;</span>)</span><br><span class="line">    base64.decode(io.BytesIO(b64), out)</span><br><span class="line">    out.close()</span><br><span class="line"></span><br><span class="line">    zipfile_path = <span class="string">&#x27;./row.zip&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> zipfile.ZipFile(zipfile_path, mode=<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> zfile:</span><br><span class="line">        nWaitTime = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> tqdm(zfile.namelist()):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;.webp&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> name:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> zfile.<span class="built_in">open</span>(name,mode=<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> image_file:</span><br><span class="line">                content = image_file.read() </span><br><span class="line">                image = np.asarray(<span class="built_in">bytearray</span>(content), dtype=<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">                image = cv2.imdecode(image, cv2.IMREAD_ANYCOLOR)</span><br><span class="line"></span><br><span class="line">                original_img, gray_img, RedThresh = Img_Outline(image)</span><br><span class="line">                box, draw_img = findContours_img(original_img, RedThresh)</span><br><span class="line">                result_img = Perspective_transform(box,original_img)</span><br><span class="line">                result_img[<span class="number">50</span>:<span class="number">355</span>,<span class="number">22</span>:<span class="number">280</span>] = <span class="number">255.0</span></span><br><span class="line">                cv2.imwrite(<span class="string">f&quot;./result/<span class="subst">&#123;name&#125;</span>&quot;</span>, result_img)</span><br><span class="line">                result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">                similarity1 = img_similarity(temp1, result_img)</span><br><span class="line">                similarity2 = img_similarity(temp2, result_img)</span><br><span class="line">                <span class="keyword">if</span> (similarity1 + similarity2) &gt; <span class="number">0.04</span>:</span><br><span class="line">                    final += <span class="string">&#x27;1&#x27;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    final += <span class="string">&#x27;0&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(final)</span><br><span class="line">    r.sendline(final)</span><br><span class="line">    r.interactive()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> misc </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>linuxä¸‹ä¸­æ–‡è·¯å¾„å‘½åè§„èŒƒåŒ–</title>
      <link href="/p/19affb6/"/>
      <url>/p/19affb6/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>shell ä¸­æ— æ³•æ­£å¸¸è®¿é—®å¸¦ç©ºæ ¼æˆ–æŸäº›å­—ç¬¦çš„ç›®å½•ï¼Œå†™äº†ä¸ªè„šæœ¬è§„èŒƒä¸€ä¸‹ä¸­æ–‡è·¯å¾„å‘½å</p><span id="more"></span><p>å°†æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰å­ç›®å½•å’Œæ–‡ä»¶å‘½åä¸­çš„<code>ã€ï¼Œã€‚()ï¼ã€ï¼Ÿï¼šâ€œâ€â€˜â€™ã€ã€‘ã€Šã€‹ï¼ˆï¼‰</code>å…¨éƒ¨æ›¿æ¢ä¸º<code>_</code>ï¼Œå»é™¤é¦–å°¾çš„<code>_</code>ã€‚</p><h2 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_chinese_path</span>(<span class="params">directory</span>):</span><br><span class="line">    <span class="comment"># éå†ç›®å½•</span></span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(directory):</span><br><span class="line">        <span class="keyword">for</span> dirname <span class="keyword">in</span> dirs:</span><br><span class="line">            <span class="comment"># åˆ©ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œå°†æŒ‡å®šå­—ç¬¦å…¨éƒ¨æ›¿æ¢ä¸º_</span></span><br><span class="line">            new_dirname = re.sub(<span class="string">r&#x27;[\sã€ï¼Œã€‚()ï¼ã€ï¼Ÿï¼šâ€œâ€â€˜â€™ã€ã€‘ã€Šã€‹ï¼ˆï¼‰]+&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, dirname)</span><br><span class="line">            <span class="comment"># å»é™¤é¦–å°¾çš„_</span></span><br><span class="line">            new_dirname = new_dirname.strip(<span class="string">&#x27;_&#x27;</span>)</span><br><span class="line">            <span class="comment"># æ–°ç›®å½•åå’Œæ—§ç›®å½•åä¸åŒæ—¶æ‰è¿›è¡Œé‡å‘½å</span></span><br><span class="line">            <span class="keyword">if</span> new_dirname != dirname:</span><br><span class="line">                old_path = os.path.join(root, dirname)</span><br><span class="line">                new_path = os.path.join(root, new_dirname)</span><br><span class="line">                os.rename(old_path, new_path)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> files:</span><br><span class="line">            <span class="comment"># åˆ©ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œå°†æŒ‡å®šå­—ç¬¦å…¨éƒ¨æ›¿æ¢ä¸º_</span></span><br><span class="line">            new_filename = re.sub(<span class="string">r&#x27;[\sã€ï¼Œã€‚()ï¼ï¼Ÿï¼šâ€œâ€â€˜â€™ã€ã€‘ã€Šã€‹ï¼ˆï¼‰]+&#x27;</span>, <span class="string">&#x27;_&#x27;</span>, filename)</span><br><span class="line">            <span class="comment"># å»é™¤é¦–å°¾çš„_</span></span><br><span class="line">            new_filename, suffix = os.path.splitext(new_filename)</span><br><span class="line">            new_filename = new_filename.strip(<span class="string">&#x27;_&#x27;</span>)</span><br><span class="line">            <span class="comment"># æ–°æ–‡ä»¶åå’Œæ—§æ–‡ä»¶åä¸åŒæ—¶æ‰è¿›è¡Œé‡å‘½å</span></span><br><span class="line">            <span class="keyword">if</span> new_filename != filename:</span><br><span class="line">                old_path = os.path.join(root, filename)</span><br><span class="line">                new_path = os.path.join(root, new_filename + suffix)</span><br><span class="line">                os.rename(old_path, new_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨ç¤ºä¾‹</span></span><br><span class="line">normalize_chinese_path(<span class="string">&#x27;./03 golangå¾®æœåŠ¡å®æˆ˜/&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> å·¥å…· </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ–°å¹´æ„¿æœ›</title>
      <link href="/p/d827211b/"/>
      <url>/p/d827211b/</url>
      
        <content type="html"><![CDATA[<p>å†™äºå£¬å¯…å¹´é™¤å¤•å¤œ</p><span id="more"></span><p>â é€šè¿‡è‹±è¯­å…­çº§ (2023-03-12 å¬åŠ›æ²¡æ¶‚â€¦)</p><p>âœ… <del>é€šè¿‡æŸé«˜æ ¡äººå·¥æ™ºèƒ½å­¦é™¢ç ”ç©¶ç”Ÿåˆè¯•</del> å»å›½å†…æŸGPUå¤§å‚å®ä¹ </p><p>âœ… go å¾®æœåŠ¡éƒ¨ç½²å¹¶è¡Œç¼–ç¨‹</p><p>âœ… è´­å…¥ <del>é«˜</del> ä½æ€§èƒ½å·¥ä½œç«™</p><p>  é…ç½®æ¸…å•</p><ul><li>CPUï¼ši5 10400</li><li>ä¸»æ¿ï¼šåæ“B460M-ITX/AC</li><li>æ˜¾å¡ï¼šå¾®æ˜Ÿ 2060 ä¸‡å›¾å¸ˆ 12G</li><li>å†…å­˜ï¼šé‡‘å£«é¡¿ DDR4 16G 2666MHz</li><li>å›ºæ€ï¼šç¡¬ç›˜ é‡‘å£«é¡¿ SNV2S 500G</li><li>æœºæ¢°ï¼šç¡¬ç›˜ å¸Œæ· é…·é±¼SATA3 1T(7200è½¬)</li><li>æœºç®±ï¼šé‡‘æ²³ç”°N1 mini-itx</li><li>ç”µæºï¼šèˆªå˜‰wd500k</li><li>ç³»ç»Ÿï¼šUbuntu 20.04</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç”Ÿæ´» </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>cajæ–‡æ¡£æ‰¹é‡è½¬æ¢ä¸ºpdf-shellè„šæœ¬å¤šçº¿ç¨‹</title>
      <link href="/p/5513d824/"/>
      <url>/p/5513d824/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æœ€è¿‘çœ‹çš„è®ºæ–‡æœ‰äº›å¤šï¼Œä½†çŸ¥ç½‘ä¸Šçš„ caj æ–‡æ¡£åˆå¡åˆéš¾åšç¬”è®°ï¼Œé‚å†™äº†ä¸€ä¸ª caj æ–‡æ¡£æ‰¹é‡è½¬æ¢ä¸º pdf çš„ shell è„šæœ¬ã€‚</p><span id="more"></span><h2 id="caj2pdf"><a href="#caj2pdf" class="headerlink" title="caj2pdf"></a>caj2pdf</h2><p>å®‰è£… caj2pdf å‘½ä»¤è¡Œå·¥å…·</p><p>github æºç : <a href="https://github.com/caj2pdf/caj2pdf">https://github.com/caj2pdf/caj2pdf</a></p><p>aur ç”¨æˆ·</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yay -S caj2pdf-git</span><br></pre></td></tr></table></figure><h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><p>å½“å‰ç›®å½•ä¸‹æ‰€æœ‰ caj æ–‡ä»¶æ‰¹é‡è½¬æ¢ä¸ºpdfï¼Œå¹¶åˆ é™¤åŸ caj æ–‡ä»¶</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">for file in ./*.caj; do</span><br><span class="line">    caj2pdf convert &quot;$file&quot; -o &quot;$&#123;file%.*&#125;.pdf&quot; &amp;&amp; rm &quot;$file&quot; &amp;</span><br><span class="line">done</span><br><span class="line">wait</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>CUDAç¼–ç¨‹æ€§èƒ½åˆ†æå·¥å…· nvprof/ncu --metricså‚æ•°å«ä¹‰</title>
      <link href="/p/68deaade/"/>
      <url>/p/68deaade/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>åœ¨ç½‘ä¸Šæ²¡æœ‰æ¯”è¾ƒå…¨çš„ä¸­æ–‡ ncu â€”metrics å‚æ•°å«ä¹‰ï¼Œäºæ˜¯è‡ªå·±æ•´ç†äº†ä¸€ä¸‹å®˜æ–¹å’Œå¤–å›½å‹äººçš„ç¬”è®°ã€‚</p><span id="more"></span><h2 id="nvprof-å’Œ-ncu"><a href="#nvprof-å’Œ-ncu" class="headerlink" title="nvprof å’Œ ncu"></a>nvprof å’Œ ncu</h2><p>nvprof æ˜¯è¿‡å»æ¯”è¾ƒå¸¸ç”¨çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œä½†åœ¨ç»ˆç«¯ç›´æ¥è¾“å…¥<code>nvprof ./*.o</code>ä¼šå¾—åˆ°ä»¥ä¸‹ Warning</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">======== Warning: nvprof is not supported on devices with compute capability 8.0 and higher.</span><br><span class="line">                  Use NVIDIA Nsight Systems for GPU tracing and CPU sampling and NVIDIA Nsight Compute for GPU profiling.</span><br><span class="line">                  Refer  for more details.</span><br></pre></td></tr></table></figure><p>ç›®å‰ä¸»æµçš„ CUDA é©±åŠ¨ä¸å†æ”¯æŒ<code>nvprof</code>å‘½ä»¤ï¼Œä½†æˆ‘ä»¬ä»å¯ä»¥åœ¨ NVIDIA Nsight Systems ä¸­ä½¿ç”¨ï¼Œåœ¨ç»ˆç«¯è¾“å…¥ <code>nsys nvprof ./*.o</code>å°±å¯ä»¥çœ‹åˆ°CUDA ç¨‹åºæ‰§è¡Œçš„å…·ä½“å†…å®¹ã€‚</p><p>å¦å¤–ï¼Œ<code>nvprof --metrics</code> å‘½ä»¤çš„åŠŸèƒ½è¢«è½¬æ¢åˆ°äº† <code>ncu --metrics</code> å‘½ä»¤ä¸­ï¼Œä¸‹é¢å°±å¯¹ <code>nvprof/ncu --metrics</code>å‘½ä»¤çš„å‚æ•°ä½œè¯¦ç»†è§£é‡Šï¼Œnsys å’Œ ncu å·¥å…·éƒ½æœ‰å¯è§†åŒ–ç‰ˆæœ¬ï¼Œè¿™é‡Œåªè®¨è®ºå‘½ä»¤è¡Œç‰ˆæœ¬ã€‚</p><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><ul><li><code>inst_per_warp</code>: æ¯ä¸ª warp æ‰§è¡Œçš„å¹³å‡æŒ‡ä»¤æ•°</li><li><code>branch_efficiency</code>: éå‘æ•£åˆ†æ”¯ä¸æ€»åˆ†æ”¯çš„æ¯”ç‡</li><li><code>warp_execution_efficiency</code>: æ¯ä¸ª warp çš„å¹³å‡æ´»åŠ¨çº¿ç¨‹æ•°ä¸ SM æ”¯æŒçš„æ¯ä¸ª warp çš„æœ€å¤§çº¿ç¨‹æ•°ä¹‹æ¯”</li><li><code>warp_nonpred_execution_efficiency</code>: æ‰§è¡Œéè°“è¯æŒ‡ä»¤çš„æ¯ä¸ª warp çš„å¹³å‡æ´»åŠ¨çº¿ç¨‹æ•°ä¸ SM æ”¯æŒçš„æ¯ä¸ª warp çš„æœ€å¤§çº¿ç¨‹æ•°ä¹‹æ¯”</li><li><code>inst_replay_overhead</code>: æ¯æ¡æŒ‡ä»¤æ‰§è¡Œçš„å¹³å‡é‡æ”¾æ¬¡æ•°</li><li><code>shared_load_transactions_per_request</code>: æ¯æ¬¡å…±äº«å†…å­˜åŠ è½½æ—¶æ‰§è¡Œçš„å¹³å‡å…±äº«å†…å­˜åŠ è½½äº‹åŠ¡æ•°</li><li><code>shared_store_transactions_per_request</code>: æ¯æ¬¡å…±äº«å†…å­˜åŠ è½½æ—¶æ‰§è¡Œçš„å¹³å‡å…±äº«å†…å­˜å†™å…¥äº‹åŠ¡æ•°</li><li><code>local_load_transactions_per_request</code>: æ¯æ¬¡æœ¬åœ°å†…å­˜åŠ è½½æ‰§è¡Œçš„æœ¬åœ°å†…å­˜åŠ è½½äº‹åŠ¡å¹³å‡æ•°</li><li><code>local_store_transactions_per_request</code>: ä¸ºæ¯ä¸ªæœ¬åœ°å†…å­˜å­˜å‚¨æ‰§è¡Œçš„æœ¬åœ°å†…å­˜å­˜å‚¨äº¤æ˜“çš„å¹³å‡æ•°é‡</li><li><code>gld_transactions_per_request</code>: ä¸ºæ¯ä¸ªå…¨å±€å†…å­˜åŠ è½½æ‰§è¡Œçš„å…¨å±€å†…å­˜åŠ è½½äº‹åŠ¡çš„å¹³å‡æ•°ã€‚</li><li><code>gst_transactions_per_request</code>: ä¸ºæ¯ä¸ªå…¨å±€å†…å­˜å­˜å‚¨æ‰§è¡Œçš„å¹³å‡å…¨å±€å†…å­˜å­˜å‚¨äº‹åŠ¡æ•°</li><li><code>shared_store_transactions</code>: å…±äº«å†…å­˜å­˜å‚¨äº‹åŠ¡æ•°</li><li><code>shared_load_transactions</code>: å…±äº«å†…å­˜åŠ è½½äº‹åŠ¡æ•°</li><li><code>local_load_transactions</code>: æœ¬åœ°å†…å­˜åŠ è½½äº‹åŠ¡æ•°</li><li><code>local_store_transactions</code>: æœ¬åœ°å†…å­˜å­˜å‚¨äº‹åŠ¡æ•°</li><li><code>gld_transactions</code>: å…¨å±€å†…å­˜åŠ è½½äº‹åŠ¡æ•°</li><li><code>gst_transactions</code>: å…¨å±€å†…å­˜å­˜å‚¨äº‹åŠ¡æ•°</li><li><code>sysmem_read_transactions</code>: ç³»ç»Ÿå†…å­˜è¯»å–äº‹åŠ¡æ•°</li><li><code>sysmem_write_transactions</code>: ç³»ç»Ÿå†…å­˜å†™å…¥äº‹åŠ¡æ•°</li><li><code>l2_read_transactions</code>: æ‰€æœ‰è¯»å–è¯·æ±‚åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„å†…å­˜è¯»å–äº‹åŠ¡</li><li><code>l2_write_transactions</code>: æ‰€æœ‰å†™å…¥è¯·æ±‚åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„å†…å­˜å†™å…¥äº‹åŠ¡</li><li><code>dram_read_transactions</code>: è®¾å¤‡å†…å­˜è¯»å–äº‹åŠ¡</li><li><code>dram_write_transactions</code>: è®¾å¤‡å†…å­˜å†™å…¥äº‹åŠ¡</li><li><code>global_hit_rate</code>: ç»Ÿä¸€ L1/tex ç¼“å­˜ä¸­å…¨å±€åŠ è½½çš„å‘½ä¸­ç‡</li><li><code>local_hit_rate</code>: æœ¬åœ°åŠ è½½å’Œå­˜å‚¨çš„å‘½ä¸­ç‡</li><li><code>gld_requested_throughput</code>: è¯·æ±‚çš„å…¨å±€å†…å­˜è´Ÿè½½ååé‡</li><li><code>gst_requested_throughput</code>: è¯·æ±‚çš„å…¨å±€å†…å­˜å­˜å‚¨ååé‡</li><li><code>gld_throughput</code>: å…¨å±€å†…å­˜è´Ÿè½½ååé‡</li><li><code>gst_throughput</code>: å…¨å±€å†…å­˜å­˜å‚¨ååé‡</li><li><code>local_memory_overhead</code>: æœ¬åœ°å†…å­˜æµé‡å  L1 å’Œ L2 ç¼“å­˜ä¹‹é—´æ€»å†…å­˜æµé‡ä¹‹æ¯”</li><li><code>tex_cache_hit_rate</code>: ç»Ÿä¸€ç¼“å­˜å‘½ä¸­ç‡</li><li><code>l2_tex_read_hit_rate</code>: æ¥è‡ªçº¹ç†ç¼“å­˜çš„æ‰€æœ‰è¯»å–è¯·æ±‚åœ¨ L2 ç¼“å­˜ä¸­çš„å‘½ä¸­ç‡</li><li><code>l2_tex_write_hit_rate</code>: æ¥è‡ªçº¹ç†ç¼“å­˜çš„æ‰€æœ‰å†™å…¥è¯·æ±‚åœ¨ L2 ç¼“å­˜ä¸­çš„å‘½ä¸­ç‡</li><li><code>dram_read_throughput</code>: è®¾å¤‡å†…å­˜è¯»å–ååé‡</li><li><code>dram_write_throughput</code>: è®¾å¤‡å†…å­˜å†™å…¥ååé‡</li><li><code>tex_cache_throughput</code>: ç»Ÿä¸€ç¼“å­˜ååé‡</li><li><code>l2_tex_read_throughput</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„æ¥è‡ªçº¹ç†ç¼“å­˜çš„å†…å­˜è¯»å–ååé‡</li><li><code>l2_tex_write_throughput</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„æ¥è‡ªçº¹ç†ç¼“å­˜çš„å†…å­˜å†™å…¥ååé‡</li><li><code>l2_read_throughput</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„æ‰€æœ‰å†…å­˜è¯»å–ååé‡</li><li><code>l2_write_throughput</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„æ‰€æœ‰å†…å­˜å†™å…¥ååé‡</li><li><code>sysmem_read_throughput</code>: ç³»ç»Ÿå†…å­˜è¯»å–ååé‡</li><li><code>sysmem_write_throughput</code>: ç³»ç»Ÿå†…å­˜å†™å…¥ååé‡</li><li><code>local_load_throughput</code>: æœ¬åœ°å†…å­˜åŠ è½½ååé‡</li><li><code>local_store_throughput</code>: æœ¬åœ°å†…å­˜å­˜å‚¨ååé‡</li><li><code>shared_load_throughput</code>: å…±äº«å†…å­˜è´Ÿè½½ååé‡</li><li><code>shared_store_throughput</code>: å…±äº«å†…å­˜å­˜å‚¨ååé‡</li><li><code>gld_efficiency</code>: è¯·æ±‚çš„å…¨å±€å†…å­˜è´Ÿè½½ååé‡ä¸æ‰€éœ€çš„å…¨å±€å†…å­˜è´Ÿè½½ååé‡çš„æ¯”ç‡</li><li><code>gst_efficiency</code>: è¯·æ±‚çš„å…¨å±€å†…å­˜å­˜å‚¨ååé‡ä¸æ‰€éœ€çš„å…¨å±€å†…å­˜å­˜å‚¨ååé‡çš„æ¯”ç‡</li><li><code>tex_cache_transactions</code>: ç»Ÿä¸€ç¼“å­˜è¯»å–äº‹åŠ¡</li><li><code>flop_count_dp</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„åŒç²¾åº¦æµ®ç‚¹è¿ç®—æ•°ï¼ˆåŠ æ³•ã€ä¹˜æ³•å’Œä¹˜æ³•ç´¯åŠ ï¼‰ã€‚æ¯ä¸ªä¹˜æ³•ç´¯åŠ è¿ç®—å¯¹è®¡æ•°è´¡çŒ® 2ã€‚</li><li><code>flop_count_dp_add</code>: éæ–­è¨€çº¿ç¨‹æ‰§è¡Œçš„åŒç²¾åº¦æµ®ç‚¹åŠ æ³•è¿ç®—æ¬¡æ•°</li><li><code>flop_count_dp_fma</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„åŒç²¾åº¦æµ®ç‚¹ä¹˜ç´¯åŠ è¿ç®—æ¬¡æ•°ï¼Œæ¯ä¸ªä¹˜æ³•ç´¯åŠ è¿ç®—ä½¿è®¡æ•°åŠ ä¸€</li><li><code>flop_count_dp_mul</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„åŒç²¾åº¦æµ®ç‚¹ä¹˜æ³•è¿ç®—æ¬¡æ•°</li><li><code>flop_count_sp</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„å•ç²¾åº¦æµ®ç‚¹è¿ç®—æ•°ï¼ˆåŠ æ³•ã€ä¹˜æ³•å’Œä¹˜æ³•ç´¯åŠ ï¼‰ï¼Œæ¯ä¸ªä¹˜æ³•ç´¯åŠ è¿ç®—ä½¿è®¡æ•°åŠ äºŒï¼ˆä¸åŒ…æ‹¬ç‰¹æ®Šæ“ä½œï¼‰</li><li><code>flop_count_sp_add</code>: éæ–­è¨€çº¿ç¨‹æ‰§è¡Œçš„å•ç²¾åº¦æµ®ç‚¹åŠ æ³•è¿ç®—æ¬¡æ•°</li><li><code>flop_count_sp_fma</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„å•ç²¾åº¦æµ®ç‚¹ä¹˜ç´¯åŠ è¿ç®—æ¬¡æ•°ã€‚æ¯ä¸ªä¹˜æ³•ç´¯åŠ è¿ç®—ä½¿è®¡æ•°åŠ ä¸€</li><li><code>flop_count_sp_mul</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„å•ç²¾åº¦æµ®ç‚¹ä¹˜æ³•è¿ç®—æ¬¡æ•°</li><li><code>flop_count_sp_special</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„å•ç²¾åº¦æµ®ç‚¹ç‰¹æ®Šæ“ä½œæ•°</li><li><code>inst_executed</code>: æ‰§è¡Œçš„æŒ‡ä»¤æ•°</li><li><code>inst_issued</code>: å‘å‡ºçš„æŒ‡ä»¤æ•°</li><li><p><code>dram_utilization</code>: è®¾å¤‡å†…å­˜åˆ©ç”¨ç‡ç›¸å¯¹äºç†è®ºå³°å€¼åˆ©ç”¨ç‡çš„çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0 åˆ° 10</p></li><li><p><code>sysmem_utilization</code>: ç³»ç»Ÿå†…å­˜åˆ©ç”¨ç‡ç›¸å¯¹äºç†è®ºå³°å€¼åˆ©ç”¨ç‡çš„çº§åˆ«</p></li><li><code>stall_inst_fetch</code>: ç”±äºå°šæœªè·å–ä¸‹ä¸€æ¡æ±‡ç¼–æŒ‡ä»¤è€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_exec_dependency</code>: ç”±äºæŒ‡ä»¤æ‰€éœ€çš„è¾“å…¥å°šä¸å¯ç”¨è€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_memory_dependency</code>: ç”±äºæ‰€éœ€èµ„æºä¸å¯ç”¨æˆ–æœªå®Œå…¨åˆ©ç”¨è€Œæ— æ³•æ‰§è¡Œå†…å­˜æ“ä½œï¼Œæˆ–è€…ç”±äºç»™å®šç±»å‹çš„å¤ªå¤šè¯·æ±‚æœªå®Œæˆè€Œå¯¼è‡´çš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_texture</code>: ç”±äºçº¹ç†å­ç³»ç»Ÿè¢«å……åˆ†åˆ©ç”¨æˆ–æœ‰å¤ªå¤šæœªå®Œæˆçš„è¯·æ±‚è€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_sync</code>: ç”±äº warp åœ¨ __syncthreads() è°ƒç”¨æ—¶è¢«é˜»å¡è€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_other</code>: ç”±äºå„ç§åŸå› å‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_constant_memory_dependency</code>: ç”±äºç«‹å³å¸¸é‡é«˜é€Ÿç¼“å­˜æœªå‘½ä¸­è€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_pipe_busy</code>: ç”±äºè®¡ç®—ç®¡é“ç¹å¿™è€Œæ— æ³•æ‰§è¡Œè®¡ç®—æ“ä½œè€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>shared_efficiency</code>: è¯·æ±‚çš„å…±äº«å†…å­˜ååé‡ä¸æ‰€éœ€å…±äº«å†…å­˜ååé‡çš„æ¯”ç‡</li><li><code>inst_fp_32</code>: éè°“è¯çº¿ç¨‹ï¼ˆç®—æœ¯ã€æ¯”è¾ƒç­‰ï¼‰æ‰§è¡Œçš„å•ç²¾åº¦æµ®ç‚¹æŒ‡ä»¤æ•°</li><li><code>inst_fp_64</code>: éè°“è¯çº¿ç¨‹ï¼ˆç®—æœ¯ã€æ¯”è¾ƒç­‰ï¼‰æ‰§è¡Œçš„åŒç²¾åº¦æµ®ç‚¹æŒ‡ä»¤æ•°</li><li><code>inst_integer</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„æ•´æ•°æŒ‡ä»¤æ•°</li><li><code>inst_bit_convert</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„ä½è½¬æ¢æŒ‡ä»¤æ•°</li><li><code>inst_control</code>: éè°“è¯çº¿ç¨‹ï¼ˆè·³è½¬ã€åˆ†æ”¯ç­‰ï¼‰æ‰§è¡Œçš„æ§åˆ¶æµæŒ‡ä»¤æ•°</li><li><code>inst_compute_ld_st</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„è®¡ç®—åŠ è½½/å­˜å‚¨æŒ‡ä»¤æ•°</li><li><code>inst_misc</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„æ‚é¡¹æŒ‡ä»¤æ•°</li><li><code>inst_inter_thread_communication</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„çº¿ç¨‹é—´é€šä¿¡æŒ‡ä»¤æ•°</li><li><code>issue_slots</code>: ä½¿ç”¨çš„é—®é¢˜æ§½æ•°</li><li><code>cf_issued</code>: å‘å‡ºçš„æ§åˆ¶æµæŒ‡ä»¤æ•°</li><li><code>cf_executed</code>: æ‰§è¡Œçš„æ§åˆ¶æµæŒ‡ä»¤æ•°</li><li><code>ldst_issued</code>: å‘å‡ºçš„æœ¬åœ°ã€å…¨å±€ã€å…±äº«å’Œçº¹ç†å†…å­˜åŠ è½½å’Œå­˜å‚¨æŒ‡ä»¤çš„æ•°é‡</li><li><code>ldst_executed</code>: æ‰§è¡Œçš„æœ¬åœ°ã€å…¨å±€ã€å…±äº«å’Œçº¹ç†å†…å­˜åŠ è½½å’Œå­˜å‚¨æŒ‡ä»¤çš„æ•°é‡</li><li><code>atomic_transactions</code>: å…¨å±€å†…å­˜åŸå­å’Œå‡å°‘äº‹åŠ¡</li><li><code>atomic_transactions_per_request</code>: ä¸ºæ¯ä¸ªåŸå­å’Œå½’çº¦æŒ‡ä»¤æ‰§è¡Œçš„å…¨å±€å†…å­˜åŸå­å’Œå½’çº¦äº‹åŠ¡çš„å¹³å‡æ•°é‡</li><li><code>l2_atomic_throughput</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„åŸå­å’Œå‡å°‘è¯·æ±‚çš„å†…å­˜è¯»å–ååé‡</li><li><code>l2_atomic_transactions</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„å†…å­˜è¯»å–äº‹åŠ¡ï¼Œç”¨äºåŸå­è¯·æ±‚å’Œç¼©å‡è¯·æ±‚</li><li><code>l2_tex_read_transactions</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„å†…å­˜è¯»å–äº‹åŠ¡ï¼Œç”¨äºæ¥è‡ªçº¹ç†ç¼“å­˜çš„è¯»å–è¯·æ±‚</li><li><code>stall_memory_throttle</code>: ç”±äºå†…å­˜èŠ‚æµè€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>stall_not_selected</code>: ç”±äºæœªé€‰æ‹© warp è€Œå‘ç”Ÿçš„åœé¡¿ç™¾åˆ†æ¯”</li><li><code>l2_tex_write_transactions</code>: åœ¨ L2 ç¼“å­˜ä¸­æ¥æ”¶åˆ°çš„å†…å­˜å†™å…¥äº‹åŠ¡ï¼Œç”¨äºæ¥è‡ªçº¹ç†ç¼“å­˜çš„å†™å…¥è¯·æ±‚</li><li><code>flop_count_hp</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„åŠç²¾åº¦æµ®ç‚¹è¿ç®—æ•°ï¼ˆåŠ æ³•ã€ä¹˜æ³•å’Œä¹˜æ³•ç´¯åŠ ï¼‰ï¼Œæ¯ä¸ªä¹˜æ³•ç´¯åŠ è¿ç®—ä½¿è®¡æ•°åŠ äºŒ</li><li><code>flop_count_hp_add</code>: éæ–­è¨€çº¿ç¨‹æ‰§è¡Œçš„åŠç²¾åº¦æµ®ç‚¹åŠ æ³•è¿ç®—çš„æ¬¡æ•°</li><li><code>flop_count_hp_mul</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„åŠç²¾åº¦æµ®ç‚¹ä¹˜æ³•è¿ç®—æ¬¡æ•°</li><li><code>flop_count_hp_fma</code>: éè°“è¯çº¿ç¨‹æ‰§è¡Œçš„åŠç²¾åº¦æµ®ç‚¹ä¹˜ç´¯åŠ è¿ç®—æ¬¡æ•°ã€‚æ¯ä¸ªä¹˜æ³•ç´¯åŠ è¿ç®—ä½¿è®¡æ•°åŠ ä¸€</li><li><code>inst_fp_16</code>: éè°“è¯çº¿ç¨‹ï¼ˆç®—æœ¯ã€æ¯”è¾ƒç­‰ï¼‰æ‰§è¡Œçš„åŠç²¾åº¦æµ®ç‚¹æŒ‡ä»¤æ•°</li><li><code>ipc</code>: æ¯ä¸ªå‘¨æœŸæ‰§è¡Œçš„æŒ‡ä»¤</li><li><code>issued_ipc</code>: æ¯ä¸ªå‘¨æœŸå‘å‡ºçš„æŒ‡ä»¤</li><li><code>issue_slot_utilization</code>: å‘å‡ºè‡³å°‘ä¸€æ¡æŒ‡ä»¤çš„å‘å¸ƒæ§½çš„ç™¾åˆ†æ¯”ï¼Œåœ¨æ‰€æœ‰å‘¨æœŸä¸­å–å¹³å‡å€¼</li><li><code>sm_efficiency</code>: è‡³å°‘ä¸€ä¸ª warp åœ¨ç‰¹å®š SM ä¸Šå¤„äºæ´»åŠ¨çŠ¶æ€çš„æ—¶é—´ç™¾åˆ†æ¯”</li><li><code>achieved_occupancy</code>: æ¯ä¸ªæ´»åŠ¨å‘¨æœŸçš„å¹³å‡æ´»åŠ¨ warp ä¸ SM æ”¯æŒçš„æœ€å¤§ warp æ•°ä¹‹æ¯”</li><li><code>eligible_warps_per_cycle</code>: æ¯ä¸ªæ´»åŠ¨å‘¨æœŸæœ‰èµ„æ ¼å‘å¸ƒçš„å¹³å‡ warp æ•°</li><li><code>shared_utilization</code>: å…±äº«å†…å­˜ç›¸å¯¹äºç†è®ºå³°å€¼åˆ©ç”¨ç‡çš„åˆ©ç”¨ç‡çº§åˆ«</li><li><p><code>l2_utilization</code>: L2 ç¼“å­˜åˆ©ç”¨ç‡ç›¸å¯¹äºç†è®ºå³°å€¼åˆ©ç”¨ç‡çš„çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0 åˆ° 10</p></li><li><p><code>tex_utilization</code>: ç»Ÿä¸€ç¼“å­˜åˆ©ç”¨ç‡ç›¸å¯¹äºç†è®ºå³°å€¼åˆ©ç”¨ç‡çš„çº§åˆ«</p></li><li><code>ldst_fu_utilization</code>: æ‰§è¡Œå…±äº«åŠ è½½ã€å…±äº«å­˜å‚¨å’Œæ’å®šåŠ è½½æŒ‡ä»¤çš„ SM çš„åˆ©ç”¨ç‡çº§åˆ«</li><li><p><code>cf_fu_utilization</code>: æ‰§è¡Œæ§åˆ¶æµæŒ‡ä»¤çš„ SM çš„åˆ©ç”¨ç‡çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0 åˆ° 10</p></li><li><p><code>tex_fu_utilization</code>: æ‰§è¡Œå…¨å±€ã€å±€éƒ¨å’Œçº¹ç†å†…å­˜æŒ‡ä»¤çš„ SM çš„åˆ©ç”¨ç‡çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0 åˆ° 10</p></li><li><p><code>special_fu_utilization</code>: æ‰§è¡Œ sinã€cosã€ex2ã€popcã€flo å’Œç±»ä¼¼æŒ‡ä»¤çš„ SM çš„åˆ©ç”¨ç‡çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0 åˆ° 10</p></li><li><p><code>half_precision_fu_utilization</code>: æ‰§è¡Œ 16 ä½æµ®ç‚¹æŒ‡ä»¤å’Œæ•´æ•°æŒ‡ä»¤çš„ SM çš„åˆ©ç”¨ç‡çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0åˆ°10</p></li><li><p><code>single_precision_fu_utilization</code>: æ‰§è¡Œå•ç²¾åº¦æµ®ç‚¹æŒ‡ä»¤å’Œæ•´æ•°æŒ‡ä»¤çš„ SM çš„åˆ©ç”¨ç‡çº§åˆ«</p></li><li><code>double_precision_fu_utilization</code>: æ‰§è¡ŒåŒç²¾åº¦æµ®ç‚¹æŒ‡ä»¤çš„ SM çš„åˆ©ç”¨ç‡çº§åˆ«</li><li><code>flop_hp_efficiency</code>: å®ç°çš„åŠç²¾åº¦æµ®ç‚¹è¿ç®—ä¸ç†è®ºå³°å€¼çš„æ¯”å€¼</li><li><code>flop_sp_efficiency</code>: å®ç°çš„å•ç²¾åº¦æµ®ç‚¹è¿ç®—ä¸ç†è®ºå³°å€¼çš„æ¯”å€¼</li><li><code>flop_dp_efficiency</code>: å®ç°çš„åŒç²¾åº¦æµ®ç‚¹è¿ç®—ä¸ç†è®ºå³°å€¼çš„æ¯”å€¼</li><li><p><code>sysmem_read_utilization</code>: ç³»ç»Ÿå†…å­˜çš„è¯»å–åˆ©ç”¨ç‡ç›¸å¯¹äºç†è®ºå³°å€¼åˆ©ç”¨ç‡çš„çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0 åˆ° 10</p></li><li><p><code>sysmem_write_utilization</code>: ç³»ç»Ÿå†…å­˜çš„å†™å…¥åˆ©ç”¨ç‡ç›¸å¯¹äºç†è®ºå³°å€¼åˆ©ç”¨ç‡çš„çº§åˆ«ï¼ŒèŒƒå›´ä¸º 0 åˆ° 10</p></li></ul><h2 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h2><div class="table-container"><table><thead><tr><th>nvprof â€”metrics</th><th>ncu â€”metrics (&gt;= SM 7.0)</th></tr></thead><tbody><tr><td><code>achieved_occupancy</code></td><td><code>sm__warps_active.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>atomic_transactions</code></td><td><code>l1tex__t_set_accesses_pipe_lsu_mem_global_op_atom.sum + l1tex__t_set_accesses_pipe_lsu_mem_global_op_red.sum</code></td></tr><tr><td><code>atomic_transactions_per_request</code></td><td><code>(l1tex__t_sectors_pipe_lsu_mem_global_op_atom.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_red.sum) / (l1tex__t_requests_pipe_lsu_mem_global_op_atom.sum + l1tex__t_requests_pipe_lsu_mem_global_op_red.sum)</code></td></tr><tr><td><code>branch_efficiency</code></td><td><code>smsp__sass_average_branch_targets_threads_uniform.pct</code></td></tr><tr><td><code>cf_executed</code></td><td><code>smsp__inst_executed_pipe_cbu.sum + smsp__inst_executed_pipe_adu.sum</code></td></tr><tr><td><code>cf_fu_utilization</code></td><td><code>n/a</code></td></tr><tr><td><code>cf_issued</code></td><td><code>n/a</code></td></tr><tr><td><code>double_precision_fu_utilization</code></td><td><code>smsp__inst_executed_pipe_fp64.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>dram_read_bytes</code></td><td><code>dram__bytes_read.sum</code></td></tr><tr><td><code>dram_read_throughput</code></td><td><code>dram__bytes_read.sum.per_second</code></td></tr><tr><td><code>dram_read_transactions</code></td><td><code>dram__sectors_read.sum</code></td></tr><tr><td><code>dram_utilization</code></td><td><code>dram__throughput.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>dram_write_bytes</code></td><td><code>dram__bytes_write.sum</code></td></tr><tr><td><code>dram_write_throughput</code></td><td><code>dram__bytes_write.sum.per_second</code></td></tr><tr><td><code>dram_write_transactions</code></td><td><code>dram__sectors_write.sum</code></td></tr><tr><td><code>eligible_warps_per_cycle</code></td><td><code>smsp__warps_eligible.sum.per_cycle_active</code></td></tr><tr><td><code>flop_count_dp</code></td><td><code>smsp__sass_thread_inst_executed_op_dadd_pred_on.sum + smsp__sass_thread_inst_executed_op_dmul_pred_on.sum + smsp__sass_thread_inst_executed_op_dfma_pred_on.sum * 2</code></td></tr><tr><td><code>flop_count_dp_add</code></td><td><code>smsp__sass_thread_inst_executed_op_dadd_pred_on.sum</code></td></tr><tr><td><code>flop_count_dp_fma</code></td><td><code>smsp__sass_thread_inst_executed_op_dfma_pred_on.sum</code></td></tr><tr><td><code>flop_count_dp_mul</code></td><td><code>smsp__sass_thread_inst_executed_op_dmul_pred_on.sum</code></td></tr><tr><td><code>flop_count_hp</code></td><td><code>smsp__sass_thread_inst_executed_op_hadd_pred_on.sum + smsp__sass_thread_inst_executed_op_hmul_pred_on.sum + smsp__sass_thread_inst_executed_op_hfma_pred_on.sum * 2</code></td></tr><tr><td><code>flop_count_hp_add</code></td><td><code>smsp__sass_thread_inst_executed_op_hadd_pred_on.sum</code></td></tr><tr><td><code>flop_count_hp_fma</code></td><td><code>smsp__sass_thread_inst_executed_op_hfma_pred_on.sum</code></td></tr><tr><td><code>flop_count_hp_mul</code></td><td><code>smsp__sass_thread_inst_executed_op_hmul_pred_on.sum</code></td></tr><tr><td><code>flop_count_sp</code></td><td><code>smsp__sass_thread_inst_executed_op_fadd_pred_on.sum + smsp__sass_thread_inst_executed_op_fmul_pred_on.sum + smsp__sass_thread_inst_executed_op_ffma_pred_on.sum * 2</code></td></tr><tr><td><code>flop_count_sp_add</code></td><td><code>smsp__sass_thread_inst_executed_op_fadd_pred_on.sum</code></td></tr><tr><td><code>flop_count_sp_fma</code></td><td><code>smsp__sass_thread_inst_executed_op_ffma_pred_on.sum</code></td></tr><tr><td><code>flop_count_sp_mul</code></td><td><code>smsp__sass_thread_inst_executed_op_fmul_pred_on.sum</code></td></tr><tr><td><code>flop_count_sp_special</code></td><td><code>n/a</code></td></tr><tr><td><code>flop_dp_efficiency</code></td><td><code>smsp__sass_thread_inst_executed_ops_dadd_dmul_dfma_pred_on.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>flop_hp_efficiency</code></td><td><code>smsp__sass_thread_inst_executed_ops_hadd_hmul_hfma_pred_on.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>flop_sp_efficiency</code></td><td><code>smsp__sass_thread_inst_executed_ops_fadd_fmul_ffma_pred_on.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>gld_efficiency</code></td><td><code>smsp__sass_average_data_bytes_per_sector_mem_global_op_ld.pct</code></td></tr><tr><td><code>gld_requested_throughput</code></td><td><code>n/a</code></td></tr><tr><td><code>gld_throughput</code></td><td><code>l1tex__t_bytes_pipe_lsu_mem_global_op_ld.sum.per_second</code></td></tr><tr><td><code>gld_transactions</code></td><td><code>l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum</code></td></tr><tr><td><code>gld_transactions_per_request</code></td><td><code>l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_ld.ratio</code></td></tr><tr><td><code>global_atomic_requests</code></td><td><code>l1tex__t_requests_pipe_lsu_mem_global_op_atom.sum</code></td></tr><tr><td><code>global_hit_rate</code></td><td><code>(l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_hit.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_hit.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_red_lookup_hit.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_atom_lookup_hit.sum) / (l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_red.sum + l1tex__t_sectors_pipe_lsu_mem_global_op_atom.sum)</code></td></tr><tr><td><code>global_load_requests</code></td><td><code>l1tex__t_requests_pipe_lsu_mem_global_op_ld.sum</code></td></tr><tr><td><code>global_reduction_requests</code></td><td><code>l1tex__t_requests_pipe_lsu_mem_global_op_red.sum</code></td></tr><tr><td><code>global_store_requests</code></td><td><code>l1tex__t_requests_pipe_lsu_mem_global_op_st.sum</code></td></tr><tr><td><code>gst_efficiency</code></td><td><code>smsp__sass_average_data_bytes_per_sector_mem_global_op_st.pct</code></td></tr><tr><td><code>gst_requested_throughput</code></td><td><code>n/a</code></td></tr><tr><td><code>gst_throughput</code></td><td><code>l1tex__t_bytes_pipe_lsu_mem_global_op_st.sum.per_second</code></td></tr><tr><td><code>gst_transactions</code></td><td><code>l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum</code></td></tr><tr><td><code>gst_transactions_per_request</code></td><td><code>l1tex__average_t_sectors_per_request_pipe_lsu_mem_global_op_st.ratio</code></td></tr><tr><td><code>half_precision_fu_utilization</code></td><td><code>smsp__inst_executed_pipe_fp16.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>inst_bit_convert</code></td><td><code>smsp__sass_thread_inst_executed_op_conversion_pred_on.sum</code></td></tr><tr><td><code>inst_compute_ld_st</code></td><td><code>smsp__sass_thread_inst_executed_op_memory_pred_on.sum</code></td></tr><tr><td><code>inst_control</code></td><td><code>smsp__sass_thread_inst_executed_op_control_pred_on.sum</code></td></tr><tr><td><code>inst_executed</code></td><td><code>smsp__inst_executed.sum</code></td></tr><tr><td><code>inst_executed_global_atomics</code></td><td><code>smsp__sass_inst_executed_op_global_atom.sum</code></td></tr><tr><td><code>inst_executed_global_loads</code></td><td><code>smsp__inst_executed_op_global_ld.sum</code></td></tr><tr><td><code>inst_executed_global_reductions</code></td><td><code>smsp__inst_executed_op_global_red.sum</code></td></tr><tr><td><code>inst_executed_global_stores</code></td><td><code>smsp__inst_executed_op_global_st.sum</code></td></tr><tr><td><code>inst_executed_local_loads</code></td><td><code>smsp__inst_executed_op_local_ld.sum</code></td></tr><tr><td><code>inst_executed_local_stores</code></td><td><code>smsp__inst_executed_op_local_st.sum</code></td></tr><tr><td><code>inst_executed_shared_atomics</code></td><td><code>smsp__inst_executed_op_shared_atom.sum + smsp__inst_executed_op_shared_atom_dot_alu.sum + smsp__inst_executed_op_shared_atom_dot_cas.sum</code></td></tr><tr><td><code>inst_executed_shared_loads</code></td><td><code>smsp__inst_executed_op_shared_ld.sum</code></td></tr><tr><td><code>inst_executed_shared_stores</code></td><td><code>smsp__inst_executed_op_shared_st.sum</code></td></tr><tr><td><code>inst_executed_surface_atomics</code></td><td><code>smsp__inst_executed_op_surface_atom.sum</code></td></tr><tr><td><code>inst_executed_surface_loads</code></td><td><code>smsp__inst_executed_op_surface_ld.sum + smsp__inst_executed_op_shared_atom_dot_alu.sum + smsp__inst_executed_op_shared_atom_dot_cas.sum</code></td></tr><tr><td><code>inst_executed_surface_reductions</code></td><td><code>smsp__inst_executed_op_surface_red.sum</code></td></tr><tr><td><code>inst_executed_surface_stores</code></td><td><code>smsp__inst_executed_op_surface_st.sum</code></td></tr><tr><td><code>inst_executed_tex_ops</code></td><td><code>smsp__inst_executed_op_texture.sum</code></td></tr><tr><td><code>inst_fp_16</code></td><td><code>smsp__sass_thread_inst_executed_op_fp16_pred_on.sum</code></td></tr><tr><td><code>inst_fp_32</code></td><td><code>smsp__sass_thread_inst_executed_op_fp32_pred_on.sum</code></td></tr><tr><td><code>inst_fp_64</code></td><td><code>smsp__sass_thread_inst_executed_op_fp64_pred_on.sum</code></td></tr><tr><td><code>inst_integer</code></td><td><code>smsp__sass_thread_inst_executed_op_integer_pred_on.sum</code></td></tr><tr><td><code>inst_inter_thread_communication</code></td><td><code>smsp__sass_thread_inst_executed_op_inter_thread_communication_pred_on.sum</code></td></tr><tr><td><code>inst_issued</code></td><td><code>smsp__inst_issued.sum</code></td></tr><tr><td><code>inst_misc</code></td><td><code>smsp__sass_thread_inst_executed_op_misc_pred_on.sum</code></td></tr><tr><td><code>inst_per_warp</code></td><td><code>smsp__average_inst_executed_per_warp.ratio</code></td></tr><tr><td><code>inst_replay_overhead</code></td><td><code>n/a</code></td></tr><tr><td><code>ipc</code></td><td><code>smsp__inst_executed.avg.per_cycle_active</code></td></tr><tr><td><code>issue_slot_utilization</code></td><td><code>smsp__issue_active.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>issue_slots</code></td><td><code>smsp__inst_issued.sum</code></td></tr><tr><td><code>issued_ipc</code></td><td><code>smsp__inst_issued.avg.per_cycle_active</code></td></tr><tr><td><code>l1_sm_lg_utilization</code></td><td><code>l1tex__lsu_writeback_active.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>l2_atomic_throughput</code></td><td><code>2 * ( lts__t_sectors_op_atom.sum.per_second + lts__t_sectors_op_red.sum.per_second )</code></td></tr><tr><td><code>l2_atomic_transactions</code></td><td><code>2 * ( lts__t_sectors_op_atom.sum + lts__t_sectors_op_red.sum )</code></td></tr><tr><td><code>l2_global_atomic_store_bytes</code></td><td><code>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_global_op_atom.sum</code></td></tr><tr><td><code>l2_global_load_bytes</code></td><td><code>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_global_op_ld.sum</code></td></tr><tr><td><code>l2_local_global_store_bytes</code></td><td><code>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_local_op_st.sum + lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_global_op_st.sum</code></td></tr><tr><td><code>l2_local_load_bytes</code></td><td><code>lts__t_bytes_equiv_l1sectormiss_pipe_lsu_mem_local_op_ld.sum</code></td></tr><tr><td><code>l2_read_throughput</code></td><td><code>lts__t_sectors_op_read.sum.per_second + lts__t_sectors_op_atom.sum.per_second + lts__t_sectors_op_red.sum.per_second</code></td></tr><tr><td><code>l2_read_transactions</code></td><td><code>lts__t_sectors_op_read.sum + lts__t_sectors_op_atom.sum + lts__t_sectors_op_red.sum</code></td></tr><tr><td><code>l2_surface_load_bytes</code></td><td><code>lts__t_bytes_equiv_l1sectormiss_pipe_tex_mem_surface_op_ld.sum</code></td></tr><tr><td><code>l2_surface_store_bytes</code></td><td><code>lts__t_bytes_equiv_l1sectormiss_pipe_tex_mem_surface_op_st.sum</code></td></tr><tr><td><code>l2_tex_hit_rate</code></td><td><code>lts__t_sector_hit_rate.pct</code></td></tr><tr><td><code>l2_tex_read_hit_rate</code></td><td><code>lts__t_sector_op_read_hit_rate.pct</code></td></tr><tr><td><code>l2_tex_read_throughput</code></td><td><code>lts__t_sectors_srcunit_tex_op_read.sum.per_second</code></td></tr><tr><td><code>l2_tex_read_transactions</code></td><td><code>lts__t_sectors_srcunit_tex_op_read.sum</code></td></tr><tr><td><code>l2_tex_write_hit_rate</code></td><td><code>lts__t_sector_op_write_hit_rate.pct</code></td></tr><tr><td><code>l2_tex_write_throughput</code></td><td><code>lts__t_sectors_srcunit_tex_op_write.sum.per_second</code></td></tr><tr><td><code>l2_tex_write_transactions</code></td><td><code>lts__t_sectors_srcunit_tex_op_write.sum</code></td></tr><tr><td><code>l2_utilization</code></td><td><code>lts__t_sectors.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>l2_write_throughput</code></td><td><code>lts__t_sectors_op_write.sum.per_second + lts__t_sectors_op_atom.sum.per_second + lts__t_sectors_op_red.sum.per_second</code></td></tr><tr><td><code>l2_write_transactions</code></td><td><code>lts__t_sectors_op_write.sum + lts__t_sectors_op_atom.sum + lts__t_sectors_op_red.sum</code></td></tr><tr><td><code>ldst_executed</code></td><td><code>n/a</code></td></tr><tr><td><code>ldst_fu_utilization</code></td><td><code>smsp__inst_executed_pipe_lsu.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>ldst_issued</code></td><td><code>n/a</code></td></tr><tr><td><code>local_hit_rate</code></td><td><code>n/a</code></td></tr><tr><td><code>local_load_requests</code></td><td><code>l1tex__t_requests_pipe_lsu_mem_local_op_ld.sum</code></td></tr><tr><td><code>local_load_throughput</code></td><td><code>l1tex__t_bytes_pipe_lsu_mem_local_op_ld.sum.per_second</code></td></tr><tr><td><code>local_load_transactions</code></td><td><code>l1tex__t_sectors_pipe_lsu_mem_local_op_ld.sum</code></td></tr><tr><td><code>local_load_transactions_per_request</code></td><td><code>l1tex__average_t_sectors_per_request_pipe_lsu_mem_local_op_ld.ratio</code></td></tr><tr><td><code>local_memory_overhead</code></td><td><code>n/a</code></td></tr><tr><td><code>local_store_requests</code></td><td><code>l1tex__t_requests_pipe_lsu_mem_local_op_st.sum</code></td></tr><tr><td><code>local_store_throughput</code></td><td><code>l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum.per_second</code></td></tr><tr><td><code>local_store_transactions</code></td><td><code>l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum</code></td></tr><tr><td><code>local_store_transactions_per_request</code></td><td><code>l1tex__average_t_sectors_per_request_pipe_lsu_mem_local_op_st.ratio</code></td></tr><tr><td><code>nvlink_data_receive_efficiency</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_data_transmission_efficiency</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_overhead_data_received</code></td><td><code>(nvlrx__bytes_data_protocol.sum / nvlrx__bytes.sum) * 100</code></td></tr><tr><td><code>nvlink_overhead_data_transmitted</code></td><td><code>(nvltx__bytes_data_protocol.sum / nvltx__bytes.sum) * 100</code></td></tr><tr><td><code>nvlink_receive_throughput</code></td><td><code>nvlrx__bytes.sum.per_second</code></td></tr><tr><td><code>nvlink_total_data_received</code></td><td><code>nvlrx__bytes.sum</code></td></tr><tr><td><code>nvlink_total_data_transmitted</code></td><td><code>nvltx__bytes.sum</code></td></tr><tr><td><code>nvlink_total_nratom_data_transmitted</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_total_ratom_data_transmitted</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_total_response_data_received</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_total_write_data_transmitted</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_transmit_throughput</code></td><td><code>nvltx__bytes.sum.per_second</code></td></tr><tr><td><code>nvlink_user_data_received</code></td><td><code>nvlrx__bytes_data_user.sum</code></td></tr><tr><td><code>nvlink_user_data_transmitted</code></td><td><code>nvltx__bytes_data_user.sum</code></td></tr><tr><td><code>nvlink_user_nratom_data_transmitted</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_user_ratom_data_transmitted</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_user_response_data_received</code></td><td><code>n/a</code></td></tr><tr><td><code>nvlink_user_write_data_transmitted</code></td><td><code>n/a</code></td></tr><tr><td><code>pcie_total_data_received</code></td><td><code>pcie__read_bytes.sum</code></td></tr><tr><td><code>pcie_total_data_transmitted</code></td><td><code>pcie__write_bytes.sum</code></td></tr><tr><td><code>shared_efficiency</code></td><td><code>smsp__sass_average_data_bytes_per_wavefront_mem_shared.pct</code></td></tr><tr><td><code>shared_load_throughput</code></td><td><code>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum.per_second</code></td></tr><tr><td><code>shared_load_transactions</code></td><td><code>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum</code></td></tr><tr><td><code>shared_load_transactions_per_request</code></td><td><code>n/a</code></td></tr><tr><td><code>shared_store_throughput</code></td><td><code>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum.per_second</code></td></tr><tr><td><code>shared_store_transactions</code></td><td><code>l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum</code></td></tr><tr><td><code>shared_store_transactions_per_request</code></td><td><code>n/a</code></td></tr><tr><td><code>shared_utilization</code></td><td><code>l1tex__data_pipe_lsu_wavefronts_mem_shared.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>single_precision_fu_utilization</code></td><td><code>smsp__pipe_fma_cycles_active.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>sm_efficiency</code></td><td><code>smsp__cycles_active.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>sm_tex_utilization</code></td><td><code>l1tex__texin_sm2tex_req_cycles_active.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>special_fu_utilization</code></td><td><code>smsp__inst_executed_pipe_xu.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>stall_constant_memory_dependency</code></td><td><code>smsp__warp_issue_stalled_imc_miss_per_warp_active.pct</code></td></tr><tr><td><code>stall_exec_dependency</code></td><td><code>smsp__warp_issue_stalled_short_scoreboard_per_warp_active.pct + smsp__warp_issue_stalled_wait_per_warp_active.pct</code></td></tr><tr><td><code>stall_inst_fetch</code></td><td><code>smsp__warp_issue_stalled_no_instruction_per_warp_active.pct</code></td></tr><tr><td><code>stall_memory_dependency</code></td><td><code>smsp__warp_issue_stalled_long_scoreboard_per_warp_active.pct</code></td></tr><tr><td><code>stall_memory_throttle</code></td><td><code>smsp__warp_issue_stalled_drain_per_warp_active.pct + smsp__warp_issue_stalled_lg_throttle_per_warp_active.pct</code></td></tr><tr><td><code>stall_not_selected</code></td><td><code>smsp__warp_issue_stalled_not_selected_per_warp_active.pct</code></td></tr><tr><td><code>stall_other</code></td><td><code>smsp__warp_issue_stalled_dispatch_stall_per_warp_active.pct + smsp__warp_issue_stalled_misc_per_warp_active.pct</code></td></tr><tr><td><code>stall_pipe_busy</code></td><td><code>smsp__warp_issue_stalled_math_pipe_throttle_per_warp_active.pct + smsp__warp_issue_stalled_mio_throttle_per_warp_active.pct</code></td></tr><tr><td><code>stall_sleeping</code></td><td><code>smsp__warp_issue_stalled_sleeping_per_warp_active.pct</code></td></tr><tr><td><code>stall_sync</code></td><td><code>smsp__warp_issue_stalled_barrier_per_warp_active.pct + smsp__warp_issue_stalled_membar_per_warp_active.pct</code></td></tr><tr><td><code>stall_texture</code></td><td><code>smsp__warp_issue_stalled_tex_throttle_per_warp_active.pct</code></td></tr><tr><td><code>surface_atomic_requests</code></td><td><code>l1tex__t_requests_pipe_tex_mem_surface_op_atom.sum</code></td></tr><tr><td><code>surface_load_requests</code></td><td><code>l1tex__t_requests_pipe_tex_mem_surface_op_ld.sum</code></td></tr><tr><td><code>surface_reduction_requests</code></td><td><code>l1tex__t_requests_pipe_tex_mem_surface_op_red.sum</code></td></tr><tr><td><code>surface_store_requests</code></td><td><code>l1tex__t_requests_pipe_tex_mem_surface_op_st.sum</code></td></tr><tr><td><code>sysmem_read_bytes</code></td><td><code>lts__t_sectors_aperture_sysmem_op_read * 32</code></td></tr><tr><td><code>sysmem_read_throughput</code></td><td><code>lts__t_sectors_aperture_sysmem_op_read.sum.per_second</code></td></tr><tr><td><code>sysmem_read_transactions</code></td><td><code>lts__t_sectors_aperture_sysmem_op_read.sum</code></td></tr><tr><td><code>sysmem_read_utilization</code></td><td><code>n/a</code></td></tr><tr><td><code>sysmem_utilization</code></td><td><code>n/a</code></td></tr><tr><td><code>sysmem_write_bytes</code></td><td><code>lts__t_sectors_aperture_sysmem_op_write * 32</code></td></tr><tr><td><code>sysmem_write_throughput</code></td><td><code>lts__t_sectors_aperture_sysmem_op_write.sum.per_second</code></td></tr><tr><td><code>sysmem_write_transactions</code></td><td><code>lts__t_sectors_aperture_sysmem_op_write.sum</code></td></tr><tr><td><code>sysmem_write_utilization</code></td><td><code>n/a</code></td></tr><tr><td><code>tensor_precision_fu_utilization</code></td><td><code>sm__pipe_tensor_op_hmma_cycles_active.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>tensor_precision_int_utilization</code></td><td><code>sm__pipe_tensor_op_imma_cycles_active.avg.pct_of_peak_sustained_active (SM 7.2+)</code></td></tr><tr><td><code>tex_cache_hit_rate</code></td><td><code>l1tex__t_sector_hit_rate.pct</code></td></tr><tr><td><code>tex_cache_throughput</code></td><td><code>n/a</code></td></tr><tr><td><code>tex_cache_transactions</code></td><td><code>l1tex__lsu_writeback_active.avg.pct_of_peak_sustained_active + l1tex__tex_writeback_active.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>tex_fu_utilization</code></td><td><code>smsp__inst_executed_pipe_tex.avg.pct_of_peak_sustained_active</code></td></tr><tr><td><code>tex_sm_tex_utilization</code></td><td><code>l1tex__f_tex2sm_cycles_active.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>tex_sm_utilization</code></td><td><code>sm__mio2rf_writeback_active.avg.pct_of_peak_sustained_elapsed</code></td></tr><tr><td><code>tex_utilization</code></td><td><code>n/a</code></td></tr><tr><td><code>texture_load_requests</code></td><td><code>l1tex__t_requests_pipe_tex_mem_texture.sum</code></td></tr><tr><td><code>warp_execution_efficiency</code></td><td><code>smsp__thread_inst_executed_per_inst_executed.ratio</code></td></tr><tr><td><code>warp_nonpred_execution_efficiency</code></td><td><code>smsp__thread_inst_executed_per_inst_executed.pct</code></td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> CUDA ç¼–ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å·¥å…· </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CT-WindowingåŒ»å­¦CTå›¾åƒå¢å¼º</title>
      <link href="/p/b1e8187e/"/>
      <url>/p/b1e8187e/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>CT winding æ˜¯CTæ‰«æçš„ä¸€é¡¹å›¾åƒå¤„ç†ä»»åŠ¡ï¼Œå®ƒæœ‰åŠ©äºçªå‡ºå…³é”®çš„ç»„ç»‡ç»“æ„ï¼Œé€šè¿‡ä¿®æ”¹ HU (Hounsfield Units) å‚æ•°ï¼Œä½¿å›¾åƒæ›´æ˜“äºåˆ†æã€‚</p><span id="more"></span><p><img src="/image/CT-WindowingåŒ»å­¦CTå›¾åƒå¢å¼º/0.webp" style="zoom:50%;" /></p><h2 id="Hounsfield-Unit-HU"><a href="#Hounsfield-Unit-HU" class="headerlink" title="Hounsfield Unit (HU)"></a>Hounsfield Unit (HU)</h2><p>äº¨æ°é‡è¡¨ï¼ˆHounsfield scaleï¼‰é˜»å°„ç‡çš„æ•°é‡å°ºåº¦å•ä½ï¼Œå‘½åè‡ªXå°„çº¿ç”µè„‘æ–­å±‚æ‰«æçš„å‘æ˜äººé«˜å¼—é›·Â·è±ªæ–¯è´¹å°”å¾·ï¼ˆGodfrey Newbold Hounsfieldï¼‰ã€‚äº¨æ°å•ä½å¸¸ç”¨äºXå°„çº¿ç”µè„‘æ–­å±‚æ‰«æï¼Œå› æ­¤åˆç§°ä¸ºCTå€¼ï¼ˆCT numberï¼‰ã€‚</p><p>HU å€¼ä¸ç»„ç»‡çš„ç»„æˆå’Œæ€§è´¨æœ‰å…³ï¼Œå› æ­¤ä»£è¡¨å„ç§ç»„ç»‡çš„å¯†åº¦ï¼ŒHU å€¼è¶Šé«˜ï¼Œææ–™è¶Šè‡´å¯†ï¼Œåä¹‹äº¦ç„¶ã€‚</p><p>ä»¥ä¸‹ä¸ºå„ç»„ç»‡åœ¨ HU é‡è¡¨ä¸Šçš„ä¸€äº›å€¼</p><p><img src="/image/CT-WindowingåŒ»å­¦CTå›¾åƒå¢å¼º/1.webp" style="zoom:80%;" /></p><h2 id="Window-Width-amp-Window-Level"><a href="#Window-Width-amp-Window-Level" class="headerlink" title="Window Width &amp; Window Level"></a>Window Width &amp; Window Level</h2><h3 id="Window-Width-WW"><a href="#Window-Width-WW" class="headerlink" title="Window Width (WW)"></a>Window Width (WW)</h3><p>æ˜¯ CT å›¾åƒåŒ…å«çš„ HU å€¼èŒƒå›´çš„åº¦é‡ï¼Œä»»ä½•ä½äº WW ä¸‹é™å€¼çš„ HU å€¼å°†åœ¨æ‰«æä¸­æ˜¾ç¤ºä¸ºé»‘è‰²ï¼Œè€Œé«˜äº WW ä¸Šé™å€¼çš„ HU å€¼å°†æ˜¾ç¤ºä¸ºç™½è‰²ã€‚</p><p>éšç€ WW çš„å¢åŠ ï¼Œå°†éœ€è¦æ›´å¤§çš„å¯†åº¦å˜åŒ–æ¥æ”¹å˜ä»£è¡¨æŸä¸ª HU å•ä½çš„ç°è‰²é˜´å½±ã€‚è¿™ä¼šå¯¼è‡´å¯¹æ¯”åº¦æŸå¤±ï¼Œå› ä¸ºéšç€ HU å€¼çš„å¢åŠ ï¼Œæ›´å¤šçš„ç»“æ„å°†çœ‹èµ·æ¥ç›¸ä¼¼ï¼ˆå°½ç®¡å…·æœ‰ä¸åŒçš„å¯†åº¦ï¼‰ã€‚</p><p>éšç€ WW çš„å‡å°ï¼Œè¾ƒå°çš„å¯†åº¦å˜åŒ–å°†å¯¼è‡´ CT å›¾åƒä¸Šçš„é¢œè‰²å‘ç”Ÿå˜åŒ–ï¼Œå¯¼è‡´å¯†åº¦æ¥è¿‘çš„ç»“æ„å°†åˆ†é…ç»™ä¸åŒçš„ç°åº¦ï¼Œè¿™å°†å¢åŠ å¯¹æ¯”åº¦ã€‚</p><p><img src="/image/CT-WindowingåŒ»å­¦CTå›¾åƒå¢å¼º/3.webp" style="zoom: 67%;" /></p><h3 id="Window-Level-WL"><a href="#Window-Level-WL" class="headerlink" title="Window Level (WL)"></a>Window Level (WL)</h3><p>è¡¨ç¤ºçª—å£ä¸­å¿ƒæˆ–ä¸­ç‚¹çš„ HU å€¼ï¼Œä¸ºå›¾åƒè®¾ç½®çš„ WL è¶Šä½ï¼Œæ•´ä¸ªå›¾åƒå°†å˜å¾—è¶Šäº®ã€‚</p><p>éšç€ WL çš„é™ä½ï¼Œè¾ƒä½çš„ HU å€¼å°±èƒ½å°†ç»„ç»‡è¡¨ç¤ºä¸ºç™½è‰²ï¼Œè¿™å°†å…è®¸æ›´å¤šçš„ç™½è‰²é€šè¿‡ï¼Œä»è€Œä½¿å›¾åƒæ›´äº®ã€‚å› æ­¤ï¼ŒWL å½±å“å›¾åƒçš„äº®åº¦ã€‚</p><p><img src="/image/CT-WindowingåŒ»å­¦CTå›¾åƒå¢å¼º/4.webp" style="zoom:67%;" /></p><h3 id="WW-amp-WL-è®¡ç®—"><a href="#WW-amp-WL-è®¡ç®—" class="headerlink" title="WW &amp; WL è®¡ç®—"></a>WW &amp; WL è®¡ç®—</h3><p>ç°åº¦ä¸Šé™ï¼šWL + (WW / 2)<br>ç°åº¦ä¸‹é™ï¼šWL - (WW / 2)</p><p><img src="/image/CT-WindowingåŒ»å­¦CTå›¾åƒå¢å¼º/2.webp" style="zoom:80%;" /></p><h3 id="WW-amp-WL-ç¤ºä¾‹"><a href="#WW-amp-WL-ç¤ºä¾‹" class="headerlink" title="WW &amp; WL ç¤ºä¾‹"></a>WW &amp; WL ç¤ºä¾‹</h3><p>åœ¨ CT å›¾åƒæŸ¥çœ‹è½¯ä»¶ä¸­ï¼Œé€šå¸¸æœ‰å„ç§æ ‡å‡† WL å’Œ WWã€‚</p><div class="table-container"><table><thead><tr><th>Tissue</th><th>WW</th><th>WL</th></tr></thead><tbody><tr><td>éª¨å¤´</td><td>2000</td><td>500</td></tr><tr><td>è‚º</td><td>1600</td><td>-600</td></tr><tr><td>è…¹</td><td>400</td><td>40</td></tr><tr><td>è„‘</td><td>70</td><td>30</td></tr><tr><td>è½¯ç»„ç»‡</td><td>350</td><td>50</td></tr><tr><td>è‚</td><td>160</td><td>60</td></tr><tr><td>çºµéš”è†œï¼ˆèƒ¸è…”ï¼‰</td><td>500</td><td>50</td></tr><tr><td>ä¸­é£ï¼ˆä½å¯†åº¦è„‘æˆåƒï¼‰</td><td>30</td><td>30</td></tr><tr><td>è¡€ç®¡æˆåƒ</td><td>600</td><td>170</td></tr></tbody></table></div><h3 id="WW-amp-WL-é€‰æ‹©"><a href="#WW-amp-WL-é€‰æ‹©" class="headerlink" title="WW &amp; WL  é€‰æ‹©"></a>WW &amp; WL  é€‰æ‹©</h3><p>ä¸€ã€æ ¹æ®æ‰€éœ€éƒ¨ä½çš„ HU å€¼ï¼ˆå¯¹äºCTå›¾åƒè€Œè¨€ï¼‰åˆ†å¸ƒèŒƒå›´é€‰å–ï¼Œè‹¥æ˜¯å¢å¼º CT çš„è¯ HU å€¼ä¼šæœ‰ä¸€äº›å·®åˆ«ï¼Œå¯ä»¥è§‚å¯Ÿç›´æ–¹å›¾ï¼Œè‡ªå®šä¹‰ WW å’Œ WL</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">transform_ctdata</span>(<span class="params">self, windowWidth, windowLevel, normal=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        æ³¨æ„ï¼Œè¿™ä¸ªå‡½æ•°çš„self.imageä¸€å®šå¾—æ˜¯floatç±»å‹çš„ï¼Œå¦åˆ™å°±æ— æ•ˆï¼</span></span><br><span class="line"><span class="string">        return: trucated image according to window level and window width</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        minWindow = <span class="built_in">float</span>(windowLevel) - <span class="number">0.5</span>*<span class="built_in">float</span>(windowWidth)</span><br><span class="line">        newimg = (self.image - minWindow) / <span class="built_in">float</span>(windowWidth)</span><br><span class="line">        newimg[newimg &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        newimg[newimg &gt; <span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> normal:</span><br><span class="line">            newimg = (newimg * <span class="number">255</span>).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> newimg</span><br></pre></td></tr></table></figure><p>äºŒã€æ ¹æ®å›¾åƒçš„ç»Ÿè®¡ä¿¡æ¯ï¼Œä¾‹å¦‚å›¾åƒå‡å€¼ä½œä¸ºçª—å£ä¸­å¿ƒï¼Œ$\pm \delta$ çš„æ–¹å·®ä½œä¸º WW</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> SimpleITK <span class="keyword">as</span> sitk</span><br><span class="line"><span class="keyword">import</span> torchvision <span class="keyword">as</span> tv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StatisticalNormalization</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Normalize an image by mapping intensity with intensity distribution</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sigma</span>):</span><br><span class="line">        self.name = <span class="string">&#x27;StatisticalNormalization&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(sigma, <span class="built_in">float</span>)</span><br><span class="line">        self.sigma = sigma</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, sample</span>):</span><br><span class="line">        image, label = sample[<span class="string">&#x27;image&#x27;</span>], sample[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">        statisticsFilter = sitk.StatisticsImageFilter()</span><br><span class="line">        statisticsFilter.Execute(image)</span><br><span class="line"></span><br><span class="line">        intensityWindowingFilter = v.IntensityWindowingImageFilter()</span><br><span class="line">        intensityWindowingFilter.SetOutputMaximum(<span class="number">255</span>)</span><br><span class="line">        intensityWindowingFilter.SetOutputMinimum(<span class="number">0</span>)</span><br><span class="line">        intensityWindowingFilter.SetWindowMaximum(</span><br><span class="line">            statisticsFilter.GetMean() + self.sigma * statisticsFilter.GetSigma())</span><br><span class="line">        intensityWindowingFilter.SetWindowMinimum(</span><br><span class="line">            statisticsFilter.GetMean() - self.sigma * statisticsFilter.GetSigma())</span><br><span class="line"></span><br><span class="line">        image = intensityWindowingFilter.Execute(image)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: image, <span class="string">&#x27;label&#x27;</span>: label&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å›¾åƒå¤„ç† </category>
          
      </categories>
      
      
        <tags>
            
            <tag> çŸ¥è¯†ç‚¹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GroupFormerç®€è¦å­¦ä¹ ç¬”è®°</title>
      <link href="/p/28e012f/"/>
      <url>/p/28e012f/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å¿«é€Ÿè®°å½•ä¸‹ GroupFormer ç½‘ç»œçš„æ ¸å¿ƒæ€æƒ³ã€‚</p><span id="more"></span><p>paper: </p><p>code: </p><h2 id="ä¸»è¦ç»“æ„"><a href="#ä¸»è¦ç»“æ„" class="headerlink" title="ä¸»è¦ç»“æ„"></a>ä¸»è¦ç»“æ„</h2><p>![figure1](</p><ol><li>æå–è§†é¢‘clipçš„ç‰¹å¾è¡¨ç¤ºçš„<strong>CNNä¸»å¹²</strong>;</li><li>ç”¨äºä¸ªä½“å’Œåœºæ™¯ç‰¹å¾åˆå§‹åŒ–çš„<strong>ç¾¤ä½“è¡¨ç¤ºç”Ÿæˆå™¨ (Group Representation Generatorï¼ŒGRG)</strong>;</li><li>ç”¨äºå»ºæ¨¡æ—¶ç©ºå…³ç³»ï¼Œç»†åŒ–ç¾¤ä½“è¡¨ç¤ºå’Œä¸ªä½“è¡¨ç¤ºçš„<strong>èšç±»æ—¶ç©ºTransformer (CSTT)</strong>;</li></ol><h2 id="ç‰¹å¾æå–å™¨"><a href="#ç‰¹å¾æå–å™¨" class="headerlink" title="ç‰¹å¾æå–å™¨"></a>ç‰¹å¾æå–å™¨</h2><p>Kineticsé¢„è®­ç»ƒçš„3Dç½‘ç»œ (I3D) ä½œä¸ºBackbone</p><h2 id="ç¾¤ä½“è¡¨ç¤ºç”Ÿæˆå™¨"><a href="#ç¾¤ä½“è¡¨ç¤ºç”Ÿæˆå™¨" class="headerlink" title="ç¾¤ä½“è¡¨ç¤ºç”Ÿæˆå™¨"></a>ç¾¤ä½“è¡¨ç¤ºç”Ÿæˆå™¨</h2><p>æ˜¯ä¸€ä¸ªåœ¨æ¨¡å‹ä¸­ç”¨äºåˆå§‹åŒ–ç¾¤ä½“è¡¨ç¤ºçš„é¢„å¤„ç†ç»„ä»¶ï¼Œå°†åœºæ™¯ç‰¹å¾å’Œä¸ªä½“ç‰¹å¾åˆ†åˆ«è½¬æ¢ä¸ºè§†è§‰tokenï¼Œå°†å®ƒä»¬èšåˆä»¥ç”Ÿæˆç¾¤ä½“è¡¨ç¤º</p><h2 id="èšç±»æ—¶ç©ºTransformer"><a href="#èšç±»æ—¶ç©ºTransformer" class="headerlink" title="èšç±»æ—¶ç©ºTransformer"></a>èšç±»æ—¶ç©ºTransformer</h2><h3 id="æ—¶ç©ºTransformer"><a href="#æ—¶ç©ºTransformer" class="headerlink" title="æ—¶ç©ºTransformer"></a>æ—¶ç©ºTransformer</h3><p>ä¸ºç¾¤ä½“æ´»åŠ¨è¯†åˆ«è€Œè®¾è®¡çš„æ—¶ç©ºTransformer(STT)å¢å¼ºäº†ä¸ªä½“è¡¨å¾å’Œç¾¤ä½“è¡¨å¾ã€‚å®ƒåŒ…æ‹¬ä¸¤ä¸ªå¹¶è¡Œçš„ç¼–ç å™¨ï¼ˆä¸€ä¸ªç©ºé—´ç¼–ç å™¨å’Œæ—¶é—´ç¼–ç å™¨ ï¼‰ï¼Œåˆ†åˆ«ç”Ÿæˆç©ºé—´å’Œæ—¶é—´ç‰¹å¾ã€‚å¹¶å¼•å…¥äº¤å‰çš„ä¸ªä½“è§£ç å™¨ æ¥è§£ç æ—¶ç©ºä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æœ€åï¼Œç”¨ä¸€ä¸ªç¾¤ä½“è§£ç å™¨ æ¥å¢å¼ºç¾¤ä½“çš„è¡¨ç¤ºã€‚</p><h4 id="Encoders"><a href="#Encoders" class="headerlink" title="Encoders"></a>Encoders</h4><p>é‡‡ç”¨äº†ä¸¤ä¸ªå¹¶è¡Œç¼–ç å™¨æ¥embedä¸Šä¸‹æ–‡ç‰¹å¾ã€‚åœ¨ä¸€ä¸ªåˆ†æ”¯ä¸­ï¼Œä½œè€…é‡‡ç”¨äº†ä¸€ä¸ªåŸºäºTransformerçš„ç©ºé—´ç¼–ç å™¨ æ¥å­¦ä¹ ä¸ªä½“çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å°†æ—¶é—´ç»´åº¦è§†ä¸ºBatchç»´åº¦ï¼Œå¹¶åº”ç”¨ä¸€ä¸ªç¼–ç å™¨æ¥å»ºæ¨¡æ‰€æœ‰å¸§çš„ç©ºé—´ä¸Šä¸‹æ–‡ã€‚</p><p>å¦ä¸€ç§å¹¶è¡Œæ—¶é—´ç¼–ç å™¨ åˆ©ç”¨æ—¶é—´åŠ¨æ€çº¿ç´¢å¢å¼ºè¾“å…¥ç‰¹å¾ï¼Œé€šè¿‡çªå‡ºæ¯ä¸ªä¸ªä½“æ²¿æ—¶é—´ç»´åº¦çš„ä¿¡æ¯ç‰¹å¾æ¥ä¸°å¯Œæ—¶é—´ä¸Šä¸‹æ–‡ã€‚æ—¶é—´ç¼–ç å™¨éµå¾ªç©ºé—´ç¼–ç å™¨çš„æ“ä½œã€‚ä¸ä¸Šè¿°ç©ºé—´ç¼–ç å™¨çš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œæ—¶é—´ç¼–ç å™¨å°†ç©ºé—´ç»´åº¦è§†ä¸ºä¸€ä¸ªBatchç»´åº¦ã€‚</p><h4 id="Individual-Decoders"><a href="#Individual-Decoders" class="headerlink" title="Individual Decoders"></a>Individual Decoders</h4><p>ä½œè€…æå‡ºäº†ä¸ªä½“è§£ç å™¨ æ¥ç»¼åˆè€ƒè™‘ç©ºé—´å’Œæ—¶ç©ºä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ä¸ªä½“è§£ç å™¨éµå¾ªæ ‡å‡†Transformerçš„è§£ç å™¨çš„è®¾è®¡ï¼Œæ¥äº’è¡¥åˆ©ç”¨æ—¶ç©ºä¸Šä¸‹æ–‡ã€‚</p><p>å¯¹äºç©ºé—´è§£ç å™¨ ï¼Œç©ºé—´ç¼–ç å™¨çš„è¾“å‡ºç»“æœè¢«è§†ä¸º actor queryï¼Œæ—¶é—´ç¼–ç å™¨è¾“å‡ºç»“æœçš„embeddingè¢«è§†ä¸ºkeyå’Œvalueã€‚actor queryå’Œkeyã€valueè¿›è¡Œcross-attentionï¼Œæ•è·æ—¶é—´åŠ¨æ€ï¼Œå¹¶è¾“å‡ºæ›´æ–°åçš„ä¸Šä¸‹æ–‡ç‰¹å¾ã€‚</p><p>åŒæ ·çš„ï¼Œå¯¹äºæ—¶é—´è§£ç å™¨ ï¼Œç©ºé—´ç¼–ç å™¨çš„è¾“å‡ºç»“æœå°†æ—¶é—´ç»´åº¦ä¸ç©ºé—´ç»´åº¦è¿›è¡Œè½¬æ¢ï¼Œå¯ä»¥çœ‹ä½œæ˜¯è§£ç å™¨ä½¿ç”¨çš„keyå’Œvalueã€‚è§£ç å™¨å°†æ—¶é—´ä¸Šä¸‹æ–‡è§†ä¸ºtime queryï¼Œç„¶åè¿›è¡Œcross-attentionçš„è¿‡ç¨‹ï¼Œæ—¶é—´è§£ç å™¨æœ‰åŠ©äºæŸ¥æ‰¾è§†é¢‘ä¸­æ„Ÿå…´è¶£çš„å¸§ã€‚</p><p>æœ€åï¼Œå°†è¿™ä¸¤ä¸ªäº¤å‰è§£ç å™¨çš„è¾“å‡ºembeddingè¿›è¡Œèåˆï¼Œç”Ÿæˆå¢å¼ºçš„ä¸ªä½“è¡¨ç¤ºã€‚è¿™ä¸¤ç§äº¤å‰è§£ç å™¨æ˜¯åˆ©ç”¨äº†åŸºäºç©ºé—´ä¸Šä¸‹æ–‡å’Œæ—¶é—´ä¸Šä¸‹æ–‡çš„è¯­ä¹‰å…³è”æ¥å¢å¼ºä¸ªä½“è¡¨å¾ã€‚</p><h4 id="Group-Decoder"><a href="#Group-Decoder" class="headerlink" title="Group Decoder"></a>Group Decoder</h4><p>å¼•å…¥äº†ä¸€ä¸ªç¾¤ä½“è§£ç å™¨ ï¼ˆGroup Decoderï¼‰æ¥é€šè¿‡ä¸ªä½“è¡¨ç¤ºæ¥å¢å¼ºç¾¤ä½“è¡¨ç¤ºã€‚ç¾¤ä½“è§£ç å™¨ä¹Ÿéµå¾ªTransformerçš„è§£ç å™¨è®¾è®¡ã€‚ä¸åŸTransformerçš„åŒºåˆ«åœ¨äºï¼Œç¾¤ä½“è§£ç å™¨åªåŒ…å«å¤šå¤´äº¤å‰æ³¨æ„æœºåˆ¶å’Œä¸€ä¸ªå‰é¦ˆç½‘ç»œï¼Œä¸åŒ…å«Self-Attentionã€‚</p><h3 id="Clustered-Attention-Mechanism"><a href="#Clustered-Attention-Mechanism" class="headerlink" title="Clustered Attention Mechanism"></a>Clustered Attention Mechanism</h3><p>è™½ç„¶åŸºäºå…¨è¿æ¥æ³¨æ„æœºåˆ¶çš„æ—¶ç©ºTransformer(STT)èƒ½å¤Ÿå»ºæ¨¡ä¸ªä½“çš„å…³ç³»ï¼Œä½†å®ƒåŒ…å«äº†è®¸å¤šä¸ç›¸å…³ä¸ªä½“çš„å…³ç³»ã€‚ä¸ºäº†ä½¿æ¨¡å‹èƒ½å¤Ÿå…³æ³¨å…³é”®çš„ç¾¤ä½“å…³ç³»ï¼Œä½œè€…å°†å…¨è¿æ¥çš„æ³¨æ„åŠ›æ›¿æ¢ä¸ºèšç±»çš„æ³¨æ„åŠ›ï¼Œå¹¶å°†æ•´ä¸ªæ¨¡å—ç§°ä¹‹ä¸ºèšç±»æ—¶ç©ºTransformer(Clustered Spatial-Temporal Transformerï¼ŒCSTT) ã€‚å®ƒå¯ä»¥å¯¹ä¸ªä½“è¿›è¡Œåˆ†ç»„ï¼Œå¹¶åˆ©ç”¨ç»„å†…å’Œç»„é—´çš„å…³ç³»æ¥æ•è·å…¨å±€æ´»åŠ¨ä¸Šä¸‹æ–‡ã€‚</p><p>é¦–å…ˆå°†ä¸ªä½“åˆ†ç»„ä¸ºCä¸ªèšç±»ï¼Œç„¶åè®¡ç®—ä¸€ä¸‹ä¸¤ç§ç±»å‹çš„æ³¨æ„ï¼š</p><ol><li>ç»„å†…æ³¨æ„ï¼ˆintra-group attentionï¼‰ ï¼šåªæœ‰æ¥è‡ªåŒä¸€ä¸ªèšç±»å†…çš„queryå’Œkeyæ‰ä¼šè¢«è€ƒè™‘ã€‚</li><li>ç»„é—´æ³¨æ„ï¼ˆinter-group attentionï¼‰ ï¼šè€ƒè™‘äº†èšç±»ä¹‹é—´æˆå¯¹çš„åŠ æƒè¿æ¥ã€‚</li></ol><h2 id="ç½‘ç»œä¼˜åŒ–"><a href="#ç½‘ç»œä¼˜åŒ–" class="headerlink" title="ç½‘ç»œä¼˜åŒ–"></a>ç½‘ç»œä¼˜åŒ–</h2><p>æœ¬æ–‡æå‡ºçš„CSTTä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚åœ¨CSTTä¸­ï¼Œå¯ä»¥ç›´æ¥ä»ç¾¤ä½“è¡¨ç¤ºç”Ÿæˆç¾¤ä½“æ´»åŠ¨åˆ†æ•°ã€‚åŒæ ·ï¼Œé‡‡ç”¨å¦ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œä½¿ç”¨CSTTç”Ÿæˆçš„ä¸ªä½“è¡¨ç¤ºæ¥é¢„æµ‹ä¸ªä½“çš„åŠ¨ä½œå¾—åˆ†ã€‚å¯¹äºè¿™ä¸¤ä¸ªä»»åŠ¡ï¼Œä½œè€…éƒ½é€‰æ‹©äº†äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥æŒ‡å¯¼ä¼˜åŒ–è¿‡ç¨‹ï¼š</p><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>åœ¨æœ¬æ–‡ä¸­ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºTransformerçš„ç»“æ„ï¼Œç§°ä¸ºGroupFormerï¼Œå®ƒè”åˆå»ºæ¨¡äº†æ—¶ç©ºä¸Šä¸‹æ–‡è¡¨ç¤ºæ¥æ¨æ–­ç¾¤ä½“æ´»åŠ¨ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜å¼•å…¥äº†èšç±»æ³¨æ„æœºåˆ¶æ¥å¯¹ä¸ªä½“è¿›è¡Œåˆ†ç»„ï¼Œå¹¶åˆ©ç”¨ç»„å†…å’Œç»„é—´çš„å…³ç³»è·å¾—æ›´å¥½çš„ç¾¤ä½“ç‰¹å¾è¡¨ç¤ºã€‚ä½œè€…åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒGroupFormerçš„è¡¨ç°è¶…è¿‡äº†å¤§å¤šæ•°ç›®å‰çš„SOTAæ–¹æ³•ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç¾¤ä½“è¡Œä¸ºè¯†åˆ« </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>é«˜æ–¯å‡½æ•°ä¸é«˜æ–¯æ ¸å‡½æ•°</title>
      <link href="/p/908291b2/"/>
      <url>/p/908291b2/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å›¾åƒå¤„ç†é¢†åŸŸä¸­ï¼Œé«˜æ–¯æ ¸å‡½æ•°å¸¸ç”¨äºå›¾åƒä½é€šæ»¤æ³¢ï¼Œè®°å½•ä¸‹åŸç†ï¼ŒåŒæ—¶ç”¨ä»£ç å®ç°ä¸‹ã€‚</p><span id="more"></span><h2 id="é«˜æ–¯å‡½æ•°"><a href="#é«˜æ–¯å‡½æ•°" class="headerlink" title="é«˜æ–¯å‡½æ•°"></a>é«˜æ–¯å‡½æ•°</h2><h3 id="ä¸€ç»´é«˜æ–¯å‡½æ•°"><a href="#ä¸€ç»´é«˜æ–¯å‡½æ•°" class="headerlink" title="ä¸€ç»´é«˜æ–¯å‡½æ•°"></a>ä¸€ç»´é«˜æ–¯å‡½æ•°</h3><script type="math/tex; mode=display">f(x) = ae^{\frac{-(x-b)^2}{2c^2}}</script><p>$a, b, c$ ä¸ºå®æ•°å¸¸æ•°ï¼Œ ä¸” $a&gt;0$</p><p>$a$ ä¸ºæ›²çº¿å°–å³°é«˜åº¦ï¼Œ$b$ ä¸ºå°–å³°çš„ä¸­å¿ƒä½ç½®ï¼Œ $c$ ä¸ºé’Ÿçš„å®½åº¦</p><p><img src="" style="zoom: 40%;" /></p><p>ç”±é«˜æ–¯ç§¯åˆ†å…¬å¼ï¼Œå¾—</p><script type="math/tex; mode=display">\int_{-\infty}^{\infty}e^{-x^2}dx = \sqrt{\pi}</script><p>ä»¤ $y=x-b$, å¾— $dx = dy$</p><script type="math/tex; mode=display">a \int_{-\infty}^{\infty}e^{-\frac{y^2}{2c^2}}dx</script><p>ä»¤ $z= \frac{y}{\sqrt{2}c}$, å¾— $dy = \sqrt{2}cdz$</p><script type="math/tex; mode=display">\begin{aligned}  & a\int_{-\infty}^{\infty}e^{-z^2}\sqrt{2}cdz \\= & \sqrt{2}ac \int_{-\infty}^{\infty}e^{-z^2}dz \\= & \sqrt{2\pi}\cdot ac\end{aligned}</script><p>å¾—</p><script type="math/tex; mode=display">\int_{-\infty}^{\infty}ae^{\frac{-(x-b)^2}{2c^2}}dx = \sqrt{2\pi}\cdot ac</script><p>ä»¤ $f(x)=1$ï¼Œä½¿å®½åº¦èŒƒå›´å†…æ‰€æœ‰æ¦‚ç‡ä¸º$ 1$ï¼Œå¾—</p><script type="math/tex; mode=display">a = \frac{1}{\sqrt{2\pi}\cdot c}</script><p>ä»¤æœŸæœ› $\mu$ ä¸º $b$ï¼Œæ ‡å‡†å·® $\sigma$ ä¸º $c$ï¼Œå¾—æ»¡è¶³æ­£æ€åˆ†å¸ƒçš„é«˜æ–¯å‡½æ•°</p><script type="math/tex; mode=display">g(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^{2}}</script><h3 id="äºŒç»´é«˜æ–¯å‡½æ•°ï¼ˆé«˜æ–¯åˆ†å¸ƒã€æ­£æ€åˆ†å¸ƒï¼‰"><a href="#äºŒç»´é«˜æ–¯å‡½æ•°ï¼ˆé«˜æ–¯åˆ†å¸ƒã€æ­£æ€åˆ†å¸ƒï¼‰" class="headerlink" title="äºŒç»´é«˜æ–¯å‡½æ•°ï¼ˆé«˜æ–¯åˆ†å¸ƒã€æ­£æ€åˆ†å¸ƒï¼‰"></a>äºŒç»´é«˜æ–¯å‡½æ•°ï¼ˆé«˜æ–¯åˆ†å¸ƒã€æ­£æ€åˆ†å¸ƒï¼‰</h3><script type="math/tex; mode=display">G(x,y) = \frac{1}{2\pi\sigma^2}e^{-(x^2+y^2)/2\sigma^2}</script><p>$\mu=0$ï¼Œå³åŸç‚¹ä¸ºä¸­å¿ƒç‚¹</p><p>åœ¨å®é™…ç¼–ç¨‹åº”ç”¨ä¸­ï¼Œé«˜æ–¯å‡½æ•°ä¸­çš„å‚æ•°å¦‚ä¸‹</p><ul><li>ksize æ ¸å¤§å°</li><li>sigma æ–¹å·®</li><li>center å°–å³°ä¸­å¿ƒç‚¹åæ ‡</li><li>bias å°–å³°ä¸­å¿ƒç‚¹çš„åç§»é‡ï¼Œç”¨äºæ§åˆ¶æˆªæ–­é«˜æ–¯å‡½æ•°</li></ul><p>ä»¥ä¸‹ç¨‹åºé€’å¢é«˜æ–¯å‡½æ•°çš„æ–¹å·®ï¼Œå¹¶å°†ç»“æœå›¾ä¿å­˜ä¸º gif å›¾åƒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line">item = <span class="number">10</span></span><br><span class="line">dt = <span class="number">1</span></span><br><span class="line">ksize = <span class="number">20</span></span><br><span class="line">sigma = <span class="number">2</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.ion()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">range</span>(item)):</span><br><span class="line">    center = <span class="built_in">round</span>(ksize/<span class="number">2</span>)</span><br><span class="line">    bias = ksize *<span class="number">10</span>/<span class="number">10</span></span><br><span class="line">    ksigma = np.multiply(cv2.getGaussianKernel(ksize, sigma),</span><br><span class="line">            (cv2.getGaussianKernel(ksize,sigma)).T)</span><br><span class="line">    [m, n] = ksigma.shape</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">range</span>(m)):</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">range</span>(n)):</span><br><span class="line">            <span class="keyword">if</span>((x&lt;center-bias) <span class="keyword">or</span> (x&gt;center+bias) <span class="keyword">or</span> (y&lt;center-bias) <span class="keyword">or</span></span><br><span class="line">                    (y&gt;center+bias)):</span><br><span class="line">                ksigma[x, y] = <span class="number">0</span></span><br><span class="line">    sigma = sigma + dt</span><br><span class="line"></span><br><span class="line">    ax3 = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">    ax3.set_zlim3d(<span class="number">0</span>,<span class="number">8e-3</span>)</span><br><span class="line">    x = <span class="built_in">list</span>(<span class="built_in">range</span>(ksize))</span><br><span class="line">    y = x</span><br><span class="line">    ax3.plot_surface(x,y,ksigma,cmap=<span class="string">&#x27;rainbow&#x27;</span>)</span><br><span class="line">    plt.draw()</span><br><span class="line">    plt.pause(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>å›¾ç‰‡å¦‚ä¸‹</p><p><img src="/image/é«˜æ–¯å‡½æ•°ä¸é«˜æ–¯æ ¸å‡½æ•°/gaussian_curve.gif" style="zoom: 80%;" /></p><p>éšç€æ–¹å·®çš„å¢å¤§ï¼Œæ•´ä¸ªé«˜æ–¯å‡½æ•°çš„å°–å³°é€æ¸å‡å°ï¼Œæ•´ä½“ä¹Ÿå˜çš„æ›´åŠ å¹³ç¼“ï¼Œåˆ™å¯¹å›¾åƒçš„å¹³æ»‘æ•ˆæœè¶Šæ¥è¶Šæ˜æ˜¾</p><p>ä¿æŒå‚æ•°ä¸å˜ï¼Œå¯¹ä¸Šè¿°é«˜æ–¯å‡½æ•°è¿›è¡Œæˆªæ–­ï¼Œbias çš„å¤§å°ä¸º ksize *3/10ï¼Œåˆ™ç»“æœå¦‚ä¸‹</p><p><img src="/image/é«˜æ–¯å‡½æ•°ä¸é«˜æ–¯æ ¸å‡½æ•°/gaussian_curve2.gif" style="zoom: 80%;" /></p><p>bias çš„ä½œç”¨ä¸»è¦æ˜¯å¯¹è¶…è¿‡ä¸€å®šåŒºåŸŸçš„åŸå§‹å›¾åƒä¿¡æ¯ä¸å†è€ƒè™‘ï¼Œè¿™å°±ä¿è¯åœ¨æ›´åŠ åˆç†çš„åˆ©ç”¨é è¿‘é«˜æ–¯å‡½æ•°ä¸­å¿ƒç‚¹çš„å‘¨å›´åƒç´ ï¼ŒåŒæ—¶è¿˜å¯ä»¥æ”¹å˜é«˜æ–¯å‡½æ•°çš„ä¸­å¿ƒåæ ‡</p><h2 id="é«˜æ–¯æ ¸å‡½æ•°å·ç§¯"><a href="#é«˜æ–¯æ ¸å‡½æ•°å·ç§¯" class="headerlink" title="é«˜æ–¯æ ¸å‡½æ•°å·ç§¯"></a>é«˜æ–¯æ ¸å‡½æ•°å·ç§¯</h2><p>å¾„å‘åŸºå‡½æ•°ï¼ˆRadial Basis Functionï¼‰ï¼Œ å°±æ˜¯æŸç§æ²¿å¾„å‘å¯¹ç§°çš„æ ‡é‡å‡½æ•°ã€‚ é€šå¸¸å®šä¹‰ä¸ºç©ºé—´ä¸­ä»»ä¸€ç‚¹ $x_1$ åˆ°æŸä¸€ä¸­å¿ƒ $x_2$ ä¹‹é—´æ¬§æ°è·ç¦»çš„å•è°ƒå‡½æ•°ï¼Œå…¶ä½œç”¨å¾€å¾€æ˜¯å±€éƒ¨çš„ , å³å½“ $x_1$ è¿œç¦» $x_2$ æ—¶å‡½æ•°å–å€¼å¾ˆå°</p><p>æœ€å¸¸ç”¨çš„ä¸€ä¸ªæ ¸å‡½æ•°ä¸ºé«˜æ–¯æ ¸å‡½æ•°ï¼Œå½¢å¼ä¸º</p><script type="math/tex; mode=display">k(\|x_1-x_2\|)=e^{-\|x_1-x_2\|^2/2\sigma^2}</script><p>ä¹Ÿç§°ä¸º<strong>å¾„å‘åŸºå‡½æ•°</strong></p><p>é«˜æ–¯æ ¸å‡½æ•°çš„ä»£ç å®ç°å¦‚ä¸‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_kernel</span>(<span class="params">x1, x2, l=<span class="number">1.0</span>, sigma_f=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Easy to understand but inefficient.&quot;&quot;&quot;</span></span><br><span class="line">    m, n = x1.shape[<span class="number">0</span>], x2.shape[<span class="number">0</span>]</span><br><span class="line">    dist_matrix = np.zeros((m, n), dtype=<span class="built_in">float</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            dist_matrix[i][j] = np.<span class="built_in">sum</span>((x1[i] - x2[j]) ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> sigma_f ** <span class="number">2</span> * np.exp(- <span class="number">0.5</span> / l ** <span class="number">2</span> * dist_matrix)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian_kernel_vectorization</span>(<span class="params">x1, x2, l=<span class="number">1.0</span>, sigma_f=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;More efficient approach.&quot;&quot;&quot;</span></span><br><span class="line">    dist_matrix = np.<span class="built_in">sum</span>(x1**<span class="number">2</span>, <span class="number">1</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>) + np.<span class="built_in">sum</span>(x2**<span class="number">2</span>, <span class="number">1</span>) - <span class="number">2</span> * np.dot(x1, x2.T)</span><br><span class="line">    <span class="keyword">return</span> sigma_f ** <span class="number">2</span> * np.exp(-<span class="number">0.5</span> / l ** <span class="number">2</span> * dist_matrix)</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">700</span>, <span class="number">800</span>, <span class="number">1029</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(gaussian_kernel_vectorization(x, x, l=<span class="number">500</span>, sigma=<span class="number">10</span>))</span><br></pre></td></tr></table></figure><p>è¾“å‡º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">100.</span>          <span class="number">98.01986733</span>  <span class="number">80.5347031</span> ]</span><br><span class="line"> [ <span class="number">98.01986733</span> <span class="number">100.</span>          <span class="number">90.04307671</span>]</span><br><span class="line"> [ <span class="number">80.5347031</span>   <span class="number">90.04307671</span> <span class="number">100.</span>        ]]</span><br></pre></td></tr></table></figure><h2 id="é«˜æ–¯å‡½æ•°æ€§è´¨"><a href="#é«˜æ–¯å‡½æ•°æ€§è´¨" class="headerlink" title="é«˜æ–¯å‡½æ•°æ€§è´¨"></a>é«˜æ–¯å‡½æ•°æ€§è´¨</h2><p>é«˜æ–¯å‡½æ•°å…·æœ‰äº”ä¸ªé‡è¦çš„æ€§è´¨ï¼Œè¿™äº›æ€§è´¨ä½¿å¾—å®ƒåœ¨æ—©æœŸå›¾åƒå¤„ç†ä¸­ç‰¹åˆ«æœ‰ç”¨ã€‚è¿™äº›æ€§è´¨è¡¨æ˜ï¼Œé«˜æ–¯å¹³æ»‘æ»¤æ³¢å™¨æ— è®ºåœ¨ç©ºé—´åŸŸè¿˜æ˜¯åœ¨é¢‘ç‡åŸŸéƒ½æ˜¯ååˆ†æœ‰æ•ˆçš„ä½é€šæ»¤æ³¢å™¨ï¼Œä¸”åœ¨å®é™…å›¾åƒå¤„ç†ä¸­å¾—åˆ°äº†æœ‰æ•ˆä½¿ç”¨ã€‚é«˜æ–¯å‡½æ•°å…·æœ‰äº”ä¸ªååˆ†é‡è¦çš„æ€§è´¨</p><ol><li><p>äºŒç»´é«˜æ–¯å‡½æ•°å…·æœ‰æ—‹è½¬å¯¹ç§°æ€§ï¼Œå³æ»¤æ³¢å™¨åœ¨å„ä¸ªæ–¹å‘ä¸Šçš„å¹³æ»‘ç¨‹åº¦æ˜¯ç›¸åŒçš„ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œä¸€å¹…å›¾åƒçš„è¾¹ç¼˜æ–¹å‘æ˜¯äº‹å…ˆä¸çŸ¥é“çš„ï¼Œå› æ­¤ï¼Œåœ¨æ»¤æ³¢å‰æ˜¯æ— æ³•ç¡®å®šä¸€ä¸ªæ–¹å‘ä¸Šæ¯”å¦ä¸€æ–¹å‘ä¸Šéœ€è¦æ›´å¤šçš„å¹³æ»‘ã€‚æ—‹è½¬å¯¹ç§°æ€§æ„å‘³ç€é«˜æ–¯å¹³æ»‘æ»¤æ³¢å™¨åœ¨åç»­è¾¹ç¼˜æ£€æµ‹ä¸­ä¸ä¼šåå‘ä»»ä¸€æ–¹å‘ã€‚</p></li><li><p>é«˜æ–¯å‡½æ•°æ˜¯å•å€¼å‡½æ•°ã€‚è¿™è¡¨æ˜ï¼Œé«˜æ–¯æ»¤æ³¢å™¨ç”¨åƒç´ é‚»åŸŸçš„åŠ æƒå‡å€¼æ¥ä»£æ›¿è¯¥ç‚¹çš„åƒç´ å€¼ï¼Œè€Œæ¯ä¸€é‚»åŸŸåƒç´ ç‚¹æƒå€¼æ˜¯éšè¯¥ç‚¹ä¸ä¸­å¿ƒç‚¹çš„è·ç¦»å•è°ƒå¢å‡çš„ã€‚è¾¹ç¼˜æ˜¯ä¸€ç§å›¾åƒå±€éƒ¨ç‰¹å¾ï¼Œå¦‚æœå¹³æ»‘è¿ç®—å¯¹ç¦»ç®—å­ä¸­å¿ƒå¾ˆè¿œçš„åƒç´ ç‚¹ä»ç„¶æœ‰å¾ˆå¤§ä½œç”¨ï¼Œåˆ™å¹³æ»‘è¿ç®—ä¼šä½¿å›¾åƒå¤±çœŸã€‚</p></li><li><p>é«˜æ–¯å‡½æ•°çš„å‚…ç«‹å¶å˜æ¢é¢‘è°±æ˜¯å•ç“£çš„ã€‚æ­£å¦‚ä¸‹é¢æ‰€ç¤ºï¼Œè¿™ä¸€æ€§è´¨æ˜¯é«˜æ–¯å‡½æ•°å‚…ç«‹å¶å˜æ¢ç­‰äºé«˜æ–¯å‡½æ•°æœ¬èº«è¿™ä¸€äº‹å®çš„ç›´æ¥æ¨è®ºã€‚å›¾åƒå¸¸è¢«ä¸å¸Œæœ›çš„é«˜é¢‘ä¿¡å·æ‰€æ±¡æŸ“ï¼ˆå™ªå£°å’Œç»†çº¹ç†ï¼‰ã€‚è€Œæ‰€å¸Œæœ›çš„å›¾åƒç‰¹å¾ï¼ˆå¦‚è¾¹ç¼˜ï¼‰ï¼Œæ—¢å«æœ‰ä½é¢‘åˆ†é‡ï¼Œåˆå«æœ‰é«˜é¢‘åˆ†é‡ã€‚é«˜æ–¯å‡½æ•°å‚…ç«‹å¶å˜æ¢çš„å•ç“£æ„å‘³ç€å¹³æ»‘å›¾åƒä¸ä¼šè¢«ä¸éœ€è¦çš„é«˜é¢‘ä¿¡å·æ‰€æ±¡æŸ“ï¼ŒåŒæ—¶ä¿ç•™äº†å¤§éƒ¨åˆ†æ‰€éœ€ä¿¡å·ã€‚</p></li><li><p>é«˜æ–¯æ»¤æ³¢å™¨å®½åº¦(å†³å®šç€å¹³æ»‘ç¨‹åº¦)æ˜¯ç”±å‚æ•° $\sigma$ è¡¨å¾çš„ï¼Œè€Œä¸” $\sigma$ å’Œå¹³æ»‘ç¨‹åº¦çš„å…³ç³»æ˜¯éå¸¸ç®€å•çš„ã€‚ $\sigma$ è¶Šå¤§ï¼Œé«˜æ–¯æ»¤æ³¢å™¨çš„é¢‘å¸¦å°±è¶Šå®½ï¼Œå¹³æ»‘ç¨‹åº¦å°±è¶Šå¥½ã€‚é€šè¿‡è°ƒèŠ‚å¹³æ»‘ç¨‹åº¦å‚æ•° $\sigma$ ï¼Œå¯åœ¨å›¾åƒç‰¹å¾è¿‡åˆ†æ¨¡ç³Š(è¿‡å¹³æ»‘)ä¸å¹³æ»‘å›¾åƒä¸­ç”±äºå™ªå£°å’Œç»†çº¹ç†æ‰€å¼•èµ·çš„è¿‡å¤šçš„ä¸å¸Œæœ›çªå˜é‡ï¼ˆæ¬ å¹³æ»‘ï¼‰ä¹‹é—´å–å¾—æŠ˜è¡·ã€‚</p></li><li><p>ç”±äºé«˜æ–¯å‡½æ•°çš„å¯åˆ†ç¦»æ€§ï¼Œå¤§é«˜æ–¯æ»¤æ³¢å™¨å¯ä»¥å¾—ä»¥æœ‰æ•ˆåœ°å®ç°ã€‚äºŒç»´é«˜æ–¯å‡½æ•°å·ç§¯å¯ä»¥åˆ†ä¸¤æ­¥æ¥è¿›è¡Œï¼Œé¦–å…ˆå°†å›¾åƒä¸ä¸€ç»´é«˜æ–¯å‡½æ•°è¿›è¡Œå·ç§¯ï¼Œç„¶åå°†å·ç§¯ç»“æœä¸æ–¹å‘å‚ç›´çš„ç›¸åŒä¸€ç»´é«˜æ–¯å‡½æ•°å·ç§¯ã€‚å› æ­¤ï¼ŒäºŒç»´é«˜æ–¯æ»¤æ³¢çš„è®¡ç®—é‡éšæ»¤æ³¢æ¨¡æ¿å®½åº¦æˆçº¿æ€§å¢é•¿è€Œä¸æ˜¯æˆå¹³æ–¹å¢é•¿ã€‚</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> å›¾åƒå¤„ç† </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç©ºé—´æ»¤æ³¢ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»</title>
      <link href="/p/5f24596c/"/>
      <url>/p/5f24596c/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ä¸€å¼ å°æ–¹æ¡Œï¼Œæœ‰ä¸€è¤ä¸€ç´ </p><span id="more"></span><h2 id="æ—¶é—´çº¿"><a href="#æ—¶é—´çº¿" class="headerlink" title="æ—¶é—´çº¿"></a>æ—¶é—´çº¿</h2><h3 id="2022å¹´6æœˆ10æ—¥"><a href="#2022å¹´6æœˆ10æ—¥" class="headerlink" title="2022å¹´6æœˆ10æ—¥"></a>2022å¹´6æœˆ10æ—¥</h3><ul><li>é’æ¤’åœŸè±†ä¸</li><li>è…Šè‚ è’¸è›‹</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-10.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´6æœˆ11æ—¥"><a href="#2022å¹´6æœˆ11æ—¥" class="headerlink" title="2022å¹´6æœˆ11æ—¥"></a>2022å¹´6æœˆ11æ—¥</h3><ul><li>é’æ¤’åœŸè±†ä¸</li><li>çº¢çƒ§å¸¦é±¼</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-11.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´6æœˆ12æ—¥"><a href="#2022å¹´6æœˆ12æ—¥" class="headerlink" title="2022å¹´6æœˆ12æ—¥"></a>2022å¹´6æœˆ12æ—¥</h3><ul><li>åœŸè±†é¸¡è…¿</li><li>ç‚’é’èœ</li><li>ç´«èœè›‹æ±¤</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-12.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´6æœˆ13æ—¥"><a href="#2022å¹´6æœˆ13æ—¥" class="headerlink" title="2022å¹´6æœˆ13æ—¥"></a>2022å¹´6æœˆ13æ—¥</h3><ul><li>ç•ªèŒ„é¸¡è›‹é¢</li><li>åŒ…èœç‚’è‚‰</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-13.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´6æœˆ14æ—¥"><a href="#2022å¹´6æœˆ14æ—¥" class="headerlink" title="2022å¹´6æœˆ14æ—¥"></a>2022å¹´6æœˆ14æ—¥</h3><ul><li>ç•ªèŒ„é¸¡è›‹é¢</li><li>åŒ…èœç‚’è‚‰</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-14.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´6æœˆ16æ—¥"><a href="#2022å¹´6æœˆ16æ—¥" class="headerlink" title="2022å¹´6æœˆ16æ—¥"></a>2022å¹´6æœˆ16æ—¥</h3><ul><li>è›‹é»„ç²½</li><li>çº¢æ£ç²½</li><li>è™çš®é’æ¤’</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-16.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´6æœˆ17æ—¥"><a href="#2022å¹´6æœˆ17æ—¥" class="headerlink" title="2022å¹´6æœˆ17æ—¥"></a>2022å¹´6æœˆ17æ—¥</h3><ul><li>çº¢çƒ§é³Šé±¼</li><li>åœŸè±†æ´‹è‘±ç‚’è…Šè‚ </li><li>ç´«èœè›‹æ±¤</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-17.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´6æœˆ23æ—¥-30-æ—¥"><a href="#2022å¹´6æœˆ23æ—¥-30-æ—¥" class="headerlink" title="2022å¹´6æœˆ23æ—¥ - 30 æ—¥"></a>2022å¹´6æœˆ23æ—¥ - 30 æ—¥</h3><ul><li>å»å­¦æ ¡å¤©å¤©åƒå¤§é¤</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-24.webp" style="zoom: 50%;" /></p><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-06-30.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´07æœˆ02æ—¥"><a href="#2022å¹´07æœˆ02æ—¥" class="headerlink" title="2022å¹´07æœˆ02æ—¥"></a>2022å¹´07æœˆ02æ—¥</h3><ul><li>è’¸è´è´å—ç“œ</li><li>è’œè“‰èŒ„å­</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-07-02.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´07æœˆ03æ—¥"><a href="#2022å¹´07æœˆ03æ—¥" class="headerlink" title="2022å¹´07æœˆ03æ—¥"></a>2022å¹´07æœˆ03æ—¥</h3><ul><li>é‡‘è‰²ä¼ è¯´ç…é¥º</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-07-03.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´07æœˆ04æ—¥"><a href="#2022å¹´07æœˆ04æ—¥" class="headerlink" title="2022å¹´07æœˆ04æ—¥"></a>2022å¹´07æœˆ04æ—¥</h3><ul><li>ç©ºæ°”ç‚¸é”…å¥¥å°”è‰¯é¸¡è…¿</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-07-04.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´07æœˆ07æ—¥"><a href="#2022å¹´07æœˆ07æ—¥" class="headerlink" title="2022å¹´07æœˆ07æ—¥"></a>2022å¹´07æœˆ07æ—¥</h3><ul><li><p>ç•ªèŒ„é©¬é“ƒè–¯æ’éª¨</p></li><li><p>ç‚’è±‡è±†</p></li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-07-07.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´07æœˆ14æ—¥"><a href="#2022å¹´07æœˆ14æ—¥" class="headerlink" title="2022å¹´07æœˆ14æ—¥"></a>2022å¹´07æœˆ14æ—¥</h3><ul><li>å¥¥å°”è‰¯é¸¡è…¿</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-07-14.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´07æœˆ19æ—¥"><a href="#2022å¹´07æœˆ19æ—¥" class="headerlink" title="2022å¹´07æœˆ19æ—¥"></a>2022å¹´07æœˆ19æ—¥</h3><ul><li>ç³–æœç…®è›‹</li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-07-19.webp" style="zoom: 50%;" /></p><h3 id="2022å¹´07æœˆ20æ—¥"><a href="#2022å¹´07æœˆ20æ—¥" class="headerlink" title="2022å¹´07æœˆ20æ—¥"></a>2022å¹´07æœˆ20æ—¥</h3><ul><li><p>ç©ºæ°”ç‚¸é”…é¸¡ç±³èŠ±</p></li><li><p>ä¸ç“œç‚’è›‹</p></li><li><p>ç•ªèŒ„é¸¡è›‹æ±¤</p></li><li><p>é’æ¤’åœŸè±†ä¸</p></li></ul><p><img src="/image/æˆ‘çš„2022æš‘å‡ç‹¬å±…ç”Ÿæ´»/2022-07-20.webp" style="zoom: 50%;" /></p>]]></content>
      
      
      <categories>
          
          <category> ç”Ÿæ´» </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>ç¬¬äºŒå±Šç½‘åˆƒæ¯miscæ‰€è§éæ‰€è§wp</title>
      <link href="/p/68ed93d0/"/>
      <url>/p/68ed93d0/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è®°å½•ä¸€ä¸‹è¿™é“æ·±åº¦å­¦ä¹ å…¥é—¨çš„wp</p><span id="more"></span><h2 id="æ€è·¯"><a href="#æ€è·¯" class="headerlink" title="æ€è·¯"></a>æ€è·¯</h2><p>éšè—å±‚çš„è¾“å‡ºä¸º512ï¼Œè¾“å‡ºå±‚çš„è¾“å‡º10ï¼Œå¯¼å…¥æ¨¡å‹å¾—åˆ°æŠ¥é”™ï¼Œç¥ç»ç½‘ç»œçš„è¾“å…¥å¿…é¡»ä¸º<code>(28,28)</code>ï¼Œå†ç”¨ <code>tf.latest_checkpoint</code> å’Œ <code>tf.load_weights</code> å¯¼å…¥æ¨¡å‹æ–‡ä»¶ï¼Œæœ€åè¾“å‡ºæ¦‚ç‡æœ€å¤§çš„é¢„æµ‹ç»“æœç»„æˆ <code>flag</code> ï¼Œç”±äºé¢„æµ‹å›¾ç‰‡åœ¨å‹ç¼©ä¸­æœ‰ç²¾åº¦è¯¯å·®ï¼Œå’ŒçœŸå®ç»“æœä¸åŒï¼Œæ‰€å¹¸èµ›æ–¹ç»™å‡ºäº† <code>hint4</code>ï¼Œä¿®æ”¹ç¬¬4ä½ä¸º 2ã€‚</p><h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models,layers</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">model</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        model = models.Sequential()</span><br><span class="line">        model.add(layers.Flatten(input_shape = (<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br><span class="line">        model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">        model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        model.summary()</span><br><span class="line">        self.model = model</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Predict</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        latest = tf.train.latest_checkpoint(<span class="string">&#x27;./weights&#x27;</span>)</span><br><span class="line">        self.cnn = model()</span><br><span class="line">        self.cnn.model.load_weights(latest)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, image_path</span>):</span><br><span class="line">        img = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&#x27;I&#x27;</span>)</span><br><span class="line">        img = img.resize((<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">        img = np.reshape(img, (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)) / <span class="number">255.</span></span><br><span class="line">        x = np.array([img])</span><br><span class="line">        y = np.argmax(self.cnn.model.predict(x))</span><br><span class="line">        <span class="built_in">print</span>(image_path)</span><br><span class="line">        <span class="built_in">print</span>(y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    p = Predict()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">14</span>):</span><br><span class="line">        p.predict(<span class="string">&#x27;./flag/&#123;&#125;.webp&#x27;</span>.<span class="built_in">format</span>(i))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> misc </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°</title>
      <link href="/p/d43ce4e7/"/>
      <url>/p/d43ce4e7/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å¤šç›®æ ‡ä¼˜åŒ– ( MOO ) - Multi-Objective Optimization</p><p>ä»é—®é¢˜å®šä¹‰ï¼Œå•ç›®æ ‡ã€å¤šç›®æ ‡ï¼Œæ— çº¦æŸã€æœ‰çº¦æŸæ–¹é¢äº†è§£å¤šç›®æ ‡ä¼˜åŒ–</p><span id="more"></span><h2 id="åŸºç¡€"><a href="#åŸºç¡€" class="headerlink" title="åŸºç¡€"></a>åŸºç¡€</h2><h3 id="æ— çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜"><a href="#æ— çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜" class="headerlink" title="æ— çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜"></a>æ— çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜</h3><script type="math/tex; mode=display">\min_{x} f(x),x \in R^{N}</script><h3 id="æ— çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜"><a href="#æ— çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜" class="headerlink" title="æ— çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜"></a>æ— çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜</h3><script type="math/tex; mode=display">\min_{x} F(x) = [f_1(x), f_2(x),\cdots, f_n(x)], x \in R^{N}</script><p>$ n $ ä¸ºå­ç›®æ ‡çš„æ•°é‡ï¼Œ$ f_n(x) $ä¸ºä¸€é˜¶å¯å¯¼ç›®æ ‡å‡½æ•° $F(x)$ çš„å­å‡½æ•°</p><h3 id="æœ‰çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜"><a href="#æœ‰çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜" class="headerlink" title="æœ‰çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜"></a>æœ‰çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜</h3><script type="math/tex; mode=display">\begin{array}{lcl}\min_{x} & f(x) & \\\text { s.t. } & g_{i}(x) \geq 0 & , i \in[1, M] \\& h_{j}(x)=0 & , j \in[1, L]\end{array}</script><p>$\text { s.t. }$ ä¸º <code>subject to</code> ï¼Œå—é™äºçš„ç¼©å†™ï¼Œè®¾ $ D $ ä¸ºå¯è¡ŒåŸŸ</p><script type="math/tex; mode=display">D = \{x | g_i(x) \geq 0, i \in [1, M], h_j(x) =0 , j \in [1,L]  \}</script><h3 id="æœ‰çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜"><a href="#æœ‰çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜" class="headerlink" title="æœ‰çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜"></a>æœ‰çº¦æŸçš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜</h3><script type="math/tex; mode=display">\begin{array}{lcl}\min_x & F(x) = [f_1(x), f_2(x),\cdots, f_n(x)]\\\text{s.t.} & g_i(x) \geq 0 ,\quad i\in(1, M) \\& h_j(x) = 0 ,\quad j \in (1,L)\end{array}</script><p>è®¾ $ D $ ä¸ºå¯è¡ŒåŸŸ</p><script type="math/tex; mode=display">D = \{x | g_i(x) \geq 0, i \in [1, M], h_j(x) =0 , j \in [1,L]  \}</script><h2 id="MOO-çš„è§£é›†"><a href="#MOO-çš„è§£é›†" class="headerlink" title="MOO çš„è§£é›†"></a>MOO çš„è§£é›†</h2><p>å¯¹äº MOOï¼Œé€šå¸¸æ²¡æœ‰è§£  $ x^\ast \in D $, ä½¿ $ f_i(x), \forall i \in [1,N] $  åŒæ—¶å¤„äºæœ€ä¼˜è§£ï¼Œå› æ­¤å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜çš„è§£åœ¨ MOO ä¸­é€šå¸¸ä¸é€‚ç”¨</p><p>MOO ä¸­çš„è§£é›†åˆ†ä¸º <strong>ç»å¯¹æœ‰æ•ˆè§£</strong>ï¼Œ<strong>æœ‰æ•ˆè§£</strong>ï¼Œ<strong>å¼±æœ‰æ•ˆè§£</strong></p><p>è®¾ $R^N $ä¸º $N$ ç»´çš„å®å‘é‡ç©ºé—´ï¼Œ$y=(y_1,y_2,\cdots, y_N)^{T}$ï¼Œ$z=(z_1,z_2,\cdots, z_N)^{T}$</p><script type="math/tex; mode=display">\begin{cases}\text { ç›¸ç­‰ } & y=z \Leftrightarrow y_{i}=z_{i}, i=1,2, \ldots, N \\ \text { ä¸¥æ ¼å°äº } & y<z \Leftrightarrow y_{i}<z_{i}, i=1,2, \ldots, N \\ \text { å°äº } & y \leqq z \Leftrightarrow y_{i} \leqslant z_{i}, i=1,2, \ldots, N \\ \text { å°äºä¸”ä¸ç›¸ç­‰(æ”¯é…) } & y \leqslant z \Leftrightarrow y_{i} \leqslant z_{i}, i=1,2, \ldots, N, y \neq z\end{cases}</script><h3 id="Pareto-æ”¯é…ï¼ˆPareto-Dominanceï¼‰"><a href="#Pareto-æ”¯é…ï¼ˆPareto-Dominanceï¼‰" class="headerlink" title="Pareto æ”¯é…ï¼ˆPareto Dominanceï¼‰"></a>Pareto æ”¯é…ï¼ˆPareto Dominanceï¼‰</h3><p>$ \forall x_1, x_2 \in R^{N}     $ï¼Œ å¯¹äº $ k = 1,\cdots,K $ï¼Œéƒ½æœ‰ $ f_k(x_1) \leqslant f_k(x_2)$ï¼Œåˆ™ $ x_1 $ æ”¯é… $ x_2 $</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/D.webp" style="zoom:67%;" /></p><h3 id="Pareto-è§£é›†ï¼ˆç»å¯¹æœ€ä¼˜è§£ï¼‰"><a href="#Pareto-è§£é›†ï¼ˆç»å¯¹æœ€ä¼˜è§£ï¼‰" class="headerlink" title="Pareto è§£é›†ï¼ˆç»å¯¹æœ€ä¼˜è§£ï¼‰"></a>Pareto è§£é›†ï¼ˆç»å¯¹æœ€ä¼˜è§£ï¼‰</h3><p>$ x^{\ast}{\in}{D} $ ï¼Œ $ \forall x \in D,\quad f(x^\ast) {\leqq} f(x) $ ï¼Œå³ $ \forall k \in 1,\cdots,K, \quad f<em>K(x^\ast) \leqq f</em>{K}(x) $ ï¼Œåˆ™ $ x^\ast $ ä¸º MOO é—®é¢˜çš„æœ€ä¼˜è§£</p><h3 id="Pareto-è§£é›†ï¼ˆæœ‰æ•ˆè§£ï¼‰"><a href="#Pareto-è§£é›†ï¼ˆæœ‰æ•ˆè§£ï¼‰" class="headerlink" title="Pareto è§£é›†ï¼ˆæœ‰æ•ˆè§£ï¼‰"></a>Pareto è§£é›†ï¼ˆæœ‰æ•ˆè§£ï¼‰</h3><p>$x^\ast\in{D}$ ï¼Œè‹¥ $f_k(x)\leq f_k(x^\ast) \wedge \exists i,f_i(x) &lt; f_i(x^\ast),i\in [1,k]$ ä¸æˆç«‹ï¼Œåˆ™ $x^\ast$ æ˜¯ MOO é—®é¢˜çš„æœ‰æ•ˆè§£ï¼Œä¹Ÿå« Pareto æœ€ä¼˜è§£ï¼Œå…¶å«ä¹‰æ˜¯å¦‚æœ $x^\ast$ æ˜¯ Pareto æœ€ä¼˜è§£ï¼Œåˆ™æ‰¾ä¸åˆ°è¿™æ ·çš„å¯è¡Œè§£  $x\in{D}$ ï¼Œä½¿å¾— $f(x)$ çš„æ¯ä¸ªç›®æ ‡å€¼éƒ½ä¸æ¯” $f(x^\ast)$ çš„ç›®æ ‡å€¼å,å¹¶ä¸” $ f (x) $ è‡³å°‘æœ‰ä¸€ä¸ªç›®æ ‡æ¯” $f(x^\ast)$ çš„ç›¸åº”ç›®æ ‡å€¼å¥½ï¼Œå³ $ x^\ast $ æ˜¯æœ€å¥½çš„ï¼Œä¸èƒ½å†è¿›è¡Œæ”¹è¿›ï¼ˆPareto æ”¹è¿›ï¼‰</p><h3 id="Pareto-è§£é›†ï¼ˆå¼±æœ‰æ•ˆè§£ï¼‰"><a href="#Pareto-è§£é›†ï¼ˆå¼±æœ‰æ•ˆè§£ï¼‰" class="headerlink" title="Pareto è§£é›†ï¼ˆå¼±æœ‰æ•ˆè§£ï¼‰"></a>Pareto è§£é›†ï¼ˆå¼±æœ‰æ•ˆè§£ï¼‰</h3><p>$x^\ast\in{D}$ ï¼Œå¦‚æœä¸å­˜åœ¨ $x\in{D}$ï¼Œä½¿å¾— $f(x)&lt;f(x^\ast)$ ï¼Œå³</p><script type="math/tex; mode=display">f_k(x) < f_k(x^*) \quad \wedge \quad \forall k \in [1,K]</script><p>åˆ™ $x^\ast$ æ˜¯ MOO é—®é¢˜çš„æœ‰æ•ˆè§£ï¼Œå…¶å«ä¹‰æ˜¯å¦‚æœ $x^\ast$ æ˜¯å¼±æœ‰æ•ˆè§£,åˆ™æ‰¾ä¸åˆ°è¿™æ ·çš„å¯è¡Œè§£ $x\in{D}$ï¼Œä½¿å¾— $f(x)$ çš„æ¯ä¸ªç›®æ ‡å€¼éƒ½æ¯” $f(x^\ast)$ çš„ç›®æ ‡å€¼ä¸¥æ ¼ï¼ˆ $&lt;$ ï¼‰çš„å¥½</p><h3 id="Pareto-æœ€ä¼˜è§£é›†ï¼ˆPareto-optimal-Setï¼‰"><a href="#Pareto-æœ€ä¼˜è§£é›†ï¼ˆPareto-optimal-Setï¼‰" class="headerlink" title="Pareto æœ€ä¼˜è§£é›†ï¼ˆPareto-optimal Setï¼‰"></a>Pareto æœ€ä¼˜è§£é›†ï¼ˆPareto-optimal Setï¼‰</h3><p>ç»™å®šé—®é¢˜çš„æœ‰æ•ˆè§£é›†ï¼ˆPareto æœ€ä¼˜è§£ï¼‰æ„æˆçš„è§£é›†ï¼Œé›†åˆä¸­çš„è§£æ˜¯ç›¸äº’éæ”¯é…çš„ï¼Œä¸¤ä¸¤éæ”¯é…å…³ç³»ï¼Œç®€ç§° $PS$</p><h3 id="Pareto-æœ€ä¼˜å‰æ²¿ï¼ˆPareto-optimal-Frontï¼‰"><a href="#Pareto-æœ€ä¼˜å‰æ²¿ï¼ˆPareto-optimal-Frontï¼‰" class="headerlink" title="Pareto æœ€ä¼˜å‰æ²¿ï¼ˆPareto-optimal Frontï¼‰"></a>Pareto æœ€ä¼˜å‰æ²¿ï¼ˆPareto-optimal Frontï¼‰</h3><p>Pareto æ¯ä¸€ä¸ªè§£å¯¹åº”çš„ç›®æ ‡å€¼å‘é‡ç»„æˆçš„é›†åˆï¼Œç®€ç§° $PF$</p><script type="math/tex; mode=display">PF = \{F(x)|x\in PS\}</script><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/PF.webp" style="zoom:50%;" /></p><h3 id="MOO-çš„æœ€ä¼˜æ€§æ¡ä»¶"><a href="#MOO-çš„æœ€ä¼˜æ€§æ¡ä»¶" class="headerlink" title="MOO çš„æœ€ä¼˜æ€§æ¡ä»¶"></a>MOO çš„æœ€ä¼˜æ€§æ¡ä»¶</h3><p>çº¦æŸè§„æ ¼å®šä¹‰ï¼šå¯¹ä¼˜åŒ–é—®é¢˜çš„çº¦æŸå‡½æ•°ï¼Œé™„åŠ æŸäº›é™åˆ¶æ¡ä»¶ï¼Œä½¿å¾—å…¶æœ€ä¼˜è§£æ»¡è¶³çš„æœ€ä¼˜æ€§æ¡ä»¶</p><p>ä¸‹é¢ç»™å‡ºä¸€ä¸ªä¸¥æ ¼æ¡ä»¶ä¸‹å¤šç›®æ ‡ä¼˜åŒ–çš„å……åˆ†å¿…è¦æ¡ä»¶ï¼Œç»™å‡ºçš„å……è¦æ¡ä»¶å‰ï¼Œå…ˆå¼•å…¥äº†çº¦æŸè§„æ ¼æ¡ä»¶</p><script type="math/tex; mode=display">\begin{aligned}\min _{x \in \hat{D}} F(x) &=\sum_{k=1}^{K} f_{k}(x) \\\hat{D} &=x \in D \mid f(x) \leq f(\hat{x})\end{aligned}</script><p>å®šç†ï¼šè®¾ $ f (x)$ ï¼Œ$ g(x) $ ä¸ºå‡¸å‡½æ•°,ä¸”åœ¨ $x \in D$ å¤„å¯å¾®ï¼Œ$h(x)$ ä¸ºçº¿æ€§å‡½æ•°ï¼Œä¸” $\hat{D} = x \in D|f (x) \leq f (\hat{x})$ æ»¡è¶³ $ KKT $ çº¦æŸè§„æ ¼ï¼Œåˆ™ $x^\ast$ æ˜¯ MOO çš„æœ‰æ•ˆè§£çš„å……åˆ†å¿…è¦æ¡ä»¶æ˜¯å­˜åœ¨ $ \lambda \in  R^K , u \in R^M , v \in R^L$ï¼Œ ä½¿å¾—</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\nabla_{x} L\left(x^{*}, \lambda^{*}, u^{*}, v^{*}\right)=\nabla f\left(x^{*}\right) \lambda^{*}+\nabla g\left(x^{*}\right) u^{*}+\nabla h\left(x^{*}\right) v^{*}=0 \\u^{* T} g\left(x^{*}\right)=0 \\\lambda^{*}>0, u^{*} \geq 0\end{array}\right.</script><h2 id="MOO-çš„ç»å…¸ç®—æ³•"><a href="#MOO-çš„ç»å…¸ç®—æ³•" class="headerlink" title="MOO çš„ç»å…¸ç®—æ³•"></a>MOO çš„ç»å…¸ç®—æ³•</h2><h3 id="çº¿æ€§åŠ æƒæ³•"><a href="#çº¿æ€§åŠ æƒæ³•" class="headerlink" title="çº¿æ€§åŠ æƒæ³•"></a>çº¿æ€§åŠ æƒæ³•</h3><p>æ ¹æ® $f(x)$ çš„é‡è¦ç¨‹åº¦ï¼Œè®¾å®šæƒé‡è¿›è¡Œçº¿æ€§åŠ æƒ</p><script type="math/tex; mode=display">\begin{array}{r}& \min _{x} \sum_{k=1}^{K} \lambda_{k} f_{k}(x) \\\text { s.t. } & g_{i}(x) \geq 0,\quad i \in[1, M] \\& h_{j}(x)=0,\quad j \in[1, L]\end{array}</script><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/weight.webp" style="zoom:67%;" /></p><p>äºæ˜¯å°±å˜æˆäº†å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼Œä¸Šè¿°é—®é¢˜å­˜åœ¨æœ‰æ•ˆè§£çš„æ¡ä»¶ï¼Œå¯¹äºç»™å®šçš„ $\lambda \in \Lambda^{++}$ ï¼Œåˆ™ä¸Šè¿°é—®é¢˜çš„æœ€ä¼˜è§£æ˜¯ MOO é—®é¢˜çš„æœ‰æ•ˆè§£ï¼Œå…¶ä¸­</p><script type="math/tex; mode=display">\Lambda^{++}=\left\{\lambda \mid \lambda_{k}>0, k=1,2 \ldots K, \sum_{k=1}^{K} \lambda_{k}=1\right\}</script><ul><li>ä¼˜ç‚¹ï¼šå®ç°ç®€å•ï¼Œæœ‰æˆç†Ÿçš„ç®—æ³•æ±‚è§£</li><li>ç¼ºç‚¹ï¼š$\lambda_k$ éš¾ä»¥ç¡®å®šï¼Œæ±‚å‡ºçš„è§£çš„ä¼˜åŠ£æ— æ³•ç¡®å®š</li></ul><h3 id="ä¸»è¦ç›®æ ‡æ³•"><a href="#ä¸»è¦ç›®æ ‡æ³•" class="headerlink" title="ä¸»è¦ç›®æ ‡æ³•"></a>ä¸»è¦ç›®æ ‡æ³•</h3><p>ä¹Ÿç§° $\epsilon$-çº¦æŸæ–¹æ³•</p><script type="math/tex; mode=display">\begin{array}{l}& \min _{x} & f_{p}(x) \\\text { s.t. } & f_{k}(x) &\leq \epsilon_{k} &,k=1, \ldots, K, k \neq p \\& g_{i}(x) &\geq 0, i \in[1, M] \\& h_{j}(x) &= 0, j \in[1, L]\end{array}</script><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/constraint.webp" style="zoom: 67%;" /></p><p>$\epsilon$-çº¦æŸæ–¹æ³•ä» $K$ ä¸ªç›®æ ‡ä¸­é€‰æ‹©æœ€é‡è¦çš„å­ç›®æ ‡ä½œä¸ºä¼˜åŒ–ç›®æ ‡,å…¶ä½™çš„å­ç›®æ ‡ä½œä¸ºçº¦æŸæ¡ä»¶ã€‚æ¯ä¸ªå­ç›®æ ‡,é€šè¿‡ä¸Šç•Œ $\epsilon_{K}$ æ¥çº¦æŸ</p><h4 id="ä¸»è¦ç›®æ ‡æ³•æœ€ä¼˜è§£å’Œ-MOO-è§£é›†çš„å…³ç³»"><a href="#ä¸»è¦ç›®æ ‡æ³•æœ€ä¼˜è§£å’Œ-MOO-è§£é›†çš„å…³ç³»" class="headerlink" title="ä¸»è¦ç›®æ ‡æ³•æœ€ä¼˜è§£å’Œ MOO è§£é›†çš„å…³ç³»"></a>ä¸»è¦ç›®æ ‡æ³•æœ€ä¼˜è§£å’Œ MOO è§£é›†çš„å…³ç³»</h4><ul><li><p>ä¸»è¦ç›®æ ‡æ³•æœ€ä¼˜è§£æ˜¯ MOO è§£çš„å¼±æœ‰æ•ˆè§£</p></li><li><p>è‹¥ä¸»è¦ç›®æ ‡ $f_p (x)$ æ˜¯ä¸¥æ ¼å‡¸å‡½æ•°ï¼Œå¯è¡ŒåŸŸä¸º $\hat{D}$ çš„å‡¸é›†ï¼Œåˆ™ä¸»è¦ç›®æ ‡æ³•æœ€ä¼˜è§£æ˜¯ MOO è§£çš„æœ‰æ•ˆè§£</p></li></ul><h4 id="ç•Œé™å€¼-epsilon-çš„é€‰å–"><a href="#ç•Œé™å€¼-epsilon-çš„é€‰å–" class="headerlink" title="ç•Œé™å€¼ $\epsilon$ çš„é€‰å–"></a>ç•Œé™å€¼ $\epsilon$ çš„é€‰å–</h4><p>å¯ä»¥å–å­ç›®æ ‡å‡½æ•°çš„ä¸Šé™å€¼</p><script type="math/tex; mode=display">\min \left\{f_{k} \mid f_{k}(x), k=1, \ldots, K, k \neq p\right\} \leq \epsilon_{k}</script><p>è¿™ç§å–æ³•å¯ä»¥ä½¿å¾—æŸäº› $f_k(x)$ ç•™åœ¨å¯è¡ŒåŸŸ $\hat{D}$ å†…,å¹¶ä¸” $\hat{D}$ å†…æœ‰è¾ƒå¤šçš„ç‚¹é è¿‘ $f_k (x)$ çš„æœ€ä¼˜è§£</p><ul><li>ä¼˜ç‚¹ï¼šç®€å•ï¼Œèƒ½åº”ç”¨åˆ°å‡¸å‡½æ•°å’Œéå‡¸å‡½æ•°åœºæ™¯ä¸‹</li><li>ç¼ºç‚¹ï¼š$\epsilon_k$ å¦‚æœå–å€¼ä¸åˆé€‚ï¼Œå¯è¡ŒåŸŸ $\hat{D}$ å¯èƒ½ä¸ºç©ºå€¼</li></ul><h3 id="é€¼è¿‘ç›®æ ‡æ³•"><a href="#é€¼è¿‘ç›®æ ‡æ³•" class="headerlink" title="é€¼è¿‘ç›®æ ‡æ³•"></a>é€¼è¿‘ç›®æ ‡æ³•</h3><p>æå‡ºä¸€ä¸ªç›®æ ‡å€¼ $f^0 = (f_1^0,f_2^0,\cdots,f_k^0)$ï¼Œä½¿å¾—æ¯ä¸ªç›®æ ‡å‡½æ•° $f_k(x)$ éƒ½é€¼è¿‘å¯¹åº”çš„ç›®æ ‡å€¼</p><script type="math/tex; mode=display">\begin{array}{l}L = (f(x), f^0) & = ||f(x) - f^0 ||^{\lambda}_{2} \\&= \sum_{k=1}^{K} \lambda_k(f_k(x)-f^0)^2,\lambda \in \Lambda^{++}\end{array}</script><p>å’Œæœºå™¨å­¦ä¹ ä¸­çš„æŸå¤±å‡½æ•°ç±»ä¼¼ï¼Œæ˜¯ä¸€ä¸ªå•ç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ç»å…¸çš„æ–¹æ³•è¿›è¡Œæ±‚è§£ï¼Œè¿™é‡Œæ±‚è§£çš„æœ€ä¼˜è§£å’Œæœ‰æ•ˆè§£åŠå¼±æœ‰æ•ˆè§£æ²¡æœ‰ç›´æ¥çš„è”ç³»ï¼Œåæ˜ äº†å†³ç­–è€…å¸Œæœ›çš„ç›®æ ‡å€¼</p><h3 id="æ¢¯åº¦ä¸‹é™ç®—æ³•"><a href="#æ¢¯åº¦ä¸‹é™ç®—æ³•" class="headerlink" title="æ¢¯åº¦ä¸‹é™ç®—æ³•"></a>æ¢¯åº¦ä¸‹é™ç®—æ³•</h3><p>è¿™æ˜¯ä¸€ç§ç›´æ¥ä¼˜åŒ–çš„æ–¹æ³•ï¼Œè€Œä¸Šé¢æåˆ°çš„ç®—æ³•éƒ½æ˜¯é‡‡å–å…ˆéªŒçš„çŸ¥è¯†å°†å¤šç›®æ ‡ä¼˜åŒ–è½¬åŒ–æˆå•ç›®æ ‡ä¼˜åŒ–</p><h4 id="æœ€é€Ÿæ¢¯åº¦ä¸‹é™"><a href="#æœ€é€Ÿæ¢¯åº¦ä¸‹é™" class="headerlink" title="æœ€é€Ÿæ¢¯åº¦ä¸‹é™"></a>æœ€é€Ÿæ¢¯åº¦ä¸‹é™</h4><p>ç®€å•èµ·è§ï¼Œå°†è®¨è®ºé—®é¢˜é™åˆ¶åœ¨æ— çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶è¦æ±‚æ— çº¦æŸçš„å•ç›®æ ‡ä¼˜åŒ–é—®é¢˜ä¸­çš„ $f (x)$ å…·æœ‰ä¸€é˜¶è¿ç»­åå¯¼æ•°ï¼Œå¯¹äºè¿™ç±»é—®é¢˜ï¼Œèƒ½å¤Ÿä»æŸä¸€ç‚¹å‡ºå‘ï¼Œé€‰æ‹©ç›®æ ‡å‡½æ•° $f (x) $ ä¸‹é™æœ€å¿«çš„æ–¹å‘è¿›è¡Œæœç´¢ï¼Œå°½å¿«è¾¾åˆ°æœ€å°å€¼ï¼Œé—®é¢˜æ˜¯å¦‚ä½•é€‰æ‹©ä¸‹é™æœ€å¿«çš„æ–¹å‘</p><script type="math/tex; mode=display">DF(x;d) = \nabla f(x)^T d</script><p>æ±‚ $f(x)$ åœ¨ç‚¹ $x$ å¤„çš„ä¸‹é™æœ€å¿«çš„æ–¹å‘å¯¼æ•°ï¼Œå½’ç»“ä¸ºæ±‚å¦‚ä¸‹æœ€ä¼˜åŒ–é—®é¢˜</p><script type="math/tex; mode=display">\min \nabla f(x)^T d \\\text{s.t.} \quad ||d|| \leq 1</script><p>å…¶ä¸­ $||\cdot||$ ä¸ºæ¬§å¼è·ç¦»ï¼Œä¸Šè¿°é—®é¢˜çš„è§£ä¸º</p><script type="math/tex; mode=display">d = -\frac{\nabla f(x)}{||\nabla f(x)||}</script><p>è´Ÿæ¢¯åº¦æ–¹å‘ä¸ºæœ€é€Ÿä¸‹é™æ–¹å‘ï¼Œæœ€é€Ÿä¸‹é™æ³•çš„è¿­ä»£å…¬å¼ä¸º</p><script type="math/tex; mode=display">x^{t+1} = x^t + \lambda_k d^{(k)}</script><p>å…¶ä¸­ï¼Œ$\lambda _k$ å¯ä»¥é€šè¿‡ä¸€ç»´æœç´¢æ¥å¾—åˆ°</p><h4 id="å¤šç›®æ ‡æ¢¯åº¦ä¸‹é™ç®—æ³•"><a href="#å¤šç›®æ ‡æ¢¯åº¦ä¸‹é™ç®—æ³•" class="headerlink" title="å¤šç›®æ ‡æ¢¯åº¦ä¸‹é™ç®—æ³•"></a>å¤šç›®æ ‡æ¢¯åº¦ä¸‹é™ç®—æ³•</h4><p>è®¾å½“å‰ä¸º $t+1$ è½®è¿­ä»£ï¼Œæ¢¯åº¦è¿­ä»£å…¬å¼</p><script type="math/tex; mode=display">x^{t+1} = x^t + \lambda \cdot d^{t}</script><p>å¤šç›®æ ‡ä¼˜åŒ–çš„æ–¹å‘å¯¼æ•°</p><script type="math/tex; mode=display">\nabla f_k(x)^T d,k = 1,2,\cdots,K</script><p>å®šä¹‰æœ€å¤§æ–¹å‘å¯¼æ•°</p><script type="math/tex; mode=display">M_x(d^t) = max\{ \nabla f_k(x)^T d^t \mid k = 1,2,\cdots,K\}</script><p>å¤šç›®æ ‡é—®é¢˜çš„æœ€é€Ÿæ¢¯åº¦ä¸‹é™æ–¹å‘ï¼Œå¯ä»¥å½’ç»“ä¸ºæ±‚è§£ä»¥ä¸‹é—®é¢˜</p><script type="math/tex; mode=display">\begin{array}{l}\min & M_x(d^t) + \frac{1}{2} \| d^t \| ^2 \\\text{s.t.} & d^t \in R\end{array}</script><p>ä¸Šè¿°ä¼˜åŒ–é—®é¢˜æ˜¯é—­ä¸”å¼ºå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œä¸€å®šå­˜åœ¨æœ€ä¼˜è§£ï¼Œä»¤ $M_x (d^t) = \alpha$ï¼Œå¯ä»¥å°†ä¸€é˜¶åå¯¼é¡¹æ¶ˆå»</p><script type="math/tex; mode=display">\begin{array}{l}\min & \alpha + \frac{1}{2} \|d^t \|^2 \\\text{s.t.} & \nabla f_k(x)^T d^t \leq \alpha ,k = 1,2,\cdots,K \\& d^t \in R\end{array}</script><p>ä¸Šè¿°é—®é¢˜ä¸ºå¸¦çº¿æ€§ä¸ç­‰å¼çº¦æŸçš„å‡¸äºŒæ¬¡è§„åˆ’é—®é¢˜</p><p>ä»¤ $d^\ast$ï¼Œ$a^\ast$ ä¸ºä¸Šè¿°ä¼˜åŒ–é—®é¢˜çš„æœ€ä¼˜è§£ï¼Œå¾—åˆ°</p><ul><li>è‹¥ $x^\ast$ ä¸º Pareto æœ€ä¼˜ï¼Œåˆ™ $d^\ast=0,a^\ast=0$ </li><li>è‹¥ $x^\ast$ ä¸ä¸º Pareto æœ€ä¼˜ï¼Œåˆ™ $a^\ast&lt;0$</li></ul><p>ä¸”</p><script type="math/tex; mode=display">\alpha  \leq-\frac{1}{2} \|\left. d^{t}\right|^{2}<0 \\\nabla f_{k}(x)^{T} d^{t}  \leq \alpha, k=1, \cdots, K</script><p>å› æ­¤</p><ul><li>å¦‚æœ $d^\ast = 0$ï¼Œåˆ™è¯´æ˜æ­¤æ—¶ä¸å­˜åœ¨ä¸‹é™æ–¹å‘,ä½¿å¾—æ‰€æœ‰çš„ç›®æ ‡éƒ½ä¸‹é™</li><li>å¦‚æœ $d^\ast \neq 0$ï¼Œåˆ™æœ‰ $\nabla f_{k}(x)^{T} d^{t} &lt; 0$ï¼Œåˆ™ $d^t$ æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å¤šç›®æ ‡æœç´¢æ–¹å‘ï¼ŒæŒ‰å¦‚ä¸‹å…¬å¼æ›´æ–°ï¼Œå³å¯ä»¥ä½¿ç›®æ ‡å‡½æ•°ä¸‹é™</li></ul><script type="math/tex; mode=display">\begin{array}{l}x^{(t+1)}&=& x^{t}+\lambda \cdot d^{t} \\f_{k}\left(x^{(t+1)}\right) &\leq& f_{k}\left(x^{t}\right), k=1, \ldots, K\end{array}</script><h2 id="å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰"><a href="#å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰" class="headerlink" title="å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰"></a>å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰</h2><p>å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰- Multi-Task Learning</p><h3 id="å®šä¹‰"><a href="#å®šä¹‰" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h3><p>åœ¨åŒä¸€æ—¶é—´å­¦ä¹ å¤šä¸ªä»»åŠ¡ï¼Œæ±‚å¾—æœ€ä¼˜è§£</p><p>è®¾æœ‰ $N$ ä¸ªæ ·æœ¬ç‚¹ ${ x,y_i^1,y_i^2,\cdots, y_i^T},i \in N$ï¼Œå…¶ä¸­ $T$ ä¸ºä»»åŠ¡æ•°é‡ï¼Œ$y_i^t$ æ˜¯ç¬¬ $t^{th}$ ä¸ªä»»åŠ¡ï¼Œç¬¬ $i^{th}$ ä¸ªæ ·æœ¬ç‚¹æ ‡ç­¾ï¼Œå®šä¹‰ä¸º</p><script type="math/tex; mode=display">f^t(x;\theta^{sh},\theta^t):X \rightarrow Y^t</script><p>å…¶ä¸­ $\theta^{sh}$ ä¸ºå¤šä¸ªä»»åŠ¡çš„å…±äº«å‚æ•°ï¼Œ$\theta^t$ ä¸ºå•ä¸ªä»»åŠ¡çš„ç‹¬æœ‰å‚æ•°</p><p>$Loss$ ä¸º</p><script type="math/tex; mode=display">L^t(\_,\_) = Y^t \times Y^t \rightarrow R^+</script><script type="math/tex; mode=display">\min_{\theta^{sh} ,\theta} = \sum_{t=1}^{T} c^t \hat{L}^{t}(\theta^{sh},\theta)</script><p>$c^t$ ä¸ºæ¯ä¸ªå…·ä½“ä»»åŠ¡çš„æƒé‡ï¼Œæ¯ä¸ªå…·ä½“ä»»åŠ¡ $t$ çš„ $Loss$ ä¸º</p><script type="math/tex; mode=display">\hat{L}^t(\theta^{sh},\theta) \triangleq \frac{1}{N} \sum_t L(f^t(x;\theta^{sh}, \theta^t), y^t_i)</script><h3 id="å¤šä»»åŠ¡å­¦ä¹ è½¬åŒ–ä¸ºå¤šç›®æ ‡ä¼˜åŒ–"><a href="#å¤šä»»åŠ¡å­¦ä¹ è½¬åŒ–ä¸ºå¤šç›®æ ‡ä¼˜åŒ–" class="headerlink" title="å¤šä»»åŠ¡å­¦ä¹ è½¬åŒ–ä¸ºå¤šç›®æ ‡ä¼˜åŒ–"></a>å¤šä»»åŠ¡å­¦ä¹ è½¬åŒ–ä¸ºå¤šç›®æ ‡ä¼˜åŒ–</h3><p>å°†å¤šä»»åŠ¡å­¦ä¹ è½¬æ¢ä¸º MOO é—®é¢˜æ±‚è§£ï¼Œå®šä¹‰</p><script type="math/tex; mode=display">\min _{\theta^{s h}, \theta} L\left(\theta^{s h}, \theta^{1}, \ldots, \theta^{T}\right)=\min _{\theta^{s h}, \theta}\left(\hat{L}^{1}\left(\theta^{s h}, \theta^{1}\right), \cdots, \hat{L}^{T}\left(\theta^{s h}, \theta^{T}\right)\right)</script><p>å¤šç›®æ ‡ä¼˜åŒ–çš„ç›®çš„æ˜¯æ±‚å¾— Pareto æœ€ä¼˜è§£ï¼Œå¤šç›®æ ‡ä¼˜åŒ–çš„ Pareto æœ€ä¼˜è§£å®šä¹‰</p><p>ä¸€ä¸ªè§£ $\theta$ æ”¯é…å¦ä¸€ä¸ªè§£ $\bar{\theta}$ ï¼Œå¦‚æœ</p><script type="math/tex; mode=display">\hat{L}(\theta^{sh},\theta^t) \leq \hat{L}(\bar{\theta}^{sh},\bar{\theta}^t)</script><p>å¯¹äºæ‰€æœ‰çš„ä»»åŠ¡ $t$ éƒ½æˆç«‹ï¼Œä¸”</p><script type="math/tex; mode=display">L(\theta^{sh},\theta^1,\theta^2,\cdots,\theta^{T}) \neq L(\bar{\theta}^{sh},\bar{\theta}^1,\bar{\theta}^2,\cdots, \bar{\theta}^T)</script><p>ä¸€ä¸ªè§£ $\theta^{\ast}$ ç§°ä¸º Pareto æœ€ä¼˜è§£çš„é›†åˆç§°ä¸º Pareto æœ€ä¼˜è§£é›†ï¼Œå…¶å›¾åƒç§°ä¸º Pareto å‰æ²¿ï¼ˆPareto Frontï¼‰</p><h2 id="å¤šä»»åŠ¡æ±‚è§£ï¼šå•ä¸ª-Pareto-è§£"><a href="#å¤šä»»åŠ¡æ±‚è§£ï¼šå•ä¸ª-Pareto-è§£" class="headerlink" title="å¤šä»»åŠ¡æ±‚è§£ï¼šå•ä¸ª Pareto è§£"></a>å¤šä»»åŠ¡æ±‚è§£ï¼šå•ä¸ª Pareto è§£</h2><h3 id="é—®é¢˜è½¬åŒ–"><a href="#é—®é¢˜è½¬åŒ–" class="headerlink" title="é—®é¢˜è½¬åŒ–"></a>é—®é¢˜è½¬åŒ–</h3><p>å•ä¸ª Pareto è§£ä½¿ç”¨äº†å¤šé‡æ¢¯åº¦ä¸‹é™æ³•ï¼Œç”±å¤šç›®æ ‡ä¼˜åŒ–çš„ $KKT$ æ¡ä»¶ï¼Œå¾—</p><p>å­˜åœ¨ $\alpha^1,\alpha^2,\cdots,\alpha^T \geq 0$ï¼Œä½¿å¾—</p><script type="math/tex; mode=display">\begin{array}{r}\sum_{t=1}^{T} \alpha^T = 1 \\\sum_{t=1}^{T} \alpha^t \nabla_{\theta^{sh}} \hat{L}(\theta^{sh},\theta^{t}) = 0\end{array}</script><p>å¯¹åº”æ‰€æœ‰çš„ä»»åŠ¡ $t$</p><script type="math/tex; mode=display">\nabla_{\theta^t}\hat{L}(\theta^{sh},\theta^t) = 0</script><p>æ»¡è¶³ä¸Šå¼çš„è§£ç§°ä¸º Pareto å¹³è¡¡ç‚¹ï¼ˆPareto Stationary Pointï¼‰ï¼ŒPareto æœ€ä¼˜ç‚¹éƒ½æ˜¯ Pareto å¹³ç¨³ç‚¹ï¼Œåä¹‹ä¸ä¸€å®šæˆç«‹ï¼Œè€ƒè™‘å¦‚ä¸‹çš„ä¼˜åŒ–é—®é¢˜</p><script type="math/tex; mode=display">\begin{gathered}\min _{\alpha^{1}, \cdots ,\alpha^{T}}\left\|\sum_{t=1}^{T} \alpha^{t} \nabla_{\theta s h} \hat{L}^{t}\left(\theta^{s h}, \theta^{t}\right)\right\| \\\sum_{t=1}^{T} \alpha^{t}=1, \alpha^{t} \geq 0, \forall t\end{gathered}</script><p>ä¸Šè¿°ä¼˜åŒ–é—®é¢˜çš„è§£å­˜åœ¨ä¸¤ç§æƒ…å†µ</p><ul><li>æœ€ä¼˜å€¼ $=0$ï¼Œåˆ™å¯¹åº”çš„è§£æ»¡è¶³ $KKT$ æ¡ä»¶</li><li>æœ€ä¼˜å€¼ $\neq 0$ï¼Œåˆ™å¯¹åº”çš„è§£ç»™å‡ºäº†ä¸‹é™æ–¹å‘ï¼Œä½¿å¾—å¤šä»»åŠ¡ç›®æ ‡å‡½æ•°æå‡ï¼ˆå‡½æ•°å€¼ä¸‹é™ï¼‰ä¸Šè¿°ä¼˜åŒ–é—®é¢˜ç­‰ä»·äºåœ¨è¾“å…¥ç‚¹é›†å‡¸åŒ…ä¸­æ‰¾åˆ°æœ€å°æ¨¡ç‚¹</li></ul><h3 id="ä¸¤ä¸ªä»»åŠ¡çš„æƒ…å½¢"><a href="#ä¸¤ä¸ªä»»åŠ¡çš„æƒ…å½¢" class="headerlink" title="ä¸¤ä¸ªä»»åŠ¡çš„æƒ…å½¢"></a>ä¸¤ä¸ªä»»åŠ¡çš„æƒ…å½¢</h3><p>ç”±å¤šç›®æ ‡ä¼˜åŒ–çš„ $KKT$ æ¡ä»¶ï¼Œå¾—</p><script type="math/tex; mode=display">\begin{gathered}\min _{\alpha^{1}, \ldots \alpha^{T}}\|\gamma \theta+(1-\gamma) \bar{\theta}\| \\\gamma+(1-\gamma)=1, \gamma \geq 0\end{gathered}</script><p>å…¶ä¸­ $\theta,\bar{\theta}$ å®šä¹‰ä¸º</p><script type="math/tex; mode=display">\begin{aligned}&\theta \triangleq \nabla_{\theta s h} \hat{L}^{1}\left(\theta^{s h}, \theta^{1}\right) \\&\bar{\theta} \triangleq \nabla_{\theta s h} \hat{L}^{2}\left(\theta^{s h}, \theta^{2}\right)\end{aligned}</script><p>å…¶è§£çš„æƒ…å†µæšä¸¾å¦‚ä¸‹</p><ul><li>å½“ $\theta^T \bar{\theta} \geq \theta^T \theta,\gamma = 1$</li><li>å½“ $\theta^T \bar{\theta} \geq \bar{\theta}^T \bar{\theta},\gamma = 0$</li><li>$\text{otherwise}$</li></ul><script type="math/tex; mode=display">\gamma=\frac{(\bar{\theta}-\theta)^{T} \bar{\theta}}{\| \bar{\theta}-\theta) \|_{2}^{2}}p7</script><p>å‡ ä½•è§£é‡Š</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/interpret.webp" style="zoom:66%;" /></p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/algo1.webp" style="zoom:60%;" /></p><p>åŸºäº Frank-wolfe ç®—æ³•ï¼Œå¾—æ±‚è§£ MTL ä»»åŠ¡ç®—æ³•</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/algo2.webp" style="zoom: 66%;" /></p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/frankwolfesolver.webp" style="zoom:62%;" /></p><h2 id="å¤šä»»åŠ¡æ±‚è§£ï¼šå¤šä¸ª-Pareto-è§£"><a href="#å¤šä»»åŠ¡æ±‚è§£ï¼šå¤šä¸ª-Pareto-è§£" class="headerlink" title="å¤šä»»åŠ¡æ±‚è§£ï¼šå¤šä¸ª Pareto è§£"></a>å¤šä»»åŠ¡æ±‚è§£ï¼šå¤šä¸ª Pareto è§£</h2><p>ä¸Šä¸€èŠ‚ä»‹ç»çš„æ–¹æ³•åªèƒ½æ±‚å¾—ä¸€ä¸ª pareto è§£ï¼Œæœ‰æ—¶éœ€è¦å¤šä¸ª pareto è§£æ‰èƒ½åšå‡ºæ›´å¥½çš„å†³ç­–</p><h3 id="ä¸»è¦æ€æƒ³"><a href="#ä¸»è¦æ€æƒ³" class="headerlink" title="ä¸»è¦æ€æƒ³"></a>ä¸»è¦æ€æƒ³</h3><p>å°†å¤šä»»åŠ¡å­¦ä¹ åˆ†è§£ä¸ºå¤šä¸ªå¸¦çº¦æŸçš„å¤šç›®æ ‡å­é—®é¢˜ï¼Œé€šè¿‡å¯¹å­é—®é¢˜è¿›è¡Œå¹¶è¡Œæ±‚è§£</p><p>åŸå§‹å¤šä»»åŠ¡å­¦ä¹ å®šä¹‰</p><script type="math/tex; mode=display">\min_{\theta} L(\theta) = (L_1(\theta),L_2(\theta),\cdots,L_i(\theta),\cdots,L_m(\theta))</script><p>$L_i(\theta)$ æ˜¯ç¬¬ $i$ ä¸ªä»»åŠ¡çš„æŸå¤±å‡½æ•°</p><p>ä¸‹å›¾æ‰€ç¤º</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/pareto1.webp" style="zoom:60%;" /></p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/pareto2.webp" style="zoom:60%;" /></p><p>ç”¨ä¸€ç»„åˆ†å¸ƒè‰¯å¥½çš„ Preference Vectorsï¼ˆPVï¼‰å°†å¤šä»»åŠ¡å­¦ä¹ çš„ç›®æ ‡ç©ºé—´åˆ†è§£ä¸º $K$ ä¸ªå­åŒºåŸŸ</p><script type="math/tex; mode=display">PV = \{u_1,u_2,\cdots,u_k,\cdots,u_K\},u_k \in R_+^m</script><p>é‡æ–°å®šä¹‰å¤šä»»åŠ¡å­¦ä¹ </p><script type="math/tex; mode=display">\min_{\theta} L(\theta) = (L_1(\theta),L_2(\theta),L_m(\theta)) \\s.t. \quad L(\theta) \in \Omega_k,k = 1,\cdots,K</script><p>$\Omega_k$ æ˜¯ç›®æ ‡ç©ºé—´çš„å­åŒºåŸŸ</p><script type="math/tex; mode=display">\Omega_k = \{v \in R_+^m | u_j^T v \leq u_k^Tv,\forall j = 1,\cdots,K \}</script><p>$\Omega_k$ ä¸­çš„å…ƒç´  $v$</p><script type="math/tex; mode=display">v \in \Omega_k \Leftrightarrow u_k^T v = \| u_k \| \cdot \| v \| \cos{\alpha}</script><p>$u_k^T v$ ä¸ºæœ€å¤§çš„å†…ç§¯</p><p>é‡æ–°å®šä¹‰å¤šä»»åŠ¡å­¦ä¹ </p><script type="math/tex; mode=display">\begin{array}{l}& \min_\theta L(\theta) = (L_1(\theta),L_2(\theta),L_m(\theta)) \\\text{s.t.} & G_j(\theta_t) = (u_j - u_k)^T \\& L(\theta_t) \leq 0 \\& j=1,\cdots,K\end{array}</script><p>è¿™æ ·å¾—åˆ°çš„è§£é›†å°†ä¼šåˆ†å¸ƒåœ¨ä¸åŒçš„å­åŒºåŸŸ $\Omega_k$</p><h3 id="å­é—®é¢˜çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•"><a href="#å­é—®é¢˜çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•" class="headerlink" title="å­é—®é¢˜çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•"></a>å­é—®é¢˜çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•</h3><h4 id="å¯»æ‰¾åˆå§‹è§£-theta-r"><a href="#å¯»æ‰¾åˆå§‹è§£-theta-r" class="headerlink" title="å¯»æ‰¾åˆå§‹è§£ $\theta_r$"></a>å¯»æ‰¾åˆå§‹è§£ $\theta_r$</h4><p>æ±‚è§£å¤šä»»åŠ¡å­¦ä¹ ï¼Œéœ€è¦æ‰¾åˆ°ä¸€ä¸ªæ»¡è¶³çº¦æŸçš„åŸºæœ¬å¯è¡Œè§£ï¼Œå¯¹äºéšæœºäº§ç”Ÿçš„å¯è¡Œè§£ $\theta_r$ ï¼Œä¸€ç§æœ€ç›´æ¥çš„æ–¹æ³•å°±æ˜¯æ‰¾åˆ°åˆå§‹å¯è¡Œè§£ $\theta_0$ </p><script type="math/tex; mode=display">\begin{array}{l}& \min_{\theta_0} \| \theta_0 - \theta_r \|^2 \\ \text{s.t.} & L(\theta_0) \in \Omega_k\end{array}</script><p>ä¸Šè¿°é—®é¢˜æŠ•å½±æ–¹æ³•æ±‚è§£çš„æ•ˆç‡ä¸é«˜ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§è§„æ¨¡çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œæ”¹å†™ä¸ºæ— çº¦æŸä¼˜åŒ–é—®é¢˜ï¼Œä½¿ç”¨åºåˆ—æ¢¯åº¦æ–¹æ³•æ‰¾åˆ°åˆå§‹è§£ $\theta_0$</p><p>å®šä¹‰æ´»è·ƒé™åˆ¶é›†åˆï¼ˆactivated constraintsï¼‰</p><script type="math/tex; mode=display">I(\theta_r) = \{ j|G_j(\theta_r) \geq 0,j=1,\cdots,K \}</script><p>ä»¤ $I(\theta_r)$ ä¸­æ‰€æœ‰çš„æ´»è·ƒé™åˆ¶å‡½æ•°å€¼ä¸‹é™çš„æ–¹å‘</p><script type="math/tex; mode=display">(d_r,\alpha_r) = \text{argmin}_{d \in R^n,\alpha \in R} \quad \alpha + \frac{1}{2} \|d\|^2 \\\text{s.t.} \quad \nabla G_j (\theta_r)^T d \leq \alpha,j\in I(\theta_r)</script><p>å¾—åˆ°æ›´æ–°å…¬å¼</p><script type="math/tex; mode=display">\theta_{r_{t+1}} = \theta_{r_t} + \eta_r d_{r_t}</script><p>ä¸Šè¿°æ–¹æ³•èƒ½å°†æ´»è·ƒé›†å†…çš„çº¦æŸç›®æ ‡å€¼å‡å°‘ï¼Œä½¿å¾—è¶Šæ¥è¶Šå¤šçš„çº¦æŸç›®æ ‡å°äº 0ï¼Œ$I(\theta<em>{r})$ æœ€åå˜ä¸ºç©ºé›†ï¼Œåˆ™ $\theta</em>{r}$ æ˜¯å¯è¡Œè§£</p><h4 id="æ±‚è§£å­é—®é¢˜"><a href="#æ±‚è§£å­é—®é¢˜" class="headerlink" title="æ±‚è§£å­é—®é¢˜"></a>æ±‚è§£å­é—®é¢˜</h4><p>å—é™ pareto æœ€ä¼˜ï¼š$\theta^{\ast}$ æ˜¯å¤šä»»åŠ¡ $L(\theta)$ åœ¨å­åŒºåŸŸ $\Omega_k$ çš„æœ€ä¼˜è§£ï¼Œå¦‚æœ $\theta^{\ast} \in \Omega_k$ ä¸”ä¸å­˜åœ¨ $\hat{\theta} \in  \Omega_k$ï¼Œä½¿å¾— $\hat{\theta} &lt; \theta^{\ast}$</p><p>è€ƒè™‘å¦‚ä¸‹å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜</p><script type="math/tex; mode=display">\begin{array}{l}& (d_t,\alpha_t)  = \text{argmin}_{d\in R^n,\alpha \in R} \quad \alpha + \frac{1}{2}\|d\|^2 \\\text{s.t.} & \nabla L_i(\theta_t)^Td \leq \alpha,i=1,\cdots,m\\& \nabla G_j(\theta_t)^Td \leq \alpha,j \in I_{\in}(\theta_t)\end{array}</script><p> å…¶ä¸­ $I_{\in}(\theta_t)$ å®šä¹‰</p><script type="math/tex; mode=display">I_{\in} (\theta_t) = \{j \in I | G_j (\theta) \geq - \epsilon \}</script><p>ä»¤ $(d^k,a^k)$ æ˜¯å¤šä»»åŠ¡å­¦ä¹ é—®é¢˜çš„è§£ï¼Œåˆ™</p><ul><li><p>å¦‚æœ $\theta_t$ æ˜¯ä¸¥æ ¼å—é™äº $\Omega_k$ï¼Œåˆ™ $d_t = 0 \in R^n$ ä¸” $\alpha_t = 0$</p></li><li><p>å¦‚æœ $\theta_t$ ä¸æ˜¯ä¸¥æ ¼å—é™äº $\Omega_k$ï¼Œåˆ™</p><script type="math/tex; mode=display">\begin{array}{l}\alpha_{t} \leq-\frac{1}{2}\left\|d_{t}\right\|^{2}<0 \\\nabla L_{i}\left(\theta_{t}\right)^{T} d \leq \alpha,& i=1, \ldots, m \\\nabla G_{j}\left(\theta_{t}\right)^{T} d \leq \alpha,& j \in I_{\epsilon}\left(\theta_{t}\right)\end{array}</script><p>è¿­ä»£å…¬å¼</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t + \eta d_t</script></li></ul><p>é€šè¿‡æ±‚è§£ä¸Šè¿°é—®é¢˜ï¼Œèƒ½å¤Ÿè·å¾—ä¸€ä¸ªæœ‰æ•ˆçš„æœç´¢æ–¹å‘</p><h4 id="å¤§è§„æ¨¡æ±‚è§£æ–¹æ³•"><a href="#å¤§è§„æ¨¡æ±‚è§£æ–¹æ³•" class="headerlink" title="å¤§è§„æ¨¡æ±‚è§£æ–¹æ³•"></a>å¤§è§„æ¨¡æ±‚è§£æ–¹æ³•</h4><p>ä¸Šè¿°æ–¹æ³•èƒ½å¤Ÿè·å¾—ä¸€ä¸ªæœ‰æ•ˆçš„æœç´¢æ–¹å‘ï¼Œå¯¹äºå¤§è§„æ¨¡çš„é—®é¢˜ï¼Œä¼šæ¯”è¾ƒå›°éš¾ï¼Œè¿™é‡Œå°†é—®é¢˜é‡å†™ï¼Œå°†å…¶è¡¨ç¤ºä¸ºå¯¹å¶å½¢å¼</p><ul><li><p>$KKT$ æ¡ä»¶</p><script type="math/tex; mode=display">\begin{array}{l}& d_{t} =-\sum_{i=1}^{m} \lambda_{i} \nabla L_{i}\left(\theta_{t}\right)+\sum_{j \in I_{\epsilon}(\theta)} \beta_{i} \nabla G_{j}\left(\theta_{t}\right) \\\text{s.t.} & \sum_{i=1}^{m} \lambda_{i}+\sum_{j \in I_{\epsilon}(\theta)} \beta_{j}=1\end{array}</script></li><li><p>å¯¹å¶é—®é¢˜</p><script type="math/tex; mode=display">\begin{array}{l}& \max_{\lambda_{i}, \beta_{j}}-\frac{1}{2}\left\|\sum_{i=1}^{m} \lambda_{i} \nabla L_{i}\left(\theta_{t}\right)+\sum_{j \in I_{\epsilon}(\theta)} \beta_{i} \nabla G_{j}\left(\theta_{t}\right)\right\|^{2} \\\text { s.t. } & \sum_{i=1}^{m} \lambda_{i}+\sum_{j \in I_{\epsilon}(\theta)} \beta_{j}=1 \\ & \lambda_{i} \geq 0, \beta_{j} \geq 0 \\& \forall i=1, \cdots, m\\& \forall j \in I_{\epsilon}(\theta)\end{array}</script></li></ul><p>å°†å¤šä»»åŠ¡å­¦ä¹ è½¬åŒ–ä¸ºå…¶å¯¹å¶é—®é¢˜åï¼Œæ±‚è§£ç©ºé—´ä¸å†æ˜¯å‚æ•°ç©ºé—´ï¼Œè€Œæ˜¯å˜æˆäº†ä»»åŠ¡ä¸ªæ•°å’Œå—é™æ¡ä»¶æ•°ï¼Œä½¿å¾—æ±‚è§£é—®é¢˜æå¤§çš„å‡å°‘äº†</p><p>Pareto MTL ç®—æ³•å¦‚ä¸‹å›¾</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/pareto_MTL.webp" style="zoom: 50%;" /></p><p>ä¸ºè¡¨è¿°æ–¹ä¾¿ï¼Œè¿™é‡Œå¼•ç”¨è®ºæ–‡ä¸­å…³äºå¤šä»»åŠ¡å­¦ä¹ çš„å®šä¹‰</p><p>è®¾ $f(x)$ è¡¨é¢å…‰æ»‘</p><script type="math/tex; mode=display">f(x):\mathcal{R}^n \rightarrow \mathcal{R}^m \\f_i(x):\mathcal{R}^n \rightarrow \mathcal{R},i=1,\cdots,m</script><h3 id="å‡†å¤‡ï¼š-Krylov-å­ç©ºé—´"><a href="#å‡†å¤‡ï¼š-Krylov-å­ç©ºé—´" class="headerlink" title="å‡†å¤‡ï¼š$Krylov$ å­ç©ºé—´"></a>å‡†å¤‡ï¼š$Krylov$ å­ç©ºé—´</h3><p>å¤§è§„æ¨¡ç¨€ç–çº¿æ€§æ–¹ç¨‹ç»„ $AX=b$ æ±‚è§£çš„é¦–å…ˆæ–¹æ³•æ˜¯ $krylov$ å­ç©ºé—´æ–¹æ³•ï¼ŒåŸºæœ¬æ€æƒ³æ˜¯åœ¨ä¸€ä¸ªè¾ƒå°çš„å­ç©ºé—´ $\mathcal{K} \subset R_n$ ä¸­å¯»æ‰¾è¿‘ä¼¼è§£</p><p>å®šä¹‰ï¼šè®¾ $A \in R^{n \times n},r \in R^n$ï¼Œåˆ™</p><script type="math/tex; mode=display">\mathcal{K}_{m}(A, r) \triangleq \text{span}\{r, Ar, \cdots, A^{m-1} r\} \subseteq R_{n}</script><p>æ˜¯ç”± $A$ å’Œ $r$ ç”Ÿæˆçš„ $Krylov$ å­ç©ºé—´ï¼Œé€šå¸¸ç®€è®°ä¸º $\mathcal{K}_m$ï¼Œ$Krylov$ å­ç©ºé—´æœ‰å¦‚ä¸‹çš„ä¸‰ä¸ªæ€§è´¨</p><ul><li>$Krylov$ å­ç©ºé—´åµŒå¥—æ€§ï¼š$\mathcal{K}<em>{1} \subseteq \mathcal{K}</em>{2} \subseteq \cdots \subseteq \mathcal{K}_{m}$</li><li>$\mathcal{K}_m$ çš„ç»´æ•°ä¸è¶…è¿‡ $m$</li><li>$\mathcal{K}_{m}(A, r)={x=p(A)}$ï¼Œ$r$ ä¸ºæ¬¡æ•°å°äº $m$ çš„å¤šé¡¹å¼</li></ul><p>æ±‚è§£ $Krylov$ å­ç©ºé—´çš„è§£æ¥è¿‘ä¼¼åŸå§‹çº¿æ€§æ–¹ç¨‹ç»„çš„è§£</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/krylov.webp" style="zoom:50%;" /></p><h3 id="åŸºæœ¬æ¦‚å¿µ"><a href="#åŸºæœ¬æ¦‚å¿µ" class="headerlink" title="åŸºæœ¬æ¦‚å¿µ"></a>åŸºæœ¬æ¦‚å¿µ</h3><ul><li><p>Pareto å¹³ç¨³ç‚¹ï¼ˆPareto Stationaryï¼‰ï¼šè®¾ $f_i(x)$ è¿ç»­å¯èº«å¾®ï¼Œç‚¹ $x$ ç§°ä¸º Pareto å¹³ç¨³ç‚¹ï¼Œå¦‚æœå­˜åœ¨ $\alpha \in \mathcal{R}^{m},a_i \geq 0$ ä½¿å¾—ä¸‹å¼æˆç«‹</p><script type="math/tex; mode=display">\sum_{i=1}^{m} \alpha_i \nabla f_i(x) = 0 \\\sum_{i=1}^{m} \alpha_i = 1</script></li><li><p>Pareto ç‚¹éƒ½æ˜¯ Pareto å¹³ç¨³ç‚¹</p></li><li><p>è®¾ $f(x)$ æ˜¯å…‰æ»‘ä¸” $x^{\ast}$ æ˜¯ Pareto ç‚¹ï¼Œ$x(t)$ æ˜¯è¿‡ç‚¹ $x^{\ast}$ çš„æ›²çº¿</p><script type="math/tex; mode=display">x(t):t\in (-\epsilon,\epsilon) \rightarrow \mathcal{R}^n \\x(0) = x^{\ast}</script><p>åˆ™å­˜åœ¨ $\beta \in \mathcal{R}^m$ ä½¿å¾—</p><script type="math/tex; mode=display">H(x^{\ast})x'(t) = \nabla f(x^{\ast})^T \beta \\H(x^{\ast}) = \sum_{i=1}^{m} \alpha_i \nabla^2 f_i(x^{\ast})</script><p>$xâ€™(t)$ ä¸ºåˆ‡çº¿</p></li></ul><p>ä¸Šå¼è¡¨æ˜,ç®—å­ $H(x^{\ast})$ å°†ç‚¹ $x$ å¤„çš„åˆ‡å‘é‡ $v = xâ€™(t)$ å˜æ¢ä¸ºç”± $âˆ‡f_i(x^{\ast})$ æ‰©å¼ æˆçš„ $Krylov$ å­ç©ºé—´çš„å‘é‡</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/krylov_expand.webp" style="zoom:70%;" /></p><h3 id="ç¦»æ•£-Pareto-æ±‚è§£"><a href="#ç¦»æ•£-Pareto-æ±‚è§£" class="headerlink" title="ç¦»æ•£ Pareto æ±‚è§£"></a>ç¦»æ•£ Pareto æ±‚è§£</h3><p>ç»™å®šåˆå§‹ç‚¹ $x_0 \in \mathcal{R}^n,f_i(x)$ å…‰æ»‘ï¼Œå¯ä»¥ä»å¦‚ä¸‹ä¸‰æ­¥æ¥è·å–è¿ç»­ Pareto è§£</p><ul><li>æ±‚è§£ Pareto å¹³ç¨³ç‚¹: ä»åˆå§‹ç‚¹ $x_0$ å‡ºå‘ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•æ±‚è§£ Pareto å¹³ç¨³ç‚¹ $x_0^{\ast}$</li><li>æ‰©å±• Pareto å¹³ç¨³ç‚¹ï¼Œ$f(x)$ åœ¨ç‚¹ $x_0^{\ast}$ å¤„å…‰æ»‘ï¼Œå¦‚æœ Pareto å‰æ²¿å­˜åœ¨ï¼Œåˆ™åœ¨ç‚¹ $x_0^{\ast}$ å¤„çš„æŸä¸ªé¢†åŸŸå†…å­˜åœ¨ Pareto å¹³ç¨³ç‚¹ï¼Œç”±æ­¤å‡ºå‘ï¼Œå¯ä»¥æ±‚å¾—ä¸€ç³»åˆ—çš„ Pareto å¹³ç¨³ç‚¹ $x_i^{\ast}$</li><li>å°†å·²çŸ¥çš„å¹³ç¨³ç‚¹æ‰€åœ¨çš„å±€éƒ¨ Pareto å‰æ²¿è¿›è¡Œè¿æ¥åˆå¹¶ï¼Œæ‰©å……æˆæ›´å¤§çš„è¿ç»­Pareto å‰æ²¿</li></ul><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/pareto_front.webp" style="zoom:50%;" /></p><p>æ¥ä¸‹æ¥è®¨è®ºè·å– Pareto å¹³ç¨³ç‚¹çš„æ–¹æ³•</p><h3 id="æ¢¯åº¦æ±‚è§£æ³•"><a href="#æ¢¯åº¦æ±‚è§£æ³•" class="headerlink" title="æ¢¯åº¦æ±‚è§£æ³•"></a>æ¢¯åº¦æ±‚è§£æ³•</h3><p>è§ä¸Šè¿°</p><h3 id="ä¸€é˜¶æ¢¯åº¦æ±‚è§£æ³•æ‰©å¼ "><a href="#ä¸€é˜¶æ¢¯åº¦æ±‚è§£æ³•æ‰©å¼ " class="headerlink" title="ä¸€é˜¶æ¢¯åº¦æ±‚è§£æ³•æ‰©å¼ "></a>ä¸€é˜¶æ¢¯åº¦æ±‚è§£æ³•æ‰©å¼ </h3><p>é€šè¿‡æ¢¯åº¦æ±‚è§£æ³•æ±‚è§£å‡º Pareto å¹³ç¨³ç‚¹ $x_0^{\ast}$ åï¼ŒåŸºäºè¯¥ç‚¹æ‰©å±•å‡ºå±€éƒ¨ Pareto é›† ${x_i }$ï¼Œè¿™ä¸€è¿‡ç¨‹åˆ†è§£ä¸ºä¸¤æ­¥</p><ul><li>è®¡ç®—æƒé‡ $\alpha$</li><li>æ±‚è§£æœç´¢æ–¹å‘ $v$ï¼Œä¼°è®¡æ¢¯åº¦è¿­ä»£çš„æœç´¢æ–¹å‘ $v_i$</li></ul><p>é€šè¿‡å¦‚ä¸‹æ›´æ–°å…¬å¼æ±‚è§£</p><script type="math/tex; mode=display">x_i = x_0^{\ast} + sv_i</script><p>è®¡ç®— $\alpha$ å¯ä»¥å½’ç»“ä¸ºæ±‚è§£å¦‚ä¸‹çš„çº¦æŸé—®é¢˜</p><script type="math/tex; mode=display">\min_\alpha \| \sum_{i=1}^m \alpha_i \nabla f_i(x_0^{\ast}) \|^2 \\\text{s.t.} \quad \alpha_i \geq 0,\sum_{i=1}^m \alpha_i = 1</script><p>ä¸Šè¿°é—®é¢˜è§„æ¨¡ä¸º $m$ï¼Œ é‡çº§è¾ƒå°ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„æ±‚è§£å‡ºæ¥</p><p>å†ç”±åŸºæœ¬æ¦‚å¿µï¼Œå¾—æ±‚è§£çš„çº¿æ€§æ–¹ç¨‹ç»„</p><script type="math/tex; mode=display">H(x_0^{\ast})v = \nabla f(x_0^{\ast})^T \beta</script><p>ä¸Šè¿°é—®é¢˜æ±‚è§£æœ‰ä¸¤ä¸ªéš¾ç‚¹</p><ul><li>$x_0^{\ast}$ ä¸ä¸€å®šä¸º Pareto å¹³ç¨³ç‚¹</li><li>å½“ $n$ éå¸¸å¤§æ—¶ï¼Œæ±‚è§£èµ·æ¥éå¸¸å›°éš¾</li></ul><p>ä¸ºæ­¤å¼•å…¥æ ¡æ­£å‘é‡ $c$ï¼ˆcorrection vectorï¼‰ï¼Œçº¦æŸé—®é¢˜æ”¹å†™ä¸º</p><script type="math/tex; mode=display">\begin{array}{l}&\min_{a,c} \| c \|^2 \\\text{s.t.} & \alpha_i \geq 0 \\& \sum_{i=1}^m \alpha_i = 1 \\& \sum_{i=1}^{m} \alpha_i(\nabla f_i(x_0^{\ast})-c)=0\end{array}</script><p>ç”¨ $\nabla f_i(x_0^{\ast})-c$ è¿‘ä¼¼ $\nabla f_i(x_0^{\ast})$ï¼Œ$x_0^{\ast}$ å°†ä¼šæ˜¯ Pareto å¹³ç¨³ç‚¹</p><p>è®¾ $a^{\ast}$ æ˜¯æœªå¼•å…¥æ ¡æ­£å‘é‡çº¦æŸé—®é¢˜çš„è§£ï¼Œåˆ™å¼•å…¥ $c$ åçš„è§£ä¸º</p><script type="math/tex; mode=display">(a,c) = (a^{\ast},\nabla f(x_0^{\ast})^T a^{\ast})</script><p>åœ¨è®¡ç®—å‡º $a^{\ast},x_0^{\ast},c$ åï¼Œå¯ä»¥è®¡ç®—å‡º $\nabla f(x_0^{\ast})$ï¼Œè€ƒè™‘å¦‚ä¸‹ç¨€ç–çº¿æ€§æ–¹ç¨‹ç»„</p><script type="math/tex; mode=display">H(x_0^{\ast})v = (\nabla f(x_0^{\ast})^T - c^T) \beta</script><p>$\beta$ ä¸ºéšæœºç”Ÿæˆçš„å‘é‡ï¼Œ$v$ ä¸ºå¾…æ±‚è§£çš„å˜é‡ã€‚ä¸Šè¿°å¼å¯ä»¥é€šè¿‡ $krylov$ å­ç©ºé—´ï¼Œ$MINERS$ æ–¹æ³•æ±‚è§£</p><p>å¯»æ‰¾ç¦»æ•£ Pareto è§£é›†åˆçš„æ±‚è§£ç®—æ³•</p><ul><li>Inputï¼šéšæœºåˆå§‹åŒ–ç½‘ç»œ</li><li>ParetoExpand($x^{\ast}$) ç”Ÿæˆç‚¹ $x^{\ast}$ çš„ $K$ ä¸ªæœç´¢æ–¹å‘ $v_i$</li><li>ç”± $K$ ä¸ªæœç´¢æ–¹å‘æ‰©å±•å‡º $K$ ä¸ªå­ç½‘ç»œ</li><li>æ›´æ–°å­ç½‘ç»œèŠ‚ç‚¹ $x_i = x^{\ast} + sv_i$</li><li>ParetoExpand($x_i$) è¾“å‡º Pareto å¹³ç¨³ç‚¹ $x_i^{\ast}$</li><li>Outputï¼š$N$ ä¸ª Pareto å¹³ç¨³ç½‘ç»œ</li></ul><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/efficient_Pareto.webp" style="zoom: 60%;" /></p><h3 id="è¿ç»­-Pareto-è§£ï¼ˆPareto-frontï¼‰æ„å»º"><a href="#è¿ç»­-Pareto-è§£ï¼ˆPareto-frontï¼‰æ„å»º" class="headerlink" title="è¿ç»­ Pareto è§£ï¼ˆPareto frontï¼‰æ„å»º"></a>è¿ç»­ Pareto è§£ï¼ˆPareto frontï¼‰æ„å»º</h3><p>é€šè¿‡å‰é¢æ±‚è§£å‡ºæ¥ $N$ ä¸ª Pareto å¹³ç¨³ç½‘ç»œï¼ˆçˆ¶èŠ‚ç‚¹åŠ $K$ ä¸ªå­ç½‘ç»œï¼‰ï¼Œç”±ç¦»æ•£ Pareto ç‚¹åˆå¹¶æˆæ›´å¤§çš„è¿ç»­ Pareto å‰æ²¿</p><p>ç»™å®š $x<em>i^{\ast}$ åŠåŸºå…¶å¯¹åº”çš„ $K$ ä¸ªèŠ‚ç‚¹ ${ {x_i^{\ast}}_1,\cdots,{x_i^{\ast}}_k }$ï¼Œå®šä¹‰è¿ç»­å˜é‡ $r</em>{i \rightarrow {i}_j} \in [0,1]$ ä»¥åŠæœç´¢æ–¹å‘</p><script type="math/tex; mode=display">v_{i \rightarrow {i}_j} = {x_i^{\ast}}_j - x_i^{\ast},j = 1,2,\cdots,K</script><p>$x_i^{\ast}$ å¤„å±€éƒ¨ Pareto é›†å¯ä»¥é€šè¿‡ä¸‹å¼è¿›è¡Œæ„å»º</p><script type="math/tex; mode=display">S(x_i^{\ast}) = \{x_i^{\ast} + \sum_{i=1}^K r_{i \rightarrow {i}_j} u_{i \rightarrow {i}_j} | r_{i \rightarrow {i}_j} \geq 0,\sum_{i=1}^K r_{i \rightarrow {i}_j} \leq 1 \}</script><p>$S(x_i^{\ast})$ æ˜¯ç‚¹ $x_i^{\ast}$ åŠå¯¹åº”çš„ $K$ ä¸ªå­èŠ‚ç‚¹ ${ {x_i^{\ast}}_1,\cdots,{x_i^{\ast}}_K }$ æ„æˆçš„å‡¸åŒ…ï¼Œåˆ‡å¹³é¢ä¸­åˆ‡å‘é‡çš„çº¿æ€§ç»„åˆä»ç„¶åœ¨åˆ‡å¹³é¢</p><p>å¯¹äº $N$ ä¸ªå±€éƒ¨ Pareto é›†</p><script type="math/tex; mode=display">\{ S(x_1^{\ast}),\cdots,S(x_N^{\ast}) \}</script><p>å¯ä»¥å°†ä¸¤ä¸¤æ¥å£¤å¤„åˆå¹¶æˆä¸€ä¸ªæ›´å¤§çš„å±€éƒ¨ Pareto é›†åˆï¼Œå…¨éƒ¨åˆå¹¶å®Œåï¼Œå¯ä»¥ç”Ÿæˆå¤šä¸ªçš„è¿ç»­ Pareto å‰æ²¿</p><p><img src="/image/å¤šç›®æ ‡ä¼˜åŒ–ç¬”è®°/pareto_continuous.webp" style="zoom:67%;" /></p>]]></content>
      
      
      <categories>
          
          <category> æ•°å­¦å»ºæ¨¡ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¤šç›®æ ‡ä¼˜åŒ– </tag>
            
            <tag> æœ€ä¼˜åŒ–æ–¹æ³• </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨å¹³è¡Œçº¿æ®µçš„ç›¸æœºæ ‡å®š[è®¡åˆ’æ›´æ–°]</title>
      <link href="/p/66d4364b/"/>
      <url>/p/66d4364b/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ä¸€ç§ä½¿ç”¨å¹³è¡Œçº¿æ®µæ¥è¿›è¡Œç›¸æœºæ ‡å®šä»¥åŠå½¢çŠ¶é‡å»ºçš„æ–¹æ³•</p><span id="more"></span><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>ç›‘æ§æ‘„åƒæœºæ ‡å®šä¸€ç›´æ˜¯è®¡ç®—æœºè§†è§‰å·¥ä¸šåº”ç”¨çš„ä¸€ä¸ªé‡è¦è¯¾é¢˜ã€‚å†…éƒ¨å’Œå¤–éƒ¨å‚æ•°éƒ½å¿…é¡»ç²¾ç¡®æ ¡å‡†ï¼Œæ‰èƒ½ä»è®°å½•çš„ 2D å›¾åƒæˆ–è§†é¢‘ä¸­è¯†åˆ«å‡º 3D åœºæ™¯ä¸­å‘ç”Ÿçš„äº‹æƒ…ï¼Œç›¸æœºæ ‡å®šçš„ä¸€èˆ¬æ–¹æ³•æ˜¯ä½¿ç”¨æ ‡å®šå¯¹è±¡ï¼Œå¦‚æ£‹ç›˜æ ‡å®šã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¯¹äºç›‘æ§æ‘„åƒæœºæ¥è¯´å¾€å¾€æ˜¯ä¸åˆ‡å®é™…çš„ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦ä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ ¡å‡†å¯¹è±¡æ¥è¦†ç›–æ•´ä¸ªæ‹æ‘„åŒºåŸŸã€‚</p><blockquote><p> æºç ï¼š<a href="https://github.com/EmanueleGhelfi/iacv">https://github.com/EmanueleGhelfi/iacv</a></p></blockquote><h2 id="ç›´çº¿æå–"><a href="#ç›´çº¿æå–" class="headerlink" title="ç›´çº¿æå–"></a>ç›´çº¿æå–</h2><h3 id="Canny"><a href="#Canny" class="headerlink" title="Canny"></a>Canny</h3><h3 id="Hough-Transform"><a href="#Hough-Transform" class="headerlink" title="Hough Transform"></a>Hough Transform</h3><h2 id="å½¢çŠ¶é‡å»º"><a href="#å½¢çŠ¶é‡å»º" class="headerlink" title="å½¢çŠ¶é‡å»º"></a>å½¢çŠ¶é‡å»º</h2><h3 id="Affine-Rectification"><a href="#Affine-Rectification" class="headerlink" title="Affine Rectification"></a>Affine Rectification</h3><h3 id="Euclidean-Rectification"><a href="#Euclidean-Rectification" class="headerlink" title="Euclidean Rectification"></a>Euclidean Rectification</h3><h2 id="åº¦é‡æŒ‡æ ‡å±æ€§"><a href="#åº¦é‡æŒ‡æ ‡å±æ€§" class="headerlink" title="åº¦é‡æŒ‡æ ‡å±æ€§"></a>åº¦é‡æŒ‡æ ‡å±æ€§</h2><h2 id="ç›¸æœºæ ‡å®š"><a href="#ç›¸æœºæ ‡å®š" class="headerlink" title="ç›¸æœºæ ‡å®š"></a>ç›¸æœºæ ‡å®š</h2><h2 id="ä¸–ç•Œåæ ‡å®šä½"><a href="#ä¸–ç•Œåæ ‡å®šä½" class="headerlink" title="ä¸–ç•Œåæ ‡å®šä½"></a>ä¸–ç•Œåæ ‡å®šä½</h2><h2 id="3D-å½¢çŠ¶é‡æ„"><a href="#3D-å½¢çŠ¶é‡æ„" class="headerlink" title="3D å½¢çŠ¶é‡æ„"></a>3D å½¢çŠ¶é‡æ„</h2><h2 id="å®ç°ç»†èŠ‚"><a href="#å®ç°ç»†èŠ‚" class="headerlink" title="å®ç°ç»†èŠ‚"></a>å®ç°ç»†èŠ‚</h2><h3 id="Fitting-Vanishing-Point"><a href="#Fitting-Vanishing-Point" class="headerlink" title="Fitting Vanishing Point"></a>Fitting Vanishing Point</h3><h3 id="Fitting-Line-at-Infinity"><a href="#Fitting-Line-at-Infinity" class="headerlink" title="Fitting Line at Infinity"></a>Fitting Line at Infinity</h3><h3 id="Fitting-Conics"><a href="#Fitting-Conics" class="headerlink" title="Fitting Conics"></a>Fitting Conics</h3><h2 id="æ€»ç»“åˆ†æ"><a href="#æ€»ç»“åˆ†æ" class="headerlink" title="æ€»ç»“åˆ†æ"></a>æ€»ç»“åˆ†æ</h2><h2 id="è®¡ç®—ç»“æœ"><a href="#è®¡ç®—ç»“æœ" class="headerlink" title="è®¡ç®—ç»“æœ"></a>è®¡ç®—ç»“æœ</h2>]]></content>
      
      
      <categories>
          
          <category> å›¾åƒå¤„ç† </category>
          
      </categories>
      
      
        <tags>
            
            <tag> è®ºæ–‡å¤ç° </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®¾è®¡å®ç°å†…å­˜çš„åˆ†é…å’Œå›æ”¶ç®—æ³•</title>
      <link href="/p/7f21964e/"/>
      <url>/p/7f21964e/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æ“ä½œç³»ç»Ÿä½œä¸š</p><span id="more"></span><h2 id="é¢˜ç›®"><a href="#é¢˜ç›®" class="headerlink" title="é¢˜ç›®"></a>é¢˜ç›®</h2><p>å¦‚ä¸‹æ•°æ®ç»“æ„ä¸‹ï¼Œè®¾è®¡å®ç°å†…å­˜çš„åˆ†é…å’Œå›æ”¶ç®—æ³•ï¼š</p><ul><li>å½’è¿˜åŒºæœ‰ä¸‹é‚»ç©ºé—²åŒºï¼›</li><li>å½’è¿˜åŒºæœ‰ä¸Šé‚»ç©ºé—²åŒºï¼›</li><li>å½’è¿˜åŒºæ—¢æœ‰ä¸Šé‚»ç©ºé—²åŒºåˆæœ‰ä¸‹é‚»ç©ºé—²åŒºï¼›</li><li>å½’è¿˜åŒºæ—¢æ— ä¸Šé‚»ç©ºé—²åŒºåˆæ— ä¸‹é‚»ç©ºé—²åŒº</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">struct</span><br><span class="line">&#123; float address;  /*å·²åˆ†åˆ†åŒºèµ·å§‹åœ°å€*/</span><br><span class="line"> float length;  /*å·²åˆ†åˆ†åŒºé•¿åº¦ï¼Œå•ä½ä¸ºå­—èŠ‚*/</span><br><span class="line"> int flag;   /*å·²åˆ†é…åŒºè¡¨ç™»è®°æ æ ‡å¿—ï¼Œç”¨â€œ0â€è¡¨ç¤ºç©ºæ ç›®ï¼Œå®éªŒä¸­åªæ”¯æŒä¸€ä¸ªå­—ç¬¦çš„ä½œä¸šå*/</span><br><span class="line">&#125;used_table[n]; /*å·²åˆ†é…åŒºè¡¨*/</span><br><span class="line">struct</span><br><span class="line">&#123;float address;/*ç©ºé—²åŒºèµ·å§‹åœ°å€*/</span><br><span class="line"> float length;    /*ç©ºé—²åŒºé•¿åº¦ï¼Œå•ä½ä¸ºå­—èŠ‚*/</span><br><span class="line"> int flag;  /*ç©ºé—²åŒºè¡¨ç™»è®°æ æ ‡å¿—ï¼Œç”¨â€œ0â€è¡¨ç¤ºç©ºæ ç›®ï¼Œç”¨â€œ1â€è¡¨ç¤ºæœªåˆ†é…*/</span><br><span class="line">&#125;free_table[m]; /*ç©ºé—²åŒºè¡¨*/</span><br></pre></td></tr></table></figure><p>ç¼–å†™ç¨‹åºï¼Œå¹¶è¾“å‡ºç»“æœã€‚</p><h2 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//åŒºè¡¨æ•°ç»„ç»“æ„</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">UsedTable</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> address;  <span class="comment">/*å·²åˆ†åˆ†åŒºèµ·å§‹åœ°å€*/</span></span><br><span class="line">    <span class="type">int</span> length;  <span class="comment">/*å·²åˆ†åˆ†åŒºé•¿åº¦ï¼Œå•ä½ä¸ºå­—èŠ‚*/</span></span><br><span class="line">    <span class="type">int</span> flag;   <span class="comment">/*å·²åˆ†é…åŒºè¡¨ç™»è®°æ æ ‡å¿—ï¼Œç”¨â€œ0â€è¡¨ç¤ºç©ºæ ç›®ï¼Œå®éªŒä¸­åªæ”¯æŒä¸€ä¸ªç¼–å·çš„ä½œä¸šå*/</span></span><br><span class="line">&#125; usedTable[<span class="number">100</span>]; <span class="comment">/*å·²åˆ†é…åŒºè¡¨*/</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">FreeTable</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> address;<span class="comment">/*ç©ºé—²åŒºèµ·å§‹åœ°å€*/</span></span><br><span class="line">    <span class="type">int</span> length;    <span class="comment">/*ç©ºé—²åŒºé•¿åº¦ï¼Œå•ä½ä¸ºå­—èŠ‚*/</span></span><br><span class="line">    <span class="type">int</span> flag;  <span class="comment">/*ç©ºé—²åŒºè¡¨ç™»è®°æ æ ‡å¿—ï¼Œç”¨â€œ0â€è¡¨ç¤ºç©ºæ ç›®ï¼Œç”¨â€œ1â€è¡¨ç¤ºæœªåˆ†é…*/</span></span><br><span class="line">&#125; freeTable[<span class="number">100</span>]; <span class="comment">/*ç©ºé—²åŒºè¡¨*/</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">InitTable</span><span class="params">()</span>;                                                   <span class="comment">// åˆå§‹åŒ–åŒºè¡¨</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">allocTable</span><span class="params">(<span class="type">const</span> <span class="type">int</span> proName, <span class="type">const</span> <span class="type">int</span> proLenth)</span>;             <span class="comment">// åˆ›å»ºä½œä¸š</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">reclaimTable</span><span class="params">(<span class="type">const</span> <span class="type">int</span> proName)</span>;                               <span class="comment">// å›æ”¶ä½œä¸š</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">findProName</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> UsedTable temp[], <span class="type">const</span> <span class="type">int</span> proName)</span>;  <span class="comment">// æŒ‰ä½œä¸šåæŸ¥æ‰¾ä¸‹æ ‡</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sortUsedTable</span><span class="params">(<span class="keyword">struct</span> UsedTable temp[])</span>;                        <span class="comment">// æ’åºå·²åˆ†é…åŒºè¡¨</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">printUsedTable</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> UsedTable temp)</span>;                   <span class="comment">// è¾“å‡ºä½œä¸šåˆ†åŒºä¿¡æ¯</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">printFreeTable</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> FreeTable temp)</span>;                   <span class="comment">// è¾“å‡ºç©ºé—²åˆ†åŒºä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> i=<span class="number">0</span>;                    <span class="comment">//è®°å½•å½“å‰ å·²åˆ†é…/ç©ºé—² åŒºè¡¨æ•°é‡</span></span><br><span class="line"><span class="type">int</span> Minsize=<span class="number">1</span>;              <span class="comment">//ä½œä¸šé—´æœ€å°ç©ºä½™åœ°å€</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">InitTable</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//OS</span></span><br><span class="line">    usedTable[<span class="number">0</span>].address = <span class="number">0</span>;</span><br><span class="line">    usedTable[<span class="number">0</span>].length = <span class="number">3</span>;</span><br><span class="line">    usedTable[<span class="number">0</span>].flag = <span class="number">1</span>; <span class="comment">//OS çš„ä½œä¸šåä¸º1</span></span><br><span class="line">    </span><br><span class="line">    freeTable[<span class="number">0</span>].address = <span class="number">3</span>;</span><br><span class="line">    freeTable[<span class="number">0</span>].length = <span class="number">97</span>;</span><br><span class="line">    freeTable[<span class="number">0</span>].flag = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//å›¾å½¢ç•Œé¢</span></span><br><span class="line">    freeTable[<span class="number">0</span>].address = <span class="number">8</span>;</span><br><span class="line">    freeTable[<span class="number">0</span>].length = <span class="number">92</span>;</span><br><span class="line">    freeTable[<span class="number">0</span>].flag = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    usedTable[<span class="number">1</span>].address = <span class="number">3</span>;</span><br><span class="line">    usedTable[<span class="number">1</span>].length = <span class="number">5</span>;</span><br><span class="line">    usedTable[<span class="number">1</span>].flag = <span class="number">2</span>; <span class="comment">//å›¾å½¢ç•Œé¢ çš„ä½œä¸šåä¸º2</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//ç½‘ç»œç¨‹åº</span></span><br><span class="line">    freeTable[<span class="number">0</span>].address = <span class="number">8</span>;</span><br><span class="line">    freeTable[<span class="number">0</span>].length = <span class="number">12</span>;</span><br><span class="line">    freeTable[<span class="number">0</span>].flag = <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    usedTable[<span class="number">2</span>].address = <span class="number">20</span>;</span><br><span class="line">    usedTable[<span class="number">2</span>].length = <span class="number">10</span>;</span><br><span class="line">    usedTable[<span class="number">2</span>].flag = <span class="number">3</span>; <span class="comment">//ç½‘ç»œç¨‹åº çš„ä½œä¸šåä¸º3</span></span><br><span class="line"></span><br><span class="line">    freeTable[<span class="number">1</span>].address = <span class="number">30</span>;</span><br><span class="line">    freeTable[<span class="number">1</span>].length = <span class="number">70</span>;</span><br><span class="line">    freeTable[<span class="number">1</span>].flag = <span class="number">1</span>;</span><br><span class="line">    i += <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">allocTable</span><span class="params">(<span class="type">const</span> <span class="type">int</span> proName, <span class="type">const</span> <span class="type">int</span> proLenth)</span> &#123;</span><br><span class="line">    <span class="type">int</span> j=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(freeTable[j].flag) &#123;</span><br><span class="line">        <span class="keyword">if</span>(freeTable[j].length &gt;= proLenth) <span class="keyword">break</span>;</span><br><span class="line">        j++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(freeTable[j].flag == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;31mNo free space available\033[0m\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(freeTable[j].length - proLenth &lt;= Minsize) &#123;</span><br><span class="line">        usedTable[i].address = freeTable[j].address;</span><br><span class="line">        usedTable[i].length  = freeTable[j].length;</span><br><span class="line">        usedTable[i].flag    = proName;</span><br><span class="line">        <span class="keyword">while</span>(freeTable[j].flag) &#123;</span><br><span class="line">            freeTable[j] = freeTable[j+<span class="number">1</span>];</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        freeTable[j].address = freeTable[j].length = freeTable[j].flag = <span class="number">0</span>;</span><br><span class="line">        i++;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        usedTable[i].address = freeTable[j].address;</span><br><span class="line">        usedTable[i].length  = proLenth;</span><br><span class="line">        usedTable[i].flag    = proName;</span><br><span class="line">        freeTable[j].address = freeTable[j].address + proLenth;</span><br><span class="line">        freeTable[j].length  = freeTable[j].length  - proLenth;</span><br><span class="line">        i++;</span><br><span class="line">    &#125; <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">findProName</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> UsedTable temp[], <span class="type">const</span> <span class="type">int</span> proName)</span> &#123;</span><br><span class="line">    <span class="type">int</span> m=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(; m&lt;i; m++) &#123;</span><br><span class="line">        <span class="keyword">if</span>(temp[m].flag == proName)</span><br><span class="line">            <span class="keyword">return</span> m;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">reclaimTable</span><span class="params">(<span class="type">const</span> <span class="type">int</span> proName)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(proName==<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;31mCannot reclaim OS progress!\n\033[0m&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> k=<span class="number">0</span>,j=<span class="number">0</span>,h=<span class="number">0</span>;</span><br><span class="line">    sortUsedTable(usedTable);</span><br><span class="line">    <span class="keyword">if</span>(findProName(usedTable, <span class="number">1</span>) == <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;31mERROR!\033[0m&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    k = findProName(usedTable, proName);</span><br><span class="line">    <span class="keyword">if</span>(k == <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;31mCannot find this progress!\033[0m\n&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">while</span>(freeTable[j].flag || usedTable[h].flag) &#123;</span><br><span class="line">            <span class="keyword">if</span>(freeTable[j].address + freeTable[j].length == usedTable[k].address) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(freeTable[j+<span class="number">1</span>].flag &amp;&amp; usedTable[k].address + usedTable[k].length == freeTable[j+<span class="number">1</span>].address) &#123;</span><br><span class="line">                    freeTable[j].length += (usedTable[k].length + freeTable[j+<span class="number">1</span>].length);</span><br><span class="line">                    usedTable[k].address = usedTable[k].flag = usedTable[k].length = <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">for</span>(<span class="type">int</span> l=j+<span class="number">1</span>; freeTable[l].flag; l++) &#123;</span><br><span class="line">                        freeTable[l] = freeTable[l+<span class="number">1</span>];</span><br><span class="line">                    &#125; <span class="comment">//ä¸Šæœ‰ï¼Œä¸‹æœ‰</span></span><br><span class="line">                    i--;</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    freeTable[j].length += usedTable[k].length;</span><br><span class="line">                    usedTable[k].address = usedTable[k].length = usedTable[k].flag = <span class="number">0</span>;</span><br><span class="line">                    i--;</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125; <span class="comment">//ä¸Šæœ‰ï¼Œä¸‹æ— </span></span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (usedTable[k].address + usedTable[k].length == freeTable[j].address) &#123;</span><br><span class="line">                freeTable[j].address = usedTable[k].address;</span><br><span class="line">                freeTable[j].length += usedTable[k].length;</span><br><span class="line">                usedTable[k].address = usedTable[k].flag = usedTable[k].length = <span class="number">0</span>;</span><br><span class="line">                <span class="comment">//ä¸Šæ— ï¼Œä¸‹æœ‰</span></span><br><span class="line">                i--;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">            &#125;  <span class="keyword">else</span> <span class="keyword">if</span> (usedTable[k<span class="number">-1</span>].address + usedTable[k<span class="number">-1</span>].length + usedTable[k].length == usedTable[k+<span class="number">1</span>].address) &#123;</span><br><span class="line">                <span class="type">int</span> e=<span class="number">0</span>;</span><br><span class="line">                <span class="keyword">while</span>(freeTable[e].flag) &#123;</span><br><span class="line">                    e++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">for</span>(<span class="type">int</span> m=e; j&lt;m; m--) &#123;</span><br><span class="line">                    freeTable[m].address = freeTable[m<span class="number">-1</span>].address;</span><br><span class="line">                    freeTable[m].length  = freeTable[m<span class="number">-1</span>].length;</span><br><span class="line">                    freeTable[m].flag    = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                freeTable[j].address = usedTable[k].address;</span><br><span class="line">                freeTable[j].length  = usedTable[k].length;</span><br><span class="line">                usedTable[k].address = usedTable[k].length = usedTable[k].flag = <span class="number">0</span>;</span><br><span class="line">                <span class="comment">//ä¸Šæ— ï¼Œä¸‹æ— </span></span><br><span class="line">                i--;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">            &#125; <span class="comment">//elif</span></span><br><span class="line">            j++, h++;</span><br><span class="line">        &#125; <span class="comment">//while</span></span><br><span class="line">    &#125; <span class="comment">//else</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">sortUsedTable</span><span class="params">(<span class="keyword">struct</span> UsedTable temp[])</span> &#123;</span><br><span class="line">    <span class="type">int</span> j, k, f;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">UsedTable</span> <span class="title">t</span>;</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> l=<span class="number">0</span>; l&lt;i; l++) &#123;</span><br><span class="line">        <span class="keyword">if</span>(temp[l].flag == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> m = l; m&lt;=i; m++) temp[m] = temp[m+<span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;i<span class="number">-1</span>; j++) &#123;</span><br><span class="line">        f=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(k=<span class="number">0</span>; k&lt;i<span class="number">-1</span>-j; k++)</span><br><span class="line">            <span class="keyword">if</span>(temp[k+<span class="number">1</span>].address &lt; temp[k].address) &#123;</span><br><span class="line">                f=<span class="number">0</span>;</span><br><span class="line">                t         = temp[k];</span><br><span class="line">                temp[k]   = temp[k+<span class="number">1</span>];</span><br><span class="line">                temp[k+<span class="number">1</span>] = t;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">if</span>(f) <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">printUsedTable</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> UsedTable temp)</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\t%d\t%d\t%d\tNormal\n&quot;</span>, temp.flag, temp.address, temp.length);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">printFreeTable</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> FreeTable temp)</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\033[0;36m\tNULL\t%d\t%d\tNULL\n\033[0m&quot;</span>, temp.address, temp.length);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> a=<span class="number">0</span>, proName=<span class="number">0</span>, proLenth=<span class="number">0</span>;</span><br><span class="line">    InitTable();</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="type">int</span> m=<span class="number">0</span>, j=<span class="number">0</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;32m*Select operation:\n\033[0m&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\t(0) - exit\n\t(1) - allocate memory\n\t(2) - reclaim memory\n\t(3) - print table\n&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;32minput operation: \033[0m&quot;</span>);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;a);</span><br><span class="line">        <span class="keyword">switch</span>(a) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Bye~\n&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;\033[0;32mthe name of the progress: \033[0m&quot;</span>);</span><br><span class="line">                    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;proName);</span><br><span class="line">                    <span class="keyword">if</span>(proName == <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;31munvalidated proName!\033[0m\n&quot;</span>);</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span>(findProName(usedTable, proName) != <span class="number">-1</span>) &#123;</span><br><span class="line">                        <span class="built_in">printf</span>(<span class="string">&quot;\033[0;31mthis proName has been used!\033[0m\n&quot;</span>);</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;\033[0;32mrequired memory size: \033[0m&quot;</span>);</span><br><span class="line">                <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;proLenth);</span><br><span class="line">                allocTable(proName, proLenth);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;\033[0;32mthe name of the progress to reclaim: \033[0m&quot;</span>);</span><br><span class="line">                <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;proName);</span><br><span class="line">                reclaimTable(proName);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;----------------------------------------------\n&quot;</span>);</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;\033[0;32mmemory table:\033[0m\n&quot;</span>);</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;\033[0;34m\tproName\taddress\tlength\tstatus\033[0m\n&quot;</span>);</span><br><span class="line">                sortUsedTable(usedTable);</span><br><span class="line">                <span class="keyword">while</span>(usedTable[m].flag || freeTable[j].flag) &#123;</span><br><span class="line">                    <span class="keyword">if</span>(usedTable[m].address &lt; freeTable[j].address &amp;&amp; usedTable[m].flag) &#123;</span><br><span class="line">                        printUsedTable(usedTable[m]);</span><br><span class="line">                        m++;</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (freeTable[j].flag) &#123;</span><br><span class="line">                        printFreeTable(freeTable[j]);</span><br><span class="line">                        j++;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;----------------------------------------------\n&quot;</span>);</span><br><span class="line">                <span class="comment">//getchar();</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>: <span class="built_in">printf</span>(<span class="string">&quot;\033[0;31mNo such this operation\n\033[0m&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æ“ä½œç³»ç»Ÿ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ä½œä¸š </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>åˆ¶ä½œç›®æ ‡æ£€æµ‹æ•°æ®é›†å¸¸ç”¨pythonè„šæœ¬æ•´ç†</title>
      <link href="/p/ddce6477/"/>
      <url>/p/ddce6477/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>åˆ¶ä½œä¸ªäººç›®æ ‡æ£€æµ‹æ•°æ®é›†æ—¶ï¼Œæœ‰æŸ¥æ‰¾çˆ¬å–çš„é”™è¯¯å›¾ç‰‡ï¼Œæ›´æ”¹æ ‡æ³¨è·¯å¾„ç­‰ç­‰éœ€è¦ï¼Œå†™äº†ä»¥ä¸‹pythonè„šæœ¬</p><span id="more"></span><h2 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h2><h3 id="æŸ¥æ‰¾é”™è¯¯å›¾ç‰‡"><a href="#æŸ¥æ‰¾é”™è¯¯å›¾ç‰‡" class="headerlink" title="æŸ¥æ‰¾é”™è¯¯å›¾ç‰‡"></a>æŸ¥æ‰¾é”™è¯¯å›¾ç‰‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> imghdr</span><br><span class="line"><span class="keyword">from</span> progressbar <span class="keyword">import</span> ProgressBar</span><br><span class="line"></span><br><span class="line">path =<span class="string">&#x27;./JPEGImages&#x27;</span></span><br><span class="line">original_images =[]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, filenames <span class="keyword">in</span> os.walk(path):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        original_images.append(os.path.join(root, filename))</span><br><span class="line"></span><br><span class="line">original_images = <span class="built_in">sorted</span>(original_images)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;num:&#x27;</span>,<span class="built_in">len</span>(original_images))</span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;check_error.txt&#x27;</span>,<span class="string">&#x27;w+&#x27;</span>)</span><br><span class="line">error_images =[]</span><br><span class="line">progress = ProgressBar()</span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> progress(original_images):</span><br><span class="line">    check = imghdr.what(filename)</span><br><span class="line">    <span class="keyword">if</span> check == <span class="literal">None</span>:</span><br><span class="line">        f.write(filename)</span><br><span class="line">        f.write(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        error_images.append(filename)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(error_images))</span><br><span class="line">f.seek(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> f:</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure><h3 id="æŒ‰é¡ºåºé‡å‘½åæ ‡æ³¨æ–‡ä»¶å’Œå›¾ç‰‡ï¼ˆåˆ†æˆä¸¤éƒ¨åˆ†é˜²æ­¢å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶æ•°é‡ä¸ä¸€è‡´ï¼‰"><a href="#æŒ‰é¡ºåºé‡å‘½åæ ‡æ³¨æ–‡ä»¶å’Œå›¾ç‰‡ï¼ˆåˆ†æˆä¸¤éƒ¨åˆ†é˜²æ­¢å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶æ•°é‡ä¸ä¸€è‡´ï¼‰" class="headerlink" title="æŒ‰é¡ºåºé‡å‘½åæ ‡æ³¨æ–‡ä»¶å’Œå›¾ç‰‡ï¼ˆåˆ†æˆä¸¤éƒ¨åˆ†é˜²æ­¢å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶æ•°é‡ä¸ä¸€è‡´ï¼‰"></a>æŒ‰é¡ºåºé‡å‘½åæ ‡æ³¨æ–‡ä»¶å’Œå›¾ç‰‡ï¼ˆåˆ†æˆä¸¤éƒ¨åˆ†é˜²æ­¢å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶æ•°é‡ä¸ä¸€è‡´ï¼‰</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BatchRename</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.path1 = <span class="string">&#x27;./JPEGImages&#x27;</span></span><br><span class="line">        self.path2 = <span class="string">&#x27;./Annotations&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rename</span>(<span class="params">self</span>):</span><br><span class="line">        filelist1 = os.listdir(self.path1)</span><br><span class="line">        filelist1.sort()</span><br><span class="line">        total_num1 = <span class="built_in">len</span>(filelist1)</span><br><span class="line">        i1 = <span class="number">1</span></span><br><span class="line">        srcpath1 = os.path.abspath(self.path1)</span><br><span class="line">        <span class="keyword">for</span> item1 <span class="keyword">in</span> filelist1:</span><br><span class="line">            os.rename(os.path.join(srcpath1, item1), os.path.join(srcpath1, <span class="built_in">str</span>(i1).zfill(<span class="number">5</span>) + <span class="string">&#x27;.jpg&#x27;</span>))</span><br><span class="line">            i1 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        filelist2 = os.listdir(self.path2)</span><br><span class="line">        filelist2.sort()</span><br><span class="line">        total_num2 = <span class="built_in">len</span>(filelist2)</span><br><span class="line">        i2 = <span class="number">1</span></span><br><span class="line">        srcpath2 = os.path.abspath(self.path2)</span><br><span class="line">        <span class="keyword">for</span> item2 <span class="keyword">in</span> filelist2:</span><br><span class="line">            os.rename(os.path.join(srcpath2, item2), os.path.join(srcpath2, <span class="built_in">str</span>(i2).zfill(<span class="number">5</span>) + <span class="string">&#x27;.xml&#x27;</span>))</span><br><span class="line">            i2 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo = BatchRename()</span><br><span class="line">    demo.rename()</span><br></pre></td></tr></table></figure><h3 id="ä¿®æ”¹æ ‡æ³¨æ–‡ä»¶ä¸­çš„å›¾ç‰‡è·¯å¾„ä¸ºæœ¬ç›®å½•ä¸‹"><a href="#ä¿®æ”¹æ ‡æ³¨æ–‡ä»¶ä¸­çš„å›¾ç‰‡è·¯å¾„ä¸ºæœ¬ç›®å½•ä¸‹" class="headerlink" title="ä¿®æ”¹æ ‡æ³¨æ–‡ä»¶ä¸­çš„å›¾ç‰‡è·¯å¾„ä¸ºæœ¬ç›®å½•ä¸‹"></a>ä¿®æ”¹æ ‡æ³¨æ–‡ä»¶ä¸­çš„å›¾ç‰‡è·¯å¾„ä¸ºæœ¬ç›®å½•ä¸‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os,sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FilesChange</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.path = <span class="string">&#x27;./Annotations&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Change</span>(<span class="params">self</span>):</span><br><span class="line">        filelist = os.listdir(self.path)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> filelist:</span><br><span class="line">            srcfile = os.path.join(os.path.abspath(self.path), item)</span><br><span class="line">            item = item.rstrip(<span class="string">&#x27;.xml&#x27;</span>)</span><br><span class="line">            item = item.zfill(<span class="number">5</span>)</span><br><span class="line">            line_replace = <span class="number">2</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(srcfile,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fd:</span><br><span class="line">                lines = fd.readlines()</span><br><span class="line">            lines[line_replace] = (<span class="string">&#x27;        &lt;filename&gt;&#x27;</span> + item + <span class="string">&#x27;.webp&lt;/filename&gt;\n&#x27;</span>)</span><br><span class="line">            lines[line_replace + <span class="number">1</span>] = (<span class="string">&#x27;        &lt;path&gt;&#x27;</span> + <span class="built_in">format</span>(srcfile[:-<span class="number">21</span>]) + <span class="string">&#x27;JPEGImages/&#x27;</span> + item + <span class="string">&#x27;.webp&lt;/path&gt;\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(srcfile,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fd:</span><br><span class="line">                fd.writelines(lines)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo = FilesChange()</span><br><span class="line">    demo.Change()</span><br></pre></td></tr></table></figure><h3 id="è¾“å‡ºæ²¡æœ‰æ ‡æ³¨çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶ååˆ°-txt-æ–‡ä»¶"><a href="#è¾“å‡ºæ²¡æœ‰æ ‡æ³¨çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶ååˆ°-txt-æ–‡ä»¶" class="headerlink" title="è¾“å‡ºæ²¡æœ‰æ ‡æ³¨çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶ååˆ° txt æ–‡ä»¶"></a>è¾“å‡ºæ²¡æœ‰æ ‡æ³¨çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶ååˆ° txt æ–‡ä»¶</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os,sys,re</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AppleSearch</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.path = <span class="string">&#x27;./Annotations&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Search</span>(<span class="params">self</span>):</span><br><span class="line">        filetxt = <span class="string">&#x27;NoAppleXml.txt&#x27;</span></span><br><span class="line">        txtlist = []</span><br><span class="line">        filelist = os.listdir(self.path)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> filelist:</span><br><span class="line">            srcfile = os.path.join(os.path.abspath(self.path), item)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(srcfile,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fd:</span><br><span class="line">                content = fd.read()</span><br><span class="line">                target = re.findall(<span class="string">&quot;apple&quot;</span>, content)</span><br><span class="line">            <span class="keyword">if</span> target == []:</span><br><span class="line">                txtlist.append(item.rstrip(<span class="string">&#x27;.xml&#x27;</span>))</span><br><span class="line">        txtpath = os.path.join(os.path.abspath(<span class="string">&#x27;./&#x27;</span>), filetxt)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txtpath,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fd:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> txtlist:</span><br><span class="line">                <span class="built_in">print</span>(i)</span><br><span class="line">                fd.write(<span class="string">&quot;&#123;&#125;\n&quot;</span>.<span class="built_in">format</span>(i)) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo = AppleSearch()</span><br><span class="line">    demo.Search()</span><br></pre></td></tr></table></figure><h3 id="ä»-txt-æ–‡ä»¶è¯»å–è¦åˆ é™¤çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶"><a href="#ä»-txt-æ–‡ä»¶è¯»å–è¦åˆ é™¤çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶" class="headerlink" title="ä» txt æ–‡ä»¶è¯»å–è¦åˆ é™¤çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶"></a>ä» txt æ–‡ä»¶è¯»å–è¦åˆ é™¤çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os,sys,fileinput,re</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DeleteNoApple</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.path1 = <span class="string">&#x27;./JPEGImages&#x27;</span></span><br><span class="line">        self.path2 = <span class="string">&#x27;./Annotations&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Delete</span>(<span class="params">self</span>):</span><br><span class="line">        filetxt = <span class="string">&#x27;./NoAppleXml.txt&#x27;</span></span><br><span class="line">        content = []</span><br><span class="line">        txtpath = os.path.join(os.path.abspath(<span class="string">&#x27;./&#x27;</span>), filetxt)</span><br><span class="line">        <span class="comment"># with open(txtpath) as fd:</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fileinput.<span class="built_in">input</span>(txtpath):</span><br><span class="line">            content.append(line.rstrip(<span class="string">&#x27;\n&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> content:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> content:</span><br><span class="line">                srcpath1 = os.path.join(os.path.abspath(self.path1), i+<span class="string">&#x27;.webp&#x27;</span>)</span><br><span class="line">                os.remove(srcpath1)</span><br><span class="line">                srcpath2 = os.path.join(os.path.abspath(self.path2), i+<span class="string">&#x27;.xml&#x27;</span>)</span><br><span class="line">                os.remove(srcpath2)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo = DeleteNoApple()</span><br><span class="line">    demo.Delete()</span><br></pre></td></tr></table></figure><h3 id="æ‰¹é‡å›¾ç‰‡æ ¼å¼è½¬æ¢-ï¼ˆæœªè¿‡æ»¤-jpg-å›¾ç‰‡é˜²æ­¢å›¾ç‰‡ç¼–ç é”™è¯¯ï¼‰"><a href="#æ‰¹é‡å›¾ç‰‡æ ¼å¼è½¬æ¢-ï¼ˆæœªè¿‡æ»¤-jpg-å›¾ç‰‡é˜²æ­¢å›¾ç‰‡ç¼–ç é”™è¯¯ï¼‰" class="headerlink" title="æ‰¹é‡å›¾ç‰‡æ ¼å¼è½¬æ¢ ï¼ˆæœªè¿‡æ»¤ jpg å›¾ç‰‡é˜²æ­¢å›¾ç‰‡ç¼–ç é”™è¯¯ï¼‰"></a>æ‰¹é‡å›¾ç‰‡æ ¼å¼è½¬æ¢ ï¼ˆæœªè¿‡æ»¤ jpg å›¾ç‰‡é˜²æ­¢å›¾ç‰‡ç¼–ç é”™è¯¯ï¼‰</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">imgList = os.listdir(<span class="string">&#x27;./JPEGImages&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> imgList:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        img = Image.<span class="built_in">open</span>(item)</span><br><span class="line">        file_name, file_type = os.path.splitext(item)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># if file_type == &#x27;jpg&#x27;:</span></span><br><span class="line">        <span class="comment">#     continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            img.save(<span class="string">&quot;%s.webp&quot;</span>%(file_name), <span class="string">&#x27;jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> IOError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;picture convert error&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="æ‰¹é‡æ›´æ”¹æ ‡ç­¾å"><a href="#æ‰¹é‡æ›´æ”¹æ ‡ç­¾å" class="headerlink" title="æ‰¹é‡æ›´æ”¹æ ‡ç­¾å"></a>æ‰¹é‡æ›´æ”¹æ ‡ç­¾å</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os,sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FilesChange</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.path = <span class="string">&#x27;./Annotations&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Change</span>(<span class="params">self</span>):</span><br><span class="line">        old = <span class="string">&quot;Apple&quot;</span></span><br><span class="line">        new = <span class="string">&quot;apple&quot;</span></span><br><span class="line">        filelist = os.listdir(self.path)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> filelist:</span><br><span class="line">            srcfile = os.path.join(os.path.abspath(self.path), item)</span><br><span class="line">            line_replace = <span class="number">2</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(srcfile,<span class="string">&#x27;r+&#x27;</span>) <span class="keyword">as</span> fd:</span><br><span class="line">                lines = fd.readlines()</span><br><span class="line">                fd.seek(<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                    <span class="keyword">if</span> old <span class="keyword">in</span> line:</span><br><span class="line">                        lines=<span class="string">&quot;&quot;</span>.join(lines).replace(old,new)</span><br><span class="line">                fd.writelines(<span class="string">&quot;&quot;</span>.join(lines))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    demo = FilesChange()</span><br><span class="line">    demo.Change()</span><br></pre></td></tr></table></figure><h3 id="æŸ¥æ‰¾æ— å¯¹åº”å›¾ç‰‡çš„æ ‡ç­¾-å’Œ-æ— å¯¹åº”æ ‡ç­¾çš„å›¾ç‰‡"><a href="#æŸ¥æ‰¾æ— å¯¹åº”å›¾ç‰‡çš„æ ‡ç­¾-å’Œ-æ— å¯¹åº”æ ‡ç­¾çš„å›¾ç‰‡" class="headerlink" title="æŸ¥æ‰¾æ— å¯¹åº”å›¾ç‰‡çš„æ ‡ç­¾ å’Œ æ— å¯¹åº”æ ‡ç­¾çš„å›¾ç‰‡"></a>æŸ¥æ‰¾æ— å¯¹åº”å›¾ç‰‡çš„æ ‡ç­¾ å’Œ æ— å¯¹åº”æ ‡ç­¾çš„å›¾ç‰‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">path1 = <span class="string">r&#x27;./JPEGImages&#x27;</span></span><br><span class="line">path2 = <span class="string">r&#x27;./Annotations&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">file_name</span>(<span class="params">image_dir,xml_dir</span>):</span><br><span class="line">    jpg_list = []</span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(image_dir):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            jpg_list.append(os.path.splitext(file)[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(xml_dir):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            xml_list.append(os.path.splitext(file)[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(jpg_list))</span><br><span class="line">    diff = <span class="built_in">set</span>(xml_list).difference(<span class="built_in">set</span>(jpg_list))  <span class="comment"># å·®é›†ï¼Œåœ¨aä¸­ä½†ä¸åœ¨bä¸­çš„å…ƒç´ </span></span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> diff:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;no jpg&quot;</span>, name + <span class="string">&quot;.xml&quot;</span>)</span><br><span class="line">    diff2 = <span class="built_in">set</span>(jpg_list).difference(<span class="built_in">set</span>(xml_list))  <span class="comment"># å·®é›†ï¼Œåœ¨bä¸­ä½†ä¸åœ¨aä¸­çš„å…ƒç´ </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(diff2))</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> diff2:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;no xml&quot;</span>, name + <span class="string">&quot;.webp&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    file_name(path1,path2)</span><br></pre></td></tr></table></figure><h3 id="ä½¿ç”¨-imgaug-åº“å›¾åƒå¢å¹¿"><a href="#ä½¿ç”¨-imgaug-åº“å›¾åƒå¢å¹¿" class="headerlink" title="ä½¿ç”¨ imgaug åº“å›¾åƒå¢å¹¿"></a>ä½¿ç”¨ <code>imgaug</code> åº“å›¾åƒå¢å¹¿</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> getcwd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> imgaug <span class="keyword">as</span> ia</span><br><span class="line"><span class="keyword">from</span> imgaug <span class="keyword">import</span> augmenters <span class="keyword">as</span> iaa</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageFile</span><br><span class="line"></span><br><span class="line">ImageFile.LOAD_TRUNCATED_IMAGES = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ia.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_xml_annotation</span>(<span class="params">root, image_id</span>):</span><br><span class="line">    in_file = <span class="built_in">open</span>(os.path.join(root, image_id))</span><br><span class="line">    tree = ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    bndboxlist = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">object</span> <span class="keyword">in</span> root.findall(<span class="string">&#x27;object&#x27;</span>):  <span class="comment"># æ‰¾åˆ°rootèŠ‚ç‚¹ä¸‹çš„æ‰€æœ‰countryèŠ‚ç‚¹</span></span><br><span class="line">        bndbox = <span class="built_in">object</span>.find(<span class="string">&#x27;bndbox&#x27;</span>)  <span class="comment"># å­èŠ‚ç‚¹ä¸‹èŠ‚ç‚¹rankçš„å€¼</span></span><br><span class="line"></span><br><span class="line">        xmin = <span class="built_in">int</span>(<span class="built_in">float</span>(bndbox.find(<span class="string">&#x27;xmin&#x27;</span>).text))</span><br><span class="line">        xmax = <span class="built_in">int</span>(<span class="built_in">float</span>(bndbox.find(<span class="string">&#x27;xmax&#x27;</span>).text))</span><br><span class="line">        ymin = <span class="built_in">int</span>(<span class="built_in">float</span>(bndbox.find(<span class="string">&#x27;ymin&#x27;</span>).text))</span><br><span class="line">        ymax = <span class="built_in">int</span>(<span class="built_in">float</span>(bndbox.find(<span class="string">&#x27;ymax&#x27;</span>).text))</span><br><span class="line">        <span class="comment"># print(xmin,ymin,xmax,ymax)</span></span><br><span class="line">        bndboxlist.append([xmin,ymin,xmax,ymax])</span><br><span class="line">        <span class="comment"># print(bndboxlist)</span></span><br><span class="line"></span><br><span class="line">    bndbox = root.find(<span class="string">&#x27;object&#x27;</span>).find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> bndboxlist</span><br><span class="line"><span class="comment"># (506.0000, 330.0000, 528.0000, 348.0000) -&gt; (520.4747, 381.5080, 540.5596, 398.6603)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">change_xml_annotation</span>(<span class="params">root, image_id, new_target</span>):</span><br><span class="line">    new_xmin = new_target[<span class="number">0</span>]</span><br><span class="line">    new_ymin = new_target[<span class="number">1</span>]</span><br><span class="line">    new_xmax = new_target[<span class="number">2</span>]</span><br><span class="line">    new_ymax = new_target[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    in_file = <span class="built_in">open</span>(os.path.join(root, <span class="built_in">str</span>(image_id) + <span class="string">&#x27;.xml&#x27;</span>))  <span class="comment"># è¿™é‡Œrootåˆ†åˆ«ç”±ä¸¤ä¸ªæ„æ€</span></span><br><span class="line">    tree = ET.parse(in_file)</span><br><span class="line">    xmlroot = tree.getroot()</span><br><span class="line">    <span class="built_in">object</span> = xmlroot.find(<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">    bndbox = <span class="built_in">object</span>.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">    xmin = bndbox.find(<span class="string">&#x27;xmin&#x27;</span>)</span><br><span class="line">    xmin.text = <span class="built_in">str</span>(new_xmin)</span><br><span class="line">    ymin = bndbox.find(<span class="string">&#x27;ymin&#x27;</span>)</span><br><span class="line">    ymin.text = <span class="built_in">str</span>(new_ymin)</span><br><span class="line">    xmax = bndbox.find(<span class="string">&#x27;xmax&#x27;</span>)</span><br><span class="line">    xmax.text = <span class="built_in">str</span>(new_xmax)</span><br><span class="line">    ymax = bndbox.find(<span class="string">&#x27;ymax&#x27;</span>)</span><br><span class="line">    ymax.text = <span class="built_in">str</span>(new_ymax)</span><br><span class="line">    tree.write(os.path.join(root, <span class="built_in">str</span>(image_id) + <span class="string">&quot;_aug&quot;</span> + <span class="string">&#x27;.xml&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">change_xml_list_annotation</span>(<span class="params">root, image_id, new_target,saveroot,<span class="built_in">id</span></span>):</span><br><span class="line"></span><br><span class="line">    in_file = <span class="built_in">open</span>(os.path.join(root, <span class="built_in">str</span>(image_id) + <span class="string">&#x27;.xml&#x27;</span>))  <span class="comment"># è¿™é‡Œrootåˆ†åˆ«ç”±ä¸¤ä¸ªæ„æ€</span></span><br><span class="line">    tree = ET.parse(in_file)</span><br><span class="line">    xmlroot = tree.getroot()</span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">object</span> <span class="keyword">in</span> xmlroot.findall(<span class="string">&#x27;object&#x27;</span>):  <span class="comment"># æ‰¾åˆ°rootèŠ‚ç‚¹ä¸‹çš„æ‰€æœ‰countryèŠ‚ç‚¹</span></span><br><span class="line">        bndbox = <span class="built_in">object</span>.find(<span class="string">&#x27;bndbox&#x27;</span>)  <span class="comment"># å­èŠ‚ç‚¹ä¸‹èŠ‚ç‚¹rankçš„å€¼</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># xmin = int(bndbox.find(&#x27;xmin&#x27;).text)</span></span><br><span class="line">        <span class="comment"># xmax = int(bndbox.find(&#x27;xmax&#x27;).text)</span></span><br><span class="line">        <span class="comment"># ymin = int(bndbox.find(&#x27;ymin&#x27;).text)</span></span><br><span class="line">        <span class="comment"># ymax = int(bndbox.find(&#x27;ymax&#x27;).text)</span></span><br><span class="line"></span><br><span class="line">        new_xmin = new_target[index][<span class="number">0</span>]</span><br><span class="line">        new_ymin = new_target[index][<span class="number">1</span>]</span><br><span class="line">        new_xmax = new_target[index][<span class="number">2</span>]</span><br><span class="line">        new_ymax = new_target[index][<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        xmin = bndbox.find(<span class="string">&#x27;xmin&#x27;</span>)</span><br><span class="line">        xmin.text = <span class="built_in">str</span>(new_xmin)</span><br><span class="line">        ymin = bndbox.find(<span class="string">&#x27;ymin&#x27;</span>)</span><br><span class="line">        ymin.text = <span class="built_in">str</span>(new_ymin)</span><br><span class="line">        xmax = bndbox.find(<span class="string">&#x27;xmax&#x27;</span>)</span><br><span class="line">        xmax.text = <span class="built_in">str</span>(new_xmax)</span><br><span class="line">        ymax = bndbox.find(<span class="string">&#x27;ymax&#x27;</span>)</span><br><span class="line">        ymax.text = <span class="built_in">str</span>(new_ymax)</span><br><span class="line"></span><br><span class="line">        index = index + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    tree.write(os.path.join(saveroot, <span class="built_in">str</span>(image_id) + <span class="string">&quot;_aug_&quot;</span> + <span class="built_in">str</span>(<span class="built_in">id</span>) + <span class="string">&#x27;.xml&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mkdir</span>(<span class="params">path</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># å»é™¤é¦–ä½ç©ºæ ¼</span></span><br><span class="line">    path = path.strip()</span><br><span class="line">    <span class="comment"># å»é™¤å°¾éƒ¨ \ ç¬¦å·</span></span><br><span class="line">    path = path.rstrip(<span class="string">&quot;\\&quot;</span>)</span><br><span class="line">    <span class="comment"># åˆ¤æ–­è·¯å¾„æ˜¯å¦å­˜åœ¨</span></span><br><span class="line">    <span class="comment"># å­˜åœ¨     True</span></span><br><span class="line">    <span class="comment"># ä¸å­˜åœ¨   False</span></span><br><span class="line">    isExists = os.path.exists(path)</span><br><span class="line">    <span class="comment"># åˆ¤æ–­ç»“æœ</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">        <span class="comment"># å¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºç›®å½•</span></span><br><span class="line">         <span class="comment"># åˆ›å»ºç›®å½•æ“ä½œå‡½æ•°</span></span><br><span class="line">        os.makedirs(path)</span><br><span class="line">        <span class="built_in">print</span>(path + <span class="string">&#x27; åˆ›å»ºæˆåŠŸ&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># å¦‚æœç›®å½•å­˜åœ¨åˆ™ä¸åˆ›å»ºï¼Œå¹¶æç¤ºç›®å½•å·²å­˜åœ¨</span></span><br><span class="line">        <span class="built_in">print</span>(path + <span class="string">&#x27; ç›®å½•å·²å­˜åœ¨&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    IMG_DIR = <span class="string">&quot;./JPEGImages&quot;</span></span><br><span class="line">    XML_DIR = <span class="string">&quot;./Annotations&quot;</span></span><br><span class="line"></span><br><span class="line">    AUG_XML_DIR = <span class="string">&quot;./aug_Annotations&quot;</span>  <span class="comment"># å­˜å‚¨å¢å¼ºåçš„XMLæ–‡ä»¶å¤¹è·¯å¾„</span></span><br><span class="line">    mkdir(AUG_XML_DIR)</span><br><span class="line"></span><br><span class="line">    AUG_IMG_DIR = <span class="string">&quot;./aug_JPEGImages&quot;</span>  <span class="comment"># å­˜å‚¨å¢å¼ºåçš„å½±åƒæ–‡ä»¶å¤¹è·¯å¾„</span></span><br><span class="line">    mkdir(AUG_IMG_DIR)</span><br><span class="line"></span><br><span class="line">    AUGLOOP = <span class="number">2</span> <span class="comment"># æ¯å¼ å½±åƒå¢å¼ºçš„æ•°é‡</span></span><br><span class="line"></span><br><span class="line">    boxes_img_aug_list = []</span><br><span class="line">    new_bndbox = []</span><br><span class="line">    new_bndbox_list = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># å½±åƒå¢å¼º</span></span><br><span class="line">    seq = iaa.Sequential([</span><br><span class="line">        <span class="comment"># iaa.Flipud(0.5),  # vertically flip 20% of all images</span></span><br><span class="line">        iaa.Fliplr(<span class="number">0.5</span>),  <span class="comment"># é•œåƒ</span></span><br><span class="line">        iaa.Multiply((<span class="number">1.2</span>, <span class="number">1.5</span>)),  <span class="comment"># change brightness, doesn&#x27;t affect BBs</span></span><br><span class="line">        iaa.GaussianBlur(sigma=(<span class="number">0</span>, <span class="number">3.0</span>)), <span class="comment"># iaa.GaussianBlur(0.5),</span></span><br><span class="line">        iaa.Affine(</span><br><span class="line">            translate_px=&#123;<span class="string">&quot;x&quot;</span>: <span class="number">15</span>, <span class="string">&quot;y&quot;</span>: <span class="number">15</span>&#125;,</span><br><span class="line">            scale=(<span class="number">0.8</span>, <span class="number">0.95</span>),</span><br><span class="line">            rotate=(-<span class="number">30</span>, <span class="number">30</span>)</span><br><span class="line">        )  <span class="comment"># translate by 40/60px on x/y axis, and scale to 50-70%, affects BBs</span></span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> root, sub_folders, files <span class="keyword">in</span> os.walk(XML_DIR):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line"></span><br><span class="line">            bndbox = read_xml_annotation(XML_DIR, name)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(AUGLOOP):</span><br><span class="line">                seq_det = seq.to_deterministic()  <span class="comment"># ä¿æŒåæ ‡å’Œå›¾åƒåŒæ­¥æ”¹å˜ï¼Œè€Œä¸æ˜¯éšæœº</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># è¯»å–å›¾ç‰‡</span></span><br><span class="line">                img = Image.<span class="built_in">open</span>(os.path.join(IMG_DIR, name[:-<span class="number">4</span>] + <span class="string">&#x27;.webp&#x27;</span>))</span><br><span class="line">                img = np.array(img)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># bndbox åæ ‡å¢å¼º</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(bndbox)):</span><br><span class="line">                    bbs = ia.BoundingBoxesOnImage([</span><br><span class="line">                        ia.BoundingBox(x1=bndbox[i][<span class="number">0</span>], y1=bndbox[i][<span class="number">1</span>], x2=bndbox[i][<span class="number">2</span>], y2=bndbox[i][<span class="number">3</span>]),</span><br><span class="line">                    ], shape=img.shape)</span><br><span class="line"></span><br><span class="line">                    bbs_aug = seq_det.augment_bounding_boxes([bbs])[<span class="number">0</span>]</span><br><span class="line">                    boxes_img_aug_list.append(bbs_aug)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># new_bndbox_list:[[x1,y1,x2,y2],...[],[]]</span></span><br><span class="line">                    new_bndbox_list.append([<span class="built_in">int</span>(bbs_aug.bounding_boxes[<span class="number">0</span>].x1),</span><br><span class="line">                                            <span class="built_in">int</span>(bbs_aug.bounding_boxes[<span class="number">0</span>].y1),</span><br><span class="line">                                            <span class="built_in">int</span>(bbs_aug.bounding_boxes[<span class="number">0</span>].x2),</span><br><span class="line">                                            <span class="built_in">int</span>(bbs_aug.bounding_boxes[<span class="number">0</span>].y2)])</span><br><span class="line">                <span class="comment"># å­˜å‚¨å˜åŒ–åçš„å›¾ç‰‡</span></span><br><span class="line">                image_aug = seq_det.augment_images([img])[<span class="number">0</span>]</span><br><span class="line">                path = os.path.join(AUG_IMG_DIR, <span class="built_in">str</span>(name[:-<span class="number">4</span>]) + <span class="string">&quot;_aug_&quot;</span> + <span class="built_in">str</span>(epoch) + <span class="string">&#x27;.webp&#x27;</span>)</span><br><span class="line">                <span class="comment"># image_auged = bbs.draw_on_image(image_aug, thickness=0)</span></span><br><span class="line">                Image.fromarray(image_aug).save(path)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># å­˜å‚¨å˜åŒ–åçš„XML</span></span><br><span class="line">                change_xml_list_annotation(XML_DIR, name[:-<span class="number">4</span>], new_bndbox_list,AUG_XML_DIR,epoch)</span><br><span class="line">                <span class="built_in">print</span>(<span class="built_in">str</span>(name[:-<span class="number">4</span>]) + <span class="string">&quot;_aug_&quot;</span> + <span class="built_in">str</span>(epoch) + <span class="string">&#x27;.webp&#x27;</span>)</span><br><span class="line">                new_bndbox_list = []</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•°æ®é›† </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster-RCNNåŸç†ç¬”è®°</title>
      <link href="/p/6e84daf2/"/>
      <url>/p/6e84daf2/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è¯¦ç»†è®°å½•äº† Faster RCNN ç½‘ç»œåŸç†å’Œä¸ªäººçš„ç†è§£</p><span id="more"></span><ul><li><a href="https://arxiv.org/abs/1506.01497">è®ºæ–‡ä¸‹è½½</a></li><li><a href="https://github.com/rbgirshick/py-faster-rcnn">è®ºæ–‡æºç </a></li></ul><h2 id="åŸç†"><a href="#åŸç†" class="headerlink" title="åŸç†"></a>åŸç†</h2><h3 id="è®ºæ–‡ä¸­çš„ç½‘ç»œç»“æ„å›¾è§£"><a href="#è®ºæ–‡ä¸­çš„ç½‘ç»œç»“æ„å›¾è§£" class="headerlink" title="è®ºæ–‡ä¸­çš„ç½‘ç»œç»“æ„å›¾è§£"></a>è®ºæ–‡ä¸­çš„ç½‘ç»œç»“æ„å›¾è§£</h3><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/faster-rcnn-network.webp" style="zoom:30%;" /></p><p>ä¸»è¦æ­¥éª¤æ˜¯</p><ol><li>è¾“å…¥å›¾ç‰‡</li><li>å¯¹å›¾ç‰‡è¿›è¡Œå·ç§¯ï¼Œæå–ç‰¹å¾</li><li>ä½¿ç”¨ RPN ç½‘ç»œç”Ÿæˆ Anchor boxï¼Œå¯¹å…¶è£å‰ªè¿‡æ»¤åï¼Œé€šè¿‡ softmax å¯¹å‰æ™¯å’Œåæ™¯åˆ†ç±»ï¼ŒåŒæ—¶ï¼Œbounding box regression ä¿®æ­£ anchor boxï¼Œå½¢æˆæ ¡æ­£åçš„ proposals</li><li>å°† proposals æ˜ å°„åˆ° feature maps ä¸Š</li><li>é€šè¿‡ RoI pooling å±‚ä½¿æ¯ä¸ª RoI ç”Ÿæˆå›ºå®šå°ºå¯¸çš„ feature map</li><li>åˆ©ç”¨ Softmax Loss å’Œ Smooth L1 Loss å¯¹åˆ†ç±»æ¦‚ç‡å’Œè¾¹æ¡†å›å½’è”åˆè®­ç»ƒ</li></ol><h3 id="Faster-RCNN-å…·ä½“çš„ç½‘ç»œç»“æ„å›¾"><a href="#Faster-RCNN-å…·ä½“çš„ç½‘ç»œç»“æ„å›¾" class="headerlink" title="Faster RCNN å…·ä½“çš„ç½‘ç»œç»“æ„å›¾"></a>Faster RCNN å…·ä½“çš„ç½‘ç»œç»“æ„å›¾</h3><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/construction.webp" alt="construction"></p><h3 id="ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œ"><a href="#ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œ" class="headerlink" title="ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œ"></a>ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œ</h3><p>å¯é€‰ ResNetï¼ŒMobileNetï¼ŒVGG16 ç­‰ç½‘ç»œï¼Œæœ¬æ¨¡å‹ä½¿ç”¨çš„æ˜¯ VGG16 ç½‘ç»œï¼Œç”±å·ç§¯å±‚æ¨¡å—åæ¥å…¨è¿æ¥å±‚æ¨¡å—æ„æˆï¼Œæ¯ä¸ªå·ç§¯å±‚çš„å‚æ•°åˆ†åˆ«ä¸º <code>kernel_size=(3,3), padding=&#39;same&#39;, activation=&#39;relu&#39;, kernel_regularizer=&#39;l2&#39;</code>ï¼Œæœ€å¤§æ± åŒ–å±‚çš„å‚æ•°ä¸º <code>pool_size=(2,2), padding=&#39;same&#39;</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">____________________________________________________________________________________________________</span><br><span class="line">Layer (<span class="built_in">type</span>)                                 Output Shape                            Param <span class="comment">#        </span></span><br><span class="line">====================================================================================================</span><br><span class="line">input_1 (InputLayer)                         [(<span class="literal">None</span>, <span class="number">500</span>, <span class="number">500</span>, <span class="number">3</span>)]                   <span class="number">0</span>              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d (Conv2D)                              (<span class="literal">None</span>, <span class="number">500</span>, <span class="number">500</span>, <span class="number">64</span>)                    <span class="number">1792</span>           </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_1 (Conv2D)                            (<span class="literal">None</span>, <span class="number">500</span>, <span class="number">500</span>, <span class="number">64</span>)                    <span class="number">36928</span>          </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">max_pooling2d (MaxPooling2D)                 (<span class="literal">None</span>, <span class="number">250</span>, <span class="number">250</span>, <span class="number">64</span>)                    <span class="number">0</span>              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_2 (Conv2D)                            (<span class="literal">None</span>, <span class="number">250</span>, <span class="number">250</span>, <span class="number">128</span>)                   <span class="number">73856</span>          </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_3 (Conv2D)                            (<span class="literal">None</span>, <span class="number">250</span>, <span class="number">250</span>, <span class="number">128</span>)                   <span class="number">147584</span>         </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">max_pooling2d_1 (MaxPooling2D)               (<span class="literal">None</span>, <span class="number">125</span>, <span class="number">125</span>, <span class="number">128</span>)                   <span class="number">0</span>              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_4 (Conv2D)                            (<span class="literal">None</span>, <span class="number">125</span>, <span class="number">125</span>, <span class="number">256</span>)                   <span class="number">295168</span>         </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_5 (Conv2D)                            (<span class="literal">None</span>, <span class="number">125</span>, <span class="number">125</span>, <span class="number">256</span>)                   <span class="number">590080</span>         </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_6 (Conv2D)                            (<span class="literal">None</span>, <span class="number">125</span>, <span class="number">125</span>, <span class="number">256</span>)                   <span class="number">590080</span>         </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">max_pooling2d_2 (MaxPooling2D)               (<span class="literal">None</span>, <span class="number">63</span>, <span class="number">63</span>, <span class="number">256</span>)                     <span class="number">0</span>              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_7 (Conv2D)                            (<span class="literal">None</span>, <span class="number">63</span>, <span class="number">63</span>, <span class="number">512</span>)                     <span class="number">1180160</span>        </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_8 (Conv2D)                            (<span class="literal">None</span>, <span class="number">63</span>, <span class="number">63</span>, <span class="number">512</span>)                     <span class="number">2359808</span>        </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_9 (Conv2D)                            (<span class="literal">None</span>, <span class="number">63</span>, <span class="number">63</span>, <span class="number">512</span>)                     <span class="number">2359808</span>        </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">max_pooling2d_3 (MaxPooling2D)               (<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">512</span>)                     <span class="number">0</span>              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_10 (Conv2D)                           (<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">512</span>)                     <span class="number">2359808</span>        </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_11 (Conv2D)                           (<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">512</span>)                     <span class="number">2359808</span>        </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv2d_12 (Conv2D)                           (<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">512</span>)                     <span class="number">2359808</span>        </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">dense (Dense)                                (<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">10</span>)                      <span class="number">5130</span>           </span><br><span class="line">====================================================================================================</span><br><span class="line">Total params: <span class="number">14</span>,<span class="number">719</span>,<span class="number">818</span></span><br><span class="line">Trainable params: <span class="number">14</span>,<span class="number">719</span>,<span class="number">818</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">____________________________________________________________________________________________________</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨ VGG16 ç½‘ç»œä¸åƒresneté‚£ä¹ˆå¤æ‚ï¼Œæ›´æ·±çš„ç½‘ç»œç†è®ºä¸Šæ•ˆæœä¹Ÿæ›´å¥½</p><h3 id="RPN-Region-Proposal-Networks"><a href="#RPN-Region-Proposal-Networks" class="headerlink" title="RPN (Region Proposal Networks)"></a>RPN (Region Proposal Networks)</h3><p>åœ¨å›¾åƒä¸­äº§ç”Ÿæ‰€æœ‰å¯èƒ½ä¸ºç›®æ ‡çš„å€™é€‰åŒºåŸŸï¼Œç”¨æ¥è§£å†³ç”Ÿæˆæ£€æµ‹æ¡†è€—æ—¶è¾ƒå¤šçš„é—®é¢˜ã€‚RPN æ ¹æ® CNN ç”Ÿæˆçš„ç‰¹å¾å›¾ï¼Œåœ¨ img çš„å°ºåº¦ä¸Šç”Ÿæˆå¤šä¸ªé”šæ¡†ï¼Œå¯¹ç”Ÿæˆçš„é”šæ¡†è¿›è¡Œåˆ†ç±»å’Œå›å½’ã€‚</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/rpn.webp" alt="rpn" style="zoom:67%;" /></p><p>ç½‘ç»œåˆ†ä¸º2æ¡çº¿ï¼Œä¸Šé¢ä¸€æ¡é€šè¿‡softmaxåˆ†ç±» anchors è·å¾—positive å’Œ negative åˆ†ç±»ï¼Œä¸‹é¢ä¸€æ¡ç”¨äºè®¡ç®—å¯¹äº anchors çš„ bounding box regression åç§»é‡ï¼Œè·å¾—ç²¾ç¡®çš„ proposalã€‚æœ€åçš„ Proposal layer è´Ÿè´£ç»¼åˆ positive anchors å’Œå¯¹åº” bounding box regression åç§»é‡è·å– proposalsï¼ŒåŒæ—¶å‰”é™¤å¤ªå°å’Œè¶…å‡ºè¾¹ç•Œçš„ proposals</p><h4 id="ahchors"><a href="#ahchors" class="headerlink" title="ahchors"></a>ahchors</h4><p>æ˜¯ä¸€ç§å¤šå°ºåº¦æ–¹æ³•ï¼Œä»¥ä¸€ä¸ªåƒç´ ç‚¹ä¸ºä¸­å¿ƒï¼Œç”Ÿæˆä¸€ç»„æè¿° 9 ä¸ªçŸ©å½¢çš„çŸ©é˜µï¼Œæ¯è¡Œ4ä¸ªå€¼ $(x_min, y_min, x_max, y_max)$ è¡¨ç¤ºçŸ©å½¢å·¦ä¸Šå’Œå³ä¸‹è§’ç‚¹åæ ‡ï¼Œé•¿å®½æ¯”ä¸º $ width:height \in { 1:1, 1:2, 2:1 } $ </p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/anchors.webp" alt="anchors"></p><p>å…¶ä¸­ï¼Œanchors size æ˜¯æ ¹æ®æ£€æµ‹å›¾åƒè®¾ç½®çš„ï¼ŒFaster RCNNç½‘ç»œä¼šæŠŠæ‰€æœ‰è¾“å…¥çš„å›¾åƒ reshape æˆå›ºå®šå¤§å°ï¼Œåœ¨è®ºæ–‡ä¸­ï¼Œä¼šä¸º feature map ä¸­çš„æ¯ä¸ªåƒç´ ç‚¹ç”Ÿæˆ anchorsï¼Œåé¢çš„2æ¬¡ bounding box regression ä¼šä¿®æ­£ anchors æ£€æµ‹æ¡†ä½ç½®</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/anchors.webp" alt="anchors" style="zoom:67%;" /></p><p>ä¸Šå›¾æˆªå–è‡ªè®ºæ–‡ï¼Œå…¶ä¸­</p><ul><li>256-d: è®ºæ–‡ä¸­ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œçš„æœ€åä¸€å±‚ num_output=256ï¼Œå¯¹åº”ç”Ÿæˆçš„ feature map æ˜¯256ç»´çš„</li><li>sliding window: feature map åœ¨è¿›å…¥ RPN ç½‘ç»œåï¼Œåˆè¿›è¡Œäº†ä¸€æ¬¡ 3x3 çš„å·ç§¯ï¼Œ256-d æ²¡æœ‰å˜</li><li>$cls \quad layer$: å·²çŸ¥æ¯ä¸ªåƒç´ ç‚¹ä¸Šæœ‰ k ä¸ª anchor(å›¾ä¸­ k = 9)ï¼Œæ¯ä¸ª anchor è¦åˆ†å‰æ™¯(positive)å’ŒèƒŒæ™¯(negative)ï¼Œæ‰€ä»¥æ¯ä¸ªç‚¹ç”± 256-d çš„ feature map è½¬åŒ–ä¸º 2k scores</li><li>$reg \quad layer$: å·²çŸ¥æ¯ä¸ªåƒç´ ç‚¹ä¸Šæœ‰ k ä¸ª anchor(å›¾ä¸­ k = 9)ï¼Œæ¯ä¸ª anchor æœ‰ $(x, y, w, h)$ å¯¹åº”çš„4ä¸ªåç§»é‡ï¼Œæ‰€ä»¥æ¯ä¸ªç‚¹ç”± 256-d çš„ feature map è½¬åŒ–ä¸º 4k coordinates</li></ul><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/gernerate_anchors.webp" alt="gernerate_anchors" style="zoom:60%;" /></p><p>ä¸Šå›¾ä»¥ å›¾ç‰‡å¤§å° 500x500 ä¸ºä¾‹ï¼Œè®¡ç®—ç”Ÿæˆçš„ gernerate anchors çš„æ•°é‡</p><script type="math/tex; mode=display">\operatorname{ceil}(500 / 16) \times \operatorname{ceil}(500 / 16) \times 9=32 \times 32 \times 9= 9216</script><p>ceil()ä¸ºå‘ä¸Šå–æ•´ï¼Œå› ä¸ºå›¾ä¸­VGG16ç½‘ç»œè¾“å‡ºçš„ feature map size ä¸ºæ•´æ•°</p><h4 id="åˆ¤å®š-positive-negative"><a href="#åˆ¤å®š-positive-negative" class="headerlink" title="åˆ¤å®š positive/negative"></a>åˆ¤å®š positive/negative</h4><p>ä¸»è¦æ­¥éª¤ï¼š</p><ol><li>RPN ç½‘ç»œå›¾ä¸­ä¸Šé¢ä¸€æ¡è¾“å…¥ä¸ºå…±äº«å±‚å·ç§¯çš„è¾“å‡º</li><li>è¿›è¡Œé€šé“æ•°ä¸º2k(k=num_anchors)çš„ 1x1 å·ç§¯</li><li>reshape æˆä¸¤ä¸ªé€šé“</li><li>å¯¹é€šé“å±‚åšå½’ä¸€åŒ–ï¼Œä½¿ç±»åˆ«é¢„æµ‹çš„æ¦‚ç‡å’Œä¸º 1</li><li>å–æœ€ç»ˆçš„é¢„æµ‹ç±»åˆ«å’Œæ¦‚ç‡</li><li>reshape å›å¤åŸçŠ¶ <code>[1, h, w, 9*2]</code></li></ol><p>è®ºæ–‡ä½œè€…åœ¨æºç ä¸­çš„ softmax_loss_layer.cpp å¯¹æœ€å reshapeå±‚ çš„è§£é‡Š:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Number of labels must match number of predictions; &quot;</span></span><br><span class="line"><span class="string">&quot;e.g., if softmax axis == 1 and prediction shape is (N, C, H, W), &quot;</span></span><br><span class="line"><span class="string">&quot;label count (number of labels) must be N*H*W, &quot;</span></span><br><span class="line"><span class="string">&quot;with integer values in &#123;0, 1, ..., C-1&#125;.&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="bounding-box-regression"><a href="#bounding-box-regression" class="headerlink" title="bounding box regression"></a>bounding box regression</h4><p>å›¾ä¸­æ‰€ç¤ºï¼Œç»¿è‰²æ¡†ä¸ºè‹¹æœçš„ ground truthï¼Œçº¢è‰²ä¸ºæå–çš„ positive anchorsï¼Œå³ä¾¿çº¢è‰²çš„æ¡†è¢«åˆ†ç±»å™¨è¯†åˆ«ä¸ºè‹¹æœï¼Œä½†æ˜¯ç”±äºçº¢è‰²çš„æ¡†å®šä½ä¸å‡†ï¼Œè¿™å¼ å›¾ç›¸å½“äºæ²¡æœ‰æ­£ç¡®çš„æ£€æµ‹å‡ºè‹¹æœã€‚æ‰€ä»¥éœ€è¦é‡‡ç”¨ä¸€ç§æ–¹æ³•å¯¹çº¢è‰²çš„æ¡†è¿›è¡Œå¾®è°ƒï¼Œä½¿å¾— positive anchors å’Œ ground truth æ›´åŠ æ¥è¿‘</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/bounding.webp" alt="bounding" style="zoom:75%;" /></p><p>å¯¹äºçª—å£ä¸€èˆ¬ä½¿ç”¨å››ç»´å‘é‡ $(x, y, w, h)$ è¡¨ç¤ºï¼Œåˆ†åˆ«è¡¨ç¤ºçª—å£çš„ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜ï¼Œçº¢æ¡†ä»£è¡¨åŸå§‹çš„positive anchorsï¼Œç»¿æ¡†ä»£è¡¨ç›®æ ‡çš„ ground truthï¼Œä½¿å¾—è¾“å…¥åŸå§‹çš„ anchor ç»è¿‡æ˜ å°„å¾—åˆ°ä¸€ä¸ªè·Ÿ ground truth æ›´æ¥è¿‘çš„å›å½’çª—å£ï¼Œå³</p><p>positive anchors:  $A = (A_x, A_y, A_w, A_h)$</p><p>ground truth:  $GT = (G_x, G_y, G_w, G_h)$</p><p>å¯»æ‰¾ $F$ï¼Œä½¿ $F(A) = (G<em>{x}^{\prime}, G</em>{y}^{\prime}, G<em>{w}^{\prime}, G</em>{h}^{\prime})$</p><p>å…¶ä¸­ $(G<em>{x}^{\prime}, G</em>{y}^{\prime}, G<em>{w}^{\prime}, G</em>{h}^{\prime}) \approx (G<em>{x}, G</em>{y}, G<em>{w}, G</em>{h})$</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/fag.webp" alt="fag" style="zoom:33%;" /></p><p>é€šè¿‡å˜æ¢ $F$ä» $A$ å˜æ¢åˆ° $Gâ€™$ï¼Œæˆ‘ä»¬è¦åšçš„æ˜¯</p><p>å¹³ç§»</p><script type="math/tex; mode=display">G_x^\prime = A_w \cdot d_x(A) + A_x \\G_y^\prime = A_h \cdot d_y(A) + A_y</script><p>ç¼©æ”¾</p><script type="math/tex; mode=display">G_w^\prime = A_w \cdot exp(d_w(A))\\G_h^\prime = A_h \cdot exp(d_h(A))</script><p>éœ€è¦å­¦ä¹ çš„æ˜¯ $d_x(A), d_y(A), d_w(A) ,d_h(A)$ è¿™å››ä¸ªå˜æ¢ã€‚å½“è¾“å…¥çš„ $A$ ä¸ $GT$ ç›¸å·®è¾ƒå°æ—¶ï¼Œè®¤ä¸ºè¿™ç§å˜æ¢æ˜¯ä¸€ç§çº¿æ€§å˜æ¢ï¼Œ ç”¨çº¿æ€§å›å½’æ¥å»ºæ¨¡å¯¹çª—å£è¿›è¡Œå¾®è°ƒï¼Œå½“ $A$ å’Œ $GT$ æ¯”è¾ƒæ¥è¿‘æ—¶ï¼Œè®¤ä¸ºæ˜¯å¤æ‚çš„éçº¿æ€§é—®é¢˜</p><p>å·²çŸ¥çº¿æ€§å›å½’å…¬å¼ $Y = WX$ï¼Œ$X$ ä¸º feature mapï¼Œå®šä¹‰ä¸º $\phi$ï¼Œè®­ç»ƒä¼ å…¥$A$ä¸$GT$ä¹‹é—´çš„å˜æ¢é‡ $(t_x, t_y, t_w, t_h, )$ï¼Œ$Y$ä¸º $(d_x(A), d_y(A), d_w(A) ,d_h(A))$ï¼Œåˆ™ç›®æ ‡å‡½æ•°ä¸º</p><script type="math/tex; mode=display">d_*(A) = W_*^T\phi(A)</script><p>å…¶ä¸­ $\phi(A)$ æ˜¯å¯¹åº” anchor çš„ feature map ç»„æˆçš„ç‰¹å¾å‘é‡ï¼Œ$W<em>{*}$ æ˜¯éœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œ$d</em>{*}(A)$ æ˜¯å¾—åˆ°çš„é¢„æµ‹å€¼</p><p>åœ¨ Faster RCNN è®ºæ–‡ä¸­ï¼Œpositive anchor ä¸ ground truth ä¹‹é—´çš„å¹³ç§»é‡ $(t_x, t_y)$ ä¸å°ºåº¦å› å­ $(t_w, t_h)$  å¦‚ä¸‹</p><script type="math/tex; mode=display">t_x = (x-x_a)/w_a \quad t_y = (y-y_a)/h_a \\t_w = \log(w/w_a) \quad t_h = \log(h/h_a)</script><p>ä¸ºäº†è®©é¢„æµ‹å€¼ $ {d<em>{*}(A) }$ ä¸çœŸå®å€¼å·®è·æœ€å°ï¼Œ ${\operatorname{smooth}</em>{L_{1}}}$ æŸå¤±å‡½æ•°ä¸º</p><script type="math/tex; mode=display">Loss = \begin{cases} 0.5 \cdot (\sum_i^N (t_*^i -W_*^T \cdot \phi(A^i))^2 & \text{if}|x| <1 \\\sum_i^N |t_*^i -W_*^T \cdot \phi(A^i)| - 0.5 & \text{otherwise} \\\end{cases}</script><p>ä¼˜åŒ–ç›®æ ‡å‡½æ•°ä¸º</p><script type="math/tex; mode=display">\hat{W}_* = {argmin}_{W_*} \sum_i^n (t_*^i -W_*^T \cdot \phi(A^i))^2 + \lambda \| W_* \|</script><p>ä¹‹åå¯é€šè¿‡æ¢¯åº¦ä¸‹é™ç­‰æ–¹æ³•ä¿®æ­£ anchor ä½ç½®ï¼Œæ³¨æ„å½“ $A$ å’Œ $GT$ æ¯”è¾ƒæ¥è¿‘æ—¶ï¼Œæ‰å¯è¿‘ä¼¼è®¤ä¸ºä¸Šè¿°çº¿æ€§å˜æ¢åŠä¼˜åŒ–ç›®æ ‡å‡½æ•°æˆç«‹</p><h4 id="å¯¹-proposals-è¿›è¡Œ-bounding-box-regression"><a href="#å¯¹-proposals-è¿›è¡Œ-bounding-box-regression" class="headerlink" title="å¯¹ proposals è¿›è¡Œ bounding box regression"></a>å¯¹ proposals è¿›è¡Œ bounding box regression</h4><p>åœ¨ç¬¬äºŒæ¡çº¿è·¯ä¸­ï¼Œnum_output=36ï¼Œå³ç»è¿‡è¯¥å·ç§¯è¾“å‡ºå›¾åƒä¸º WxHx36ï¼Œå­˜å‚¨ä¸º <code>[1, 4x9, H, W]</code>ï¼Œè¿™é‡Œç›¸å½“äº feature maps æ¯ä¸ªç‚¹éƒ½æœ‰9ä¸ª anchorsï¼Œæ¯ä¸ª anchors åˆéƒ½æœ‰4ä¸ªç”¨äºå›å½’çš„ $(d_x(A), d_y(A), d_w(A) ,d_h(A))$ å˜æ¢é‡</p><p>VGG16 ç½‘ç»œè¾“å‡º $32 <em> 32 </em> 512$ çš„ç‰¹å¾ï¼Œå¯¹åº”è®¾ç½® $32<em>32</em>k$ ä¸ª anchorsï¼Œå› æ­¤RPNè¾“å‡º</p><ul><li><p>å¤§å°ä¸º $32 <em> 32 </em> 2k$ çš„ positive/negative softmax åˆ†ç±»ç‰¹å¾çŸ©é˜µ</p></li><li><p>å¤§å°ä¸º $32 <em> 32 </em> 4k$ çš„ regression åæ ‡å›å½’ç‰¹å¾çŸ©é˜µ</p></li></ul><p>å¯¹åº” RPN çš„ positive/negative åˆ†ç±»å’Œ bounding box regression åæ ‡å›å½’</p><h4 id="Proposal-Layer"><a href="#Proposal-Layer" class="headerlink" title="Proposal Layer"></a>Proposal Layer</h4><p>Proposal Layerè´Ÿè´£ç»¼åˆæ‰€æœ‰ $(d_x(A), d_y(A), d_w(A), d_h(A))$ å˜æ¢é‡å’Œ positive anchorsï¼Œè®¡ç®—å‡ºç²¾å‡†çš„proposalï¼Œé€å…¥åç»­ RoI Pooling Layer</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/proposal_layer.webp" style="zoom:67%;" /></p><p>Proposal Layeræœ‰3ä¸ªè¾“å…¥ï¼špositive/negative anchors åˆ†ç±»å™¨ç»“æœ rpn_cls_scoreï¼Œ$(d_x(A), d_y(A), d_w(A), d_h(A))$ çš„å˜æ¢é‡ rpn_bbox_predï¼Œimg_info(åŒ…å« feat_stride = 16)</p><p>img_info: å¯¹äºä¸€å‰¯ä»»æ„å¤§å° PxQ å›¾åƒï¼Œä¼ å…¥ Faster RCNN å‰_probæ¦‚é¦–å…ˆreshapeåˆ°å›ºå®š MxNï¼Œim_info=[M, N, scale_factor] ä¿å­˜äº†æ­¤æ¬¡ç¼©æ”¾çš„æ‰€æœ‰ä¿¡æ¯ã€‚ç„¶åç»è¿‡ VGG16ï¼Œç»è¿‡4æ¬¡ max_pooling2d å˜ä¸º WxH=(M/16)x(N/16) å¤§å°ï¼Œå…¶ä¸­ feature_stride=16 åˆ™ä¿å­˜äº†è¯¥ä¿¡æ¯ï¼Œç”¨äºè®¡ç®— anchor åç§»é‡</p><p>Proposal Layer forwardï¼ˆå‰ä¼ å‡½æ•°ï¼‰æŒ‰ç…§ä»¥ä¸‹é¡ºåºä¾æ¬¡å¤„ç†: </p><ol><li>ç”Ÿæˆanchorsï¼Œåˆ©ç”¨ $ (d_x(A), d_y(A), d_w(A), d_h(A)) $ å¯¹æ‰€æœ‰çš„ anchors åš bbox regression å›å½’ï¼ˆè¿™é‡Œçš„ anchors ç”Ÿæˆå’Œè®­ç»ƒæ—¶ç›¸åŒï¼‰</li><li>æŒ‰ç…§è¾“å…¥çš„ positive softmax scores ç”±å¤§åˆ°å°æ’åº anchorsï¼Œæå–å‰ pre_nms_top N(e.g. 5000) ä¸ªanchorsï¼Œå³æå–ä¿®æ­£ä½ç½®åçš„ positive anchors</li><li>é™å®šè¶…å‡ºå›¾åƒè¾¹ç•Œçš„ positive anchors ä¸ºå›¾åƒè¾¹ç•Œï¼Œé˜²æ­¢åç»­ ROIpooling æ—¶ proposal è¶…å‡ºå›¾åƒè¾¹ç•Œ</li><li>å‰”é™¤å°ºå¯¸éå¸¸å°çš„ positive anchors</li><li>å¯¹å‰©ä½™çš„ positive anchors è¿›è¡ŒNMS(æå¤§å€¼æŠ‘åˆ¶)</li><li>Proposal Layer æœ‰3ä¸ªè¾“å…¥: positive å’Œ negative anchors åˆ†ç±»å™¨ç»“æœ rpn_cls_scoreï¼Œå¯¹åº”çš„ bbox reg çš„ (e.g. 300) ç»“æœä½œä¸º proposal è¾“å‡º</li></ol><p>è¾“å‡º proposal ä¸º <code>[x_min, y_min, x_max, y_max]</code>ï¼Œç”±äºéœ€è¦å°† anchors æ˜ å°„å›åŸå›¾åˆ¤æ–­æ˜¯å¦è¶…å‡ºè¾¹ç•Œï¼Œæ‰€ä»¥ proposal å¯¹åº”çš„å›¾åƒå°ºåº¦ä¸º MxN</p><h3 id="ROIHead"><a href="#ROIHead" class="headerlink" title="ROIHead"></a>ROIHead</h3><p>åœ¨ä¼ ç»Ÿçš„CNNç½‘ç»œä¸­ï¼Œå½“è®­ç»ƒå¥½åè¾“å…¥çš„å›¾åƒå°ºå¯¸å¿…é¡»æ˜¯å›ºå®šå€¼ï¼ŒåŒæ—¶ç½‘ç»œè¾“å‡ºä¹Ÿæ˜¯å›ºå®šå¤§å°çš„ vector or matrixï¼Œå¦‚æœè¾“å…¥å›¾åƒå¤§å°ä¸å®šï¼Œè¿‡å»æœ‰2ç§è§£å†³åŠæ³•:</p><ul><li>ä»å›¾åƒä¸­ crop ä¸€éƒ¨åˆ†ä¼ å…¥ç½‘ç»œ</li><li>å°†å›¾åƒwarpæˆéœ€è¦çš„å¤§å°åä¼ å…¥ç½‘ç»œ</li></ul><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/crop_warp.webp" alt="crop_warp" style="zoom:67%;" /></p><p>cropåç ´åäº†å›¾åƒçš„å®Œæ•´ç»“æ„ï¼Œwarpåç ´åäº†å›¾åƒåŸå§‹å½¢çŠ¶ä¿¡æ¯ï¼Œä¸¤ç§æ–¹æ³•éƒ½ä¸å¥½</p><p>ä¸ºäº†ä½¿ç½‘ç»œå¯ä»¥æ¥æ”¶ä¸åŒå¤§å°çš„å›¾åƒï¼ŒFaster RCNN ä¸­æå‡ºäº† ROIPoolingï¼ŒROIPooling ä» [Spatial Pyramid Pooling]( å‘å±•è€Œæ¥ï¼Œè¿™é‡Œä¸å±•å¼€è®¨è®º</p><h4 id="ROI-pooling"><a href="#ROI-pooling" class="headerlink" title="ROI pooling"></a>ROI pooling</h4><p>ROIpooling å¯¹ proposal å¯¹ feature map è£å‰ªåçš„ ROIs è¿›è¡Œ maxpooling ä½¿è¾“å…¥çš„ shape ç›¸åŒï¼Œç”Ÿæˆ proposal feature mapsï¼Œå®ƒæœ‰3ä¸ªå‚æ•°: </p><ul><li>pooled_w: proposal feature maps çš„ width</li><li>pooled_h: proposal feature maps çš„ width</li><li>spatial_scale: æ˜¯ VGG16 æå– feature map åå¯¹å›¾åƒå°ºåº¦çš„æ”¹å˜ï¼Œä¹Ÿå°±æ˜¯ feature_stride=16</li></ul><p>ç”±äº proposal æ˜¯å¯¹åº” MxN å°ºåº¦çš„ï¼Œæ‰€ä»¥é¦–å…ˆä½¿ç”¨ spatial_scale å°†å…¶æ˜ å°„å›  (M/16)x(N/16) å¤§å°çš„ feature map å°ºåº¦ï¼Œå†å°†æ¯ä¸ª proposal å¯¹åº”çš„ feature map åŒºåŸŸæ°´å¹³åˆ†ä¸º pooled_w x pooled_h çš„ç½‘æ ¼ï¼Œå¯¹ç½‘æ ¼çš„æ¯ä¸€ä»½éƒ½è¿›è¡Œmax poolingå¤„ç†</p><p>ä¾‹:</p><p>å‡å®šè¾“å…¥ feature map ä¸º</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/pool_sample1.webp" alt="pool_sample1" style="zoom:35%;" /></p><p>å‡å®šåŒºåŸŸå»ºè®®ä¸º</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/pool_sample2.webp" alt="pool_sample2" style="zoom:35%;" /></p><p>å‡å®š pooled_w=2, pooled_h=2</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/pool_sample3.webp" alt="pool_sample3" style="zoom:35%;" /></p><p>å¯¹ç½‘æ ¼çš„æ¯ä¸€ä»½éƒ½è¿›è¡Œ max pooling å¤„ç†</p><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/pool_sample4.webp" alt="pool_sample4" style="zoom:40%;" /></p><p>è¿™ç§æ–¹æ³•æ˜¾è‘—åŠ å¿«äº†è®­ç»ƒå’Œæµ‹è¯•æ—¶é—´</p><h4 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h4><p><img src="/image/Faster-RCNNåŸç†ç¬”è®°/classfication.webp" alt="classfication" style="zoom:67%;" /></p><p>åˆ©ç”¨ ROIpooling è¾“å‡ºçš„ proposal feature mapsï¼Œé€šè¿‡ 1x1çš„conv2d å±‚ä¸ softmax è®¡ç®—æ¯ä¸ª proposal å…·ä½“å±äºé‚£ä¸ªç±»åˆ«ï¼Œè¾“å‡º cls_prob æ¦‚ç‡å‘é‡ï¼ŒåŒæ—¶å†æ¬¡åˆ©ç”¨ bounding box regression è·å¾—æ¯ä¸ª proposal çš„ä½ç½®åç§»é‡ bbox_predï¼Œç”¨äºå›å½’æ›´åŠ ç²¾ç¡®çš„ç›®æ ‡æ£€æµ‹æ¡†</p><h3 id="è®­ç»ƒè¿‡ç¨‹"><a href="#è®­ç»ƒè¿‡ç¨‹" class="headerlink" title="è®­ç»ƒè¿‡ç¨‹"></a>è®­ç»ƒè¿‡ç¨‹</h3><p>è®ºæ–‡æºç ä¸­è®­ç»ƒ Faster RCNN æœ‰ä¸¤ç§æ–¹å¼ï¼Œä¸€ç§æ˜¯å››æ­¥äº¤æ›¿è®­ç»ƒæ³•ï¼Œä¸€ç§æ˜¯ end-to-end è®­ç»ƒæ³•ï¼Œæœ¬æ–‡åªè®¨è®ºå››æ­¥äº¤æ›¿è®­ç»ƒæ³•</p><p>ç”±å‰é¢æˆ‘ä»¬å¯çŸ¥ï¼ŒFaster RCNN å¤§æ¦‚å¯ä»¥åˆ†ä¸º RPN ç½‘ç»œå’Œ Fast RCNN ç½‘ç»œéƒ¨åˆ†</p><ol><li><p>è®­ç»ƒ RPNï¼Œç”¨ feature map åˆå§‹åŒ– RPN ç½‘ç»œï¼Œå¹¶ç«¯åˆ°ç«¯å¾®è°ƒï¼Œç”Ÿæˆ region proposal</p></li><li><p>ç”¨ feature map åˆå§‹åŒ– Fast RCNN ç½‘ç»œéƒ¨åˆ†ï¼Œåˆ©ç”¨ç¬¬ä¸€æ­¥çš„ RPN ç”Ÿæˆçš„ region proposals ä½œä¸ºè¾“å…¥æ•°æ®ï¼Œæ¥ç€è®­ç»ƒ Fast RCNNéƒ¨åˆ†ï¼Œè¿™æ—¶ä¸¤ä¸ªç½‘ç»œæ²¡æœ‰å…±äº«å·ç§¯å±‚</p></li><li><p>ç”¨ç¬¬äºŒæ­¥çš„ Fast RCNN model åˆå§‹åŒ– RPN ç¬¬äºŒæ¬¡è¿›è¡Œè®­ç»ƒï¼Œä½†å›ºå®šå…±äº«çš„å·ç§¯å±‚ï¼Œå¹¶ä¸”åªå¾®è°ƒ RPN ç‹¬æœ‰çš„å±‚ï¼Œç°åœ¨ä¸¤ä¸ªç½‘ç»œå…±äº«å·ç§¯å±‚</p></li><li><p>ç”±ç¬¬ä¸‰æ­¥çš„ RPN model åˆå§‹åŒ– Fast RCNN ç½‘ç»œéƒ¨åˆ†ï¼Œè¾“å…¥æ•°æ®ä¸ºç¬¬ä¸‰æ­¥ç”Ÿæˆçš„ proposalsï¼Œä¿æŒå…±äº«çš„å·ç§¯å±‚å›ºå®šï¼Œå¾®è°ƒ Fast RCNN ç½‘ç»œéƒ¨åˆ† Classification ä¸­çš„å·ç§¯å±‚ï¼Œä¸¤ä¸ªç½‘ç»œå…±äº«ç›¸åŒçš„å·ç§¯å±‚ï¼Œæ„æˆä¸€ä¸ªç»Ÿä¸€çš„ç½‘ç»œï¼Œä¹Ÿå°±æ˜¯è®ºæ–‡ä¸­çš„ unified network</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç›®æ ‡æ£€æµ‹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å·ç§¯è¿ç®—çš„è¾“å…¥è¾“å‡ºshape</title>
      <link href="/p/ec86e25e/"/>
      <url>/p/ec86e25e/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è®°å½•ä¸€ä¸‹äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œä¸­å·ç§¯è¿ç®—çš„è¾“å…¥è¾“å‡ºshapeå¤§å°</p><span id="more"></span><h2 id="æ­£æ–‡"><a href="#æ­£æ–‡" class="headerlink" title="æ­£æ–‡"></a>æ­£æ–‡</h2><ul><li><p>è¾“å…¥ï¼š$(H,W)$</p></li><li><p>å·ç§¯æ ¸ï¼š$(FH,FW)$</p></li><li><p>å¡«å……ï¼š$P$</p></li><li><p>æ­¥å¹…ï¼š$S$</p></li><li><p>è¾“å‡ºï¼š$(OH,OW)$</p></li></ul><script type="math/tex; mode=display">OH = \frac{H + 2P - FH}{S} + 1 \\\\OW = \frac{W + 2P - FW}{S} + 1</script>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> çŸ¥è¯†ç‚¹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ä¸æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„æ¨å¯¼</title>
      <link href="/p/7aac45fd/"/>
      <url>/p/7aac45fd/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æœºå™¨å­¦ä¹ æ‰€ä½¿ç”¨çš„äº¤å‰ç†µæŸå¤±å‡½æ•°ä¸ä¿¡æ¯è®ºé‡Œçš„äº¤å‰ç†µçš„æ¨å¯¼ä¸æ€è€ƒ</p><span id="more"></span><h2 id="æ­£æ–‡"><a href="#æ­£æ–‡" class="headerlink" title="æ­£æ–‡"></a>æ­£æ–‡</h2><h3 id="ä¿¡æ¯è®ºä¸­çš„äº¤å‰ç†µå®šä¹‰"><a href="#ä¿¡æ¯è®ºä¸­çš„äº¤å‰ç†µå®šä¹‰" class="headerlink" title="ä¿¡æ¯è®ºä¸­çš„äº¤å‰ç†µå®šä¹‰"></a>ä¿¡æ¯è®ºä¸­çš„äº¤å‰ç†µå®šä¹‰</h3><script type="math/tex; mode=display">H(p,q) = H(p) + D_{KL}(p||q)</script><p>åœ¨ $ p,q $ æ˜¯ç¦»æ•£åˆ†å¸ƒæ—¶ï¼Œ ä¸Šå¼ç­‰ä»·ä¸º</p><script type="math/tex; mode=display">H(p,q) = -\sum^K_{i=1} p(x_i) \log q(x_i)</script><p>å…¶ä¸­ï¼Œ $x_i$ æ˜¯ $p,q$ åˆ†å¸ƒå…±åŒæ ·æœ¬ç©ºé—´çš„åŒä¸€ä¸ªæ ·æœ¬ç‚¹ï¼Œæ ·æœ¬ç©ºé—´çš„å¤§å°ä¸º $K$</p><h3 id="æœºå™¨å­¦ä¹ ä¸­çš„äº¤å‰ç†µå®šä¹‰"><a href="#æœºå™¨å­¦ä¹ ä¸­çš„äº¤å‰ç†µå®šä¹‰" class="headerlink" title="æœºå™¨å­¦ä¹ ä¸­çš„äº¤å‰ç†µå®šä¹‰"></a>æœºå™¨å­¦ä¹ ä¸­çš„äº¤å‰ç†µå®šä¹‰</h3><p>æœºå™¨å­¦ä¹ è¿›è¡Œä¼˜åŒ–æ—¶ï¼Œ ä¼šæŠŠæ‰€æœ‰æ ·æœ¬çš„äº¤å‰ç†µå€¼æ±‚å¹³å‡ï¼Œå‡è®¾æœ‰ $N$ ä¸ªæ ·æœ¬</p><script type="math/tex; mode=display">J(w) = \frac{1}{N} \sum^N_{n=1} H(p_n,q_n)</script><p>è€Œä¿¡æ¯è®ºä¸­çš„äº¤å‰ç†µä»…ä»…æ˜¯é’ˆå¯¹ä¸€ä¸ªæ ·æœ¬</p><p>å› ä¸ºäº¤å‰ç†µå¸¸ç”¨äºè§£å†³åˆ†ç±»é—®é¢˜ï¼Œè€Œåˆ†ç±»é—®é¢˜çš„æ¦‚ç‡æœ¬è´¨æ˜¯è®¡ç®—ç±»åˆ«å˜é‡çš„å¹¿ä¹‰çš„ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œæ‰€ä»¥æœºå™¨å­¦ä¹ é‡‡ç”¨çš„æ˜¯äº¤å‰ç†µçš„ç¦»æ•£å½¢å¼</p><script type="math/tex; mode=display">CE = -\sum^K_{i=1} t_i \log s_i</script><p>å…¶ä¸­ï¼Œ$t_i$ æ˜¯æœŸæœ›çš„ç±»åˆ«æ ‡ç­¾ï¼Œ$s_i$ æ˜¯æ¨¡å‹å¯¹ç¬¬ $i$ ä¸ªç±»åˆ«è®¡ç®—å¾—åˆ°çš„ $score$ ï¼Œé€šå¸¸åœ¨è®¡ç®—æŸå¤±ä¹‹å‰ï¼Œä¼šç”¨æ¿€æ´»å‡½æ•°å¯¹ $score$ åŠ ä»¥è½¬æ¢ï¼Œç”¨ $f(s_i)$ æ›¿ä»£ä¸Šå¼çš„ $s_i$</p><p>å¾—åˆ°æœºå™¨å­¦ä¹ çš„äº¤å‰ç†µæŸå¤±å‡½æ•°</p><script type="math/tex; mode=display">J(w) = - \frac{1}{N} \sum^N_{n=1} \sum^K_{i=1} t_i \log s_i</script><p>å› ä¸ºå¯¹äºåˆ†ç±»é—®é¢˜ï¼Œå‡è®¾æ¨¡å‹çš„è¾“å‡ºå±‚ä¸Šåªæœ‰2ä¸ªè¾“å‡ºç»“ç‚¹ï¼Œè€Œä¸”æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»å•æ ‡ç­¾é—®é¢˜ï¼Œå¦‚æœè¾“å‡ºå±‚ç”¨ç¬¦å· $Y$ è¡¨ç¤ºï¼Œé‚£ä¹ˆ $Y$ æœä» $0-1$ åˆ†å¸ƒ(æ˜¯äºŒé¡¹åˆ†å¸ƒçš„ç‰¹ä¾‹ï¼Œæˆ–ç§°ä¼¯åŠªåˆ©åˆ†å¸ƒï¼ŒäºŒå…ƒåˆ†å¸ƒ)ï¼Œå³éšæœºå˜é‡ $Y$ çš„æ ·æœ¬ç©ºé—´æœ‰ä¸¤ä¸ªæ ·æœ¬ç‚¹(åˆ†åˆ«å¯¹åº”è¾“å‡ºå±‚çš„ä¸¤ä¸ªè¾“å‡ºç»“ç‚¹)ï¼Œæ¯ä¸ªæ ·æœ¬ç‚¹å°±æ˜¯ä¸€ä¸ªç±»åˆ«ã€‚æˆ‘ä»¬å¸Œæœ›æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå‡ºçš„åˆ†å¸ƒæ˜¯æŸä¸ªç±»åˆ«çš„æ¦‚ç‡ä¸º $1$ ï¼Œå¦ä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡ä¸º $0$ ã€‚æ¨å¹¿åˆ°å¤šåˆ†ç±»å•æ ‡ç­¾é—®é¢˜ï¼Œé‚£ä¹ˆ $Y$ æœä»å¹¿ä¹‰çš„ä¼¯åŠªåˆ©åˆ†å¸ƒ(æ˜¯å¤šé¡¹å¼åˆ†å¸ƒçš„ç‰¹ä¾‹ï¼Œæˆ–ç§° $Category$ åˆ†å¸ƒï¼ŒèŒƒç•´åˆ†å¸ƒï¼Œç±»åˆ«åˆ†å¸ƒï¼Œ$Multinoulli$ åˆ†å¸ƒ(2012å¹´åœ¨ã€ŠMachine Learning - A Probabilistic Perspectiveã€‹ä¸­æ­£å¼æå‡º))ã€‚</p><h3 id="æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ä¸æœ€å¤§ä¼¼ç„¶æ¨å¯¼"><a href="#æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ä¸æœ€å¤§ä¼¼ç„¶æ¨å¯¼" class="headerlink" title="æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ä¸æœ€å¤§ä¼¼ç„¶æ¨å¯¼"></a>æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ä¸æœ€å¤§ä¼¼ç„¶æ¨å¯¼</h3><p>å…ˆä»ä¸€ä¸ªç›´è§‚çš„ä¾‹å­æ„Ÿå—æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ä¸æœ€å¤§ä¼¼ç„¶çš„å…³ç³»</p><script type="math/tex; mode=display">J(w)=-\frac{1}{N} \sum_{n=1}^{N}\left[y_{n} \log \hat{y}_{n}+\left(1-y_{n}\right) \log \left(1-\hat{y}_{n}\right)\right]</script><p>å»æ‰ $\frac{1}{N}$ å¹¶ä¸å½±å“å‡½æ•°çš„å•è°ƒæ€§ï¼Œæœºå™¨å­¦ä¹ ä»»åŠ¡çš„ä¹Ÿå¯ä»¥æ˜¯æœ€å°åŒ–ä¸‹é¢çš„äº¤å‰ç†µæŸå¤±</p><script type="math/tex; mode=display">J(w)=-\sum_{n=1}^{N}\left[y_{n} \log \hat{y}_{n}+\left(1-y_{n}\right) \log \left(1-\hat{y}_{n}\right)\right]</script><p>ç­‰ä»·äºæœ€å¤§åŒ–</p><script type="math/tex; mode=display">J(w)=\sum_{n=1}^{N}\left[y_{n} \log \hat{y}_{n}+\left(1-y_{n}\right) \log \left(1-\hat{y}_{n}\right)\right]</script><p>è¿™å…¶å®å°±æ˜¯å¯¹ä¼¯åŠªåˆ©åˆ†å¸ƒæ±‚æœ€å¤§ä¼¼ç„¶ä¸­çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°</p><h3 id="ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼"><a href="#ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼" class="headerlink" title="ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼"></a>ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼</h3><p>æœ‰äºŒå…ƒéšæœºå˜é‡ $Y \in{0,1}$ ï¼Œè®¾ $p(Y=1) = \beta$ ï¼Œé‚£ä¹ˆå®ƒçš„æ¦‚ç‡è´¨é‡å‡½æ•°(PMF)ä¸º</p><script type="math/tex; mode=display">P(Y \mid \beta)=\beta^{Y}(1-\beta)^{1-Y}</script><p>ç°æœ‰ $D=\left{y<em>{1}, y</em>{2}, \ldots, y_{N}\right} $ æ¥è‡ª $Y$ ï¼Œæ ·æœ¬å®¹é‡ä¸º $N$ çš„ä¸€ä¸ªæ ·æœ¬ï¼Œä¼¼ç„¶å‡½æ•°ä¸º</p><script type="math/tex; mode=display">P(D \mid \beta)=\prod_{i=1}^{N} P\left(Y=y_{i} \mid \beta\right)=\prod_{i=1}^{N} \beta^{y_{i}}(1-\beta)^{1-y_{i}}</script><p>åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå¯¹ $\beta$ çš„å®šä¹‰ä¸º</p><script type="math/tex; mode=display">\beta = p_{\theta}(Y = 1|x_i)</script><p>å…¶ä¸­ï¼Œ$X=\left{x<em>{1}, \ldots, x</em>{N}\right}$ ï¼Œ$ x_{i} \in X$ï¼Œ$X$ æ˜¯ $D$ ä¸­æ¯ä¸ªæ ·æœ¬ç‚¹å¯¹åº”ç±»åˆ«çš„ç‰¹å¾çš„é›†åˆã€‚å³ç»™å®šæ¨¡å‹å‚æ•° $\theta$ å’Œéšæœºå˜é‡çš„æ ·æœ¬ç‚¹ $Y=1$ çš„å±æ€§ç‰¹å¾ $x_i$ ( $x_i$ å¯ä»¥æ˜¯ä¸€ä¸ªå‘é‡)ï¼Œè®©æ¨¡å‹ä¼°è®¡å‡ºäº‹ä»¶ $Y=1$ çš„æ¦‚ç‡(åŒæ—¶ä¹Ÿæ˜¯å½“å‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„å‚æ•°)</p><p>æ•…ä¸Šè¿°çš„ä¼¼ç„¶å‡½æ•°çš„å‚æ•°ä¸å†æ˜¯ä¼¯åŠªåˆ©åˆ†å¸ƒçš„ $\beta$ï¼Œè€Œæ˜¯æ¨¡å‹çš„å‚æ•° $\theta$ï¼Œæœ‰</p><script type="math/tex; mode=display">P(D \mid \theta, X)=\prod_{i=1}^{N} p_{\theta}\left(Y=1 \mid x_{i}\right)^{y_{i}}\left(1-p_{\theta}\left(Y=1 \mid x_{i}\right)\right)^{1-y_{i}}</script><p>æ˜“å¾—å¯¹æ•°ä¼¼ç„¶å‡½æ•°</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}(\theta ; X, D) &= \log \prod_{i=1}^{N} p_{\theta}\left(Y=1 \mid x_{i}\right)^{y_{i}}\left(1-p_{\theta}\left(Y=1 \mid x_{i}\right)\right)^{1-y_{i}} \\&= \sum_{i=1}^{N} \log p_{\theta}\left(Y=1 \mid x_{i}\right)^{y_{i}}\left(1-p_{\theta}\left(Y=1 \mid x_{i}\right)\right)^{1-y_{i}} \\&= \sum_{i=1}^{N} \log p_{\theta}\left(Y=1 \mid x_{i}\right)^{y_{i}}+\log \left(1-p_{\theta}\left(Y=1 \mid x_{i}\right)\right)^{1-y_{i}} \\&= \sum_{i=1}^{N} y_{i} \log p_{\theta}\left(Y=1 \mid x_{i}\right)+\left(1-y_{i}\right) \log \left(1-p_{\theta}\left(Y=1 \mid x_{i}\right)\right)\end{aligned}</script><p>ä»¥ä¸‹ç»™å‡ºæœ€å¤§ä¼¼ç„¶ä¼°è®¡ä¸æœ€å°åŒ–äº¤å‰ç†µæŸå¤±çš„è½¬åŒ–è¿‡ç¨‹ï¼Œæ„åœ¨è¯´æ˜åœ¨ä¼¯åŠªåˆ©åˆ†å¸ƒä¸‹ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡ä¸æœ€å°åŒ–äº¤å‰ç†µæŸå¤±æ˜¯åŒæ¦‚å¿µçš„</p><script type="math/tex; mode=display">\begin{aligned}\theta_{p} &= \arg \max _{\theta} \sum_{i=1}^{N} y_{i} \log p_{\theta}\left(Y=1 \mid x_{i}\right)+\left(1-y_{i}\right) \log \left(1-p_{\theta}\left(Y=1 \mid x_{i}\right)\right) \\&= \arg \max_{\theta} \sum^N_{i=1}y_i \log \hat{y_i} + (1-y_i) \log (1- \hat{y_i}) \\&= \arg \min_{\theta} - \sum^N_{i=1}y_i \log \hat{y_i} + (1-y_i) \log (1- \hat{y_i}) \\&= \arg \min_{\theta} \sum^N_{i=1} H(y_i,\hat{y_i})\end{aligned}</script><h3 id="å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼"><a href="#å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼" class="headerlink" title="å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼"></a>å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶æ¨å¯¼</h3><p>å•æ ‡ç­¾å¤šåˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«éšæœºå˜é‡åªæœä»å¤šé¡¹å¼åˆ†å¸ƒä¸­è¯•éªŒæ¬¡æ•°ä¸º1çš„æƒ…å†µï¼Œå¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒï¼ˆ $Category$ åˆ†å¸ƒï¼‰å¯¹åº”çš„æ˜¯æ›´å¸¸è§çš„å•æ ‡ç­¾å¤šåˆ†ç±»ä»»åŠ¡ï¼Œä»¥ä¸‹è®¨è®ºä¼¯åŠªåˆ©åˆ†å¸ƒåˆ°å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„è¿‡æ¸¡ä»¥åŠä¸æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„å…³ç³»</p><p>æœ‰ $K$ å…ƒç±»åˆ«éšæœºå˜é‡ $Y \in{1, \ldots, K} $ ï¼Œä¸” $p(Y=J)=\beta_{j}$ï¼Œæ¦‚ç‡è´¨é‡å‡½æ•°åº“ä¸º</p><script type="math/tex; mode=display">P(Y|B)=\prod^K_{i=1} \beta ^{I(Y=i)}_i</script><p>å¦‚æœ $Y=i$ï¼Œ$I(Y=i) = 1$ ï¼Œå¦åˆ™ï¼Œ $I(Y=i)=0$ </p><blockquote><p>è¿™ä¸ªæ¦‚ç‡è´¨é‡å‡½æ•°ä¹‹æ‰€ä»¥çœ‹ä¸Šå»æœ‰ç‚¹å¥‡æ€ªï¼Œæ˜¯å› ä¸ºå®ƒå‡ºç°äº† $Identity$ å‡½æ•°ã€‚è€Œç¬¦åˆæˆ‘ä»¬ç›´è§‰çš„æ˜¯ç»´åŸºç™¾ç§‘å¯¹å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„å¦ä¸€ä¸ªPMFå®šä¹‰ï¼Œå³ $p(Y=i)=p_i$ ï¼Œå³ç›´æ¥æ ¹æ®åˆ—è”è¡¨ï¼Œè·å¾—è¯¥äº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ã€‚å¦‚æœæƒ³è§£é‡Šä¸Šé¢æ™¦æ¶©éš¾æ‡‚çš„åŒ…å« $Identity$ å‡½æ•°çš„PMFï¼Œå¯ä»¥ç”¨ä¸¥æ ¼æŒ‰ç…§ä¼¯åŠªåˆ©è¯•éªŒçš„æè¿°æ¥è§£é‡Šï¼šåœ¨è¿›è¡Œ1æ¬¡è¯•éªŒä¸­æŠ½åˆ°ç¬¬ $j$ ä¸ªç±»åˆ«ï¼Œå…¶ä»–æ¦‚ç‡è¢«æŠ½ä¸­0æ¬¡çš„æ¦‚ç‡ï¼Œå³</p><script type="math/tex; mode=display">P(Y=j)=(1,1) \ldots p_{j-1}^{0} p_{j}^{1} p_{j+1}^{0} \ldots</script></blockquote><p>$D=\left{y<em>{1}, y</em>{2}, \ldots, y_{N}\right}$ æ˜¯æ¥è‡ª $Y$ çš„ï¼Œæ ·æœ¬å®¹é‡ä¸º $N$ï¼Œçš„ä¸€ä¸ªæ ·æœ¬ï¼Œé‚£ä¹ˆä¼¼ç„¶å‡½æ•°ä¸º</p><script type="math/tex; mode=display">P(D \mid \beta)=\prod_{i=1}^{N} \prod_{j=1}^{K} \beta_{j}^{I\left(y_{i}=j\right)}</script><p>åŒæ ·åœ°ï¼Œåœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œå¯¹ä¸Šè¿°å…³äºå¯¹ $\beta$ çš„å®šä¹‰åšå‡ºè½¬å˜</p><script type="math/tex; mode=display">\beta_{j}=p_{\theta}\left(Y=j \mid x_{i}\right)</script><p>$X=\left{x<em>{1}, \cdots, x</em>{N}\right}$ï¼Œ$x_i \in X$ï¼Œ$X$ æ˜¯ $D$ ä¸­çš„æ¯ä¸ªæ ·æœ¬ç‚¹å¯¹åº”ç‰¹å¾çš„é›†åˆ</p><p>åŒç†ä¸Šè¿°çš„ä¼¼ç„¶å‡½æ•°çš„å‚æ•°ä¸å†æ˜¯å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„ $\beta_1,beta_2,\cdots,\beta_k$ï¼Œè€Œæ˜¯æ¨¡å‹çš„å‚æ•° $\theta$ï¼Œæ‰€ä»¥ä¼¼ç„¶å‡½æ•°æœ‰</p><script type="math/tex; mode=display">P(D \mid \theta, X)=\prod_{i=1}^{N} \prod_{j=1}^{K} p_{\theta}\left(y_{i}=j \mid x_{i}\right)^{I\left(y_{i}=j\right)}</script><p>æ˜“å¾—å¯¹æ•°ä¼¼ç„¶å‡½æ•°</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}(\theta ; X, D) &= \log \prod_{i=1}^{N} \prod_{j=1}^{K} p_{\theta}\left(y_{i}=j \mid x_{i}\right)^{I\left(y_{i}=j\right)}\\&= \sum_{i=1}^{N} \log \prod_{j=1}^{K} p_{\theta}\left(y_{i}=j \mid x_{i}\right)^{I\left(y_{i}=j\right)} \\&= \sum_{i=1}^{N} \sum_{j=1}^{K} \log p_{\theta}\left(y_{i}=j \mid x_{i}\right)^{I\left(y_{i}=j\right)} \\&= \sum_{i=1}^{N} \sum_{j=1}^{K} I\left(y_{i}=j\right) \log p_{\theta}\left(y_{i}=j \mid x_{i}\right)\end{aligned}</script><p>å› ä¸ºæœ€å¤§åŒ–ä¸Šè¿°å¼å­å…·æœ‰çº¦æŸæ¡ä»¶ $\sum^K_{i=1} \beta_i = 1$ï¼Œæ‰€ä»¥æœ€å¤§åŒ–ä¸Šé¢çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°æ˜¯ä¸€ä¸ªæ¡ä»¶æå€¼é—®é¢˜ï¼Œä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•è¿›è¡Œæ±‚è§£ï¼Œå¾—åˆ°ä¸‹é¢çš„å…³äºæ±‚è§£å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒä¸‹çš„äº¤å‰ç†µçš„æ‹‰æ ¼æœ—æ—¥å‡½æ•°</p><script type="math/tex; mode=display">\tilde{\mathcal{L}}(\theta ; X, D, \lambda)=\sum_{i=1}^{N} \sum_{j=1}^{K} I\left(y_{i}=j\right) \log p_{\theta}\left(y_{i}=j \mid x_{i}\right)+\lambda\left(1-\sum_{k} \beta_{i}\right)</script><p>åœ¨æ²¡æœ‰ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹çš„å‰æä¸‹ï¼Œæˆ‘ä»¬åªéœ€å¯¹åˆ†å¸ƒçš„å‚æ•°å’Œ $\lambda$ æ±‚åå¯¼å°±èƒ½å¾—åˆ°å‚æ•°çš„ä¼°è®¡å€¼</p><p>ç”¨æ¨¡å‹çš„å‚æ•°è®°å· $\hat{\beta<em>j}$ è¡¨ç¤º $p</em>{\theta} (y_i = j | x_i)$ï¼Œç”¨ one-hot å‘é‡è¡¨ç¤º $Identity$ å‡½æ•°å€¼</p><p>å¾—</p><script type="math/tex; mode=display">\mathcal{L}(\theta ; X, D)=\sum_{i=1}^{N} \sum_{j=1}^{K} y_{j} \log \hat{\beta}_{j}</script><p>ä¸‹é¢åŒæ ·ç»™å‡ºæå¤§ä¼¼ç„¶ä¼°è®¡ä¸æœ€å°åŒ–å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒçš„äº¤å‰ç†µæŸå¤±å‡½æ•°çš„è½¬åŒ–è¿‡ç¨‹ï¼Œæ„åœ¨è¯´æ˜åœ¨å¹¿ä¹‰ä¼¯åŠªåˆ©åˆ†å¸ƒä¸‹ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡ä¸æœ€å°åŒ–äº¤å‰ç†µæŸå¤±ä¹Ÿæ˜¯åŒæ¦‚å¿µçš„</p><script type="math/tex; mode=display">\begin{aligned}\theta_{p} &= \arg \max _{\theta} \sum_{i=1}^{N} \sum_{j=1}^{K} y_{j} \log \hat{\beta}_{j} \\&= \arg \min _{\theta}-\sum_{i=1}^{N} \sum_{j=1}^{K} y_{j} \log \hat{\beta}_{j} \\&= \arg \min _{\theta} \sum_{i=1}^{N} H\left(y_{j}, \hat{\beta}_{j}\right)\end{aligned}</script><h2 id="å°ç»“"><a href="#å°ç»“" class="headerlink" title="å°ç»“"></a>å°ç»“</h2><p>æœ€å°åŒ–äº¤å‰ç†µæŸå¤±å‡½æ•°ä¸æœ€å¤§ä¼¼ç„¶ä¼°è®¡ä¹‹é—´çš„ç­‰ä»·å¹¶éå·§åˆï¼ŒåŒæ˜¯å¤„ç†ä¿¡æ¯çš„å…¬å¼ï¼Œåªæ˜¯åº”ç”¨çš„æ–¹å‘ä¸åŒ</p>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ¦‚ç‡ä¸ä¿¡æ¯è®º </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨Opencv+Pythonçš„ARå°demo</title>
      <link href="/p/e8ff6ba7/"/>
      <url>/p/e8ff6ba7/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æµ…æµ…äº†è§£ä¸€ä¸‹ Python OpenCVï¼Œè¯•ç€ç»™è‡ªå·±çš„ iphone 8 åšä¸€ä¸‹ç›¸æœºæ ‡å®š</p><span id="more"></span><h2 id="å®šä¹‰"><a href="#å®šä¹‰" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h2><blockquote><p>å¢å¼ºç°å®( AR ) æ˜¯ä¸€ç§çœŸå®ä¸–ç•Œç¯å¢ƒçš„äº¤äº’å¼ä½“éªŒï¼Œå…¶ä¸­å­˜åœ¨äºç°å®ä¸–ç•Œä¸­çš„å¯¹è±¡é€šè¿‡è®¡ç®—æœºç”Ÿæˆçš„æ„ŸçŸ¥ä¿¡æ¯å¾—åˆ°å¢å¼ºï¼Œæœ‰æ—¶è·¨è¶Šå¤šç§æ„Ÿå®˜æ¨¡å¼ï¼ŒåŒ…æ‹¬è§†è§‰ã€å¬è§‰ã€è§¦è§‰ã€ä½“æ„Ÿå’Œå—…è§‰ã€‚AR å¯ä»¥å®šä¹‰ä¸ºä¸€ä¸ªåŒ…å«ä¸‰ä¸ªåŸºæœ¬ç‰¹å¾çš„ç³»ç»Ÿï¼šçœŸå®å’Œè™šæ‹Ÿä¸–ç•Œçš„ç»“åˆã€å®æ—¶äº¤äº’ä»¥åŠè™šæ‹Ÿå’ŒçœŸå®å¯¹è±¡çš„å‡†ç¡® 3D é…å‡†ã€‚é‡å çš„æ„Ÿè§‰ä¿¡æ¯å¯ä»¥æ˜¯å»ºè®¾æ€§çš„ï¼ˆå³å¯¹è‡ªç„¶ç¯å¢ƒçš„è¡¥å……ï¼‰æˆ–ç ´åæ€§çš„ï¼ˆå³å¯¹è‡ªç„¶ç¯å¢ƒçš„æ©è”½ï¼‰ã€‚è¿™ç§ä½“éªŒä¸ç‰©ç†ä¸–ç•Œæ— ç¼äº¤ç»‡ï¼Œå› æ­¤è¢«è§†ä¸ºçœŸå®ç¯å¢ƒçš„æ²‰æµ¸å¼ä½“éªŒã€‚[4]é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¢å¼ºç°å®æ”¹å˜äº†äººä»¬å¯¹ç°å®ä¸–ç•Œç¯å¢ƒçš„æŒç»­æ„ŸçŸ¥ï¼Œè€Œè™šæ‹Ÿç°å®å®Œå…¨ç”¨æ¨¡æ‹Ÿç¯å¢ƒå–ä»£äº†ç”¨æˆ·çš„ç°å®ä¸–ç•Œç¯å¢ƒã€‚å¢å¼ºç°å®ä¸ä¸¤ä¸ªä¸»è¦åŒä¹‰è¯ç›¸å…³ï¼šæ··åˆç°å®å’Œè®¡ç®—æœºä»‹å¯¼çš„ç°å®ã€‚</p><p align="right">â€”â€”ä»¥ä¸Šå†…å®¹æ¥è‡ªWikiç™¾ç§‘</p></blockquote><h2 id="ç±»åˆ«"><a href="#ç±»åˆ«" class="headerlink" title="ç±»åˆ«"></a>ç±»åˆ«</h2><h3 id="Vision-based-ARï¼ˆåŸºäºè®¡ç®—æœºè§†è§‰çš„ARï¼‰"><a href="#Vision-based-ARï¼ˆåŸºäºè®¡ç®—æœºè§†è§‰çš„ARï¼‰" class="headerlink" title="Vision based ARï¼ˆåŸºäºè®¡ç®—æœºè§†è§‰çš„ARï¼‰"></a>Vision based ARï¼ˆåŸºäºè®¡ç®—æœºè§†è§‰çš„ARï¼‰</h3><h4 id="Marker-Based-AR-ï¼ˆåŸºäºæ ‡å®šçš„ARï¼‰"><a href="#Marker-Based-AR-ï¼ˆåŸºäºæ ‡å®šçš„ARï¼‰" class="headerlink" title="Marker-Based AR ï¼ˆåŸºäºæ ‡å®šçš„ARï¼‰"></a>Marker-Based AR ï¼ˆåŸºäºæ ‡å®šçš„ARï¼‰</h4><p>å¦‚ï¼š</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/6.webp" alt=""></p><h4 id="Marker-Less-ARï¼ˆåŸºäºç‰¹å¾ç‚¹çš„AR"><a href="#Marker-Less-ARï¼ˆåŸºäºç‰¹å¾ç‚¹çš„AR" class="headerlink" title="Marker-Less ARï¼ˆåŸºäºç‰¹å¾ç‚¹çš„AR)"></a>Marker-Less ARï¼ˆåŸºäºç‰¹å¾ç‚¹çš„AR)</h4><p>å¦‚ï¼š</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/7.webp" alt=""></p><h3 id="LBS-based-ARï¼ˆåŸºäºåœ°ç†ä½ç½®ä¿¡æ¯çš„ARï¼‰"><a href="#LBS-based-ARï¼ˆåŸºäºåœ°ç†ä½ç½®ä¿¡æ¯çš„ARï¼‰" class="headerlink" title="LBS based ARï¼ˆåŸºäºåœ°ç†ä½ç½®ä¿¡æ¯çš„ARï¼‰"></a>LBS based ARï¼ˆåŸºäºåœ°ç†ä½ç½®ä¿¡æ¯çš„ARï¼‰</h3><p>å¦‚ï¼š</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/8.webp" alt=""></p><blockquote><p>æœ¬æ–‡å°†å…·ä½“è®²è§£å’Œå®éªŒåŸºäºç‰¹å¾ç‚¹çš„ARæŠ€æœ¯ </p></blockquote><h2 id="Demo-æ¼”ç¤º"><a href="#Demo-æ¼”ç¤º" class="headerlink" title="Demo æ¼”ç¤º"></a>Demo æ¼”ç¤º</h2><h3 id="æ¼”ç¤ºç¯å¢ƒ"><a href="#æ¼”ç¤ºç¯å¢ƒ" class="headerlink" title="æ¼”ç¤ºç¯å¢ƒ"></a>æ¼”ç¤ºç¯å¢ƒ</h3><ul><li><p>iphone 8 æ‰‹æœºï¼šApp Store ä¸‹è½½ Focus [+] # æ‰‹åŠ¨å¯¹ç„¦æ‹æ‘„</p></li><li><p>è®¡ç®—æœºï¼švimï¼Œpythonå’Œ conda</p></li><li><p>OpenCV æ£‹ç›˜æ ‡å®šçº¸</p></li></ul><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/calibration_img/9.webp" alt=""></p><h3 id="å‡†å¤‡å›¾ç‰‡"><a href="#å‡†å¤‡å›¾ç‰‡" class="headerlink" title="å‡†å¤‡å›¾ç‰‡"></a>å‡†å¤‡å›¾ç‰‡</h3><ul><li>å‚è€ƒå›¾ç‰‡</li></ul><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/referenceImage.webp" alt=""></p><ul><li>ç”¨ä¾‹å›¾ç‰‡</li></ul><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/sourceImage.webp" alt=""></p><h3 id="ç›¸æœºæ ‡å®šåŸç†"><a href="#ç›¸æœºæ ‡å®šåŸç†" class="headerlink" title="ç›¸æœºæ ‡å®šåŸç†"></a>ç›¸æœºæ ‡å®šåŸç†</h3><p>ä»ä¸–ç•Œåæ ‡ç³»è½¬æ¢åˆ°å›¾åƒåæ ‡ç³»ï¼Œæ±‚æŠ•å½±çŸ©é˜µ $P$ çš„è¿‡ç¨‹</p><p>åˆ†ä¸ºä¸¤æ­¥</p><ul><li>ä»ä¸–ç•Œåæ ‡ç³»è½¬æ¢ä¸ºç›¸æœºåæ ‡ç³»ï¼Œè¿™ä¸€æ­¥æ˜¯ä¸‰ç»´ç‚¹åˆ°ä¸‰ç»´ç‚¹çš„è½¬æ¢ï¼ŒåŒ…æ‹¬ $R,t$ ï¼ˆç›¸æœºå¤–å‚ï¼‰ç­‰å‚æ•°</li></ul><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/5.webp" alt="5"></p><script type="math/tex; mode=display">\widetilde{X}_{c a m}=R(\widetilde{X}-\widetilde{C})</script><pre><code>* $ \widetilde&#123;X&#125; $ ä¸º $X$ åœ¨ä¸–ç•Œåæ ‡ä¸­çš„ä½ç½®* $ R $ ä¸ºæ—‹è½¬çŸ©é˜µ* $ \widetilde&#123;C&#125; $ ä¸ºç›¸æœºåŸç‚¹ $C$ æ‰€åœ¨ä¸–ç•Œåæ ‡ä¸­çš„ä½ç½®* $ \widetilde&#123;X&#125;_&#123;c a m&#125; $ ä¸º $ X $ åœ¨ç›¸æœºåæ ‡ç³»ä¸­çš„ä½ç½®</code></pre><ul><li>ä»ç›¸æœºåæ ‡ç³»è½¬æ¢ä¸ºå›¾åƒåæ ‡ç³»ï¼Œè¿™ä¸€æ­¥æ˜¯ä¸‰ç»´ç‚¹åˆ°äºŒç»´ç‚¹çš„è½¬æ¢ï¼ŒåŒ…æ‹¬ $K$ï¼ˆç›¸æœºå†…å‚ï¼‰ç­‰å‚æ•°</li></ul><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/9.webp" alt=""></p><ul><li><p>$C$ä¸ºç›¸æœºçš„ä¸­å¿ƒç‚¹ï¼Œä¹Ÿæ˜¯ç›¸æœºåæ ‡ç³»çš„ä¸­å¿ƒç‚¹</p></li><li><p>$Z$ä¸ºç›¸æœºçš„ä¸»è½´</p></li><li><p>$p$ä¸ºç›¸æœºçš„åƒå¹³é¢ï¼Œä¹Ÿå°±æ˜¯å›¾ç‰‡åæ ‡ç³»æ‰€åœ¨çš„äºŒç»´å¹³é¢</p></li><li><p>$C$ ç‚¹åˆ° $p$ç‚¹çš„è·ç¦»$f$ï¼Œä¸ºç›¸æœºçš„ç„¦è·</p></li></ul><p>å¯å¾—åˆ°</p><script type="math/tex; mode=display">\begin{aligned}x &=f X / Z \\y &=f Y / Z \\(X, \quad Y, \quad Z) & \mapsto(f X / Z, \quad f Y / Z)\end{aligned}</script><p>ç”±å›¾å¯çŸ¥åç§»é‡</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/10.webp" alt=""></p><script type="math/tex; mode=display">(X, \quad Y, \quad Z) \mapsto\left(f X / Z+p_{x}, \quad f Y / Z+p_{y}\right)</script><p>çŸ©é˜µå½¢å¼ä¸º</p><script type="math/tex; mode=display">\left(\begin{array}{c}X \\Y \\Z \\    1\end{array}\right) \mapsto\left(\begin{array}{c}f X+Z p_{x} \\f Y+Z p_{y} \\Z\end{array}\right)=\left[\begin{array}{ccc}f & p_{x} & 0 \\& f & p_{y} & 0 \\& & 1 & 0\end{array}\right]\left(\begin{array}{c}X \\Y \\Z \\1\end{array}\right)</script><p>åŒ–ç®€å¾—</p><script type="math/tex; mode=display">\left(\begin{array}{c}f X+Z p_{x} \\f Y+Z p_{y} \\Z\end{array}\right)=\left[\begin{array}{cc}f & p_{x} \\& f & p_{y} \\& & 1\end{array}\right]\left[\begin{array}{llll}1 & & & 0 \\& 1 & & 0 \\& & 1 & 0\end{array}\right]\left(\begin{array}{l}X \\Y \\Z \\1\end{array}\right)</script><p>åˆ™</p><script type="math/tex; mode=display">K=\left[\begin{array}{ccc}f & & p_{x} \\& f & p_{y} \\& & 1\end{array}\right]</script><p>è®¾æ—‹è½¬çŸ©é˜µ $R$ ä¸ºå•ä½çŸ©é˜µ $I$ï¼Œå¹³ç§»çŸ©é˜µ $t$ ä¸º0</p><script type="math/tex; mode=display">\begin{aligned}P &=K[R \mid t] \\&=K[I \mid 0]\end{aligned}</script><blockquote><p>ç•¸å˜å‚æ•°æœ¬ä¾‹æœªè€ƒè™‘åˆ°ï¼Œä¸ä½œè®¨è®º</p></blockquote><h3 id="è·å¾—ç›¸æœºæ ‡å®šçŸ©é˜µ"><a href="#è·å¾—ç›¸æœºæ ‡å®šçŸ©é˜µ" class="headerlink" title="è·å¾—ç›¸æœºæ ‡å®šçŸ©é˜µ"></a>è·å¾—ç›¸æœºæ ‡å®šçŸ©é˜µ</h3><h4 id="æ‰‹åŠ¨å¯¹ç„¦ï¼Œå›ºå®šç„¦è·ï¼Œæ‹æ‘„å„ä¸ªæ–¹é¢çš„æ ‡å®šæ¿"><a href="#æ‰‹åŠ¨å¯¹ç„¦ï¼Œå›ºå®šç„¦è·ï¼Œæ‹æ‘„å„ä¸ªæ–¹é¢çš„æ ‡å®šæ¿" class="headerlink" title="æ‰‹åŠ¨å¯¹ç„¦ï¼Œå›ºå®šç„¦è·ï¼Œæ‹æ‘„å„ä¸ªæ–¹é¢çš„æ ‡å®šæ¿"></a>æ‰‹åŠ¨å¯¹ç„¦ï¼Œå›ºå®šç„¦è·ï¼Œæ‹æ‘„å„ä¸ªæ–¹é¢çš„æ ‡å®šæ¿</h4><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/11.webp" alt=""></p><h4 id="å…·ä½“è¿‡ç¨‹"><a href="#å…·ä½“è¿‡ç¨‹" class="headerlink" title="å…·ä½“è¿‡ç¨‹"></a>å…·ä½“è¿‡ç¨‹</h4><ul><li>æå–è§’ç‚¹ æœ¬ä¾‹ä½¿ç”¨çš„æ ‡å®šæ¿æ¥è‡ª [calib](  æœ‰13 * 9 ä¸ªè§’ç‚¹</li><li>æå–äºšåƒç´ è§’ç‚¹ æé«˜ç²¾åº¦</li><li>è§’ç‚¹ç»˜åˆ¶</li><li>æ ‡å®š</li></ul><h4 id="ç»“æœ"><a href="#ç»“æœ" class="headerlink" title="ç»“æœ"></a>ç»“æœ</h4><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/13.webp" alt=""></p><p>å¾—åˆ° iphone 8 çš„ç›¸æœºæ ‡å®šçŸ©é˜µä¸º (ä»£ç è§camera_calibration.py)</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1.09358481e+03</span> <span class="number">0.00000000e+00</span> <span class="number">5.12119524e+02</span>]</span><br><span class="line">[<span class="number">0.00000000e+00</span> <span class="number">1.08983166e+03</span> <span class="number">6.61345525e+02</span>]</span><br><span class="line">[<span class="number">0.00000000e+00</span> <span class="number">0.00000000e+00</span> <span class="number">1.00000000e+00</span>]]</span><br></pre></td></tr></table></figure><h3 id="ç‰¹å¾å¤„ç†"><a href="#ç‰¹å¾å¤„ç†" class="headerlink" title="ç‰¹å¾å¤„ç†"></a>ç‰¹å¾å¤„ç†</h3><h4 id="ç‰¹å¾æ£€æµ‹"><a href="#ç‰¹å¾æ£€æµ‹" class="headerlink" title="ç‰¹å¾æ£€æµ‹"></a>ç‰¹å¾æ£€æµ‹</h4><p>ä½¿ç”¨ORBæ³•è¿›è¡Œç‰¹å¾æ£€æµ‹ï¼ŒORBåŸºäºFASTç®—æ³•ï¼ŒFASTç®—æ³•çš„åŸç†å¦‚ä¸‹</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/12.webp" alt=""></p><p>ä»»é€‰å›¾åƒä¸­çš„ä¸€ç‚¹ $P$ï¼Œä»¥è¯¥ç‚¹ä¸ºåœ†å½¢ï¼Œ$r$ä¸ºåŠå¾„ç¡®å®šä¸€ä¸ªåœ†ï¼Œåœ¨åœ†ä¸Šå‡åŒ€å–$m$ä¸ªåƒç´ ç‚¹ï¼Œè®¾å®šä¸€ä¸ªé˜ˆå€¼$t$ï¼Œå¦‚æœ$m$ä¸ªåƒç´ ç‚¹ä¸­ï¼Œæœ‰è¿ç»­$N$ä¸ªåƒç´ ç‚¹çš„å¤§å°å‡å¤§äºæˆ–å°äº$t$ï¼Œåˆ™è¿™ä¸ªç‚¹å°±æ˜¯è§’ç‚¹ã€‚ä½†æ˜¯åœ¨è¿›è¡ŒFASTè¿›è¡Œè§’ç‚¹æ£€æµ‹æ—¶ï¼Œè¾¹ç¼˜ä½ç½®çš„éƒ¨åˆ†æ˜“æ··æ·†ï¼Œé’ˆå¯¹è¿™ç§æƒ…å†µï¼ŒORBç®—æ³•é€šè¿‡å¢åŠ å›¾åƒé‡‘å­—å¡”å’Œè®¡ç®—è§’åº¦çš„æ–¹æ³•ï¼Œç”¨Harrisè§’ç‚¹æ£€æµ‹å™¨æŠŠ$N$ä¸ªå…³é”®ç‚¹è¿›è¡Œç­‰çº§æ’åºï¼Œä½¿ç”¨è€…å¯æå–å‰nä¸ªè‡ªå·±éœ€è¦çš„ç‚¹ã€‚ä¸åŒçš„æ˜¯ï¼ŒORBåœ¨è¿›è¡Œç‰¹å¾ç‚¹åŒ¹é…æ—¶ï¼Œæ£€æµ‹å‡ºçš„è§’ç‚¹éœ€è¦æ»¡è¶³å°ºåº¦ä¸å˜å½¢å’Œæ—‹è½¬ä¸å˜æ€§ã€‚</p><ul><li>å°ºåº¦ä¸å˜å½¢</li></ul><p>é€šè¿‡å¯¹åˆå§‹å›¾åƒçš„æŒ‰1/2çš„æ¯”ä¾‹ä¸æ–­ä¸‹é‡‡æ ·(å³æŒ‰1/2çš„æ¯”ä¾‹ä¸æ–­ç¼©æ”¾)ï¼Œå¾—åˆ°ä¸€ç³»åˆ—å›¾åƒï¼Œå½¢æˆå›¾åƒé‡‘å­—å¡”ã€‚å¯¹æ¯å±‚å›¾åƒï¼Œè¿›è¡ŒFASTè§’ç‚¹æ£€æµ‹</p><ul><li>æ—‹è½¬ä¸å˜å½¢</li></ul><p>é‡‡ç”¨ç°åº¦è´¨å¿ƒæ³•è¿›è¡Œè®¡ç®—æ¯ä¸ªç‰¹å¾ç‚¹çš„ä¸»æ–¹å‘</p><script type="math/tex; mode=display">\mathrm{m}_{p q}=\sum_{x, y} x^{p} y^{q} I(x, y)</script><p>å…¶ä¸­$x,y$åˆ†åˆ«è¡¨ç¤ºåƒç´ ç‚¹å‘¨å›´åœ†ä¸Šæ‰€é€‰å–ç‚¹çš„æ¨ªåæ ‡å’Œçºµåæ ‡ï¼Œ$I(x,y)$è¡¨ç¤ºç°åº¦å€¼å¤§å°ï¼Œ$p,q$è¡¨ç¤ºæŒ‡æ•°ï¼Œè§’åº¦è®¡ç®—çš„æ–¹æ³•å¦‚ä¸‹</p><script type="math/tex; mode=display">\theta=\operatorname{atan} 2(\mathrm{m_{01}}, \mathrm{m_{10}})</script><h4 id="ç‰¹å¾æè¿°"><a href="#ç‰¹å¾æè¿°" class="headerlink" title="ç‰¹å¾æè¿°"></a>ç‰¹å¾æè¿°</h4><p>ORBæ³•é‡‡ç”¨BRIEFæè¿°å­è®¡ç®—ç®—æ³•å®ç°ï¼ŒBRIEFç®—æ³•å¯åˆ†ä¸ºä¸¤æ­¥</p><ul><li>ç‰¹å¾ç‚¹å¤§å°çš„å¯¹æ¯”</li></ul><p>ä»¥ç‰¹å¾ç‚¹ä¸ºä¸­å¿ƒï¼Œå–é‚»åŸŸçª—å£ï¼Œåœ¨çª—å£ä¸Šé€‰æ‹©ä¸¤ä¸ªç‚¹p(x)å’Œp(y)ï¼Œæ¯”è¾ƒä¸¤ä¸ªç‚¹åƒç´ å€¼çš„å¤§å°</p><script type="math/tex; mode=display">\tau(p ; x, y):=\left\{\begin{array}{cc}1 & if\quad p(x)<p(y) \\0 & \text { otherwise }\end{array}\right.</script><ul><li>é‡å¤ç¬¬ä¸€æ­¥è¿›è¡Œåƒç´ å€¼å¤§å°çš„æ¯”è¾ƒï¼Œå½¢æˆäºŒè¿›åˆ¶ç¼–ç </li></ul><p>OBRç®—æ³•å¯¹BRIEFæœ‰ä¸¤ç§æ”¹å˜ï¼Œåˆ†åˆ«ä¸º steer BRIEF å’Œ rBRIEF</p><ul><li>steer BRIEFå…·å¤‡æ—‹è½¬ä¸å˜å½¢çš„ç‰¹å¾ï¼Œå·²çŸ¥ $ /theta $ï¼Œå°†è¯¥ç‚¹å‘¨å›´çš„ç‚¹æ—‹è½¬ $ /theta $ åº¦ï¼Œå¾—åˆ°æ–°çš„ç‚¹å¯¹<script type="math/tex; mode=display">D_{\theta}=R_{\theta} D</script></li></ul><p>$R$ ä¸ºæ—‹è½¬çŸ©é˜µ<br>æ—‹è½¬åï¼Œåœ¨æ–°çš„ä½ç½®ä¸Šæ¯”è¾ƒåƒç´ å€¼çš„å¤§å°ï¼Œå¾—åˆ°æè¿°å­</p><ul><li>rBRIEFç®—æ³•é€šè¿‡æ”¹å˜æè¿°å­çš„è®¡ç®—æ–¹æ³•ï¼Œè¿›ä¸€æ­¥å‡å¼±åŒä¸€å›¾åƒä¸­ç‰¹å¾ç‚¹çš„æè¿°å­çš„ç›¸å…³æ€§ï¼Œå¯¹æ¯ä¸ªè§’ç‚¹ï¼Œè€ƒè™‘å…¶ $31X31$ çš„é‚»åŸŸï¼Œä½¿ç”¨é¢†åŸŸä¸­æ¯ä¸ªç‚¹å‘¨å›´çš„ $5X5$ çš„é‚»åŸŸçš„åƒç´ å€¼å¹³å‡å€¼ä½œä¸ºè¯¥ç‚¹çš„åƒç´ å€¼ï¼Œè¿›è€Œæ¯”è¾ƒç‚¹å¯¹çš„å¤§å°ã€‚ä¸Šé¢è®¡ç®—å¯å¾—åˆ° $(31-5+1)*(31-5+1)=729$ ä¸ªå­çª—å£ï¼Œæå–ç‚¹å¯¹çš„æ–¹æ³•æœ‰ $729X728=265356$ ç§ï¼Œé€šè¿‡åœ¨è¿™ $265356$ ä¸­æ–¹æ³•ä¸­é€‰å– $256$ ç§å–æ³•ï¼Œå½¢æˆæè¿°å­</li></ul><p>ç»“æœ</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/1.webp" alt=""></p><h4 id="ç‰¹å¾åŒ¹é…"><a href="#ç‰¹å¾åŒ¹é…" class="headerlink" title="ç‰¹å¾åŒ¹é…"></a>ç‰¹å¾åŒ¹é…</h4><p>æœ¬ä¾‹ä½¿ç”¨ Brute-Force Matcher è¿›è¡Œç‰¹å¾åŒ¹é…ï¼Œä¹Ÿå°±æ˜¯æš´åŠ›åŒ¹é…</p><p>ç»“æœ</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/2.webp" alt=""></p><h4 id="æ˜ å°„"><a href="#æ˜ å°„" class="headerlink" title="æ˜ å°„"></a>æ˜ å°„</h4><p>å°†å‚è€ƒå›¾åƒè¡¨é¢çš„å¹³é¢çš„ç‚¹æ˜ å°„åˆ°ç”¨ä¾‹å›¾åƒçš„å¹³é¢ä¸Šï¼Œä¹Ÿå°±æ˜¯å•åº”æ€§å˜æ¢ï¼Œå•åº”æ€§å˜æ¢æ˜¯å°†ä¸€ä¸ªå¹³é¢ï¼ˆé½æ¬¡åæ ‡ï¼‰ä¸­çš„ç‚¹æ˜ å°„åˆ°å¦ä¸€ä¸ªå¹³é¢çš„äºŒç»´æŠ•å½±å˜æ¢</p><script type="math/tex; mode=display">\left[\begin{array}{l}x^{\prime} \\y^{\prime} \\z^{\prime}\end{array}\right]=\left[\begin{array}{lll}h_{1} & h_{2} & h_{3} \\h_{4} & h_{5} & h_{6} \\h_{7} & h_{8} & h_{9}\end{array}\right]\left[\begin{array}{l}x \\y \\z\end{array}\right]</script><p>ä»ä¸¤ä¸ªå›¾åƒä¸­ä¼ é€’ç‚¹é›†ï¼Œå®ƒå°†æ‰¾åˆ°è¯¥å¯¹è±¡çš„é€è§†å˜æ¢ï¼Œè‡³å°‘éœ€è¦å››ä¸ªæ­£ç¡®çš„ç‚¹æ‰èƒ½æ‰¾åˆ°è½¬æ¢ï¼Œä½†ä¸¤å¹…å›¾åƒä¹‹é—´çš„å•åº”æ€§å˜æ¢åŒ…å«ä¸é€‚åˆçš„ç‚¹ã€‚ä¼šå¯¼è‡´åŒ¹é…æ—¶å‡ºç°é”™è¯¯ï¼Œå½±å“ç»“æœï¼Œä½¿ç”¨ RANSAC è¿­ä»£æ³•éªŒè¯æ‹Ÿåˆ</p><p>ç»“æœ</p><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/3.webp" alt=""></p><h4 id="3D-ç»˜åˆ¶"><a href="#3D-ç»˜åˆ¶" class="headerlink" title="3D ç»˜åˆ¶"></a>3D ç»˜åˆ¶</h4><p>ä½¿ç”¨ <a href="https://github.com/yarolig/OBJFileLoader">yaroligçš„OBJFileLoader</a> åŠ è½½ 3D obj æ¨¡å‹ (ä»£ç è§ objloader_simple.py)</p><h3 id="ç»“æœ-1"><a href="#ç»“æœ-1" class="headerlink" title="ç»“æœ"></a>ç»“æœ</h3><p><img src="/image/ä½¿ç”¨Opencv+Pythonçš„ARå°demo/4.webp" alt="4"></p><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">ar_python_opencv.py</summary><pre><code class="python">import cv2import numpy as npimport mathimport matplotlib.pyplot as pltfrom objloader_simple import *referenceImage = cv2.imread('/home/pacaep/Tests/OpenCvArDemo/img/referenceImage.webp',0)plt.imshow(referenceImage, cmap = 'gray')sourceImage = cv2.imread('/home/pacaep/Tests/OpenCvArDemo/img/sourceImage.webp',0)plt.imshow(sourceImage, cmap='gray')orb = cv2.ORB_create()referenceImagePts = orb.detect(referenceImage, None)sourceImagePts = orb.detect(sourceImage, None)referenceImagePts, referenceImageDsc = orb.compute(referenceImage, referenceImagePts)sourceImagePts, sourceImageDsc = orb.compute(sourceImage, sourceImagePts)referenceImageFeatures = cv2.drawKeypoints(referenceImage, referenceImagePts,                                                                                        referenceImage, color = (0,255,0), flags = 0)sourceImageFeatures = cv2.drawKeypoints(sourceImage, sourceImagePts,                                                                                        sourceImage, color = (0,255,0), flags = 0)plt.figure(figsize=(10,5))plt.subplot(1,2,1)plt.axis("off")plt.imshow(referenceImageFeatures, cmap = 'gray')plt.title('Reference Image Features')plt.subplot(1,2,2)plt.axis("off")plt.imshow(sourceImageFeatures,cmap='gray')plt.title('Source Image Features')plt.tight_layout()plt.show()MIN_MATCHES = 30bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)referenceImagePts, referenceImageDsc = orb.detectAndCompute(referenceImage, None)sourceImagePts, sourceImageDsc = orb.detectAndCompute(sourceImage, None)matches = bf.match(referenceImageDsc, sourceImageDsc)matches = sorted(matches, key = lambda x: x.distance)if len(matches) > MIN_MATCHES:    idxPairs = cv2.drawMatches(referenceImage, referenceImagePts,                                sourceImage, sourceImagePts, matches[:MIN_MATCHES],0,flags =2)    plt.figure(figsize=(12,6))    plt.axis('off')    plt.imshow(idxPairs, cmap='gray')    plt.title('Matching between features')    plt.show()else:    print("Not enough matches have been found - %d/%d" %(len(matches), MIN_MATCHES))    matchesMask = Noneif len(matches) > MIN_MATCHES:    sourcePoints = np.float32([referenceImagePts[m.queryIdx].pt for m in matches]).reshape(-1,1,2)    destinationPoints = np.float32([sourceImagePts[m.trainIdx].pt for m in matches]).reshape(-1,1,2)    homography, mask = cv2.findHomography(sourcePoints, destinationPoints, cv2.RANSAC, 5.0)    matchesMask = mask.ravel().tolist()    h, w = referenceImage.shape    corners = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)    transformedCorners = cv2.perspectiveTransform(corners, homography)    sourceImageMarker = cv2.polylines(sourceImage, [np.int32(transformedCorners)], True,                                      255, 5, cv2.LINE_AA)else:    print("Not enough matches are found - %d/%d" % (len(matches), MIN_MATCHES))    matchesMask = NonedrawParameters = dict(matchColor=(0, 255, 0), singlePointColor=None,                      matchesMask=matchesMask, flags=2)result = cv2.drawMatches(referenceImage, referenceImagePts, sourceImageMarker,                         sourceImagePts, matches, None, **drawParameters)plt.figure(figsize=(12, 6))plt.imshow(result, cmap='gray')plt.show()camera_parameters = np.array([[1108.38916, 0,          513.796472],                              [0,          1111.41724, 661.637500],                              [0,          0,          1]])obj = OBJ('/home/pacaep/Tests/OpenCvArDemo/models/fox.obj', swapyz = True)def projection_matrix(camera_parameters, homography):    homography = homography * (-1)    rot_and_transl = np.dot(np.linalg.inv(camera_parameters), homography )    col_1 = rot_and_transl[:,0]    col_2 = rot_and_transl[:,1]    col_3 = rot_and_transl[:,2]    l = math.sqrt(np.linalg.norm(col_1, 2) * np.linalg.norm(col_2, 2))    rot_1 = col_1 / l    rot_2 = col_2 / l    translation = col_3 / l    c = rot_1 + rot_2    p = np.cross(rot_1, rot_2)    d = np.cross(c,p)    rot_1 = np.dot(c/np.linalg.norm(c,2) + d / np.linalg.norm(d,2), 1/math.sqrt(2))    rot_2 = np.dot(c/np.linalg.norm(c,2) - d / np.linalg.norm(d,2), 1/math.sqrt(2))    rot_3 = np.cross(rot_1, rot_2)    projection = np.stack((rot_1, rot_2, rot_3, translation)).T    return np.dot(camera_parameters, projection)def render(img, obj, projection, model, color=False):    vertices = obj.vertices    scale_matrix = np.eye(3)*6    h,w = model.shape    for face in obj.faces:        face_vertices = face[0]        points = np.array([vertices[vertex -1] for vertex in face_vertices])        points = np.dot(points, scale_matrix)        points = np.array([[p[0] + w / 2, p[1] + h/2, p[2]] for p in points])        dst = cv2.perspectiveTransform(points.reshape(-1,1,3), projection)        imgpts = np.int32(dst)        cv2.fillConvexPoly(img, imgpts, (80, 217, 81))    return imgsourcePoints = np.float32([referenceImagePts[m.queryIdx].pt for m in matches]).reshape(-1,1,2)destinationPoints = np.float32([sourceImagePts[m.trainIdx].pt for m in matches]).reshape(-1,1,2)homography, _ = cv2.findHomography(sourcePoints,destinationPoints, cv2.RANSAC, 5.0)matchesMask = mask.ravel().tolist()h, w = referenceImage.shapecorners = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)transformedCorners = cv2.perspectiveTransform(corners, homography)frame = cv2.polylines(sourceImage, [np.int32(transformedCorners)], True, 255,3,cv2.LINE_AA)projection = projection_matrix(camera_parameters, homography)frame = render(frame, obj, projection, referenceImage, True)plt.figure(figsize=(6,12))plt.imshow(frame, cmap='gray')plt.show()</code></pre></details><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">camera_calibration.py</summary><pre><code class="python">import cv2import numpy as npimport globcriteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 0.001)objp = np.zeros((9 * 13, 3), np.float32)objp[:, :2] = np.mgrid[0:13, 0:9].T.reshape(-1, 2)obj_points = []img_points = []images = glob.glob("/home/pacaep/Tests/OpenCvArDemo/calibration_img/*.webp")i=0;for fname in images:    img = cv2.imread(fname)    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    size = gray.shape[::-1]    ret, corners = cv2.findChessboardCorners(gray, (13, 9), None)    if ret:        obj_points.append(objp)        corners2 = cv2.cornerSubPix(gray, corners, (5, 5), (-1, -1), criteria)        if [corners2]:            img_points.append(corners2)        else:            img_points.append(corners)        cv2.drawChessboardCorners(img, (13, 9), corners, ret)        i+=1;        cv2.imwrite('conimg'+str(i)+'.webp', img)        cv2.waitKey(1500)print(len(img_points))cv2.destroyAllWindows()ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, size, None, None)print("ret:", ret)print("mtx:\n", mtx)print("dist:\n", dist)print("rvecs:\n", rvecs)print("tvecs:\n", tvecs )print("-----------------------------------------------------")img = cv2.imread(images[2])h, w = img.shape[:2]newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))print (newcameramtx)print("------------------use undistort-------------------")dst = cv2.undistort(img,mtx,dist,None,newcameramtx)x,y,w,h = roidst1 = dst[y:y+h,x:x+w]cv2.imwrite('calibresult.webp', dst1)print ("dst:", dst1.shape)</code></pre></details><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">objloader_simple.py</summary><pre><code class="python">class OBJ:    def __init__(self, filename, swapyz=False):        self.vertices = []        self.normals = []        self.texcoords = []        self.faces = []        material = None        for line in open(filename, "r"):            if line.startswith('#'): continue            values = line.split()            if not values: continue            if values[0] == 'v':                v = list(map(float, values[1:4]))                if swapyz:                    v = v[0], v[2], v[1]                self.vertices.append(v)            elif values[0] == 'vn':                v = list(map(float, values[1:4]))                if swapyz:                    v = v[0], v[2], v[1]                self.normals.append(v)            elif values[0] == 'vt':                self.texcoords.append(map(float, values[1:3]))            elif values[0] == 'f':                face = []                texcoords = []                norms = []                for v in values[1:]:                    w = v.split('/')                    face.append(int(w[0]))                    if len(w) >= 2 and len(w[1]) > 0:                        texcoords.append(int(w[1]))                    else:                        texcoords.append(0)                    if len(w) >= 3 and len(w[2]) > 0:                        norms.append(int(w[2]))                    else:                        norms.append(0)                self.faces.append((face, norms, texcoords))</code></pre></details>]]></content>
      
      
      <categories>
          
          <category> å›¾åƒå¤„ç† </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ä½œä¸š </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>labelImgé—ªé€€é”™è¯¯ä¿®å¤</title>
      <link href="/p/a524281d/"/>
      <url>/p/a524281d/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ä½¿ç”¨labelImgæ—¶ï¼Œåœ¨æœªé€‰ä¸­æ•°æ®æ ‡ç­¾æ—¶æŒ‰<code>Ctrl+D</code>æ—¶ä¼šé—ªé€€ï¼Œåœ¨ç»ˆç«¯ä¸­æœ‰ä»¥ä¸‹æŠ¥é”™</p><span id="more"></span><p><img src="/image/labelImgé—ªé€€é”™è¯¯ä¿®å¤/1.webp" alt="1"></p><h2 id="ä¿®å¤"><a href="#ä¿®å¤" class="headerlink" title="ä¿®å¤"></a>ä¿®å¤</h2><p>åœ¨<code>/usr/lib/python3.9/site-packages/labelImg/labelImg.py</code> ç¬¬784è¡Œï¼Œæ²¡æœ‰æ•°æ®æ ‡ç­¾é€‰ä¸­æ—¶<code>shape</code>å¯¹è±¡æ²¡æœ‰<code>paint_label</code>å±æ€§ï¼Œæ·»åŠ ä¸€ä¸ªæ¡ä»¶è¿‡æ»¤å°±å¥½</p><p>ç¬¬783è¡Œ<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_label</span>(<span class="params">self, shape</span>):</span><br><span class="line">    shape.paint_label = self.display_label_option.isChecked()</span><br><span class="line">    item = HashableQListWidgetItem(shape.label)</span><br><span class="line">    item.setFlags(item.flags() | Qt.ItemIsUserCheckable)</span><br><span class="line">    item.setCheckState(Qt.Checked)</span><br><span class="line">    item.setBackground(generate_color_by_text(shape.label))</span><br><span class="line">    self.items_to_shapes[item] = shape</span><br><span class="line">    self.shapes_to_items[shape] = item</span><br><span class="line">    self.label_list.addItem(item)</span><br><span class="line">    <span class="keyword">for</span> action <span class="keyword">in</span> self.actions.onShapesPresent:</span><br><span class="line">        action.setEnabled(<span class="literal">True</span>)</span><br><span class="line">    self.update_combo_box()</span><br></pre></td></tr></table></figure></p><p>æ”¹ä¸º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_label</span>(<span class="params">self, shape</span>):</span><br><span class="line">    <span class="keyword">if</span> shape <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;add empty label&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    shape.paint_label = self.display_label_option.isChecked()</span><br><span class="line">    item = HashableQListWidgetItem(shape.label)</span><br><span class="line">    item.setFlags(item.flags() | Qt.ItemIsUserCheckable)</span><br><span class="line">    item.setCheckState(Qt.Checked)</span><br><span class="line">    item.setBackground(generate_color_by_text(shape.label))</span><br><span class="line">    self.items_to_shapes[item] = shape</span><br><span class="line">    self.shapes_to_items[shape] = item</span><br><span class="line">    self.label_list.addItem(item)</span><br><span class="line">    <span class="keyword">for</span> action <span class="keyword">in</span> self.actions.onShapesPresent:</span><br><span class="line">        action.setEnabled(<span class="literal">True</span>)</span><br><span class="line">    self.update_combo_box()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æ‡µé€¼çš„æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> labelImg </tag>
            
            <tag> æ•°æ®é›† </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021äºšå¤ªæ•°å­¦å»ºæ¨¡ç«èµ›Aé¢˜ç®€è¦æ€è·¯</title>
      <link href="/p/ae4fbfca/"/>
      <url>/p/ae4fbfca/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å°è®°ä¸€ä¸‹ç¬¬ä¸€æ¬¡å‚åŠ æ•°æ¨¡èµ›</p><span id="more"></span><h2 id="æ€è·¯"><a href="#æ€è·¯" class="headerlink" title="æ€è·¯"></a>æ€è·¯</h2><p><img src="/image/2021äºšå¤ªæ•°å­¦å»ºæ¨¡ç«èµ›Aé¢˜/mind.webp" alt="1"></p><h3 id="é—®é¢˜ä¸€"><a href="#é—®é¢˜ä¸€" class="headerlink" title="é—®é¢˜ä¸€"></a>é—®é¢˜ä¸€</h3><p>ç”¨é«˜æ–¯æ»¤æ³¢å¯¹å›¾åƒ Pic1<em>1 å’Œ Pic1_2 è¿›è¡Œé™å™ªå¤„ç†ï¼Œç”¨ç°åº¦å€¼å¼€è¿ç®—é™ä½å›¾åƒ Pic1</em> 3çš„å™ªå£°ï¼›å¯¹ä¸‰ä¸ªå›¾åƒè¿›è¡ŒäºŒå€¼åŒ–å¤„ç†ï¼Œå°†ç°åº¦å›¾åƒè½¬åŒ–ä¸ºäºŒå€¼åŒ–å›¾åƒï¼Œå…¶æ¬¡ç”¨åœ†å½¢å…ƒç´ å¯¹åŒºåŸŸè¿›è¡Œè†¨èƒ€ï¼Œå†ç”¨æ”¹è¿›çš„ canny æ–¹æ³•æå–äºšåƒç´ ç²¾ç¡®è¾¹ç¼˜ï¼Œå¯¹ XLD è½®å»“ç”¨æœ€å°äºŒä¹˜è¿‘ä¼¼çº¿å¹³æ»‘ï¼Œå†æ ¹æ®æ–œç‡ä»¥åŠæ‹ç‚¹å°† XLD è½®å»“åˆ†å‰²ä¸ºç›´çº¿æ®µå’Œåœ†å¼§æ®µæˆ–æ¤­åœ†å¼§ï¼Œæœ€åæ ¹æ®è½®å»“çš„ç›¸å¯¹ä½ç½®å¯¹è½®å»“è¿›è¡Œæ’åºï¼Œå¹¶è·å–XLDè½®å»“çš„é•¿åº¦åŠåŒºåŸŸä½ç½®</p><h3 id="é—®é¢˜äºŒ"><a href="#é—®é¢˜äºŒ" class="headerlink" title="é—®é¢˜äºŒ"></a>é—®é¢˜äºŒ</h3><p>ä¸ºè¾¾åˆ°è‡ªæ ‡å®šæ¶ˆé™¤ç•¸å˜çš„ç›®çš„ï¼Œé€šè¿‡æœ€å°äºŒä¹˜è¿‘ä¼¼çº¿å¹³æ»‘ã€å‡å€¼æ»¤æ³¢é™å™ªã€å±€éƒ¨é˜ˆå€¼åˆ†å‰²ç­‰ç®—æ³•ï¼Œå°†è¾“å‡ºçš„XLDè½®å»“åˆ†å‰²ï¼Œè¿æ¥ä¸¤ä¸ªæ ‡å¿—æ€§çš„å¯¹è±¡å…ƒç»„é‡å¤é—®é¢˜ä¸€çš„æ­¥éª¤å¾—åˆ°æœ€ä½³çš„æ ¡å‡†å¾„å‘ç•¸å˜å‚æ•°ï¼Œç”¨æ¥æ ¡å‡†å›¾åƒçš„å¾„å‘ç•¸å˜ç”±è½®å»“çš„ç›¸å¯¹ä½ç½®å¯¹è½®å»“è¿›è¡Œæ’åºå¹¶è·å–XLDè½®å»“çš„é•¿åº¦ï¼Œæœ€åæ ¹æ®è½®å»“é•¿åº¦ä»¥åŠå®é™…çš„ç‰©ç†åæ ‡è®¡ç®—å‡º6ä¸ªè½®å»“çš„çœŸå®é•¿åº¦</p><h3 id="é—®é¢˜ä¸‰"><a href="#é—®é¢˜ä¸‰" class="headerlink" title="é—®é¢˜ä¸‰"></a>é—®é¢˜ä¸‰</h3><p>ä¾æ®é—®é¢˜ä¸€çš„æ¨¡å‹å°† XLD è½®å»“åˆ†å‰²ä¸ºç›´çº¿æ®µå’Œåœ†å¼§æ®µæˆ–æ¤­åœ†å¼§ã€‚å½“åˆ†å‰²è½®å»“ä¸ºç›´çº¿æ®µæ—¶ï¼Œç”¨æœ€å°äºŒä¹˜æ³•è¿›è¡Œç›´çº¿æ‹Ÿåˆå¹¶ç”¨å¤šè¾¹å½¢ç”ŸæˆXLDè½®å»“ï¼›åœ†å¼§æ®µæˆ–åœ†ï¼Œç”¨ algebraic æ–¹æ³•ä½¿è½®å»“ç‚¹ä¸ç”Ÿæˆçš„åœ†ä¹‹é—´çš„ä»£æ•°è·ç¦»æœ€å°åŒ–ï¼›æ¤­åœ†å¼§æˆ–æ¤­åœ†ï¼ŒåŸºäº tukey çš„ç®—æ³•å¯¹è½®å»“ç‚¹è¿›è¡ŒåŠ æƒå¹¶å¿½ç•¥å¼‚å¸¸å€¼</p><h2 id="ç»“æœ"><a href="#ç»“æœ" class="headerlink" title="ç»“æœ"></a>ç»“æœ</h2><h3 id="é—®é¢˜ä¸€-1"><a href="#é—®é¢˜ä¸€-1" class="headerlink" title="é—®é¢˜ä¸€"></a>é—®é¢˜ä¸€</h3><p><img src="/image/2021äºšå¤ªæ•°å­¦å»ºæ¨¡ç«èµ›Aé¢˜/ContoursSplit1.webp" alt="1_1"></p><p><img src="/image/2021äºšå¤ªæ•°å­¦å»ºæ¨¡ç«èµ›Aé¢˜/ContoursSplit2.webp" alt="1_2"></p><p><img src="/image/2021äºšå¤ªæ•°å­¦å»ºæ¨¡ç«èµ›Aé¢˜/ContoursSplit3.webp" alt="1_3"></p><h3 id="é—®é¢˜äºŒ-1"><a href="#é—®é¢˜äºŒ-1" class="headerlink" title="é—®é¢˜äºŒ"></a>é—®é¢˜äºŒ</h3><p><img src="/image/2021äºšå¤ªæ•°å­¦å»ºæ¨¡ç«èµ›Aé¢˜/Borders.webp" alt="2"></p><h3 id="é—®é¢˜ä¸‰-1"><a href="#é—®é¢˜ä¸‰-1" class="headerlink" title="é—®é¢˜ä¸‰"></a>é—®é¢˜ä¸‰</h3><p><img src="/image/2021äºšå¤ªæ•°å­¦å»ºæ¨¡ç«èµ›Aé¢˜/SortedContours.webp" alt="3"></p><h2 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h2><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">é—®é¢˜ä¸€</summary><pre><code class="halcon">read_image (Img, 'Pic1_1.bmp')dev_close_window ()get_image_size (Img, Width, Height)dev_open_window (0, 0, Width, Height, 'black', WindowHandle)gauss_filter(Img, ImgGauss, 11)binary_threshold (ImgGauss, Region,  'smooth_histo', 'dark', UsedThreshold)boundary (Region, RegionBorder, 'inner')dilation_circle (RegionBorder, RegionDread_image (Img, 'Pic1_1.bmp')dev_close_window ()get_image_size (Img, Width, Height)dev_open_window (0, 0, Width, Height, 'black', WindowHandle)gauss_filter(Img, ImgGauss, 11)binary_threshold (ImgGauss, Region,  'smooth_histo', 'dark', UsedThreshold)boundary (Region, RegionBorder, 'inner')dilation_circle (RegionBorder, RegionDilation, 2.5)reduce_domain (ImgGauss, RegionDilation, ImgReduced)edges_sub_pix (ImgReduced, Edges, 'canny', 2, 20, 60)smooth_contours_xld(Edges, ImgSmoothed, 9)segment_contours_xld (ImgSmoothed, ContoursSplit, 'lines_circles', 5, 4, 3)count_obj (ContoursSplit, Number)dev_display (Img)dev_set_draw ('margin')dev_set_color ('white')dev_update_window ('off')dev_set_colored (12)dev_set_line_width (3)dev_display (ContoursSplit)sort_contours_xld (ContoursSplit, SortedContours, 'upper_left', 'true', 'column')count_obj (ContoursSplit, Number)length_xld(SortedContours,Length)gen_empty_obj (Line)for i := 1 to 24 by 1    select_obj (SortedContours, ObjectSelected, i)    get_contour_xld (ObjectSelected, Row, Col)    gen_region_polygon (Region, Row,Col)    concat_obj (Line, Region, Line)endforX := ColY := Rowilation, 2.5)reduce_domain (ImgGauss, RegionDilation, ImgReduced)edges_sub_pix (ImgReduced, Edges, 'canny', 2, 20, 60)smooth_contours_xld(Edges, ImgSmoothed, 9)segment_contours_xld (ImgSmoothed, ContoursSplit, 'lines_circles', 5, 4, 3)count_obj (ContoursSplit, Number)dev_display (Img)dev_set_draw ('margin')dev_set_color ('white')dev_update_window ('off')dev_set_colored (12)dev_set_line_width (3)dev_display (ContoursSplit)sort_contours_xld (ContoursSplit, SortedContours, 'upper_left', 'true', 'column')count_obj (ContoursSplit, Number)length_xld(SortedContours,Length)gen_empty_obj (Line)for i := 1 to 24 by 1    select_obj (SortedContours, ObjectSelected, i)    get_contour_xld (ObjectSelected, Row, Col)    gen_region_polygon (Region, Row,Col)    concat_obj (Line, Region, Line)endforX := ColY := Rowread_image (Img, 'Pic1_2.bmp')dev_close_window ()get_image_size (Img, Width, Height)dev_open_window (0, 0, Width, Height, 'black', WindowHandle)gauss_filter(Img, ImgGauss, 11)binary_threshold (ImgGauss, Region,  'smooth_histo', 'dark', UsedThreshold)boundary (Region, RegionBorder, 'inner')dilation_circle (RegionBorder, RegionDilation, 2.5)reduce_domain (ImgGauss, RegionDilation, ImgReduced)edges_sub_pix (ImgReduced, Edges, 'canny', 2, 20, 60)smooth_contours_xld(Edges, ImgSmoothed, 9)segment_contours_xld (ImgSmoothed, ContoursSplit, 'lines_circles', 5, 4, 3)count_obj (ContoursSplit, Number)dev_display (Img)dev_set_draw ('margin')dev_set_color ('white')dev_update_window ('off')dev_set_colored (12)dev_set_line_width (3)dev_display (ContoursSplit)sort_contours_xld (ContoursSplit, SortedContours, 'upper_left', 'true', 'column')count_obj (ContoursSplit, Number)length_xld(SortedContours,Length)gen_empty_obj (Line)for i := 1 to 84 by 1    select_obj (SortedContours, ObjectSelected, i)    get_contour_xld (ObjectSelected, Row, Col)    gen_region_polygon (Region, Row,Col)    concat_obj (Line, Region, Line)endforx := round(Col)y := round(Row)read_image (Img, 'Pic1_3.bmp')dev_close_window ()get_image_size (Img, Width, Height)dev_open_window (0, 0, Width, Height, 'black', WindowHandle)gray_opening_shape (Img, ImgOpen, 16, 16, 'octagon')mean_image(ImgOpen, ImgMean, 9.3, 9.3)binary_threshold (ImgMean, Region,  'smooth_histo', 'dark',  UsedThreshold)boundary (Region, RegionBorder, 'inner')dilation_circle (RegionBorder, RegionDilation, 4.6)reduce_domain (ImgMean, RegionDilation, ImgReduced)edges_sub_pix (ImgReduced, Edges, 'canny', 2, 20, 60)union_cotangential_contours_xld (Edges, UnionContours, 2, 5, 3.14, 25.0, 10, 2.0, 'attr_forget')smooth_contours_xld(UnionContours, ImgSmoothed, 9)segment_contours_xld (ImgSmoothed, ContoursSplit, 'lines_circles', 5, 4, 3)count_obj (ContoursSplit, Number)dev_display (Img)dev_set_draw ('margin')dev_set_color ('white')dev_update_window ('off')dev_set_colored (12)dev_set_line_width (3)dev_display (ContoursSplit)sort_contours_xld (ContoursSplit, SortedContours, 'upper_left', 'true', 'column')count_obj (ContoursSplit, Number)length_xld(SortedContours,Length)gen_empty_obj (Line)for i := 1 to 120 by 1    select_obj (SortedContours, ObjectSelected, i)    get_contour_xld (ObjectSelected, Row, Col)    gen_region_polygon (Region, Row,Col)    concat_obj (Line, Region, Line)endforx := round(Col)y := round(Row)</code></pre></details><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">é—®é¢˜äºŒ</summary><pre><code class="halcon">dev_update_off ()read_image (Img, 'Pic2_4.bmp')dev_close_window ()dev_open_window_fit_image (Img, 0, 0, -1, -1, WindowHandle)set_display_font (WindowHandle, 16, 'mono', 'true', 'false')dev_display (Img)disp_message (WindowHandle, 'Img with radial distortions', 'window', 0, 0, 'black', 'true')disp_continue_message (WindowHandle, 'black', 'true')gen_empty_obj (Borders)for N := 1 to 4 by 1    read_image (Img, 'Pic2_' + N$'d' + '.bmp')    edges_sub_pix (Img, ImgBorders, 'canny', 1, 10, 40)    smooth_contours_xld(ImgBorders, ImgSmoothed, 9)    segment_contours_xld (ImgSmoothed, SplitBorders, 'lines_circles', 5, 4, 2)    select_shape_xld (SplitBorders, SelectedBorders, 'contlength', 'and', 30, 100000)    concat_obj (Borders, SelectedBorders, Borders)    dev_display (Img)    dev_set_colored (12)    dev_display (SelectedBorders)    disp_message (WindowHandle, 'Edges extracted from image ' + N$'d', 'window', 0, 0, 'black', 'true')endfordev_clear_window ()dev_set_colored (12)dev_display (Borders)disp_message (WindowHandle, 'Collected edges from multiple images', 'window', 0, 0, 'black', 'true')disp_continue_message (WindowHandle, 'black', 'true')dev_clear_window ()disp_message (WindowHandle, 'Performing self-calibration...', 'window', 0, 0, 'black', 'true')radial_distortion_self_calibration (Borders, CalibrationBorders, 1296, 972, 0.08, 42, 'division', 'fixed', 0, CamParMultiImage)dev_clear_window ()dev_set_colored (12)dev_display (CalibrationBorders)disp_message (WindowHandle, 'Edges used for calibration', 'window', 0, 0, 'black', 'true')disp_continue_message (WindowHandle, 'black', 'true')change_radial_distortion_cam_par ('fixed', CamParMultiImage, 0, CamParMultiImageRect)read_image (ImgCir, 'Pic2_1.bmp')get_domain (ImgCir, Domain)change_radial_distortion_image (ImgCir, Domain, ImgCirRectified, CamParMultiImage, CamParMultiImageRect)get_image_size (ImgCir, WidthCir, HeightCir)dev_open_window_fit_image (ImgCir, 0, 0, -1, -1, WindowHandleCir)set_display_font (WindowHandleCir, 16, 'mono', 'true', 'false')dev_display (ImgCir)mean_image(ImgCir, MeanCir, 61, 61)dyn_threshold(ImgCir, MeanCir, SegCir, 5, 'dark')fill_up(SegCir, SegFillUpCir)connection(SegFillUpCir, segConnectCir)select_shape(segConnectCir, SelectedRegionsCir, ['area','circularity'], 'and', [500, 0.7], [20000, 1])smallest_circle(SelectedRegionsCir, RowCir, ColumnCir, RadiusCir)area_center(SelectedRegionsCir, AreaCir, Row1Cir, Column1Cir)CRadius:=sqrt(AreaCir/3.1415926)RowSize := mean(0.5 / CRadius)read_image (Img, 'Pic2_4.bmp')get_domain (Img, Domain)change_radial_distortion_image (Img, Domain, ImageRectified, CamParMultiImage, CamParMultiImageRect)dev_close_window ()get_image_size (ImageRectified, Width, Height)dev_open_window (0, 0, Width, Height, 'black', WindowHandle)gauss_filter(Img, ImgGauss, 11)binary_threshold (ImgGauss, Region,  'smooth_histo', 'dark', UsedThreshold)boundary (Region, RegionBorder, 'inner')dilation_circle (RegionBorder, RegionDilation, 2.5)reduce_domain (ImgGauss, RegionDilation, ImgReduced)edges_sub_pix (ImgReduced, Borders, 'canny', 2, 20, 60)smooth_contours_xld(Borders, ImgSmoothed, 9)dev_display (ImgSmoothed)dev_set_draw ('margin')dev_set_color ('white')dev_update_window ('off')dev_set_colored (12)dev_set_line_width (3)sort_contours_xld (ImgSmoothed, SortedContours, 'upper_left', 'true', 'column')count_obj (ImgSmoothed, Number)length_xld(SortedContours,Length)RealSize := Length * RowSizeAllSzie := sum(RealSize)</code></pre></details><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">é—®é¢˜ä¸‰</summary><pre><code class="halcon">read_contour_xld_dxf (DxfContours, 'EdgeContour.dxf', [], [], DxfStatus)segment_contours_xld (DxfContours, ContoursSplit, 'lines_circles', 5, 4, 3)sort_contours_xld (ContoursSplit, SortedContours, 'upper_left', 'true', 'column')count_obj (SortedContours, Number)dev_display (DxfContours)dev_set_draw ('margin')dev_set_color ('white')dev_update_window ('off')dev_set_colored (12)dev_set_line_width (3)dev_display (SortedContours)dev_set_colored (3)dev_set_line_width (3)ColBL := []RowsBL := []ColEL := []RowsEL := []Lines := []ColsC := []RowsC := []RadiiC := []PhisC := []ColsSC := []RowsSC := []ColsEC := []RowsEC := []ColsE := []RowsE := []RadiiE := []PhisE := []ColsSE := []RowsSE := []ColsEE := []RowsEE := []k:=0J := []for I := 1 to Number by 1   select_obj (SortedContours, ObjectSelected, I)   get_contour_global_attrib_xld (ObjectSelected, 'cont_approx', Attrib)    if(Attrib == -1)        k := k+1        J := [J,k]        fit_line_contour_xld (ObjectSelected, 'tukey', -1, 2, 6, 2, RowBegin, ColBegin, RowEnd, ColEnd, Nr, Nc, Dist)        gen_contour_polygon_xld (ContLine, [RowBegin,RowEnd], [ColBegin,ColEnd])        RowsBL := [RowsBL,RowBegin]        RowsEL := [RowsEL,RowEnd]        ColBL := [ColBL,ColBegin]        ColEL := [ColEL,ColEnd]        length_xld(ContLine,LengthL)        Lines := [Lines, LengthL]        dev_display (ContLine)    elseif(Attrib == 1)        J := [J,0]        fit_circle_contour_xld (ObjectSelected, 'algebraic', -1, 6, 0, 3, 2, RowC, ColumnC, RadiusC, StartPhiC, EndPhiC, PointOrderC)        gen_circle_contour_xld (ContCircle, RowC, ColumnC, RadiusC, 0, rad(360), PointOrderC, 1.0)        RowsC := [RowsC,RowC]        ColsC := [ColsC,ColumnC]        RadiiC := [RadiiC,RadiusC]        PhisC := [PhisC,(EndPhiC-StartPhiC)*180/3.14159]        ColsSC := [ColsSC,ColumnC+RadiusC*cos(StartPhiC)]        RowsSC := [RowsSC,RowC+RadiusC*sin(StartPhiC)]        ColsEC := [ColsEC,ColumnC+RadiusC*cos(EndPhiC)]        RowsEC := [RowsEC,RowC+RadiusC*sin(EndPhiC)]        dev_display (ContCircle)    else        fit_ellipse_contour_xld(ObjectSelected, 'ftukey',-1, 6, 0, 2, 3, 2, RowE, ColumnE, RadiusE, RaE, RbE, StartPhiE, EndPhiE, PointOrderE)        gen_ellipse_contour_xld(ContEllipse, RowE, ColumnE, RadiusE, RaE, RbE, 0, rad(360), PointOrderE, 1.0)        RowsE := [RowsE,RowE]        ColsE := [ColsE,ColumnE]        RadiiE := [RadiiE,RadiusE]        PhisE := [PhisE,(EndPhiE-StartPhiE)*180/3.14159]        ColsSE := [ColsSE,ColumnE+RadiusE*cos(StartPhiE)]        RowsSE := [RowsSE,RowE+RadiusE*sin(StartPhiE)]        ColsEE := [ColsEE,ColumnE+RadiusE*cos(EndPhiE)]        RowsEE := [RowsEE,RowE+RadiusE*sin(EndPhiE)]        dev_display (ContEllipse)        J:=[J,-1]    endifendfor</code></pre></details><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">matlabä»£ç </summary><pre><code class="matlab">clear;clc;a = xlsread('Edge1.xlsx');b = xlsread('Edge2.xlsx');FID = dxf_open('EdgeContour.dxf');dxf_polyline(FID, a(:,1), a(:,2), zeros(length(a),1));dxf_polyline(FID, b(:,1), b(:,2), zeros(length(b),1));dxf_close(FID);</code></pre></details><blockquote><p>DXFLib åº“åœ°å€: <a href="https://www.mathworks.com/matlabcentral/fileexchange/33884-dxflib">https://www.mathworks.com/matlabcentral/fileexchange/33884-dxflib</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> æ•°å­¦å»ºæ¨¡ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å›¾åƒå¤„ç† </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å’Œå‘¨å°å§é«˜ä¸­çš„å¯¹è¯ï¼ˆä¸€ï¼‰</title>
      <link href="/p/3b4e1f24/"/>
      <url>/p/3b4e1f24/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å’Œå‘¨å°å§çš„é«˜ä¸­æ—¥å¸¸ä¹‹ä¸€</p><span id="more"></span><p>ä¸€æ—¥ï¼Œå‘¨å°å§å¿½ç„¶é€’è¿‡ä¸€å¼ çº¸æ¡ï¼Œä¸Šé¢å†™é“ï¼š</p><blockquote><p>å‡¡é£Ÿäººé—´çƒŸç«è€…ï¼Œçš†æœ‰æ‰€å¥½ï¼Œå¾ä¹‹æ‰€å¥½è€…ï¼Œä¹ä¹Ÿï¼›çˆ±åå›ä¹‹æ‰€å¥½è€…ï¼Œè‰²ä¹Ÿã€‚</p><p>ä½•ä¸ºè‰²ä¹Ÿï¼Ÿå¥³è‰²ä¹Ÿï¼Œå‡¡æœ‰é¢å®¹å§£å¥½è€…ï¼Œéš¾ä»¥é€ƒè„±çˆ±åä¹‹çœ¼ä¹Ÿã€‚</p><p>å—Ÿä¹ï¼è‰²å­—å½“å¤´ä¸€æŠŠåˆ€ï¼Œå¾ç”šæçˆ±åå›ä¸çŸ¥ä¹Ÿï¼Œç‰¹å†™æ­¤ä¹¦ä»¥å‘Šä¹‹ã€‚</p><p align="right">â€”â€”by Ting</p></blockquote><p>æˆ‘è¿™æ ·å›å¤ï¼š</p><blockquote><p>æ±åº¸ä¹Ÿï¼Œåå¤ä¸Šä¸‹äº”åƒå¹´ï¼Œå…¶äººä¹Ÿä»¥äº¿è®¡ï¼Œå¤©åœ°å¯¿ä¹Ÿæ•°åäº¿å¹´ï¼Œå…¶çµä¹Ÿä»¥ä¸‡äº¿è®¡ã€‚æ­¤çš†é›Œé›„ï¼Œç”·å¥³åˆ†å·¥ä¹‹æ³•ã€‚</p><p>ä¸‡ç‰©æœ‰çµï¼Œçµçš†çˆ±ç¾ï¼Œæ›´æœ‰å­¦è€…æ’°ã€Šç‰©ç§èµ·æºã€‹è®ºè¿›åŒ–ä¹‹äº‹çŸ£ï¼Œå…¶æ„äº¦å¦‚æ­¤ã€‚</p><p>ä»Šå¾æ‰€æ€ä¹‹å¥³å­ï¼Œé¢å®¹å§£å¥½ï¼Œä¸¾æ­¢æ·‘å¥³ï¼Œä¸–äººè§†ä¹‹çš†æ…•ä¹‹ï¼Œå¾ä½•ç†ä¸å¿µä¹‹ã€‚å¤äººäº‘ï¼šâ€œçªƒçª•æ·‘å¥³ï¼Œå›å­å¥½é€‘ã€‚â€ä¸”å¾æ­¢äºè¿œè§‚è€Œä¸éªšæ‰°ï¼Œæ±ä½•ç†ä¹‹è¨€å¾å¿ƒè‰²ä¹Ÿï¼Ÿ</p><p align="right">â€”â€”by Aep</p></blockquote><p>ä»Šæ–™æˆ‘æ‰€è¨€åº”å¦‚æ˜¯ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> ç”Ÿæ´» </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>è®°å½•ç¬¬næ¬¡ä¿®å¤å¼•å¯¼åŒº</title>
      <link href="/p/93d3d7c3/"/>
      <url>/p/93d3d7c3/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>ç»™Uç›˜è£…äº†archlinuxåï¼Œæ²¡æ³¨æ„æŠŠå›ºæ€ä¸Šarchlinuxçš„/etc/fstabåˆ†åŒºæŒ‚è½½é…ç½®æ–‡ä»¶ä¿®æ”¹äº†ï¼Œä»¥ä¸ºæ˜¯grubåˆåäº†ï¼Œå¹²è„†æŠŠæŒ‚è½½åœ¨/bootä¸‹çš„EFI ç³»ç»Ÿæ ¼å¼åŒ–äº†ï¼Œå­™å­äº‘ï¼šâ€œç½®ä¹‹æ­»åœ°è€Œåç”Ÿã€‚â€ ä»å¤´å¼€å§‹</p><span id="more"></span><h2 id="å‡†å¤‡"><a href="#å‡†å¤‡" class="headerlink" title="å‡†å¤‡"></a>å‡†å¤‡</h2><p>æ’ç½‘çº¿ï¼Œå–çƒ­æ°´</p><h2 id="è¿‡ç¨‹"><a href="#è¿‡ç¨‹" class="headerlink" title="è¿‡ç¨‹"></a>è¿‡ç¨‹</h2><ol><li><p>Uç›˜å¯åŠ¨è¿›å»åæŒ‚è½½æ ¹åˆ†åŒºå’Œå¯åŠ¨åˆ†åŒºï¼Œarch-chrootåˆ°æ ¹åˆ†åŒº</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lsblk</span><br><span class="line">mkfs.vfat -F32 /dev/$&#123;/boot&#125;# $&#123;/boot&#125; å¯åŠ¨åˆ†åŒº</span><br><span class="line">mount /dev/$&#123;/&#125; /mnt# $&#123;/&#125; æ ¹åˆ†åŒº</span><br><span class="line">mount /dev/$&#123;/boot&#125; /mnt/boot</span><br><span class="line">arch-chroot /mnt</span><br></pre></td></tr></table></figure><blockquote><p>ä»¥ä¸Šæ“ä½œåªèƒ½åœ¨å¯åŠ¨ç›˜è¿›è¡Œï¼Œå¦‚æœç”¨å®Œæ•´çš„archlinuxç³»ç»Ÿï¼Œåˆ™æ²¡æœ‰arch-chrootä»¥åŠpacstrapå‘½ä»¤<br>å¦‚æœä½¿ç”¨chrootä»£æ›¿arch-chrootå‘½ä»¤åï¼Œæ‰§è¡Œpacmanä¼šæŠ¥éæœ¬ç”¨æˆ·é”™è¯¯</p></blockquote></li><li><p>é‡æ–°ç”Ÿæˆå¼•å¯¼åŒº</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=GRUB</span><br><span class="line">grub-mkconfig -o /boot/grub/grub.cfg</span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹æœ‰æ²¡æœ‰Linuxçš„å…¥å£</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /boot/grub/grub.cfg</span><br></pre></td></tr></table></figure><p>å¦‚æœæ²¡æœ‰å…¥å£</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /boot</span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹æ˜¯å¦æœ‰ä¸‹åˆ—æ–‡ä»¶</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">initramfs-linux.img</span><br><span class="line">intel-ucode.img</span><br><span class="line">vmlinuz-linux</span><br></pre></td></tr></table></figure><p>å¦‚æœæ²¡æœ‰ï¼Œé‡è£…linux</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S linux</span><br></pre></td></tr></table></figure><p>å¦‚æœæŠ¥é”™<br><code>GDBus.Error:org.freedesktop.DBus.Error.ServiceUnknown: The name org.cinnamon.SettingsDaemon was not provided by any .service files</code><br>å› ä¸ºpacmanæ£€æµ‹åˆ°éåŸæ¥ç”¨æˆ·æ‰§è¡Œï¼Œåˆ™å¯ä»¥æ‰§è¡Œä¸‹é¢å‘½ä»¤</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkinitcpio -p linux</span><br></pre></td></tr></table></figure><p>é‡æ–°åŠ è½½å†…æ ¸æ¨¡å—ï¼Œç”Ÿæˆæ–‡ä»¶<br>å†æ‰§è¡Œ</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grub-mkconfig -o /boot/grub/grub.cfg</span><br><span class="line">ls /boot</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°æœ‰äº†ä¸‰ä¸ªæ–‡ä»¶<br>é€€å‡º/mntæ ¹åˆ†åŒºï¼Œå›åˆ°å¯åŠ¨ç›˜</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">initramfs-linux.img</span><br><span class="line">intel-ucode.img</span><br><span class="line">vmlinuz-linux</span><br><span class="line">exit</span><br></pre></td></tr></table></figure></li><li>é‡æ–°ç”Ÿæˆåˆ†åŒºæŒ‚è½½é…ç½®æ–‡ä»¶<br>å…ˆåˆ é™¤åŸæ¥çš„åˆ†åŒºæŒ‚è½½é…ç½®æ–‡ä»¶ï¼Œä¸ç„¶æ— æ³•æŒ‚è½½åˆ†åŒºï¼Œç³»ç»Ÿæ— æ³•å¯åŠ¨ï¼Œå†ç”Ÿæˆfstabæ–‡ä»¶<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /mnt/etc/fstab</span><br><span class="line">genfstab -U /mnt &gt;&gt; /mnt/etc/fstab</span><br></pre></td></tr></table></figure>æŸ¥çœ‹ç”Ÿæˆçš„ç¡¬ç›˜UUIDå’Œåˆ†åŒºå‘½åï¼Œä¸€è‡´å³å¯<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ls -l /dev/disk/by-uuid</span><br><span class="line">cat /mnt/etc/fstab</span><br><span class="line">exit</span><br><span class="line">poweroff</span><br></pre></td></tr></table></figure></li><li>è®¾ç½®UEFI<br>æœ¬äººç”µè„‘ä¸ºDELL</li></ol><ul><li>è¿›å…¥BIOS</li><li>é€‰æ‹©Boot Sequence</li><li>Add Boot Option</li><li>File Name ä¸º /boot/EFI/grubä¸‹çš„grubx64.efi</li><li>Boot Option Name éç©º</li><li>Applyï¼ŒExit<h2 id="ç»“æŸ"><a href="#ç»“æŸ" class="headerlink" title="ç»“æŸ"></a>ç»“æŸ</h2><blockquote><p>ä¿®grubçš„å‘¨æœŸå¤§æ¦‚æ˜¯3ä¸ªæœˆä¸€æ¬¡ï¼Œå„ç§åæ‰çš„åŸå› éƒ½æœ‰ï¼Œè®°å½•ä¸‹æ–¹ä¾¿ä¸‹æ¬¡è§£å†³ã€‚</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> archlinux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> grub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ±‚è§£å¾®åˆ†æ–¹ç¨‹</title>
      <link href="/p/86ad67e4/"/>
      <url>/p/86ad67e4/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>è§£å¾®åˆ†æ–¹ç¨‹æ˜¯æˆ‘çš„å¼±é¡¹ï¼Œå°±é è¿™ä¸ªäº†</p><span id="more"></span><h2 id="åŸºæœ¬æ¦‚å¿µ"><a href="#åŸºæœ¬æ¦‚å¿µ" class="headerlink" title="åŸºæœ¬æ¦‚å¿µ"></a>åŸºæœ¬æ¦‚å¿µ</h2><h3 id="å®šä¹‰"><a href="#å®šä¹‰" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h3><p>å«å¯¼æ•°æˆ–å¾®åˆ†çš„æ–¹ç¨‹ç§°ä¹‹ä¸ºå¾®åˆ†æ–¹ç¨‹ï¼Œä¸€èˆ¬å½¢å¼ä¸º$f(x,yâ€™ \cdots y^{(n)})$</p><h3 id="é˜¶æ•°"><a href="#é˜¶æ•°" class="headerlink" title="é˜¶æ•°"></a>é˜¶æ•°</h3><p>å¾®åˆ†æ–¹ç¨‹æ‰€å«çš„å¯¼æ•°æˆ–å¾®åˆ†çš„æœ€é«˜é˜¶æ•°ç§°ä¸ºå¾®åˆ†æ–¹ç¨‹çš„é˜¶æ•°</p><h3 id="è§£"><a href="#è§£" class="headerlink" title="è§£"></a>è§£</h3><p>è§£ï¼šä½¿å¾—å¾®åˆ†æ–¹ç¨‹æˆç«‹çš„å‡½æ•°<br>ç‰¹è§£ï¼šä¸å«ä»»æ„å¸¸æ•°<br>é€šè§£ï¼šæ‰€å«çš„ç›¸äº’ç‹¬ç«‹çš„ä»»æ„å¸¸æ•°çš„ä¸ªæ•°ä¸å¾®åˆ†æ–¹ç¨‹çš„é˜¶æ•°ç›¸ç­‰</p><h2 id="æ±‚è§£"><a href="#æ±‚è§£" class="headerlink" title="æ±‚è§£"></a>æ±‚è§£</h2><h3 id="å¯åˆ†ç¦»å˜é‡å¾®åˆ†æ–¹ç¨‹"><a href="#å¯åˆ†ç¦»å˜é‡å¾®åˆ†æ–¹ç¨‹" class="headerlink" title="å¯åˆ†ç¦»å˜é‡å¾®åˆ†æ–¹ç¨‹"></a>å¯åˆ†ç¦»å˜é‡å¾®åˆ†æ–¹ç¨‹</h3><script type="math/tex; mode=display">\frac{\mathrm{d}y}{\mathrm{d}x} = f(x)g(y)</script><p>è§£</p><script type="math/tex; mode=display">\int \frac{\mathrm{d}y}{g(y)} = \int f(x)\mathrm{d}x</script><blockquote><p>e.g. </p><script type="math/tex; mode=display">\frac{\mathrm{d}y}{\mathrm{d}x} = 2xy</script><p>è§£</p><script type="math/tex; mode=display">\int \frac{\mathrm{d}y}{y} = \int 2x\mathrm{d}x</script><script type="math/tex; mode=display">\ln y = x^2+C</script><script type="math/tex; mode=display">\begin{aligned} y {}& = e^{x^2+C} {} \\ & = e^C e^{x^2} {} \\ & = C_1 e^{x^2} {} \\ & \quad(C_1 = e^C) \end{aligned}</script></blockquote><h3 id="ä¸€é˜¶é½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹"><a href="#ä¸€é˜¶é½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹" class="headerlink" title="ä¸€é˜¶é½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹"></a>ä¸€é˜¶é½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹</h3><script type="math/tex; mode=display">y' +P(x)y = 0</script><p>è§£</p><script type="math/tex; mode=display">y = Ce^{-\int{P(x)\mathrm{d}x}}</script><blockquote><p>e.g.</p><script type="math/tex; mode=display">y'-xy=0</script><p>è§£</p><script type="math/tex; mode=display">y = Ce^{\int x\mathrm{d}x}=Ce^{\frac{x^2}{2}}</script></blockquote><h3 id="ä¸€é˜¶éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹"><a href="#ä¸€é˜¶éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹" class="headerlink" title="ä¸€é˜¶éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹"></a>ä¸€é˜¶éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹</h3><script type="math/tex; mode=display">y'+P(x)y = Q(x) \neq 0</script><p>è§£</p><script type="math/tex; mode=display">y = (\int Q(x)e^{\int P(x) \mathrm{d}x}\mathrm{d}x+C)e^{-\int P(x) \mathrm{d}x}</script><blockquote><p>e.g.</p><script type="math/tex; mode=display">y'+y \tan x = \cos x</script><p>è§£</p><script type="math/tex; mode=display">y = (\int \cos x e^{\int \tan x \mathrm{d}x}\mathrm{d}x+C)e^{-\int\tan x \mathrm{d}x} = (x+C)\cos x</script></blockquote><h3 id="è´åŠªåˆ©æ–¹ç¨‹"><a href="#è´åŠªåˆ©æ–¹ç¨‹" class="headerlink" title="è´åŠªåˆ©æ–¹ç¨‹"></a>è´åŠªåˆ©æ–¹ç¨‹</h3><script type="math/tex; mode=display">\frac{\mathrm{d}y}{\mathrm{d}x} + P(x)y = Q(x)y^n \quad (n \neq 0)</script><p>è§£<br>ä»¤$z = y^{1-n}$ï¼Œä»£å…¥åŸæ–¹ç¨‹å¾—$\frac{\mathrm{d}z}{\mathrm{d}x}+(1-n)P(x)z = (1-n)Q(x)$ï¼Œå†æ±‚è§£è¯¥ä¸€é˜¶éé½æ¬¡çº¿æ€§æ–¹ç¨‹å³å¯</p><blockquote><p>e.g.</p><script type="math/tex; mode=display">x^2y'+xy = y^2</script><p>è§£</p><script type="math/tex; mode=display">z = y^{1-2} = y^{-1},\quad y' = -\frac{1}{z^2}z'</script><p>ä»£å…¥åŸå¼</p><script type="math/tex; mode=display">z' - \frac{1}{x}z = -\frac{1}{x^2}</script><script type="math/tex; mode=display">z = (\int (-\frac{1}{x^2})e^{\int -\frac{1}{x}\mathrm{d}x}\mathrm{d}x +C)e^{\int \frac{1}{x}\mathrm{d}x} = (\frac{1}{2x^2}+C)x</script><script type="math/tex; mode=display">\frac{1}{y} = (\frac{1}{2x^2}+C)x</script></blockquote><h3 id="å¯é™é˜¶å¾®åˆ†æ–¹ç¨‹"><a href="#å¯é™é˜¶å¾®åˆ†æ–¹ç¨‹" class="headerlink" title="å¯é™é˜¶å¾®åˆ†æ–¹ç¨‹"></a>å¯é™é˜¶å¾®åˆ†æ–¹ç¨‹</h3><h4 id="å½¢å¼ä¸€"><a href="#å½¢å¼ä¸€" class="headerlink" title="å½¢å¼ä¸€"></a>å½¢å¼ä¸€</h4><script type="math/tex; mode=display">y^{(n) = f(x)}</script><p>è§£<br>å¯¹æ–¹ç¨‹è¿›è¡Œ$n$æ¬¡ä¸å®šç§¯åˆ†</p><blockquote><p>e.g.</p><script type="math/tex; mode=display">y'' = x^2</script><p>è§£</p><script type="math/tex; mode=display">y' = \frac{1}{3} x^3 +C_1</script><script type="math/tex; mode=display">y = \frac{1}{12}x^4+C_1 x + C_2</script></blockquote><h4 id="å½¢å¼äºŒ"><a href="#å½¢å¼äºŒ" class="headerlink" title="å½¢å¼äºŒ"></a>å½¢å¼äºŒ</h4><script type="math/tex; mode=display">f(x,y',y'') = 0</script><p>è§£</p><ol><li>ä»¤$yâ€™ = p$ï¼Œåˆ™$yâ€™â€™=pâ€™$ï¼ŒåŸæ–¹ç¨‹å˜ä¸º$f(x,p,pâ€™) = 0$</li><li>è§£å‡º$p = \varphi(x)$</li><li>$y = \int \varphi(x)\mathrm{d}x+C$<blockquote><p>e.g.</p><script type="math/tex; mode=display">y'' + \frac{y'}{x} = 0</script><p>è§£<br>ä»¤$yâ€™ = p$ï¼Œåˆ™$yâ€™â€™ = pâ€™$ï¼ŒåŸæ–¹ç¨‹å˜ä¸º$pâ€™ + \frac{p}{x} = 0$</p><script type="math/tex; mode=display">p = C_1e^{\int -\frac{1}{x}\mathrm{d}x} = \frac{C_1}{x}</script><script type="math/tex; mode=display">\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{C_1}{x}</script><script type="math/tex; mode=display">y = C_1 \ln \lvert x \rvert +C_2</script></blockquote></li></ol><h4 id="å½¢å¼ä¸‰"><a href="#å½¢å¼ä¸‰" class="headerlink" title="å½¢å¼ä¸‰"></a>å½¢å¼ä¸‰</h4><script type="math/tex; mode=display">f(y,y',y'') = 0</script><p>è§£</p><ol><li>ä»¤$yâ€™ = p$ï¼Œåˆ™$yâ€™â€™ = \frac{\mathrm{d}p}{\mathrm{d}x} = \frac{\mathrm{d}p}{\mathrm{d}y} \frac{\mathrm{d}y}{\mathrm{d}x} = p \frac{\mathrm{d}p}{\mathrm{d}y}$ï¼ŒåŸæ–¹ç¨‹å˜ä¸º$f(y,p,pâ€™) = 0$</li><li>è§£å‡º$p = \varphi(y)$</li><li>$\int \frac{\mathrm{d}y}{\varphi(y)} = x+C$<blockquote><p>e.g.</p><script type="math/tex; mode=display">y y'' = y'^2</script><p>ä»¤$yâ€™ = p$ï¼Œ$yâ€™â€™ = p \frac{\mathrm{d}p}{\mathrm{d}y}$ï¼Œä»£å…¥åŸå¼</p><script type="math/tex; mode=display">yp\frac{\mathrm{d}p}{\mathrm{d}y}-p^2 = 0 \Rightarrow p = C_1 e^{\int \frac{1}{y} \mathrm{d}y = C_1 y }</script><script type="math/tex; mode=display">\frac{\mathrm{d}y}{\mathrm{d}x} = C_1 y \Rightarrow \int \frac{\mathrm{d}y}{y} = \int C_1 \mathrm{d}x</script><script type="math/tex; mode=display">\ln y = C_1x+C_2 \Rightarrow y = e^{C_1 x+C_2} = C_3 e^{C_1 x} \quad (C_3 = e^{C_2})</script></blockquote></li></ol><h3 id="äºŒé˜¶å¸¸ç³»æ•°çº¿æ€§å¾®åˆ†æ–¹ç¨‹"><a href="#äºŒé˜¶å¸¸ç³»æ•°çº¿æ€§å¾®åˆ†æ–¹ç¨‹" class="headerlink" title="äºŒé˜¶å¸¸ç³»æ•°çº¿æ€§å¾®åˆ†æ–¹ç¨‹"></a>äºŒé˜¶å¸¸ç³»æ•°çº¿æ€§å¾®åˆ†æ–¹ç¨‹</h3><script type="math/tex; mode=display">y'' +py' +qy = 0</script><p>è§£</p><ol><li>æ±‚è§£$yâ€™â€™ +pyâ€™ +qy = 0$çš„ç‰¹å¾æ–¹ç¨‹æ˜¯$r^2+pr+q = 0$</li><li>æ ¹æ®æ–¹ç¨‹æ ¹çš„ä¸åŒåˆ†ä¸ºä¸‰ç§æƒ…å†µ<ol><li>å½“ç‰¹å¾æ–¹ç¨‹æœ‰ä¸¤ä¸ªå®æ ¹$r_1$ï¼Œ$r_2$ï¼Œä¸”$r_1\neq r_2$ï¼Œåˆ™$y = C_1e^{r1 x}+C_2e^{r_2 x}$</li><li>å½“ç‰¹å¾æ–¹ç¨‹æœ‰é‡æ ¹$r_1 = r_2$ï¼Œåˆ™$y = (C_1+C_2x)e^{r_1 x}$</li><li>å½“ç‰¹å¾æ–¹ç¨‹æœ‰ä¸¤ä¸ªå…±è½­é‡æ ¹$r_{1,2} = \alpha \pm \beta i$ï¼Œåˆ™$y = e^{\alpha x} (C_1 \cos \beta x + C_2 \sin \beta x)$<blockquote><p>e.g.1</p><script type="math/tex; mode=display">y'' - y' - 6y = 0</script><p>è§£</p><script type="math/tex; mode=display">r^2-r-6 = (r-3)(r+2) = 0 \Rightarrow r_1 = 3,\quad r_2 = -2</script><script type="math/tex; mode=display">y = C_1 e^{3x} + C_2 e^{-2x}</script><p>e.g.2</p><script type="math/tex; mode=display">y''-2y'+y = 0</script><p>è§£</p><script type="math/tex; mode=display">r^2-2r+1 = (r-1)^2 = 0 \Rightarrow r_{1,2} = 1</script><script type="math/tex; mode=display">y = (C_1 + C_2 x)e^x</script><p>e.g.3</p><script type="math/tex; mode=display">y'' - 2y' + 2y = 0</script><p>è§£</p><script type="math/tex; mode=display">r^2- 2r +2 = 0 \Rightarrow r_{1,2} = 1 \pm i</script><script type="math/tex; mode=display">y = e^x (C_1 \cos x + C_2 \sin x)</script></blockquote></li></ol></li></ol><h3 id="äºŒé˜¶å¸¸ç³»æ•°éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹"><a href="#äºŒé˜¶å¸¸ç³»æ•°éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹" class="headerlink" title="äºŒé˜¶å¸¸ç³»æ•°éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹"></a>äºŒé˜¶å¸¸ç³»æ•°éé½æ¬¡çº¿æ€§å¾®åˆ†æ–¹ç¨‹</h3><h4 id="å½¢å¼ä¸€-1"><a href="#å½¢å¼ä¸€-1" class="headerlink" title="å½¢å¼ä¸€"></a>å½¢å¼ä¸€</h4><script type="math/tex; mode=display">y'' + py' +qy = P_n(x)e^{kx}</script><p>å…¶ä¸­$P_n(x)$ä»£è¡¨$x$çš„$n$é˜¶å¤šé¡¹å¼<br>è§£<br>æ ¹æ®$k$çš„å€¼æœ‰ä»¥ä¸‹ä¸‰ç§æƒ…å†µï¼š</p><ol><li>è‹¥$k$éç‰¹å¾å€¼ï¼Œå³$k \neq r<em>1 \neq r_2$ï¼Œåˆ™ç‰¹è§£ $y^* = e^{kx} \sum</em>{i=0}^n a_i x^i$</li><li>è‹¥$k$ä¸ä¸€ä¸ªç‰¹å¾å€¼ç›¸åŒï¼Œåˆ™ç‰¹è§£  $y^* = xe^{kx} \sum_{i=0}^n a_i x^i$</li><li>è‹¥$k$ä¸ä¸¤ä¸ªç‰¹å¾å€¼ç›¸åŒï¼Œåˆ™ç‰¹è§£  $y^* = x^2e^{kx} \sum_{i=0}^n a_i x^i$</li></ol><h4 id="å½¢å¼äºŒ-1"><a href="#å½¢å¼äºŒ-1" class="headerlink" title="å½¢å¼äºŒ"></a>å½¢å¼äºŒ</h4><script type="math/tex; mode=display">y'' + py' + qy = e^{ax} [P_l \cos bx + P_s \sin bx]</script><p>å…¶ä¸­$P_l(x)$ï¼Œ$P_s(x)$ä»£è¡¨$x$çš„$l$ï¼Œ$s$é˜¶å¤šé¡¹å¼<br>è§£<br>æ ¹æ®$a$ï¼Œ$b$çš„å€¼æœ‰ä»¥ä¸‹ä¸‰ç§æƒ…å†µ</p><ol><li>è‹¥$a\pm b i$ä¸æ˜¯ç‰¹å¾å€¼ï¼Œåˆ™ç‰¹è§£ $y^* = (Q_n^{(1)}(x)\cos bx+Q_n^{(2)}(x)\sin bx)e^{ax}$</li><li>è‹¥$a\pm b i$æ˜¯ç‰¹å¾å€¼ï¼Œåˆ™ç‰¹è§£ $y^* = x(Q_n^{(1)}(x)\cos bx+Q_n^{(2)}(x)\sin bx)e^{ax}$</li></ol>]]></content>
      
      
      <categories>
          
          <category> é«˜ç­‰æ•°å­¦ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> çŸ¥è¯†ç‚¹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ‹Ÿåˆå’Œç»Ÿè®¡ä¸­çš„æ£€éªŒå‚æ•°</title>
      <link href="/p/62c5a99c/"/>
      <url>/p/62c5a99c/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æ•°æ®åˆ†æä¸­æ— å¤„ä¸åœ¨çš„çŸ¥è¯†ç‚¹</p><span id="more"></span><blockquote><p>SSE(å’Œæ–¹å·®ã€è¯¯å·®å¹³æ–¹å’Œ)ï¼šThe sum of squares due to error<br>MSE(å‡æ–¹å·®ã€æ–¹å·®)ï¼šMean squared error<br>RMSE(å‡æ–¹æ ¹ã€å‰©ä½™æ ‡å‡†å·®)ï¼šRoot mean squared error<br>$R^2$(åˆ¤æ–­ç³»æ•°ï¼Œæ‹Ÿåˆä¼˜åº¦)ï¼šCoefficient of determination</p></blockquote><h2 id="å®šä¹‰"><a href="#å®šä¹‰" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h2><p>åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œå‡æ–¹è¯¯å·®æ˜¯å‚æ•°ä¼°è®¡å€¼ä¸å‚æ•°çœŸå€¼ä¹‹å·®å¹³æ–¹çš„æœŸæœ›å€¼ï¼Œæ˜¯è¡¡é‡â€œå¹³å‡è¯¯å·®â€çš„ä¸€ç§è¾ƒæ–¹ä¾¿çš„æ–¹æ³•ï¼ŒMSEå¯ä»¥è¯„ä»·æ•°æ®çš„å˜åŒ–ç¨‹åº¦ï¼ŒMSEçš„å€¼è¶Šå°ï¼Œè¯´æ˜é¢„æµ‹æ¨¡å‹æè¿°å®éªŒæ•°æ®å…·æœ‰æ›´å¥½çš„ç²¾ç¡®åº¦ã€‚</p><h3 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h3><h4 id="æ–¹å·®"><a href="#æ–¹å·®" class="headerlink" title="æ–¹å·®"></a>æ–¹å·®</h4><p>æ–¹å·®æ˜¯åœ¨æ¦‚ç‡è®ºå’Œç»Ÿè®¡æ–¹å·®è¡¡é‡éšæœºå˜é‡æˆ–ä¸€ç»„æ•°æ®çš„ç¦»æ•£ç¨‹åº¦çš„åº¦é‡æ–¹å¼ï¼Œæ–¹å·®è¶Šå¤§ï¼Œç¦»æ•£åº¦è¶Šå¤§ã€‚æ±‚è§£æ–¹å¼ä¸ºï¼Œå„éšæœºå˜é‡ä¸å¹³å‡å€¼å·®å€¼çš„å¹³æ–¹å’Œçš„å¹³å‡æ•°<br>å¹³å‡æ•°ï¼š</p><script type="math/tex; mode=display">M = \frac{x_1+x_2+x_3+\cdots+x_n}{n}</script><p>æ–¹å·®å…¬å¼ï¼š</p><script type="math/tex; mode=display">S^2 = \frac{(x_1-M)^2+(x_1-M)^2+\cdots+(x_n-M)^2}{n}</script><h4 id="æ ‡å‡†å·®"><a href="#æ ‡å‡†å·®" class="headerlink" title="æ ‡å‡†å·®"></a>æ ‡å‡†å·®</h4><p>æ ‡å‡†å·®å°±æ˜¯æ–¹å·®çš„ç®—æœ¯å¹³æ–¹æ ¹ï¼Œå®ƒåæ˜ ç»„å†…ä¸ªä½“é—´çš„ç¦»æ•£ç¨‹åº¦ã€‚å› æ­¤å®ƒçš„è¿‡ç¨‹æ˜¯ä¸å¹³å‡å€¼ä¹‹é—´è¿›è¡Œå·®å€¼è®¡ç®—<br>æ ‡å‡†å·®å…¬å¼ï¼š</p><script type="math/tex; mode=display">\sigma=\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2}</script><h4 id="æ ·æœ¬æ–¹å·®"><a href="#æ ·æœ¬æ–¹å·®" class="headerlink" title="æ ·æœ¬æ–¹å·®"></a>æ ·æœ¬æ–¹å·®</h4><script type="math/tex; mode=display">\hat{\sigma}^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\mu)^2</script><h2 id="SSEï¼ˆè¯¯å·®å¹³æ–¹å’Œï¼‰"><a href="#SSEï¼ˆè¯¯å·®å¹³æ–¹å’Œï¼‰" class="headerlink" title="SSEï¼ˆè¯¯å·®å¹³æ–¹å’Œï¼‰"></a>SSEï¼ˆè¯¯å·®å¹³æ–¹å’Œï¼‰</h2><p>åœ¨ç»Ÿè®¡å­¦é‡Œï¼Œè¯¥å‚æ•°è®¡ç®—çš„æ˜¯æ‹Ÿåˆæ•°æ®å¾ˆåŸå§‹æ•°æ®å¯¹åº”ç‚¹çš„è¯¯å·®çš„å¹³æ–¹å’Œï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š</p><script type="math/tex; mode=display">SSE = \sum_{i=1}^m(y_i - \hat{y}_i)^2</script><p>$y_i$æ˜¯çœŸå®æ•°æ®ï¼Œ$\hat{y}_i$æ˜¯æ‹Ÿåˆæ•°æ®</p><h2 id="MSEï¼ˆæ–¹å·®ï¼‰"><a href="#MSEï¼ˆæ–¹å·®ï¼‰" class="headerlink" title="MSEï¼ˆæ–¹å·®ï¼‰"></a>MSEï¼ˆæ–¹å·®ï¼‰</h2><p>æ˜¯é¢„æµ‹æ•°æ®å’ŒåŸå§‹æ•°æ®å¯¹åº”ç‚¹è¯¯å·®çš„å¹³æ–¹å’Œçš„å‡å€¼ï¼Œä¹Ÿå°±æ˜¯$\frac{SSE}{n-m}$ï¼Œ$n$æ˜¯è§‚æµ‹æ•°æ®çš„ä¸ªæ•°ï¼Œ$m$jæ˜¯æ‹Ÿåˆæ•°æ®çš„ä¸ªæ•°,å’Œ$SSE$æ²¡æœ‰å¤ªå¤§çš„åŒºåˆ«ï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š</p><script type="math/tex; mode=display">MSE=\frac{SSE}{n-m}=\frac{1}{n-m}\sum_{i=1}^{n}(y_i-\hat{y_i })^2</script><h2 id="RMSEï¼ˆå‰©ä½™æ ‡å‡†å·®ï¼‰"><a href="#RMSEï¼ˆå‰©ä½™æ ‡å‡†å·®ï¼‰" class="headerlink" title="RMSEï¼ˆå‰©ä½™æ ‡å‡†å·®ï¼‰"></a>RMSEï¼ˆå‰©ä½™æ ‡å‡†å·®ï¼‰</h2><p>ä¹Ÿæ˜¯å«å›å½’ç³»ç»Ÿçš„æ‹Ÿåˆæ ‡å‡†å·®ï¼Œæ˜¯$MSE$çš„å¹³æ–¹æ ¹ï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š</p><script type="math/tex; mode=display">RMSE=\sqrt{MSE}=\sqrt{\frac{1}{n-m}\sum_{i=1}^{n}(y_i-\hat{y_i })^2}</script><h2 id="R-2-åˆ¤æ–­ç³»æ•°"><a href="#R-2-åˆ¤æ–­ç³»æ•°" class="headerlink" title="$R^2$(åˆ¤æ–­ç³»æ•°)"></a>$R^2$(åˆ¤æ–­ç³»æ•°)</h2><p>åœ¨è®²åˆ¤æ–­ç³»æ•°ä¹‹å‰ï¼Œå…ˆä»‹ç»å¦å¤–ä¸¤ä¸ªå‚æ•°$SSR$å’Œ$SST$ï¼Œå› ä¸ºåˆ¤æ–­ç³»æ•°å°±æ˜¯ç”±è¿™ä¸¤ä¸ªå‚æ•°å†³å®šçš„<br>å¯¹æ€»å¹³æ–¹å’Œ$SST = \sum_{i=1}^{n}(y_i-\overline{y})^2$è¿›è¡Œåˆ†è§£ï¼Œæœ‰</p><script type="math/tex; mode=display">SST = SSE+SSR,SSR = \sum_{i=1}^{n}(\hat{y_i}-\overline{y})^2</script><p>å…¶ä¸­$\overline{y} = \frac{1}{n}\sum_{i=1}^{n}y_i$ï¼Œ$SSE$æ˜¯è¯¯å·®å¹³æ–¹å’Œï¼Œåæ˜ éšæœºè¯¯å·®å¯¹$y$çš„å½±å“ï¼Œ$SSR$æ˜¯å›å½’å¹³æ–¹å’Œï¼Œåæ˜ è‡ªå˜é‡å¯¹$y$çš„å½±å“<br>åˆ¤æ–­ç³»æ•°å®šä¹‰ä¸º</p><script type="math/tex; mode=display">R^2 = \frac{SSR}{SST} = \frac{SST-SSE}{SST} = 1-\frac{SSE}{SST}</script><h2 id="è°ƒæ•´çš„-R-2"><a href="#è°ƒæ•´çš„-R-2" class="headerlink" title="è°ƒæ•´çš„$R^2$"></a>è°ƒæ•´çš„$R^2$</h2><p>ç»Ÿè®¡å­¦å®¶ä¸»å¼ åœ¨å›å½’å»ºæ¨¡æ—¶ï¼Œå°±é‡‡ç”¨å°½å¯èƒ½å°‘çš„è‡ªå˜é‡ï¼Œä¸è¦ç›²ç›®åœ°è¿½æ±‚åˆ¤å®šç³»æ•°çš„æé«˜ã€‚å½“å˜é‡å¢åŠ æ—¶ï¼Œæ®‹é‡çš„è‡ªç”±åº¦å°±ä¼šå‡å°‘ã€‚è€Œè‡ªç”±åº¦è¶Šå°ï¼Œæ•°æ®çš„ç»Ÿè®¡è¶‹åŠ¿å°±è¶Šä¸å®¹æ˜“æ˜¾ç°ã€‚ä¸ºæ­¤ï¼Œåˆå®šä¹‰äº†ä¸€ä¸ªè°ƒæ•´åˆ¤æ–­ç³»æ•°</p><script type="math/tex; mode=display">\overline{R^2} = 1-\frac{SSE/(n-m)}{SST/(n-1)}</script><p>$\overline{R^2}$ä¸$R^2$çš„å…³ç³»æ˜¯</p><script type="math/tex; mode=display">\overline{R^2} = 1-(1-R^2)\frac{n-1}{n-m}</script><p>å½“$n$å¾ˆå°ï¼Œ$m$å¾ˆå¤§æ—¶ï¼Œ$\overline{R^2}$ä¼šè¿œå°äº$R^2$</p>]]></content>
      
      
      <categories>
          
          <category> ç»Ÿè®¡å­¦ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> çŸ¥è¯†ç‚¹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ­£äº¤å¤šé¡¹å¼</title>
      <link href="/p/6b91a7a9/"/>
      <url>/p/6b91a7a9/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>æ€»ç»“ä¸€ä¸‹å¯èƒ½ä¼šé‡åˆ°çš„æ­£äº¤å¤šé¡¹å¼</p><span id="more"></span><h2 id="æ­£äº¤å¤šé¡¹å¼å®šä¹‰"><a href="#æ­£äº¤å¤šé¡¹å¼å®šä¹‰" class="headerlink" title="æ­£äº¤å¤šé¡¹å¼å®šä¹‰"></a>æ­£äº¤å¤šé¡¹å¼å®šä¹‰</h2><p>ä¸€ä¸ªå¤šé¡¹å¼åºåˆ—${ {p<em>n}(x)} </em>{n = 0}^\infty$ï¼Œé˜¶æ•°ä¸º$[p_n(x)] = n$,å¯¹äºæ¯ä¸€ä¸ª$n$ï¼Œè¿™ä¸ªå¤šé¡¹å¼åºåˆ—åœ¨å¼€åŒºé—´$(a,b)$ä¸Šå…³äºæƒå‡½æ•°$w(x)$æ­£äº¤ï¼Œå¦‚æœï¼š</p><script type="math/tex; mode=display">\int_a^bw(x)p_m(x)p_n(x)dx = h_n\delta_{mn}</script><blockquote><p>$\delta$ä¸ºç‹„å…‹æ‹‰å‡½æ•°ï¼Œä¸”$h_n$ä¸ºå¸¸æ•°<br>æƒå‡½æ•°$w(x)$åœ¨åŒºé—´$(a,b)$æ˜¯è¿ç»­ä¸”æ­£çš„,ä¸‹å¼å­˜åœ¨:</p><script type="math/tex; mode=display">\mu_n = \int_a^bw(x)x^ndx,n \in N^+</script></blockquote><p>åˆ™å¤šé¡¹å¼$f$å’Œå¤šé¡¹å¼$g$çš„å†…ç§¯å®šä¹‰ä¸ºï¼š</p><script type="math/tex; mode=display">\langle{f,g}\rangle = \int_a^bw(x)f(x)g(x)dx</script><p>åŒºé—´$(a,b)ç§°ä¸ºæ­£äº¤åŒºé—´ï¼Œæ­£äº¤åŒºé—´ä¸ä¸€å®šæ˜¯æœ‰é™åŒºé—´$</p><h3 id="e-g-ä¸‰è§’å‡½æ•°çš„æ­£äº¤æ€§"><a href="#e-g-ä¸‰è§’å‡½æ•°çš„æ­£äº¤æ€§" class="headerlink" title="e.g ä¸‰è§’å‡½æ•°çš„æ­£äº¤æ€§"></a>e.g ä¸‰è§’å‡½æ•°çš„æ­£äº¤æ€§</h3><blockquote><p>å¯¹äºä¸‰è§’å‡½æ•°åºåˆ—$1,sin(\theta),cos(\theta),sin(2\theta),cos(2\theta),â€¦,cos(n\theta)$ï¼Œ$n \in N^+$ï¼Œä»–ä»¬åœ¨åŒºé—´$(0,2\pi )$çš„æ­£äº¤æ€§ä¸ºï¼š</p><script type="math/tex; mode=display">\int_0^{2 \pi }sin(n \theta )cos(m \theta) d\theta = \delta_{mn}</script><p>å›¾ä¸­é˜´å½±éƒ¨åˆ†çš„é¢ç§¯åŠ ä¸Šç¬¦å·æ±‚å’Œä¸º0.<br><img src="/image/æ­£äº¤å¤šé¡¹å¼/1.webp" alt="1"></p></blockquote><h3 id="e-g-æ–½å¯†ç‰¹æ­£äº¤åŒ–"><a href="#e-g-æ–½å¯†ç‰¹æ­£äº¤åŒ–" class="headerlink" title="e.g æ–½å¯†ç‰¹æ­£äº¤åŒ–"></a>e.g æ–½å¯†ç‰¹æ­£äº¤åŒ–</h3><blockquote><p>æ–½å¯†ç‰¹æ­£äº¤åŒ–æ–¹æ³•æ˜¯å°†ä¸€ç»„çº¿æ€§æ— å…³çš„å‘é‡ç»„æ­£äº¤åŒ–çš„æ–¹æ³•ï¼Œå¯¹æ­£äº¤åŒ–åçš„å‘é‡ç»„è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œå¯è¿›ä¸€æ­¥å¾—åˆ°ä¸€ç»„æ ‡å‡†æ­£äº¤åŸºã€‚å¤„ç†æ­¥éª¤å¦‚ä¸‹</p><script type="math/tex; mode=display">\begin{array}{l} {\beta _1} = {\alpha _1} \\  {\beta _2} = {\alpha _2} - \frac{ {\left\langle { {\alpha _2},{\beta _1} } \right\rangle } }{ {\left\langle { {\beta _1},{\beta _1} } \right\rangle } }{\beta _1} \\   \cdots  \\  {\beta _n} = {\alpha _n} - \frac{ {\left\langle { {\alpha _n},{\beta _1} } \right\rangle } }{ {\left\langle { {\beta _1},{\beta _1} } \right\rangle } }{\beta _1} - \frac{ {\left\langle { {\alpha _n},{\beta _2} } \right\rangle } }{ {\left\langle { {\beta _2},{\beta _2} } \right\rangle } }{\beta _2} -  \cdots  - \frac{ {\left\langle { {\alpha _n},{\beta _{n - 1} } } \right\rangle } }{ {\left\langle { {\beta _{n - 1} },{\beta _{n - 1} } } \right\rangle } }{\beta _{n - 1} } \\  \end{array}</script><p>å°†ä¸‰ç»´ç©ºé—´ä¸­çš„ä¸€ç»„çº¿æ€§æ— å…³å‘é‡$a,b,c$ç”¨æ–½å¯†ç‰¹æ­£äº¤åŒ–æ–¹æ³•å¤„ç†å¾—åˆ°æ­£äº¤å‘é‡ç»„ $x,y,z$ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š</p><script type="math/tex; mode=display">\begin{array}{l} x = a \\  y = b - \frac{ {\left\langle {b,x} \right\rangle } }{ {\left\langle {x,x} \right\rangle } }x = \frac{ {\left| b \right|\cos (\theta )} }{ {\left| a \right|} }a \\  z = c - \frac{ {\left\langle {c,x} \right\rangle } }{ {\left\langle {x,x} \right\rangle } }x - \frac{ {\left\langle {c,y} \right\rangle } }{ {\left\langle {y,y} \right\rangle } }y \\ \end{array}</script><p>å‡ ä½•æè¿°å¦‚å›¾ï¼š<br><img src="/image/æ­£äº¤å¤šé¡¹å¼/2.webp" alt="2"></p></blockquote><h2 id="ç»å…¸æ­£äº¤å¤šé¡¹å¼"><a href="#ç»å…¸æ­£äº¤å¤šé¡¹å¼" class="headerlink" title="ç»å…¸æ­£äº¤å¤šé¡¹å¼"></a>ç»å…¸æ­£äº¤å¤šé¡¹å¼</h2><p>å¦‚é›…å…‹æ¯”å¤šé¡¹å¼ï¼Œåˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼ï¼Œå‹’è®©å¾·å¤šé¡¹å¼ï¼Œæ‹‰ç›–å°”å¤šé¡¹å¼ï¼Œä¼¯æ©æ–¯å¦å¤šé¡¹å¼ï¼Œçƒè°å¤šé¡¹å¼ç­‰</p><h3 id="é›…å…‹æ¯”å¤šé¡¹å¼"><a href="#é›…å…‹æ¯”å¤šé¡¹å¼" class="headerlink" title="é›…å…‹æ¯”å¤šé¡¹å¼"></a>é›…å…‹æ¯”å¤šé¡¹å¼</h3><p>é›…å…‹æ¯”å¤šé¡¹å¼æ˜¯å®šä¹‰åœ¨$(-1,1)$ä¸Šï¼Œå…³äºæƒå‡½æ•°$(1-x)^{\alpha} (1+x)^{\beta} $æ­£äº¤çš„å¤šé¡¹å¼ï¼Œå…¶ä¸­$\alpha ,\beta &gt; -1$<br>è¡¨è¾¾å¼ä¸ºï¼š</p><script type="math/tex; mode=display">P_n^{ (\alpha,\beta) } (x) = \frac{ \Gamma(\alpha+n+1) }{n!(\alpha+\beta+n+1)} \sum_{m=0}^n \begin{pmatrix} n \\ m \end{pmatrix} \frac{\Gamma(\alpha+\beta+n+m+1)}{\Gamma(\alpha+m+1)}{(\frac{x-1}{2})}^m</script><script type="math/tex; mode=display">\Gamma(\gamma) = \int_0^{+ \infty } t^{\gamma -1} e^{-t} dt</script><p>é›…å…‹æ¯”å¤šé¡¹å¼çš„æ­£äº¤æ€§ï¼š</p><script type="math/tex; mode=display">\begin{array}{l}\int_{ - 1}^1 { { {(1 - x)}^\alpha }{ {(1 + x)}^\beta }P_m^{(\alpha ,\beta )}(x)P_n^{(\alpha ,\beta )}(x)dx}  \\  = \frac{ { {2^{\alpha  + \beta  + 1} } } }{ {2n + \alpha  + \beta  + 1} }\frac{ {\Gamma (\alpha  + n + 1)\Gamma (\beta  + n + 1)} }{ {n!\Gamma (\alpha  + \beta  + n + 1)} }{\delta _{mn} } \\ \end{array}</script><h3 id="å‹’è®©å¾·å¤šé¡¹å¼"><a href="#å‹’è®©å¾·å¤šé¡¹å¼" class="headerlink" title="å‹’è®©å¾·å¤šé¡¹å¼"></a>å‹’è®©å¾·å¤šé¡¹å¼</h3><p>å‹’è®©å¾·å¤šé¡¹å¼æ˜¯å®šä¹‰åœ¨åŒºé—´ $(âˆ’1,1) $ä¸Šå…³äºæƒå‡½æ•°1æ­£äº¤çš„å¤šé¡¹å¼ã€‚å‹’è®©å¾·å¤šé¡¹å¼å®é™…ä¸Šæ˜¯é›…å…‹æ¯”å¤šé¡¹å¼åœ¨ $\alpha=\beta=0$ æ—¶çš„ç‰¹æ®Šæƒ…å†µ<br>è¡¨è¾¾å¼ä¸ºï¼š</p><script type="math/tex; mode=display">P_n(x) = \frac{1}{2^n n!} \frac{d^n}{dx^n} [ (x^2-1)^n ]</script><p>é€’æ¨å…¬å¼ä¸ºï¼š</p><script type="math/tex; mode=display">(n+1)P_{n+1}(x) = (2n+1)xP_n(x)-nP_{n-1}(x)</script><p>æ­£äº¤æ€§ï¼š</p><script type="math/tex; mode=display">\int_{-1}^1 P_m(x)P_n(x)dx = \frac{2}{2n+1}\delta_{mn}</script><p>å‰6é˜¶å‹’è®©å¾·å¤šé¡¹å¼ï¼š</p><script type="math/tex; mode=display">P_0(x) = 1</script><script type="math/tex; mode=display">P_1(x) = x</script><script type="math/tex; mode=display">{P_2}(x) = \frac{3}{2}{x^2} - \frac{1}{2}</script><script type="math/tex; mode=display">{P_3}(x) = \frac{5}{2}{x^3} - \frac{3}{2}x</script><script type="math/tex; mode=display">{P_4}(x) = \frac{ {35} }{8}{x^4} - \frac{ {15} }{4}{x^2} + \frac{3}{8}</script><script type="math/tex; mode=display">{P_5}(x) = \frac{ {63} }{8}{x^5} - \frac{ {35} }{4}{x^3} + \frac{ {15} }{8}x</script><script type="math/tex; mode=display">{P_6}(x) = \frac{ {231} }{ {16} }{x^6} - \frac{ {315} }{ {16} }{x^4} + \frac{ {105} }{ {16} }{x^2} - \frac{5}{ {16} }</script><p>å›¾åƒä¸ºï¼š<br><img src="/image/æ­£äº¤å¤šé¡¹å¼/3.webp" alt="3"></p><h3 id="åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼"><a href="#åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼" class="headerlink" title="åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼"></a>åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼</h3><p>åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼æ˜¯å®šä¹‰åœ¨åŒºé—´ $(âˆ’1,1)$ ä¸Šå…³äºæƒå‡½æ•° $\frac{1}{\sqrt{1-x^2} }$ æ­£äº¤çš„å¤šé¡¹å¼</p><h4 id="ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼"><a href="#ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼" class="headerlink" title="ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼"></a>ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼</h4><script type="math/tex; mode=display">T_n(x) = cos(n\theta)</script><p>ä»¤$x = cos(\theta)$ï¼Œåˆ™$T_n(x) = cos(n \arccos(x))$ï¼Œ<br>ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼æ­£äº¤æ€§ï¼š</p><script type="math/tex; mode=display">\int_{-1}^1 \frac{1}{\sqrt{1-x^2} } T_m(x) T_n(x)dx = \begin{cases}0 \quad m \neq n \\ \pi \quad n=m=0 \\ \frac{\pi}{2} \quad n=m \neq 0 \end{cases}</script><p>ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼é€’æ¨å…¬å¼ï¼š</p><script type="math/tex; mode=display">{T_{n + 1} }(x) = 2x{T_n}(x) - {T_{n - 1} }(x)</script><p>ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼çš„å‰6é¡¹ï¼š</p><script type="math/tex; mode=display">T_0(x) = 1</script><script type="math/tex; mode=display">T_1(x) = x</script><script type="math/tex; mode=display">T_2(x) = 2x^2-1</script><script type="math/tex; mode=display">T_3(x) = 4x^3-3x</script><script type="math/tex; mode=display">T_4(x) = 8x^4-8x^2+1</script><script type="math/tex; mode=display">T_5(x) = 16x^5-20x^3+5x</script><script type="math/tex; mode=display">T_6(x) = 32x^6-48x^4+18x^2-1</script><p>ç¬¬ä¸€ç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å›¾åƒï¼š<br><img src="/image/æ­£äº¤å¤šé¡¹å¼/4.svg" alt="4"></p><h4 id="ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼"><a href="#ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼" class="headerlink" title="ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼"></a>ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼</h4><script type="math/tex; mode=display">{T_n}(x) = \frac{ {\sin [(n + 1)\theta ]} } { {\sin \theta } }</script><p>ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼çš„æ­£äº¤ä¸ºï¼š</p><script type="math/tex; mode=display">\int_{-1}^1 \sqrt{1-x^2}{T_m}(x){T_n}(x)dx=\begin{cases}0 \quad m\neq n \\ \frac{\pi}{2} \quad m = n \end{cases}</script><p>ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼çš„é€’æ¨å…¬å¼ï¼š</p><script type="math/tex; mode=display">{T_{n + 1} }(x) = 2x{T_n}(x) - {T_{n - 1} }(x)</script><p>ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼çš„å‰6é¡¹ï¼š</p><script type="math/tex; mode=display">T_0(x) = 1</script><script type="math/tex; mode=display">T_1(x) = 2x</script><script type="math/tex; mode=display">T_2(x) = 4x^2-1</script><script type="math/tex; mode=display">T_3(x) = 8x^3-4x</script><script type="math/tex; mode=display">T_4(x) = 16x^4-12x^2+1</script><script type="math/tex; mode=display">T_5(x) = 32x^5-32x^3+6x</script><script type="math/tex; mode=display">T_6(x) = 64x^6-80x^4+24x^2-1</script><p>ç¬¬äºŒç±»åˆ‡æ¯”é›ªå¤«å¤šé¡¹å›¾åƒï¼š<br><img src="/image/æ­£äº¤å¤šé¡¹å¼/5.webp" alt="5"></p><h3 id="æ‹‰ç›–å°”å¤šé¡¹å¼"><a href="#æ‹‰ç›–å°”å¤šé¡¹å¼" class="headerlink" title="æ‹‰ç›–å°”å¤šé¡¹å¼"></a>æ‹‰ç›–å°”å¤šé¡¹å¼</h3><p>æ‹‰ç›–å°”å¤šé¡¹å¼æ˜¯å®šä¹‰åœ¨åŒºé—´ $(0,+\infty)$ ä¸Šå…³äºæƒå‡½æ•° $e^{-x}x^a$ æ­£äº¤çš„å¤šé¡¹å¼<br>æ‹‰ç›–å°”å¤šé¡¹å¼çš„æ­£äº¤å…³ç³»ï¼š</p><script type="math/tex; mode=display">\int_0^{ + \infty } { {x^\alpha }{e^{ - x} }L_m^{(\alpha )}(x)L_n^{(\alpha )}(x)dx}  = \frac{ {\left( {n + \alpha } \right)!} }{ {n!} }{\delta _{mn} }</script><p>æ‹‰ç›–å°”å¤šé¡¹å¼çš„é€’æ¨å…³ç³»ï¼š</p><script type="math/tex; mode=display">{L_{n + 1} }(x) = \frac{ {(2n + 1 - x){L_n}(x) - n{L_{n - 1} }(x)} }{ {n + 1} }</script><p>å‰6é¡¹æ‹‰ç›–å°”å¤šé¡¹å¼$(\alpha = 0)$ï¼š</p><script type="math/tex; mode=display">L_0(x) = 1</script><script type="math/tex; mode=display">L_1(x) = -x+1</script><script type="math/tex; mode=display">L_2(x) = \frac{1}{2}x^2-2x+1</script><script type="math/tex; mode=display">L_3(x) = -\frac{1}{6}x^3+\frac{3}{2}x^2-3x+1</script><script type="math/tex; mode=display">L_4(x) = \frac{1}{24}x^4-\frac{2}{3}x^3+3x^2-4x+1</script><script type="math/tex; mode=display">L_5(x) = -\frac{1}{120}x^5+\frac{5}{24}x^4-\frac{5}{3}x^3+5x^2-5x+1</script><script type="math/tex; mode=display">L_6(x) = \frac{1}{720}x^6-\frac{1}{20}x^5+\frac{5}{8}x^4-\frac{10}{3}x^3+\frac{15}{2}x^2-6x+1</script><p>å‰6é¡¹æ‹‰ç›–å°”å¤šé¡¹å¼çš„å›¾åƒï¼š<br><img src="/image/æ­£äº¤å¤šé¡¹å¼/6.webp" alt="6"></p><h3 id="åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼"><a href="#åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼" class="headerlink" title="åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼"></a>åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼</h3><p>åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼æ˜¯å®šä¹‰åœ¨åŒºé—´$(-\infty,+\infty)$ä¸Šå…³äºæƒå‡½æ•°$e^{x^2}$æ­£äº¤çš„å¤šé¡¹å¼<br>åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼åˆ†ä¸ºæ¦‚ç‡è®ºä¸­çš„åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼å’Œç‰©ç†ä¸­çš„åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼ï¼Œæ¦‚ç‡è®ºçš„åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼æ˜¯é¦–ä¸€å¤šé¡¹å¼ï¼ˆæœ€é«˜æ¬¡é¡¹ç³»æ•°ç­‰äº1ï¼‰ï¼Œè€Œç‰©ç†å­¦çš„åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼çš„æœ€é«˜æ¬¡é¡¹ç³»æ•°ç­‰äº$2n$ï¼Œè¿™é‡Œåªä»‹ç»ç‰©ç†å­¦ä¸­ä½¿ç”¨çš„åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼<br>åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼çš„è¡¨è¾¾å¼ä¸ºï¼š</p><script type="math/tex; mode=display">H_n(x) = (-1)^n e^{x^2} \frac{d^n}{dx^n}e^{-x^2}</script><p>åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼çš„æ­£äº¤æ€§ï¼š</p><script type="math/tex; mode=display">\int_{-\infty}^{+\infty} H_m(x)H_n(x)e^{-x^2}dx = \sqrt{\pi}2^n n! \delta_{mn}</script><p>åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼çš„é€’æ¨å…¬å¼ï¼š</p><script type="math/tex; mode=display">H_{n+1}(x) = 2xH_n(x)-2nH_{n-1}(x)</script><p>å‰6é¡¹åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼ä¸ºï¼š</p><script type="math/tex; mode=display">H_0(x) = 1</script><script type="math/tex; mode=display">H_1(x) = 2x</script><script type="math/tex; mode=display">H_2(x) = 4x^2-2</script><script type="math/tex; mode=display">H_3(x) = $8x^3-12x</script><script type="math/tex; mode=display">H_4(x) = 16x^4-48x^2+12</script><script type="math/tex; mode=display">H_5(x) = 32x^5-160x^3+120x</script><script type="math/tex; mode=display">H_6(x) = 64x^6-480x^4+720x^2-120</script><p>å‰6é¡¹åŸƒå°”ç±³ç‰¹å¤šé¡¹å¼å›¾åƒï¼š<br><img src="/image/æ­£äº¤å¤šé¡¹å¼/7.webp" alt="7"></p><h3 id="æ­£äº¤å¤šé¡¹å¼çš„åº”ç”¨"><a href="#æ­£äº¤å¤šé¡¹å¼çš„åº”ç”¨" class="headerlink" title="æ­£äº¤å¤šé¡¹å¼çš„åº”ç”¨"></a>æ­£äº¤å¤šé¡¹å¼çš„åº”ç”¨</h3><p>ä»…ä»¥ä¸€ä¸ªå°çš„ä¾‹å­æ¥è¯´æ˜æ­£äº¤å¤šé¡¹å¼åœ¨å‡½æ•°æ‹Ÿåˆä¸­çš„åº”ç”¨<br>å®éªŒä¸­ä½¿ç”¨çš„æµ‹è¯•å‡½æ•°ä¸º $y=4x+3x^2+cos(x)+sin(2x)+e^x$ï¼Œå®šä¹‰åŒºé—´ä¸º $(âˆ’2,2)$ ï¼Œå®éªŒæ¯”è¾ƒäº†å¤šé¡¹å¼å±•å¼€3é¡¹æ—¶ä¸åŒå¤šé¡¹å¼çš„æ‹Ÿåˆå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œå½’ä¸€åŒ–<a href="![8](/image/æ­£äº¤å¤šé¡¹å¼/8.svg">å‡æ–¹è¯¯å·®</a></p><p><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">è¾“å‡º</summary><pre><code class="matlab">MSE_power =    0.0131NMSE_power =    0.0419MSE_legendre =    0.0131NMSE_legendre =    0.0419MSE_chebyshev =    0.0131NMSE_chebyshev =    0.0419MSE_laguerre =    0.0131NMSE_laguerre =    0.0419MSE_hermite =    0.0067NMSE_hermite =    0.0215</code></pre></details><br>å¯ä»¥çœ‹å‡ºåŸƒå°”ç±³ç‰¹çš„æ‹Ÿåˆè¯¯å·®è¾ƒå°ï¼Œå…¶ä»–ç›¸å½“<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% æ­£äº¤å¤šé¡¹å¼æµ‹è¯•</span></span><br><span class="line">clear</span><br><span class="line">clc</span><br><span class="line"><span class="comment">% é‡‡æ ·ç‚¹æ•°</span></span><br><span class="line">N = <span class="number">1000</span> ; </span><br><span class="line"><span class="comment">% æ­£äº¤å¤šé¡¹å¼é˜¶æ•°</span></span><br><span class="line">M = <span class="number">3</span> ;   </span><br><span class="line"><span class="comment">% æ‹Ÿåˆå‡½æ•°åŒºé—´ä¸ºï¼ˆ-2,2ï¼‰</span></span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">-2</span>,<span class="number">2</span>,N)&#x27; ; </span><br><span class="line"><span class="comment">% ç”Ÿæˆè¢«æ‹Ÿåˆçš„å‡½æ•°ï¼ŒåŒ…æ‹¬æŒ‡æ•°å‡½æ•°ï¼Œä½™å¼¦å‡½æ•°ï¼Œå¹‚å‡½æ•°æˆåˆ†</span></span><br><span class="line">y =  <span class="number">4</span>*x + <span class="number">3</span>*x.^<span class="number">2</span> + <span class="built_in">cos</span>(x) + <span class="built_in">exp</span>(x) + <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line"> </span><br><span class="line"><span class="comment">% ç”Ÿæˆå¹‚çº§æ•°ç»„æˆçš„åŸºçŸ©é˜µ</span></span><br><span class="line">P1 = power_p(x,M) ;</span><br><span class="line"><span class="comment">% ç”Ÿæˆå‹’è®©å¾·å¤šé¡¹å¼ç»„æˆçš„åŸºçŸ©é˜µ</span></span><br><span class="line">P2 = legendre_p(N,M) ;</span><br><span class="line"><span class="comment">% ç”Ÿæˆåˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼ç»„æˆçš„åŸºçŸ©é˜µ</span></span><br><span class="line">P3 = chebyshev_p(N,M) ;</span><br><span class="line"><span class="comment">% ç”Ÿæˆæ‹‰ç›–å°”å¤šé¡¹å¼ç»„æˆçš„åŸºçŸ©é˜µ</span></span><br><span class="line">P4 = laguerre_p(N,M) ;</span><br><span class="line"><span class="comment">% ç”Ÿæˆè¯¶å°”ç±³ç‰¹å¤šé¡¹å¼ç»„æˆçš„åŸºçŸ©é˜µ</span></span><br><span class="line">P5 = hermite_p(N,M) ;</span><br><span class="line"> </span><br><span class="line"><span class="comment">%% ç”¨æœ€å°äºŒä¹˜æ‹Ÿåˆy</span></span><br><span class="line"><span class="comment">% c1å¯¹åº”å¹‚çº§æ•°ç³»æ•°</span></span><br><span class="line">c1 = P1\y ;</span><br><span class="line"><span class="comment">% c2å¯¹åº”å‹’è®©å¾·ç³»æ•°</span></span><br><span class="line">c2 = P2\y ;</span><br><span class="line"><span class="comment">% c3å¯¹åº”åˆ‡æ¯”é›ªå¤«ç³»æ•°</span></span><br><span class="line">c3 = P3\y ;</span><br><span class="line"><span class="comment">% c4å¯¹åº”æ‹‰ç›–å°”ç³»æ•°</span></span><br><span class="line">c4 = P4\y ;</span><br><span class="line"><span class="comment">% c5å¯¹åº”åŸƒå°”ç±³ç‰¹ç³»æ•°</span></span><br><span class="line">c5 = P5\y ;</span><br><span class="line"> </span><br><span class="line"><span class="comment">%% æ±‚MSEå’ŒNMSE</span></span><br><span class="line">MSE_power = norm(y-P1*c1)/N </span><br><span class="line">NMSE_power = norm(y-P1*c1)/norm(y) </span><br><span class="line"> </span><br><span class="line">MSE_legendre = norm(y-P2*c2)/N </span><br><span class="line">NMSE_legendre = norm(y-P2*c2)/norm(y) </span><br><span class="line"> </span><br><span class="line">MSE_chebyshev = norm(y-P3*c3)/N </span><br><span class="line">NMSE_chebyshev = norm(y-P3*c3)/norm(y) </span><br><span class="line"> </span><br><span class="line">MSE_laguerre = norm(y-P4*c4)/N </span><br><span class="line">NMSE_laguerre = norm(y-P4*c4)/norm(y) </span><br><span class="line"> </span><br><span class="line">MSE_hermite = norm(y-P5*c5)/N </span><br><span class="line">NMSE_hermite = norm(y-P5*c5)/norm(y) </span><br><span class="line"> </span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">plot</span>(x,y,<span class="string">&#x27;r-&#x27;</span>,x,P1*c1,<span class="string">&#x27;b-&#x27;</span>,x,P2*c2,<span class="string">&#x27;k-&#x27;</span>,x,P3*c3,<span class="string">&#x27;y-&#x27;</span>,x,P4*c4,<span class="string">&#x27;g-&#x27;</span>,x,P5*c5,<span class="string">&#x27;m-&#x27;</span>)</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;original&#x27;</span>,<span class="string">&#x27;power&#x27;</span>,<span class="string">&#x27;legendre&#x27;</span>,<span class="string">&#x27;chebyshev&#x27;</span>,<span class="string">&#x27;laguerre&#x27;</span>,<span class="string">&#x27;hermite&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[P]</span> = <span class="title">power_p</span><span class="params">(x,M)</span></span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> m = <span class="number">1</span>:M</span><br><span class="line">    P(:,m) = x.^(m<span class="number">-1</span>) ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[P]</span> = <span class="title">legendre_p</span><span class="params">(N,NN)</span></span></span><br><span class="line"><span class="comment">% æœ¬å‡½æ•°ç”ŸæˆN*Mçš„å‹’è®©å¾·åŸºçŸ©é˜µ</span></span><br><span class="line">s = <span class="built_in">linspace</span>(<span class="number">-1</span>,<span class="number">1</span>,N)&#x27; ;</span><br><span class="line">P = <span class="built_in">zeros</span>(N,NN) ;</span><br><span class="line">P(:,<span class="number">1</span>) = <span class="built_in">ones</span>(N,<span class="number">1</span>) ;</span><br><span class="line">P(:,<span class="number">2</span>) = s ;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">3</span> : NN</span><br><span class="line">    P(:,n) = ((<span class="number">2</span> * n - <span class="number">3</span>) * s .* P(:,n - <span class="number">1</span>) - (n - <span class="number">2</span>) * P(:,n - <span class="number">2</span>)) / ( n <span class="number">-1</span> ) ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[P]</span> = <span class="title">chebyshev_p</span><span class="params">(N,M)</span></span></span><br><span class="line"><span class="comment">% æœ¬å‡½æ•°ç”ŸæˆN*Mçš„åˆ‡æ¯”é›ªå¤«åŸºçŸ©é˜µ</span></span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">-1</span>,<span class="number">1</span>,N)&#x27; ;</span><br><span class="line">P = <span class="built_in">zeros</span>(N,M) ;</span><br><span class="line">P(:,<span class="number">1</span>) = <span class="built_in">ones</span>(N,<span class="number">1</span>) ;</span><br><span class="line">P(:,<span class="number">2</span>) = x ;</span><br><span class="line"><span class="keyword">for</span> k = <span class="number">3</span>:M</span><br><span class="line">    P(:,k) = <span class="number">2</span>*x.*P(:,k<span class="number">-1</span>) - P(:,k<span class="number">-2</span>) ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[P]</span> = <span class="title">laguerre_p</span><span class="params">(N,M)</span></span></span><br><span class="line"><span class="comment">% æœ¬å‡½æ•°ç”ŸæˆN*Mçš„æ‹‰ç›–å°”åŸºçŸ©é˜µ</span></span><br><span class="line">x  = <span class="built_in">linspace</span>(<span class="number">-2</span>,<span class="number">2</span>,N)&#x27; ;</span><br><span class="line">P = <span class="built_in">zeros</span>(N,M) ;</span><br><span class="line">P(:,<span class="number">1</span>) = <span class="built_in">ones</span>(N,<span class="number">1</span>) ;</span><br><span class="line">P(:,<span class="number">2</span>) = -x + <span class="built_in">ones</span>(N,<span class="number">1</span>) ;</span><br><span class="line"><span class="keyword">for</span> m = <span class="number">3</span>:M</span><br><span class="line">    P(:,m) = ((<span class="number">2</span>*(m<span class="number">-2</span>)+<span class="number">1</span>-x).*P(:,m<span class="number">-1</span>)-(m<span class="number">-2</span>)*P(:,m<span class="number">-2</span>))./(m<span class="number">-1</span>) ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[P]</span> = <span class="title">hermite_p</span><span class="params">(N,M)</span> </span></span><br><span class="line"><span class="comment">% æœ¬å‡½æ•°ç”ŸæˆN*Mçš„åŸƒå°”ç±³ç‰¹åŸºçŸ©é˜µ</span></span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">-2</span>,<span class="number">2</span>,N)&#x27; ;</span><br><span class="line">P = <span class="built_in">zeros</span>(N,M) ;</span><br><span class="line">P(:,<span class="number">1</span>) = <span class="built_in">ones</span>(N,<span class="number">1</span>) ;</span><br><span class="line">P(:,<span class="number">2</span>) = <span class="number">2</span>*x ;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> m = <span class="number">2</span>:M</span><br><span class="line">    P(:,m+<span class="number">1</span>) = <span class="number">2</span>*x.*P(:,m-) - <span class="number">2</span>*(m<span class="number">-1</span>)*P(:,m<span class="number">-1</span>) ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> æ•°å€¼åˆ†æ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> çŸ¥è¯†ç‚¹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä¼½é©¬å‡½æ•°</title>
      <link href="/p/7d2c710d/"/>
      <url>/p/7d2c710d/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>é‡åˆ°äº†è¿™ä¸ªä¼½é©¬å‡½æ•°ï¼Œ è®¸å¤šåšå®¢è¯´å¯¹è€ƒç ”å¾ˆé‡è¦ï¼Œå°±æµ…æµ…è®°å½•ä¸€ä¸‹</p><span id="more"></span><h2 id="å®šä¹‰"><a href="#å®šä¹‰" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h2><p>åœ¨æ•°å­¦ä¸­ï¼Œ$\Gamma$å‡½æ•°ï¼ˆä¼½ç›å‡½æ•°ï¼›Gammaå‡½æ•°ï¼‰ï¼Œæ˜¯é˜¶ä¹˜å‡½æ•°åœ¨å®æ•°ä¸å¤æ•°åŸŸä¸Šçš„æ‰©å±•ã€‚å¦‚æœ$n$ä¸ºæ­£æ•´æ•°ï¼Œåˆ™ï¼š</p><script type="math/tex; mode=display">\Gamma (n) = (n-1)!</script><p>å¯¹äºå®æ•°éƒ¨åˆ†ä¸ºæ­£çš„å¤æ•°$\alpha$ï¼Œä¼½ç›å‡½æ•°ä¸ºï¼š</p><script type="math/tex; mode=display">\Gamma(\alpha) = \int_0^{+\infty} x^{\alpha-1}e^{-x}dx(a>0)</script><script type="math/tex; mode=display">\Gamma(\alpha+1) = \alpha \Gamma(\alpha)</script><h2 id="å¸¸ç”¨çš„æ•°å€¼"><a href="#å¸¸ç”¨çš„æ•°å€¼" class="headerlink" title="å¸¸ç”¨çš„æ•°å€¼"></a>å¸¸ç”¨çš„æ•°å€¼</h2><script type="math/tex; mode=display">\Gamma(1) = 1</script><script type="math/tex; mode=display">\Gamma(\frac{1}{2}) = \sqrt{\pi}</script><script type="math/tex; mode=display">\Gamma(n+1) = n!</script>]]></content>
      
      
      <categories>
          
          <category> æ•°å­¦ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> çŸ¥è¯†ç‚¹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>matlabç”»å›¾åŠŸèƒ½å†æ¢</title>
      <link href="/p/1d9b66c4/"/>
      <url>/p/1d9b66c4/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>å¤ä¹ äº†ä¸€ä¸‹ matlab é‡Œé¢çš„åŸºæœ¬ç”»å›¾å‡½æ•°çš„å±æ€§</p><span id="more"></span><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">close all;</span><br><span class="line">th = <span class="built_in">linspace</span>()<span class="number">0</span>,<span class="number">2</span>*<span class="built_in">pi</span>;</span><br><span class="line">fig1 = <span class="built_in">plot</span>(th,<span class="built_in">sin</span>(th),<span class="string">&#x27;g&#x27;</span>,th,<span class="built_in">cos</span>(th),<span class="string">&#x27;b:&#x27;</span>);</span><br></pre></td></tr></table></figure><p><img src="/image/matlabä½¿ç”¨æ–¹æ³•å†æ¢/1.svg" alt="1"></p><p>plot å‘½ä»¤è¿”å›ä¸€ä¸ªæ ‡è¯†å›¾å½¢ç›®æ ‡çš„å‘é‡ï¼Œå…¶å…ƒç´ ç§°ä¸ºå¥æŸ„ï¼Œè¿™äº›å¥æŸ„å¯ä»¥ç¡®å®šç›®æ ‡çš„ç‰¹æ€§.è‹¥æƒ³çŸ¥é“ç¬¬ä¸€æ¡æ›²çº¿çš„ç‰¹æ€§ï¼Œè¾“å…¥<code>get(fig1(1))</code>ï¼Œä¸è¦å…³é—­Figure 1çª—å£.</p><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">è¾“å‡º</summary><pre><code class="matlab">    AlignVertexCenters: off            Annotation: [1Ã—1 matlab.graphics.eventdata.Annotation]          BeingDeleted: off            BusyAction: 'queue'         ButtonDownFcn: ''              Children: [0Ã—0 GraphicsPlaceholder]              Clipping: on                 Color: [0 1 0]             ColorMode: 'manual'           ContextMenu: [0Ã—0 GraphicsPlaceholder]             CreateFcn: ''       DataTipTemplate: [1Ã—1 matlab.graphics.datatip.DataTipTemplate]             DeleteFcn: ''           DisplayName: ''      HandleVisibility: 'on'               HitTest: on         Interruptible: on              LineJoin: 'round'             LineStyle: '-'         LineStyleMode: 'auto'             LineWidth: 0.5000                Marker: 'none'       MarkerEdgeColor: 'auto'       MarkerFaceColor: 'none'         MarkerIndices: [1Ã—100 uint64]            MarkerMode: 'auto'            MarkerSize: 6                Parent: [1Ã—1 Axes]         PickableParts: 'visible'              Selected: off    SelectionHighlight: on           SeriesIndex: 1                   Tag: ''                  Type: 'line'              UserData: []               Visible: on                 XData: [1Ã—100 double]             XDataMode: 'manual'           XDataSource: ''                 YData: [1Ã—100 double]           YDataSource: ''                 ZData: [1Ã—0 double]           ZDataSource: ''</code></pre></details><p>è‹¥æƒ³äº†è§£ç¬¬äºŒç¬¬æ›²çº¿çš„ç‰¹æ€§ï¼Œè¾“å…¥<code>get(fig1(2))</code>ï¼Œä¸è¦å…³é—­Figure 1çª—å£.</p><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">è¾“å‡º</summary><pre><code class="matlab">    AlignVertexCenters: off            Annotation: [1Ã—1 matlab.graphics.eventdata.Annotation]          BeingDeleted: off            BusyAction: 'queue'         ButtonDownFcn: ''              Children: [0Ã—0 GraphicsPlaceholder]              Clipping: on                 Color: [0 0 1]             ColorMode: 'manual'           ContextMenu: [0Ã—0 GraphicsPlaceholder]             CreateFcn: ''       DataTipTemplate: [1Ã—1 matlab.graphics.datatip.DataTipTemplate]             DeleteFcn: ''           DisplayName: ''      HandleVisibility: 'on'               HitTest: on         Interruptible: on              LineJoin: 'round'             LineStyle: ':'         LineStyleMode: 'manual'             LineWidth: 0.5000                Marker: 'none'       MarkerEdgeColor: 'auto'       MarkerFaceColor: 'none'         MarkerIndices: [1Ã—100 uint64]            MarkerMode: 'manual'            MarkerSize: 6                Parent: [1Ã—1 Axes]         PickableParts: 'visible'              Selected: off    SelectionHighlight: on           SeriesIndex: 2                   Tag: ''                  Type: 'line'              UserData: []               Visible: on                 XData: [1Ã—100 double]             XDataMode: 'manual'           XDataSource: ''                 YData: [1Ã—100 double]           YDataSource: ''                 ZData: [1Ã—0 double]           ZDataSource: ''</code></pre></details><p>å¯¹äºå›¾å½¢æœ¬èº«ï¼Œç”±äºæ˜¯ç¬¬ä¸€çš„å›¾å½¢ï¼Œæ‰€ä»¥å¥æŸ„æ˜¯1ï¼Œè¾“å…¥<code>get(1)</code></p><details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">è¾“å‡º</summary><pre><code class="matlab">                 Alphamap: [1Ã—64 double]             BeingDeleted: off               BusyAction: 'queue'            ButtonDownFcn: ''                 Children: [1Ã—1 Axes]                 Clipping: on          CloseRequestFcn: 'closereq'                    Color: [0.9400 0.9400 0.9400]                 Colormap: [256Ã—3 double]              ContextMenu: [0Ã—0 GraphicsPlaceholder]                CreateFcn: ''              CurrentAxes: [1Ã—1 Axes]         CurrentCharacter: ''            CurrentObject: [1Ã—1 Line]             CurrentPoint: [408 289]                DeleteFcn: ''             DockControls: on                 FileName: '/home/pacaep/aepBlog/source/image/plotä½¿ç”¨æ–¹æ³•å†æ¢/1.svg'        GraphicsSmoothing: on         HandleVisibility: 'on'                     Icon: ''            InnerPosition: [200 200 600 472]            IntegerHandle: on            Interruptible: on           InvertHardcopy: on              KeyPressFcn: ''            KeyReleaseFcn: ''                  MenuBar: 'figure'                     Name: ''                 NextPlot: 'add'                   Number: 1              NumberTitle: on            OuterPosition: [200 200 600 557]         PaperOrientation: 'portrait'            PaperPosition: [1.1250 3.0417 6.2500 4.9167]        PaperPositionMode: 'auto'                PaperSize: [8.5000 11]                PaperType: 'usletter'               PaperUnits: 'inches'                   Parent: [1Ã—1 Root]                  Pointer: 'arrow'        PointerShapeCData: [16Ã—16 double]      PointerShapeHotSpot: [8 8]                 Position: [200 200 600 472]                 Renderer: 'opengl'             RendererMode: 'auto'                   Resize: on               Scrollable: off            SelectionType: 'alt'           SizeChangedFcn: ''                      Tag: ''                  ToolBar: 'auto'                     Type: 'figure'                    Units: 'pixels'                 UserData: []                  Visible: on      WindowButtonDownFcn: ''    WindowButtonMotionFcn: ''        WindowButtonUpFcn: ''        WindowKeyPressFcn: ''      WindowKeyReleaseFcn: ''     WindowScrollWheelFcn: ''              WindowState: 'normal'              WindowStyle: 'normal'                 XDisplay: ':0'</code></pre></details>ä¸ºäº†è§£å›¾å½¢çª—å£çš„è®¾ç½®ï¼Œè¾“å…¥`set(1)``set(H,Name,Value)` ä¸º H æ ‡è¯†çš„å¯¹è±¡æŒ‡å®šå…¶ Name å±æ€§çš„å€¼ä»å›¾åƒä¸­åˆ å»ä½™å¼¦æ›²çº¿ï¼Œè¾“å…¥`delete(fig1(2))``refresh`å‘½ä»¤å¯ä»¥åˆ·æ–°å›¾åƒ.å»ºç«‹ä¸€ä¸ªæ–°çš„å›¾å½¢çª—å£ï¼Œä¿ç•™å‰ä¸€ä¸ªå›¾å½¢çª—å£ï¼Œè¾“å…¥`H=figure`ï¼Œå°†æ‰“å¼€æ–°çš„å›¾å½¢çª—å£å¹¶è®¾å®šä¸ºæ´»åŠ¨ï¼Œè¾“å…¥`gcf`è·å¾—å½“å‰å›¾å½¢çš„å¥æŸ„.<details class="custom-block details" style="display: block; position: relative; border-radius: 2px; margin: 1.6em 0px; padding: 1.6em; background-color: rgb(238, 238, 238); color: rgb(44, 62, 80); font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Oxygen, Ubuntu, Cantarell, &quot;Fira Sans&quot;, &quot;Droid Sans&quot;, &quot;Helvetica Neue&quot;, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><summary style="outline: none; cursor: pointer;">è¾“å‡º</summary><pre><code class="matlab">  Figure (2) - å±æ€§:      Number: 2        Name: ''       Color: [0.9400 0.9400 0.9400]    Position: [200 200 600 472]       Units: 'pixels'</code></pre></details>]]></content>
      
      
      <categories>
          
          <category> ä½¿ç”¨æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ‹‰æ ¼æœ—æ—¥æ’å€¼å¤šé¡¹å¼</title>
      <link href="/p/b8ab2279/"/>
      <url>/p/b8ab2279/</url>
      
        <content type="html"><![CDATA[<h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><p>åœ¨æ•°å€¼åˆ†æä¸­ï¼Œå¤šé¡¹å¼æ’å€¼æ˜¯æœ€å¸¸æåˆ°çš„å†…å®¹</p><span id="more"></span><h2 id="å¤šé¡¹å¼æ’å€¼"><a href="#å¤šé¡¹å¼æ’å€¼" class="headerlink" title="å¤šé¡¹å¼æ’å€¼"></a>å¤šé¡¹å¼æ’å€¼</h2><h3 id="å®šä¹‰"><a href="#å®šä¹‰" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h3><blockquote><p> ç»™å®šæœ‰åºç‚¹é›† ${x_0,x_1,\cdots,x_n}$ ä¸” $x_0 \lt x_1\lt \cdots\lt x_n$ ä»¥åŠå®šä¹‰åœ¨ $x_0,x_n$ ä¸Šçš„è¿ç»­å‡½æ•°$f(x)$æˆ–å¯¹åº”äº $x$ å€¼çš„ $y$ å€¼é›†åˆ $y_0,y_1,\cdots,y_n$ (å³ $(x_i,y_i)$) å¯¹.<br>å¤šé¡¹å¼æ’å€¼å°±æ˜¯è¦æ±‚å‡ºå¯¹æ•°æ® $(x_0,y_0),(x_1,y_1),\cdots,(x_n,y_n)$ è¿›è¡Œæ’å€¼çš„æ¬¡æ•°æœ€å¤šä¸º $n$ çš„å¤šé¡¹å¼ $p(x)$ ,å³</p><script type="math/tex; mode=display">y_0 = p(x_0)</script><script type="math/tex; mode=display">y_1 = p(x_1)</script><script type="math/tex; mode=display">\vdots</script><script type="math/tex; mode=display">y_n = p(x_n)</script><p> ç§° $p$ åœ¨ ${x_0,x_1,\cdots,x_n}$ ä¸Šæ’å€¼ $f$ ï¼Œä¸” $p$ æ˜¯æ’å€¼. æ’å€¼å¿…é¡»åœ¨ç›¸åº”ç‚¹ ${x_0,x_1,\cdots,x_n}$ ä¸Šä¸å‡½æ•° $f$ æˆ–  $y_0,y_1,\cdots,y_n$ å–å€¼ç›¸åŒï¼Œè¿™äº›ç‚¹é€šå¸¸ç§°ä¸ºèŠ‚ç‚¹(æˆ–åˆ†å‰²ç‚¹).<br> åˆ™æ’å€¼å¤šé¡¹å¼ä¸º</p><script type="math/tex; mode=display">p(x) = a_n x^n + a_n-1 x^n-1 + \cdots + a_1 x + a_0</script><p> æ’å€¼æ¡ä»¶ä¸º</p><script type="math/tex; mode=display">a_n x_0^n + a_n-1 x_0^n-1 + \cdots +a_1 x_0 + a_0 = y_0</script><script type="math/tex; mode=display">a_n x_1^n + a_n-1 x_1^n-1 + \cdots +a_1 x_1 + a_0 = y_1</script><script type="math/tex; mode=display">\vdots</script><script type="math/tex; mode=display">a_n x_n^n + a_n-1 x_n^n-1 + \cdots +a_1 x_n + a_0 = y_n</script><p> å…¶ä¸­çŸ©é˜µ</p><script type="math/tex; mode=display">V = \begin{bmatrix}1&x_0 &x_0^2 & \cdots & x_0^n \\1&x_1 &x_1^2 & \cdots & x_1^n \\ 1&x_2 &x_2^2 & \cdots & x_2^n \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1&x_n &x_n^2 & \cdots & x_n^n \end{bmatrix}</script><p> ç”± $x$ æ„æˆï¼Œå½¢å¦‚ $V$ çš„çŸ©é˜µç§°ä¸º $Vandermonde$ çŸ©é˜µï¼Œå¦‚æœ $x_i$ äº’å¼‚ï¼Œåˆ™ $Vandermonde$ çŸ©é˜µéå¥‡å¼‚ï¼Œå› æ­¤å¤šé¡¹å¼æ’å€¼å­˜åœ¨ä¸”å”¯ä¸€. æ’å€¼å¤šé¡¹å¼çš„ç³»æ•°ç”±æ–¹ç¨‹</p><script type="math/tex; mode=display">V \begin{bmatrix} a_0 \\ a_1 \\ \vdots \\ a_n\end{bmatrix} = \begin{bmatrix} y_0 \\ y_1 \\ \vdots \\ y_n\end{bmatrix}</script><p> çš„è§£ç»™å‡ºï¼Œå¯ä»¥é‡‡ç”¨Vandermondeæ–¹ç¨‹ç»„çš„ä¸“é—¨è§£æ³•è§£å‡º.</p></blockquote><h3 id="ä¾‹é¢˜"><a href="#ä¾‹é¢˜" class="headerlink" title="ä¾‹é¢˜"></a>ä¾‹é¢˜</h3><blockquote><p>å¯¹æ­£å¼¦æ›²çº¿ä¸Šçš„æ•°æ®ç‚¹ $(0,0),( \pi / 2,1),( \pi ,0),(3 \pi / 2, -1)$è¿›è¡Œå¤šé¡¹å¼æ’å€¼ï¼Œè¿™é‡Œ ${x_0,x_1,x_2,x_3 } = { 0,\pi / 2,\pi ,3 \pi /2 } , {y_0,y_1,y_2,y_3 } = { 0,1,0,-1 } $,æ±‚è§£</p><script type="math/tex; mode=display">\begin{bmatrix} 1&0&0&0 \\ 1&\frac{\pi}{2} & \frac{\pi^2}{4} & \frac{\pi^3}{8} \\ 1 & \pi & \pi^2 & \pi^3 \\ 1 & \frac{3\pi}{2} & \frac{9\pi^2}{4} & \frac{27\pi^3}{8}\end{bmatrix}  \begin{bmatrix} a_0 \\ a_1 \\ a_2 \\ a_3\end{bmatrix} = \begin{pmatrix} 0 \\ 1 \\ 0 \\ -1 \end{pmatrix}</script><p>å¾— $ a_0,a_1,a_2,a_3 $<br><code>V\y</code></p><script type="math/tex; mode=display">\begin{bmatrix} a_0 \\ a_1 \\ a_2 \\ a_3 \end{bmatrix} = \begin{pmatrix} 0 \\ 1.6977 \\ -0.8106 \\ 0.0860 \end{pmatrix}</script><p>å¾—</p><script type="math/tex; mode=display">p(x) = 0.0860 x^3 - 0.8106 x^2 +1.6997 x</script><p>éªŒè¯<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">3</span>/<span class="number">2</span>*<span class="built_in">pi</span>);</span><br><span class="line">y = <span class="built_in">sin</span>(x);</span><br><span class="line">a = [<span class="number">0.0860</span> <span class="number">-0.8106</span> <span class="number">1.6977</span> <span class="number">0</span>];</span><br><span class="line">p = polyval(a,x);</span><br><span class="line"><span class="built_in">plot</span>(x,y,<span class="string">&#x27;k-&#x27;</span>,x,p,<span class="string">&#x27;r--&#x27;</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;sin(x)&#x27;</span>,<span class="string">&#x27;polyval(a,x)&#x27;</span>)</span><br></pre></td></tr></table></figure></p></blockquote><p><img src="/image/æ‹‰æ ¼æœ—æ—¥æ’å€¼å¤šé¡¹å¼/1.svg" alt="1"></p><h3 id="Rungeå‡½æ•°"><a href="#Rungeå‡½æ•°" class="headerlink" title="Rungeå‡½æ•°"></a>Rungeå‡½æ•°</h3><blockquote><p>å¤šé¡¹å¼æ’å€¼è¿‘ä¼¼å‡½æ•°çš„æ•ˆæœä¼¼ä¹ä¸é”™ï¼Œä½†æœ‰æ—¶å¾ˆå·®ï¼Œå› ä¸ºVandermondeçŸ©é˜µä¸€èˆ¬æ˜¯ç—…æ€çš„ï¼Œå³ä½¿æ±‚è§£è¿‡ç¨‹æ˜¯ç²¾ç¡®çš„.<br>æ¯”å¦‚é«˜é˜¶å¤šé¡¹å¼æ’å€¼çš„æŒ¯è¡é—®é¢˜ï¼Œå³åœ¨èŠ‚ç‚¹é—´å‡ºç°å¤§çš„è¿‚å›.<br><strong>Rungeå‡½æ•°</strong></p><script type="math/tex; mode=display">f(x) = \frac{1}{1 + 25 x^2}</script><p>å›¾ä¸­ç”»å‡ºäº†Rungeå‡½æ•°ä»¥åŠå®ƒçš„10æ¬¡æ’å€¼å¤šé¡¹å¼ï¼Œå‡½æ•°çš„æŒ¯å¹…ä¼šéšç€nçš„å¢å¤§è€Œå¢å¤§ï¼Œè¿‘ä¼¼ç¨‹åº¦å°†è¶Šæ¥è¶Šå·®ï¼Œ $x \in (-1,1)$ æ—¶</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">-1</span>:<span class="number">0.2</span>:<span class="number">1</span>;</span><br><span class="line">x_ = <span class="built_in">linspace</span>(<span class="number">-1</span>,<span class="number">1</span>);</span><br><span class="line">x = x&#x27;;</span><br><span class="line">y = <span class="number">1.</span>/(<span class="number">1</span>+<span class="number">25.</span>*(x.^<span class="number">2</span>));</span><br><span class="line">y_ = <span class="number">1.</span>/(<span class="number">1</span>+<span class="number">25.</span>*(x_.^<span class="number">2</span>));</span><br><span class="line">A = <span class="built_in">ones</span>(<span class="number">11</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">10</span></span><br><span class="line">A = [A x.^<span class="built_in">i</span>];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">a = A\y;</span><br><span class="line">a = a&#x27;;</span><br><span class="line">a = a(:,<span class="keyword">end</span>:<span class="number">-1</span>:<span class="number">1</span>);</span><br><span class="line">x = <span class="number">-1</span>:<span class="number">0.001</span>:<span class="number">1</span>;</span><br><span class="line">p=<span class="built_in">zeros</span>(<span class="number">11</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">10</span>:<span class="number">-1</span>:<span class="number">0</span></span><br><span class="line">p = p+a(<span class="number">1</span>,<span class="number">11</span>-<span class="built_in">i</span>)*(x.^<span class="built_in">i</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">plot</span>(x_,y_,<span class="string">&#x27;k-&#x27;</span>,x,p,<span class="string">&#x27;r--&#x27;</span>),<span class="built_in">legend</span>(<span class="string">&#x27;1/(1+25*(x^2))&#x27;</span>,<span class="string">&#x27;p(x)&#x27;</span>),xlim([<span class="number">-1</span>,<span class="number">1</span>]),ylim([<span class="number">-0.5</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure></blockquote><p>â€‹    <img src="/image/æ‹‰æ ¼æœ—æ—¥æ’å€¼å¤šé¡¹å¼/2.svg" alt="2"></p><blockquote><p>å› æ­¤éœ€è¦æ¨å¯¼å’Œç†è§£å…¶ä»–æ–¹æ³•.</p></blockquote><h2 id="æ‹‰æ ¼æœ—æ—¥æ’å€¼å¤šé¡¹å¼"><a href="#æ‹‰æ ¼æœ—æ—¥æ’å€¼å¤šé¡¹å¼" class="headerlink" title="æ‹‰æ ¼æœ—æ—¥æ’å€¼å¤šé¡¹å¼"></a>æ‹‰æ ¼æœ—æ—¥æ’å€¼å¤šé¡¹å¼</h2><h3 id="å®šä¹‰-1"><a href="#å®šä¹‰-1" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h3><blockquote><p>å‡å®šè¦å¯¹ä¸¤ä¸ªäº’å¼‚ç‚¹ $x_a,x_b$ è¿›è¡Œç›´çº¿æ’å€¼ï¼Œå…ˆå®šä¹‰å‡½æ•° $ L_a(x) $ å’Œ $ L_b(x) $</p><script type="math/tex; mode=display">L_a(x) = \frac{x - x_b }{x_a - x_b}</script><script type="math/tex; mode=display">L_b(x) = \frac{x - x_a }{x_b - x_a}</script><p>åˆ™</p><script type="math/tex; mode=display">L_a(x_a ) = 1,\quad L_a(x_b = 0)</script><script type="math/tex; mode=display">L_b(x_a ) = 1,\quad L_b(x_b = 0)</script><p>ä¸”<br>$ L_a(x) $å’Œ $ L_b(x) $ éƒ½æ˜¯ $x$ çš„çº¿æ€§å‡½æ•°.ç»™å®š $y_a = f(x_a )$ å’Œ $y_b = f(x_b )$ï¼Œåˆ™</p><script type="math/tex; mode=display">l(x) = y_a L_a (x) + y_b L_b (x)</script><p>æ»¡è¶³</p><script type="math/tex; mode=display">\begin{aligned} l(x_a ) ={}& y_a L_a (x_a) + y_b L_b (x_a) {} \\ ={}& y_a \cdot 1 + y_b \cdot 0 \\ ={}& y_a \end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} l(x_b ) ={}& y_a L_a (x_b) + y_b L_b (x_b) {} \\ ={}& y_a \cdot 1 + y_b \cdot 0 \\ ={}& y_b \end{aligned}</script><p>å³ $l(x)$ æ˜¯ $f$ åœ¨ $(x_a , y_a )$ å’Œ $(x_b,y_b)$ ä¸Šçš„æ’å€¼.ç”±äº $l(x)$ æ˜¯ä¸¤ä¸ªçº¿æ€§å‡½æ•°çš„å’Œï¼Œæ‰€ä»¥æ˜¯çº¿æ€§çš„ï¼Œåˆå› ä¸ºè¿‡äº’å¼‚ä¸¤ç‚¹çš„ç›´çº¿åªæœ‰ä¸€æ¡ï¼Œæ‰€ä»¥ $l(x)$ æ˜¯å”¯ä¸€çš„.<br>å°†è¿™ç§åšæ³•æ¨å¹¿åˆ° $n+1$ ä¸ªäº’å¼‚ç‚¹ $x_0,x_1,\cdots,x_n $(æœ‰åºä¸” $ x_0 \lt x_1 \lt \cdots \lt x_n $ )ï¼Œå®šä¹‰å‡½æ•°</p><script type="math/tex; mode=display">\begin{aligned} L_{n,i} (x) ={}& \frac{(x-x_0)(x-x_1) \cdots (x-x_{i-1})(x-x_{i+1}) \cdots (x-x_n)}{(x_i-x_0)(x_i-x_1) \cdots (x_i-x_{i-1})(x_i-x_{i+1}) \cdots (x_i-x_n)} \\ ={}& \prod_{k=0 \\ k\neq i}^{n} \frac{(x-x_k)}{(x_i - x_k)} \end{aligned}</script><p>å½“ $n \neq i$ æ—¶ï¼Œæœ‰</p><script type="math/tex; mode=display">L_{n,i} (x_n) = 0</script><script type="math/tex; mode=display">L_{n,i} (x_i) = 1</script><p>ä¸Šå¼ä¸ºLagrangeå¤šé¡¹å¼.<br>ç”±äº $n$ æ¬¡å¤šé¡¹å¼çš„å’Œæ˜¯æ¬¡æ•°æœ€å¤šä¸º $n$ çš„å¤šé¡¹å¼ï¼Œæ‰€ä»¥ç”¨Lagrangeå¤šé¡¹å¼å¯ä»¥å¾—åˆ°è¿‡ç‚¹ $(x_0,y_0),(x_1,y_1), \cdots , (x_n,y_n) $ çš„æ¬¡æ•°ä¸è¶…è¿‡ $n$ çš„æ’å€¼å¤šé¡¹å¼ $p(x)$ </p><script type="math/tex; mode=display">\begin{aligned} p(x) ={}& y_0 L_{n,0} (x) + y_1 L_{n,1} (x) + \cdots + y_n L_{n,n} (x) \\ ={}& \sum_{i=1}^{n} y_i L_n (x) \end{aligned}</script><p>æœ‰ $L_i(x_j) = 0 $</p><script type="math/tex; mode=display">\begin{aligned} p(x) ={}& \sum_{i=0}^{n} y_i L_i (x_j) \\ ={}& y_0 L_0 (x_j) + y_1 L_1 (x_j) + \cdots + y_n L_n (x_j) \\ ={}& y_j \cdot 1 \\ ={}& y_j \end{aligned}</script><p>$p$ å°±æ˜¯æ‰€æ±‚çš„å¤šé¡¹å¼æ’å€¼ï¼Œä¸VandermondeçŸ©é˜µçš„ç»“æœç›¸åŒ.</p></blockquote><h3 id="ä¾‹é¢˜-1"><a href="#ä¾‹é¢˜-1" class="headerlink" title="ä¾‹é¢˜"></a>ä¾‹é¢˜</h3><blockquote><p>å¯¹æ­£å¼¦æ›²çº¿ä¸Šçš„æ•°æ®ç‚¹ $(0,0),( \pi / 2,1),( \pi ,0),(3 \pi / 2, -1)$è¿›è¡Œå¤šé¡¹å¼æ’å€¼ï¼Œè¿™é‡Œ ${x_0,x_1,x_2,x_3 } = { 0,\pi / 2,\pi ,3 \pi /2 } , {y_0,y_1,y_2,y_3 } = { 0,1,0,-1 } $,Lagrangeå¤šé¡¹å¼</p><script type="math/tex; mode=display">\begin{aligned}L_0(x) ={}& \frac{(x-x_1)(x-x_2)(x-x_3)}{(x_0-x_1)(x_0-x_2)(x_0-x_3)} \\ ={}& - \frac{4}{3\pi^3} (x-\frac{\pi}{2})(x-\pi)(x-\frac{3\pi}{2}) \end{aligned}</script><script type="math/tex; mode=display">L_1(x) = \frac{4}{\pi^3}x(x-\pi)(x-\frac{3\pi}{2})</script><script type="math/tex; mode=display">L_2(x) = - \frac{4}{3\pi^3} (x-\frac{\pi}{2})(x-\frac{3\pi}{2})</script><script type="math/tex; mode=display">L_3(x) = \frac{4}{3\pi^3} (x-\frac{\pi}{2})(x-\pi)</script><p>æ’å€¼å¤šé¡¹å¼ä¸º</p><script type="math/tex; mode=display">\begin{aligned} p(x) ={}& 0 \cdot L_0(x) + 1 \cdot L_1(x) + 0 \cdot L_2(x) + (-1) \cdot L_3(x) \\ ={}& 0.0860 x^3 - 0.8106 x^2 +1.6997 x \end{aligned}</script><p>åŒå‰</p></blockquote><h3 id="è¡¥å……"><a href="#è¡¥å……" class="headerlink" title="è¡¥å……"></a>è¡¥å……</h3><h5 id="Cauchyä½™é¡¹å®šç†"><a href="#Cauchyä½™é¡¹å®šç†" class="headerlink" title="Cauchyä½™é¡¹å®šç†"></a>Cauchyä½™é¡¹å®šç†</h5><blockquote><p>ç»™å®š $a \leq x_0 \lt x_1 \lt \cdots \lt x_n \leq b$ åŠ $f \in C^{n+1}[a,b]$ï¼Œåˆ™å¯¹ä»»æ„ $x \in [a,b]$ï¼Œéƒ½å­˜åœ¨ $\xi = \xi(x) \in [a,b]$ï¼Œä½¿$f$åœ¨$x_0,x_1,\cdots,x_n$ ä¸Šçš„æ’å€¼å¤šé¡¹å¼ $p(x)$ æ»¡è¶³</p><script type="math/tex; mode=display">f(x) - p(x) = \frac{f^{n+1}(\xi)}{(n+1)!}(x-x_0)(x-x_1)\cdots(x-x_n)</script><p>è¯æ˜ç•¥</p></blockquote><h4 id="Weierstrasså®šç†"><a href="#Weierstrasså®šç†" class="headerlink" title="Weierstrasså®šç†"></a>Weierstrasså®šç†</h4><blockquote><p>è‹¥$f \in C[a,b]$ï¼Œåˆ™å¯¹ä»»æ„ç»™å®šçš„ $\varepsilon \gt 0$ éƒ½å­˜åœ¨å¤šé¡¹å¼ $p(x)$ ,ä½¿å¯¹ä»»æ„ $x \in [a,b]$ï¼Œæœ‰</p><script type="math/tex; mode=display">\left | f(x) - p(x) \right | \leq \varepsilon</script><p>è¯´æ˜ä»»ä½•è¿ç»­å‡½æ•°éƒ½å¯ä»¥è¢«é«˜æ¬¡å¤šé¡¹å¼ä»»æ„é€¼è¿‘.</p></blockquote><h2 id="ç»“æŸ"><a href="#ç»“æŸ" class="headerlink" title="ç»“æŸ"></a>ç»“æŸ</h2><p>Lagrangeåªè®¨è®ºäº†æ±‚å‡ºæ’å€¼å¤šé¡¹å¼ç³»æ•°çš„æ–¹æ³•ï¼ŒåŒºé—´å¤–ï¼ŒLagrangeæ’å€¼æ˜¯ä¸å‡†ç¡®çš„ï¼Œå¦‚æœé—®é¢˜ä¸­è¦æ±‚å¤šé¡¹å¼çš„å€¼ï¼Œå¯ä»¥ä½¿ç”¨æ›´ä¸ºæœ‰æ•ˆå’Œç²¾ç¡®çš„æ–¹æ³•.</p>]]></content>
      
      
      <categories>
          
          <category> æ•°å€¼åˆ†æ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¤šé¡¹å¼æ’å€¼ </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
