<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>CUDA编程: CUDA流,并发与上下文 | Aeeeeeep Blog</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.3.0"></head><body><main class="content"><section class="outer"><article id="post-CUDA编程-CUDA流-并发与上下文" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">CUDA编程: CUDA流,并发与上下文</h1></header><div class="article-meta"><a href="/p/40cda68f/" class="article-date"><time datetime="2024-02-06T13:34:59.000Z" itemprop="datePublished">2024-02-06</time></a><div class="article-category"><a class="article-category-link" href="/categories/CUDA-%E7%BC%96%E7%A8%8B/">CUDA 编程</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>深入介绍流的使用，包括流的并发，多线程调度流，并发限制，创建流间依赖关系，重叠主机与设备的执行等，同时，结合实例讲解了 CUDA 上下文以及 MPS 的概念，简单介绍了 CUDA Driver API 对 Context 的管理。</p><span id="more"></span><h2 id="并发流的执行"><a href="#并发流的执行" class="headerlink" title="并发流的执行"></a>并发流的执行</h2><h3 id="非空流中的并发"><a href="#非空流中的并发" class="headerlink" title="非空流中的并发"></a>非空流中的并发</h3><p>以下面的核函数为例，定义一个非空流，将多个核函数加入到该流中。再循环定义多个流</p><blockquote><p>注意核函数要足够复杂才能让非空流并行</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel_4</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">double</span> val = <span class="number">0.1</span> + tid * <span class="number">0.001</span>;</span><br><span class="line">    <span class="type">double</span> res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">        res += <span class="built_in">tan</span>(val) * <span class="built_in">tan</span>(val);</span><br><span class="line">    &#125;</span><br><span class="line">    sum += res;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n_stream=<span class="number">12</span>;</span><br><span class="line">    cudaStream_t *stream=(cudaStream_t*)<span class="built_in">malloc</span>(n_stream*<span class="built_in">sizeof</span>(cudaStream_t));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamCreate</span>(&amp;stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line">    cudaEvent_t start,stop;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;n_stream; i++) &#123;</span><br><span class="line">        kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">        kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">        kernel_3&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">        kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamSynchronize</span>(stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop,<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line">    <span class="type">float</span> elapsed_time;</span><br><span class="line">    <span class="built_in">cudaEventElapsedTime</span>(&amp;elapsed_time,start,stop);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;elapsed time:%f ms\n&quot;</span>,elapsed_time);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamDestroy</span>(stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(stop);</span><br><span class="line">    <span class="built_in">free</span>(stream);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这些内核启动的执行配置被指定为单一线程块中的单一线程，以保证有足够的 GPU 资源能并发运行所有的内核。因为每个内核启动相对主机来说都是异步的，所以可以通过使用单一主机线程同时调度多个内核到不同的流中</p><p>下图可以看到 12 个流以最大 8 个工作队列并行运行</p><p><img src="/image/CUDA编程-CUDA流-并发与上下文/1.webp" alt="1"></p><h3 id="使用-OpenMP-调度流"><a href="#使用-OpenMP-调度流" class="headerlink" title="使用 OpenMP 调度流"></a>使用 OpenMP 调度流</h3><p>前面我们都是使用的单一主机线程调度流，我们可以在 CPU 上利用并行编程，使多个 CPU 线程管理多个流。这里，我们介绍一下，在 MPI (Message Passing Interface)、OpenMP 和 Pthread 这三种常见的 CPU 并行编程库：</p><ul><li>MPI：MPI 是一种消息传递库，通常用于分布式内存环境中。MPI 库提供了一组函数，可以在多个计算节点之间发送和接收消息。通过使用 MPI，程序可以在多个计算节点上同时运行，从而实现并行计算</li><li>OpenMP：OpenMP 是一种共享内存并行编程库，它可以用于在单个计算节点的多个 CPU 核之间并行执行代码。OpenMP 提供了一组指令，可以将并行计算任务分配到不同的线程上执行。这些线程共享进程的内存空间，可以在程序的不同部分之间共享数据</li><li>Pthread：Pthread 是 POSIX 线程库的简称，也是一种共享内存并行编程库，与 OpenMP 类似，可以在单个计算节点上的多个 CPU 核之间并行执行代码。Pthread 提供了一组函数，用于创建和管理线程。这些线程共享进程的内存空间，可以在程序的不同部分之间共享数据</li></ul><p>其中 OpenMP 的编译需要添加编译器预处理指令<code>#pragma</code>，创建线程等后续工作要编译器来完成。而 Pthread 所有的并行线程创建都需要我们自己完成，较 OpenMP 麻烦一点，但是更为灵活</p><p>所以我们下面学习使用 OpenMP 库同时调用多个线程，使用一个线程来管理每个流</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;omp.h&gt;</span></span></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="built_in">omp_set_num_thread</span>(n_stream);</span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> i=<span class="built_in">omp_get_thread_num</span>();</span><br><span class="line">    kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_3&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用 OpenMP 的 API 创建 n_stream 个线程，<code>#pragma omp parallel</code>宏指令告诉编译器下面花括号中的部分就是每个线程都要执行的部分，括号中的部分可以称为并行单元</p><p>使用下面的命令使 nvcc 支持 OpenMP 指令编译</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc &#123;&#125;.cu -Xcompiler -fopenmp</span><br></pre></td></tr></table></figure><p><img src="/image/CUDA编程-CUDA流-并发与上下文/2.webp" alt="2"></p><p>关于 OpenMP 与 CUDA 之间更复杂的操作我们会在之后的文章和大家细细道来</p><h3 id="使用环境变量调整流行为"><a href="#使用环境变量调整流行为" class="headerlink" title="使用环境变量调整流行为"></a>使用环境变量调整流行为</h3><p>目前 Nvidia 支持的最大 Hyper-Q 工作队列数是 32，但是在默认情况下并不是全部开启，而是被限制成 8 个，原因是每个工作队列只要开启就会有资源消耗，如果用不到 32 个可以把资源留给需要的 8 个队列，修改这个配置的方法是修改主机系统的环境变量</p><p>对于Linux系统中，可以导入环境变量修改</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_DEVICE_MAX_CONNECTIONS=32</span><br></pre></td></tr></table></figure><p>将 <code>n_stream</code> 改为 24，再次编译，下图可以看到并行工作队列数提高很多</p><p><img src="/image/CUDA编程-CUDA流-并发与上下文/3.webp" alt="3"></p><h3 id="并发限制"><a href="#并发限制" class="headerlink" title="并发限制"></a>并发限制</h3><p>有限的内核资源可以抑制应用程序中可能出现的内核并发的数量。在实际应用中，内核启动时通常会创建大量线程，这时，可用的硬件资源可能会成为并发的主要限制因素，因为它们阻止启动符合条件的内核。下面更改</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>为</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">16</span>,<span class="number">32</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">32</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>将使用的 CUDA 流增加到 24，下图可以看到只实现了 4 路并发，因为 GPU 无法分配足够的资源，这里需要我们根据需求修改各个参数</p><h3 id="空流的阻塞行为"><a href="#空流的阻塞行为" class="headerlink" title="空流的阻塞行为"></a>空流的阻塞行为</h3><p>为了演示在空流中的的阻塞行为，将 <code>n_stream</code> 改回 12，<code>block</code>和<code>grid</code>改回1，我们将深度优先调度循环改为在空流的调用 kernel_3</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">    kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_3&lt;&lt;&lt;grid,block&gt;&gt;&gt;();</span><br><span class="line">    kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到所有 kernel_3 启动以后，所有其他的流中的操作全部被阻塞，空流对于非空流具有阻塞作用</p><p><img src="/image/CUDA编程-CUDA流-并发与上下文/5.webp" alt="5"></p><h3 id="创建流间依赖关系"><a href="#创建流间依赖关系" class="headerlink" title="创建流间依赖关系"></a>创建流间依赖关系</h3><p>理想情况下，流之间不应存在非预期的依赖关系（即虚假的依赖关系）。然而在实际使用时，我们需要一个流等待另一个流中的操作完成。可以使用事件在流之间创建依赖关系。首先，使用标志<code>cudaEventDisableTiming</code>创建同步事件</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t * event=(cudaEvent_t *)<span class="built_in">malloc</span>(n_stream*<span class="built_in">sizeof</span>(cudaEvent_t));</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">    <span class="built_in">cudaEventCreateWithFlags</span>(&amp;event[i],cudaEventDisableTiming);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来，使用<code>cudaEventRecord</code>在每个流完成时记录一个不同的事件，再使用<code>cudaStreamWaitEvent</code>来强制最后一个流（即流[n_streams-1]）等待其他所有流</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n_stream;i++) &#123;</span><br><span class="line">    kernel_1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_3&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    kernel_4&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(event[i],stream[i]);</span><br><span class="line">    <span class="built_in">cudaStreamWaitEvent</span>(stream[n_stream<span class="number">-1</span>],event[i],<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从下图的时间轴可以看到我们成功创建了流间的依赖关系，最后一个流会等到前面所有流中的事件完成，再运行</p><p><img src="/image/CUDA编程-CUDA流-并发与上下文/6.webp" alt=""></p><h2 id="重叠内核执行和数据传输"><a href="#重叠内核执行和数据传输" class="headerlink" title="重叠内核执行和数据传输"></a>重叠内核执行和数据传输</h2><p>前面的章节我们已经了解了数据传输队列（HtD, DtH），不是经过同一条队列的，这两个操作可以重叠完成，但是同向数据传输的时候不能进行此操作。此外，还需要检查数据传输和内核执行之间的关系：</p><ul><li>如果内核使用数据 A，对 A 进行数据传输必须要在内核启动之前，且必须在同一个流中</li><li>如果内核不使用数据A，内核执行和数据传输可以位于不同的流中重叠执行</li></ul><p>第二种情况就是重叠内核执行和数据传输的基本做法，当数据传输和内核执行被分配到不同的流中时，CUDA 执行的时候默认这是安全的，我们要保证它们之间的依赖关系。但是第一种情况也可以进行重叠，需要对核函数进行一定的分割，我们用向量加法核函数来举例</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraysSum</span><span class="params">(<span class="type">float</span>*a, <span class="type">float</span>*b, <span class="type">float</span>*res, <span class="type">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> idx = blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(idx &lt; N) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;N_REPEAT;j++)</span><br><span class="line">            res[idx]=a[idx]+b[idx];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>向量加法的过程是为</p><ol><li>将两个输入向量从主机传入设备</li><li>内核计算结果</li><li>将结果从设备回传到主机</li></ol><p>由于这个问题就是一个一步问题，我们没办法让内核和数据传输重叠，因为内核需要全部的数据，但是由于向量加法的每一位都互不干扰，我们可以把向量分块，并且每块中的数据只用于每块的内核，而跟其它分块的内核没有关系，这样就可以把整个过程分成 N_SEGMENT 份，也就是 N_SEGMENT 个流分别执行</p><h3 id="深度优先调度重叠"><a href="#深度优先调度重叠" class="headerlink" title="深度优先调度重叠"></a>深度优先调度重叠</h3><p>我们首先使用深度优先调度的方式。这里需要注意数据传输是异步的，所以必须声明为固定内存，不能是分页内存</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N_REPEAT 10</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N_SEGMENT 4</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">ArraysSum</span><span class="params">(<span class="type">float</span>*a,<span class="type">float</span>*b,<span class="type">float</span>*res,<span class="type">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> idx=blockIdx.x*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(idx &lt; N) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;N_REPEAT;j++)</span><br><span class="line">            res[idx]=a[idx]+b[idx];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> nElem=<span class="number">1</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Vector size:%d\n&quot;</span>,nElem);</span><br><span class="line">    <span class="type">int</span> nByte=<span class="built_in">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line">    <span class="type">float</span> * a_h,*b_h,*res_h,*res_from_gpu_h;</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;a_h,nByte,cudaHostAllocDefault);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;b_h,nByte,cudaHostAllocDefault);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;res_h,nByte,cudaHostAllocDefault);</span><br><span class="line">    <span class="built_in">cudaHostAlloc</span>((<span class="type">float</span>**)&amp;res_from_gpu_h,nByte,cudaHostAllocDefault);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemset</span>(res_h,<span class="number">0</span>,nByte);</span><br><span class="line">    <span class="built_in">cudaMemset</span>(res_from_gpu_h,<span class="number">0</span>,nByte);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> *a_d,*b_d,*res_d;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;a_d,nByte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;b_d,nByte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">float</span>**)&amp;res_d,nByte);</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">512</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">((nElem<span class="number">-1</span>)/block.x+<span class="number">1</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//asynchronous calculation</span></span><br><span class="line">    <span class="type">int</span> iElem=nElem/N_SEGMENT;</span><br><span class="line">    cudaStream_t stream[N_SEGMENT];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamCreate</span>(&amp;stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    cudaEvent_t start,stop;</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line">    <span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(start,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;a_d[ioffset],&amp;a_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;b_d[ioffset],&amp;b_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        ArraysSum&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;(&amp;a_d[ioffset],&amp;b_d[ioffset],&amp;res_d[ioffset],iElem);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;res_from_gpu_h[ioffset],&amp;res_d[ioffset],nByte/N_SEGMENT,cudaMemcpyDeviceToHost,stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaEventRecord</span>(stop, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="built_in">cudaStreamDestroy</span>(stream[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cudaFree</span>(a_d);</span><br><span class="line">    <span class="built_in">cudaFree</span>(b_d);</span><br><span class="line">    <span class="built_in">cudaFree</span>(a_h);</span><br><span class="line">    <span class="built_in">cudaFree</span>(b_h);</span><br><span class="line">    <span class="built_in">cudaFree</span>(res_h);</span><br><span class="line">    <span class="built_in">cudaFree</span>(res_from_gpu_h);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line">    <span class="built_in">cudaEventDestroy</span>(stop);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>nvvp 可视化如下</p><p><img src="/image/CUDA编程-CUDA流-并发与上下文/7.webp" alt=""></p><h3 id="广度优先调度重叠"><a href="#广度优先调度重叠" class="headerlink" title="广度优先调度重叠"></a>广度优先调度重叠</h3><p>循环修改为如下代码</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(&amp;a_d[ioffset],&amp;a_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(&amp;b_d[ioffset],&amp;b_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">    ArraysSum&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;(&amp;a_d[ioffset],&amp;b_d[ioffset],&amp;res_d[ioffset],iElem);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(&amp;res_from_gpu_h[ioffset],&amp;res_d[ioffset],nByte/N_SEGMENT,cudaMemcpyDeviceToHost,stream[i]));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/image/CUDA编程-CUDA流-并发与上下文/8.webp" alt="8"></p><p>nvvp 可视化和深度优先调度重叠一模一样，所以我们不需要关注深度还是广度的调度顺序</p><h2 id="重叠主机与设备的执行"><a href="#重叠主机与设备的执行" class="headerlink" title="重叠主机与设备的执行"></a>重叠主机与设备的执行</h2><p>实现 GPU 和 CPU 的执行重合是相对直接的，因为所有的内核默认情况下是异步启动的。因此，只要启动一个内核，并立即在主机线程中实现有效操作，就会自动产生 GPU 和 CPU 执行的重叠</p><p>以下面的加法核函数为例</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">float</span> *g_data, <span class="type">float</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    g_data[idx] = g_data[idx] + value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，有两个拷贝和一个内核启动操作，记录了一个停止事件，以标记所有 CUDA 操作的完成</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpyAsync</span>(d_a, h_a, nbytes, cudaMemcpyHostToDevice);</span><br><span class="line">kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_a, value);</span><br><span class="line"><span class="built_in">cudaMemcpyAsync</span>(h_a, d_a, nbytes, cudaMemcpyDeviceToHost);</span><br><span class="line"><span class="built_in">cudaEventRecord</span>(stop);</span><br></pre></td></tr></table></figure><p>这些操作与主机都是异步的，它们都被绑定到默认流中，一旦最后一个<code>cudaMemcpyAsync</code>被发出，控制权将立即返回到主机。一旦控制权返回给主机，主机就可以做任何不依赖内核输出的有用的计算。在下面的代码段中，主机只是简单地进行迭代，等待所有CUDA操作的完成，同时递增一个计数器。在每次迭代中，主机线程查询停止事件。一旦该事件满足，主机线程就会继续</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> counter = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="built_in">cudaEventQuery</span>(stop) == cudaErrorNotReady) &#123;</span><br><span class="line">	counter++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Counter: %ld\n&quot;</span>,counter);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 输出</span></span><br><span class="line"><span class="comment">Vector size:1048576</span></span><br><span class="line"><span class="comment">Counter: 7206</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h3 id="流回调"><a href="#流回调" class="headerlink" title="流回调"></a>流回调</h3><p>流回调是另一种可以到 CUDA 流排列等待的操作类型。 一旦流回调之前的流中的所有操作都已完成，CUDA 运行时将调用流回调指定的主机端函数，该函数由应用程序提供，这允许将任意主机端逻辑插入到 CUDA 流中。 流回调是另一种 CPU 到 GPU 同步机制，但是流回调时，回调函数中不可以调用 CUDA 的 API，且不可以执行同步</p><p>流函数有特殊的参数规格，必须写成下面形式参数的函数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> CUDART_CB <span class="title">my_callback</span><span class="params">(cudaStream_t stream, cudaError_t status, <span class="type">void</span> *data)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;callback from stream %d\n&quot;</span>, *((<span class="type">int</span> *)data));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该函数有三个参数：</p><ul><li><code>cudaStream_t stream</code>：表示回调函数与哪个CUDA流相关联。当流中的所有操作都完成时，CUDA运行时将调用此回调函数</li><li><code>cudaError_t status</code>：表示流中最后一个操作的状态。如果状态是<code>cudaSuccess</code>，则表示所有操作已成功完成</li><li><code>void *data</code>：表示传递给回调函数的数据指针。在此示例中，该指针指向一个整数，其中包含与流相关的自定义数据</li></ul><p>并使用下面的函数加入流中</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamAddCallback</span><span class="params">(cudaStream_t stream,cudaStreamCallback_t callback, <span class="type">void</span> *userData, <span class="type">unsigned</span> <span class="type">int</span> flags)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>stream</code>：CUDA 流，表示将要添加回调函数的流</li><li><code>callback</code>：回调函数，该函数会在指定的流上的所有操作都已经完成时被调用。回调函数的原型为 <code>void (*)(cudaStream_t, cudaError_t, void*)</code>，其中第一个参数表示回调函数所在的流，第二个参数表示流上的最后一个 CUDA 操作的状态，第三个参数为用户自定义数据</li><li><code>userData</code>：用户自定义数据指针，会在回调函数被调用时传递给回调函数</li><li><code>flags</code>：标志位，用于控制回调函数的行为。目前只支持 <code>cudaStreamCallbackBlocking</code> 和 <code>cudaStreamCallbackNonblocking</code> 两种标志位，分别表示回调函数是阻塞还是非阻塞的。如果使用阻塞回调函数，则该回调函数必须在流上的所有操作完成后才能被调用。如果使用非阻塞回调函数，则该回调函数可能会在流上的操作尚未全部完成时被调用</li></ul><p>下面是流回调的一个例子</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// 定义一个回调函数 my_callback()，监控每个流的完成情况，并在每个流完成后输出相应流的 ID 号，用于在 CUDA 异步操作完成后执行</span></span><br><span class="line"><span class="function"><span class="type">void</span> CUDART_CB <span class="title">my_callback</span><span class="params">(cudaStream_t stream,cudaError_t status,<span class="type">void</span> * data)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;call back from stream:%d\n&quot;</span>,*((<span class="type">int</span> *)data));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N_SEGMENT;i++) &#123;</span><br><span class="line">        <span class="type">int</span> ioffset=i*iElem;</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;a_d[ioffset],&amp;a_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;b_d[ioffset],&amp;b_h[ioffset],nByte/N_SEGMENT,cudaMemcpyHostToDevice,stream[i]);</span><br><span class="line">        ArraysSum&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream[i]&gt;&gt;&gt;(&amp;a_d[ioffset],&amp;b_d[ioffset],&amp;res_d[ioffset],iElem);</span><br><span class="line">        <span class="built_in">cudaMemcpyAsync</span>(&amp;res_from_gpu_h[ioffset],&amp;res_d[ioffset],nByte/N_SEGMENT,cudaMemcpyDeviceToHost,stream[i]);</span><br><span class="line">        <span class="comment">// 使用 cudaStreamAddCallback() 将回调函数 my_callback() 添加到每个流中，以便跟踪每个流的完成情况</span></span><br><span class="line">        <span class="built_in">cudaStreamAddCallback</span>(stream[i],my_callback,(<span class="type">void</span> *)(stream+i),<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">/* 输出</span></span><br><span class="line"><span class="comment">Vector size:1048576</span></span><br><span class="line"><span class="comment">call back from stream:1947823616</span></span><br><span class="line"><span class="comment">call back from stream:1946969680</span></span><br><span class="line"><span class="comment">call back from stream:1947835744</span></span><br><span class="line"><span class="comment">call back from stream:1947835776</span></span><br><span class="line"><span class="comment">Counter: 5126</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h2 id="CUDA-Context-上下文"><a href="#CUDA-Context-上下文" class="headerlink" title="CUDA Context 上下文"></a>CUDA Context 上下文</h2><p>CUDA Context 是一个由特定进程与设备相关联的状态集合，包括：</p><ul><li><p>所有分配内存</p></li><li><p>Modules，类似于动态链接库，以.cubin和.ptx结尾 【在jcuda中要使用】</p></li><li>CUDA streams，管理执行单元的并发性</li><li>CUDA events</li><li>texture和surface引用</li><li>kernel里面使用到的本地内存（设备内存）</li><li>用于调试、分析和同步的内部资源</li><li>用于分页复制的固定缓冲区</li></ul><p>CUDA 程序通过使用 CUDA Context 来管理设备资源和执行 CUDA 指令。每个进程可以有多个 CUDA Context，每个 CUDA Context 只能与一个设备相关联。CUDA 程序通过使用 CUDA Context 来管理设备资源和执行 CUDA 指令</p><p>每个进程或 GPU 可以有多个 CUDA Context，而每个 CUDA Context 只能与一个 GPU 相关联</p><p>在 CUDA 中，每个任务都有一个独立的设备 ID，每个设备 ID 对应一个唯一的 CUDA Context。所以 Context 类似于 CPU 上的进程，由 Driver 层管理分配资源的生命周期</p><p>与 CPU 进程的管理类似，每个 Context 有自己的地址空间，且之间是隔离的，在一个 Context 中所有指针只能在这一个 Context 中使用，但一个 CUDA Context 中的任何一个 kernel 被挂掉后，则此时处于同一个 GPU 上的 所有 Context 的所有都会失效</p><h3 id="隐式创建"><a href="#隐式创建" class="headerlink" title="隐式创建"></a>隐式创建</h3><p>CUDA Runtime 软件层的库是隐式创建 context，且不提供 API 直接创建 CUDA context，而是通过延迟初始化（deferred initialization）来创建 context，也就是 lazy initialization</p><p>在 Linux 中通过导入环境变量延迟初始化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_MODULE_LOADING=LAZY</span><br></pre></td></tr></table></figure><blockquote><p>CUDA_MODULE_LOADING 默认为 <code>EAGER</code>，会最大限度地减少模块加载时的延迟，但会增加程序启动时间和内存占用</p></blockquote><p>具体意思是在调用每一个 CUDART 库函数时，它会检查当前是否有 context 存在，假如需要 context，那么才自动创建。也就是说需要创建上面这些对象的时候就会创建context。可以显式的控制初始化，即调用 cudaFree(0)，强制的初始化</p><p>CUDA Runtime 将 context 和 device 的概念合并了，即在一个 GPU 上操作可看成在一个 context 下</p><h3 id="显示创建"><a href="#显示创建" class="headerlink" title="显示创建"></a>显示创建</h3><p>可以使用 CUDA Driver API 显示创建 context，CUDA Driver API 是一种更偏向底层的 API，提供了对硬件的更细粒度的控制，直接控制 GPU 的所有硬件资源。这些函数被实现在 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html">CUDA Driver 库 </a>中，需要手动链接这个库并直接调用这些函数，下面几个函数用于管理 CUDA 上下文</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CUresult <span class="title">cuCreateContext</span><span class="params">(CUcontext* pctx, <span class="type">unsigned</span> <span class="type">int</span> flags, CUdevice dev)</span></span>;</span><br></pre></td></tr></table></figure><p>创建 CUDA 上下文</p><ul><li><p>pctx：输出参数，指向新创建的CUDA上下文句柄</p></li><li><p>flags：用于设置上下文属性的标志位，可以为 0</p></li><li><p>dev：用于创建上下文的设备句柄</p></li><li><p>返回 CUDA_SUCCESS 表示函数调用成功，否则返回错误码</p></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CUresult <span class="title">cuPushCurrent</span><span class="params">(CUcontext ctx)</span></span>;</span><br></pre></td></tr></table></figure><p>将当前线程的CUDA上下文压入上下文栈中，并将给定上下文设置为当前上下文</p><ul><li>ctx：要设置为当前上下文的CUDA上下文句柄</li><li>返回 CUDA_SUCCESS 表示函数调用成功，否则返回错误码</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">CUresult <span class="title">cuPopCurrent</span><span class="params">(CUcontext *pctx)</span></span>;</span><br></pre></td></tr></table></figure><p>将当前线程的CUDA上下文从上下文栈中弹出，并将上下文栈顶的上下文设置为当前上下文</p><ul><li>pctx：输出参数，指向弹出的CUDA上下文句柄</li><li>返回 CUDA_SUCCESS 表示函数调用成功，否则返回错误码</li></ul><p>其中，隐式调用的context是 primary context，由 CUDA 驱动程序自动创建和管理； 显示调用的 context 是standard context，需要手动管理其生命周期和状态，并且可以同时存在多个 standard context。每次 CUDA 初始化比较费时间，可能是 Runtime 进行了隐式调用 context，可以使用 <code>cudaError_t cudaSetDevice(int device)</code> 提前创建 context 节省这部分时间</p><p>使用 CUDA Driver API 编写的 CUDA 程序通常具有更高的性能，因为它们可以更充分地利用 GPU 的硬件资源。但是，由于这种API需要我们对硬件有更深入的了解，并且需要编写更多的底层代码，所以这种编程方式会更加困难和容易出错，目前阶段我们暂不深入了解这个库，下面只给出简单示例</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This code is modified from https://blog.csdn.net/weicao1990/article/details/123959648</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span>	<span class="comment">// 包含 cuda driver api</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span> </span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">define</span> checkDriver(op)  __check_cuda_driver((op), #op, __FILE__, __LINE__)</span></span><br><span class="line"> </span><br><span class="line"><span class="type">bool</span> __check_cuda_driver(CUresult code, <span class="type">const</span> <span class="type">char</span>* op, <span class="type">const</span> <span class="type">char</span>* file, <span class="type">int</span> line)&#123;</span><br><span class="line">    <span class="keyword">if</span>(code != CUresult::CUDA_SUCCESS)&#123;    <span class="comment">// 如果 成功获取CUDA情况下的返回值 与我们给定的值(0)不相等， 即条件成立， 返回值为flase</span></span><br><span class="line">        <span class="type">const</span> <span class="type">char</span>* err_name = <span class="literal">nullptr</span>;    <span class="comment">// 定义了一个字符串常量的空指针</span></span><br><span class="line">        <span class="type">const</span> <span class="type">char</span>* err_message = <span class="literal">nullptr</span>;  </span><br><span class="line">        <span class="built_in">cuGetErrorName</span>(code, &amp;err_name);    </span><br><span class="line">        <span class="built_in">cuGetErrorString</span>(code, &amp;err_message);   </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s:%d  %s failed. \n  code = %s, message = %s\n&quot;</span>, file, line, op, err_name, err_message); <span class="comment">//打印错误信息</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 检查cuda driver的初始化</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuInit</span>(<span class="number">0</span>));</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 为设备创建上下文</span></span><br><span class="line">    CUcontext ctxA = <span class="literal">nullptr</span>;                                   <span class="comment">// CUcontext 其实是 struct CUctx_st*（是一个指向结构体CUctx_st的指针）</span></span><br><span class="line">    CUcontext ctxB = <span class="literal">nullptr</span>;</span><br><span class="line">    CUdevice device = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxCreate</span>(&amp;ctxA, CU_CTX_SCHED_AUTO, device)); <span class="comment">// 这一步相当于告知要某一块设备上的某块地方创建 ctxA 管理数据。输入参数 参考 https://www.cs.cmu.edu/afs/cs/academic/class/15668-s11/www/cuda-doc/html/group__CUDA__CTX_g65dc0012348bc84810e2103a40d8e2cf.html</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxCreate</span>(&amp;ctxB, CU_CTX_SCHED_AUTO, device)); </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ctxA = %p\n&quot;</span>, ctxA);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ctxB = %p\n&quot;</span>, ctxB);</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">        contexts 栈：</span></span><br><span class="line"><span class="comment">            ctxB -- top &lt;--- current_context</span></span><br><span class="line"><span class="comment">            ctxA </span></span><br><span class="line"><span class="comment">            ...</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">// 获取当前上下文信息</span></span><br><span class="line">    CUcontext current_context = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxGetCurrent</span>(&amp;current_context));             <span class="comment">// 这个时候current_context 就是上面创建的context</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;current_context = %p\n&quot;</span>, current_context);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 可以使用上下文堆栈对设备管理多个上下文</span></span><br><span class="line">    <span class="comment">// 压入当前context</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxPushCurrent</span>(ctxA));                        <span class="comment">// 将这个 ctxA 压入CPU调用的thread上。专门用一个thread以栈的方式来管理多个contexts的切换</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxGetCurrent</span>(&amp;current_context));             <span class="comment">// 获取current_context (即栈顶的context)</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;after pushing, current_context = %p\n&quot;</span>, current_context);</span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">        contexts 栈：</span></span><br><span class="line"><span class="comment">            ctxA -- top &lt;--- current_context</span></span><br><span class="line"><span class="comment">            ctxB</span></span><br><span class="line"><span class="comment">            ...</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 弹出当前context</span></span><br><span class="line">    CUcontext popped_ctx = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxPopCurrent</span>(&amp;popped_ctx));                   <span class="comment">// 将当前的context pop掉，并用popped_ctx承接它pop出来的context</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxGetCurrent</span>(&amp;current_context));              <span class="comment">// 获取current_context(栈顶的)</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;after poping, popped_ctx = %p\n&quot;</span>, popped_ctx);       <span class="comment">// 弹出的是ctxA</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;after poping, current_context = %p\n&quot;</span>, current_context); <span class="comment">// current_context是ctxB</span></span><br><span class="line"> </span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxDestroy</span>(ctxA));</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuCtxDestroy</span>(ctxB));</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 更推荐使用cuDevicePrimaryCtxRetain获取与设备关联的context</span></span><br><span class="line">    <span class="comment">// 注意这个重点，以后的runtime也是基于此, 自动为设备只关联一个context</span></span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuDevicePrimaryCtxRetain</span>(&amp;ctxA, device));       <span class="comment">// 在 device 上指定一个新地址对ctxA进行管理</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ctxA = %p\n&quot;</span>, ctxA);</span><br><span class="line">    <span class="built_in">checkDriver</span>(<span class="built_in">cuDevicePrimaryCtxRelease</span>(device));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 输出</span></span><br><span class="line"><span class="comment">ctxA = 0x560a174cce50</span></span><br><span class="line"><span class="comment">ctxB = 0x560a179c5810</span></span><br><span class="line"><span class="comment">current_context = 0x560a179c5810</span></span><br><span class="line"><span class="comment">after pushing, current_context = 0x560a174cce50</span></span><br><span class="line"><span class="comment">after poping, popped_ctx = 0x560a174cce50</span></span><br><span class="line"><span class="comment">after poping, current_context = 0x560a179c5810</span></span><br><span class="line"><span class="comment">ctxA = 0x560a174edbd0</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><p>编译</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc &#123;&#125;.cu -lcuda</span><br></pre></td></tr></table></figure><h2 id="MPS-多进程服务"><a href="#MPS-多进程服务" class="headerlink" title="MPS 多进程服务"></a>MPS 多进程服务</h2><p>CUDA MPS（Multi-Process Service）是一种允许多个进程共享单个 GPU 的技术。它允许在同一时间多个进程使用相同的GPU，从而提高GPU的利用率。通过在 GPU 上创建多个 CUDA 上下文来实现的。每个进程都可以创建自己的 CUDA 上下文，并且在这些上下文之间共享 GPU 资源。在 MPS 模式下，多个进程可以并发地使用 GPU，而不会互相干扰</p><p>在使用MPS时，需要在每个进程中创建一个CUDA上下文，并且这些上下文需要使用相同的 GPU 设备</p><p>开启 MPS 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-cuda-mps-control -d</span><br></pre></td></tr></table></figure><p>关闭 MPS 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-cuda-mps-control quit</span><br></pre></td></tr></table></figure><p>在使用 MPS 时，需要避免使用所有 GPU 资源，因为MPS需要一些 GPU 资源来管理多个CUDA上下文。可以使用 nvidia-smi 工具来检查 MPS 所使用的 GPU 资源</p></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/p/80c749f/" class="article-nav-link"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">Jax编程: 踩坑记录</div></a><a href="/p/5a01a3bf/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">CUDA编程: CUDA流,事件与同步</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li><a target="_blank" href=https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024 style="display:inline-block;text-decoration:none;"> <img src="/images/备案图标.webp" style="float:left;width:14px;height:14px;margin-top:2px;margin-right:-3px"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备32090202001024号</p><a target="_blank" href="https://beian.miit.gov.cn" style="display:inline-block;text-decoration:none"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">&nbsp苏ICP备2023045098号</p></a></li><li>Aeeeeeep Blog &copy; 2024</li><li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li><li>theme <a target="_blank" rel="noopener" href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes...</span><script>var now=new Date,grt=new Date("11/11/2021 00:08:39");function daysInYear(e){return e%4==0&&e%100!=0||e%400==0?366:365}function createTime(){now.setTime(now.getTime()+250);for(var e=0,t=new Date(grt.getTime());t<=now;){var n=daysInYear(t.getFullYear());t.setDate(t.getDate()+n),t<=now&&e++}t.setDate(t.getDate()-daysInYear(t.getFullYear()));var a=Math.floor((now-t)/864e5),r=now.getHours(),o=now.getMinutes(),i=r<10?"0"+r:r,g=o<10?"0"+o:o;document.getElementById("timeDate").innerHTML="Site has been running for "+e+"y "+a+"d ",document.getElementById("times").innerHTML=i+"h "+g+"m "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop" style="font-size:24px"><i class="fe fe-drop-up"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>