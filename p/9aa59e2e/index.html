<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>CUDA编程: CUDA内存管理（二） | Aeeeeeep Blog</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.3.0"></head><body><main class="content"><section class="outer"><article id="post-CUDA编程-CUDA内存管理（二）" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">CUDA编程: CUDA内存管理（二）</h1></header><div class="article-meta"><a href="/p/9aa59e2e/" class="article-date"><time datetime="2024-01-16T13:34:10.000Z" itemprop="datePublished">2024-01-16</time></a><div class="article-category"><a class="article-category-link" href="/categories/CUDA-%E7%BC%96%E7%A8%8B/">CUDA 编程</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>详细讲解共享内存存储体、存储体冲突、访问模式以及内存填充等知识点。</p><span id="more"></span><h2 id="CUDA-共享内存"><a href="#CUDA-共享内存" class="headerlink" title="CUDA 共享内存"></a>CUDA 共享内存</h2><p>GPU 的物理内存可以分为</p><ul><li>板载内存</li><li>片上内存</li></ul><p>全局内存就是板载内存，有较高的延时；共享内存就是较小的片上内存 ，有较低的延时。共享有比全局内存更高的带宽，可以把它当作一个可编程的缓存。共享内存通常的用途有</p><ul><li>块内线程通信的通道</li><li>用于全局内存数据的可编程管理的缓存</li><li>高速暂存存储器，用于转换数据，优化全局内存访问模式</li></ul><p>共享内存（Shared Memory, SMEM），在 GPU 中的位置如下图所示</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/1.webp" alt=""></p><p>每个 SM 都有一个小的内存池，这个内存池被当前正在该 SM 上执行的线程块中的所有线程所共享。SMEM 使同一个线程块中的线程能够互相协作，以重用片上数据，并可以大大降低核函数所需的全局内存带宽。由于 SMEM 中的内容是由应用程序显式管理的，所以是可编程管理的缓存</p><p>上图可以看到 SMEM 不需要经过 L1，相比 DRAM，延迟低 20~30 倍，带宽为 DRAM 的 10倍</p><p>在每个线程块被执行时会分配给它一些 SMEM，线程块执行完毕后 SMEM 释放，线程块和它的 SMEM 有相同的生命周期。每个线程束对 SMEM 的访问请求分为以下几种情况</p><ul><li><p>最好的情况是当前线程束中的每个线程都访问一个不冲突的共享内存，一个事务完成整个线程束的访问</p></li><li><p>最坏的情况是有冲突访问，每个线程束的 32 个线程需要不同的 32 个事务来完成</p></li><li><p>如果线程束内 32 个线程访问 SMEM 中的同一个地址，那么一个线程访问完后以广播的形式告诉其它线程</p></li></ul><p>一个 SM 上的所有的正在执行的线程块共会划分有限的 SMEM 资源，所以核函数使用的共享内存越多，那么处于并发活跃状态的线程块就越少</p><p>下面将围绕避免 SMEM 中多个事务访问冲突的问题展开讨论</p><h3 id="共享内存分配"><a href="#共享内存分配" class="headerlink" title="共享内存分配"></a>共享内存分配</h3><p>可以动态的或静态的声明使用共享内存的变量。共享内存变量在核函数中声明，作用域就只在核函数中，在核函数外声明，对所有核函数来说作用域都是全局的，我们可以声明一维，二维和三维的共享内存数组</p><p>使用<code>__shared__</code>修饰符来声明共享内存变量，下面声明了使用共享内存的一维，二维和三维浮点数组</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="type">float</span> a[*];</span><br><span class="line">__shared__ <span class="type">float</span> b[*][*];</span><br><span class="line">__shared__ <span class="type">float</span> c[*][*][*];</span><br></pre></td></tr></table></figure><p>这里的 <code>*</code> 必须是一个编译时确定的数字，不能是变量，如果共享内存的大小在编译时是未知的，也就是动态声明一个共享内存数组，使用<code>extern</code>关键字<br></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">int</span> d[];</span><br></pre></td></tr></table></figure><p></p><p>并将所需的大小按字节数作为三重括号内的第三个参数，<code>isize</code>为数组的中的元素个数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel&lt;&lt;&lt;grid, block, <span class="function">isize * <span class="title">sizeof</span><span class="params">(<span class="type">float</span>)</span>&gt;&gt;&gt;<span class="params">(...)</span></span>;</span><br></pre></td></tr></table></figure><p>注意这里的动态声明只支持一维数组</p><h3 id="共享内存存储体和访问模式"><a href="#共享内存存储体和访问模式" class="headerlink" title="共享内存存储体和访问模式"></a>共享内存存储体和访问模式</h3><p>优化内存性能的着重指标就是</p><ul><li>延时</li><li>带宽</li></ul><p>上面提到，共享内存隐藏了全局内存延迟，并且大大提高了带宽，所以了解共享内存的原理和特性会让我们更为清晰地使用共享内存</p><h4 id="共享内存存储体-bank"><a href="#共享内存存储体-bank" class="headerlink" title="共享内存存储体 (bank)"></a>共享内存存储体 (bank)</h4><p>为了获得高内存带宽，共享内存被分为 32 个同样大小的内存模型，称为存储体（bank），对应一个线程束中的 32 个线程，存储体可以同时被访问。并且共享内存是一个一维地址空间。根据 GPU 的计算能力，共享内存的地址在不同模式下会映射到不同的存储体中。</p><h4 id="存储体冲突（bank-conflict）"><a href="#存储体冲突（bank-conflict）" class="headerlink" title="存储体冲突（bank conflict）"></a>存储体冲突（bank conflict）</h4><p>如果线程束对共享内存有操作，且在个存储体上只请求访问最多一次，那么就由一个内存事务来完成，如果线程束在任意一个存储体上请求访问大于一次，就会由多个内存事务来完成，称为存储体冲突（bank conflict）</p><p>bank conflict 会导致请求被重复执行，GPU 会将存储体冲突的请求访问分割到尽可能多的独立的无冲突事务中，而独立内存事务的数量会直接影响内存带宽</p><p>线程束访问共享内存时有以下三种模式</p><ul><li><p>并行访问，多地址访问多存储体，带宽利用率最高</p><p>如下图所示是最完美的情况，线程束中每个线程对应一个存储体</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/2.webp" alt=""></p><p>如下图所示为不规则的访问模式，并行却不冲突，带宽利用率也是最高</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/3.webp" alt=""></p><p>如下图所示同样为不规则的访问模式，但如果线程访问的是同一个存储体中相同的地址，广播访问就不会冲突，如果线程访问的是同一个存储体中不同的地址，就会产生冲突</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/4.webp" alt=""></p></li><li><p>串行访问，多地址访问同一存储体，就会有对应 32 个线程的 32 个事务，带宽利用率最差</p></li><li><p>广播访问，单一地址读取单一存储体，线程束中所有的线程都读取同一存储体中相同的地址。一个内存事务执行后，那么被访问的字就会被广播到所有请求的线程中。虽然只有一个内存事务，但只有一小部分字节被读取，所以带宽利用率很差</p></li></ul><h4 id="访问模式"><a href="#访问模式" class="headerlink" title="访问模式"></a>访问模式</h4><p>共享内存存储体宽度（bank widths）直接影响访问模式，也就是每个存储体（bank）在一个时钟周期内的带宽，在计算能力 1.x 的设备中 bank widths 为 2 字节（16 位），计算能力 2.x 的设备中为 4 字节（32 位wjg），计算能力 3.x 以上的设备中为 8 字节（64 位）</p><p>对于计算能力为 2.0 的设备来说，bank widths 为 32 位，如下图所示就是共享内存的存储体的访问模式，字节地址除以 4 转换为 4 字节索引，再模 32，将 4 字节索引转换为存储体索引</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/5.webp" alt=""></p><p>上面的操作对应如下公式</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bank index = (Byte address ÷ <span class="number">4</span> byte/bank) % <span class="number">32</span> banks</span><br></pre></td></tr></table></figure><p>现今的 GPU 同时支持 64 位模式和 32 位模式。如果为 64 位模式，由于 SMEM 只有 32 个 bank，所以每个 bank 中的地址会被逻辑分成两侧，每个时钟周期内的每个 bank 都有 64 位的带宽，公式中的<code>byte/bank</code>就是 8。如下图所示是 64 位模式的几种情况，这也解释了为什么相比 32 位模式，其更不容易引起冲突</p><ul><li><p>每个线程访问不同的 bank，无 bank conflict</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/7.webp" alt=""></p></li><li><p>多个线程访问一个 bank 中同一侧的同一个地址，地址会广播到所有线程；两个线程访问同一个 bank，所以会无 bank conflict</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/8.webp" alt=""></p></li><li><p>两个线程访问同一个存储体的同一侧，为 bank conflict</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/9.webp" alt=""></p></li><li><p>同一个 bank 的左侧被两个线程同时访问了不同的地址，会导致三向的 bank conflict</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/10.webp" alt=""></p></li></ul><p>在现今 GPU 的 32 位模式下，由于 GPU 的每个时钟周期都是 64 带宽，所以 bank 中 32 位的数据需要 2 个时钟周期才能凑够 64 位，这也就使得两个线程读同一个 bank 时，如果读取的两个地址索引分别在两个不同的时钟周期被传输，就不会产生冲突，例如两个线程可以读<code>4-byte word index</code>为 0 和 32 的两个地址。如下图所示</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/6.webp" alt=""></p><p>cuda_runtime.h 提供了如下函数设置当前共享内存访问模式</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaDeviceSetSharedMemConfig</span> <span class="params">( cudaSharedMemConfig config )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>config</code>: 请求的缓存配置，枚举类型，有如下值<ul><li><code>cudaSharedMemBankSizeDefault = 0</code>: 设置 bank widths 为设备默认值</li><li><code>cudaSharedMemBankSizeFourByte = 1</code>: 设置 bank widths 为 4 字节（32 位）</li><li><code>cudaSharedMemBankSizeEightByte = 2</code>: 设置 bank widths 为 8 字节（64 位）</li></ul></li></ul><blockquote><p>注意<code>cudaDeviceSetSharedMemConfig</code>函数在固定共享内存大小的设备上无作用</p></blockquote><p>如下函数查询当前共享内存访问模式</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaDeviceGetSharedMemConfig</span> <span class="params">( cudaSharedMemConfig ** pConfig )</span></span></span><br></pre></td></tr></table></figure><p><code>pConfig</code>: 返回的缓存配置，枚举类型，有如下值</p><ul><li><code>cudaSharedMemBankSizeFourByte = 1</code>: bank widths 为 4 字节（32 位）</li><li><code>cudaSharedMemBankSizeEightByte = 2</code>: bank widths 为 8 字节（64 位）</li></ul><p>在不同的核函数启动之间更改共享内存的配置，可能需要一个隐式的设备同步点，更改共享内存存储体的大小对性能有重大的影响。更大的 bank widths 可能有更高的带宽，也可能导致更多的 bank conflict，需要实验得出</p><p>下面的代码简单地使用了上面两个函数，仅供参考，这里笔主的显卡固定了共享内存大小，无法演示</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printSharedMemConfig</span><span class="params">(<span class="keyword">enum</span> cudaSharedMemConfig &amp;sharedMemConfig)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (sharedMemConfig) &#123;</span><br><span class="line">        <span class="keyword">case</span> cudaSharedMemBankSizeDefault:</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Shared memory config: Default\n&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> cudaSharedMemBankSizeFourByte:</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Shared memory config: Bank size of 4 bytes\n&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> cudaSharedMemBankSizeEightByte:</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Shared memory config: Bank size of 8 bytes\n&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">cudaSharedMemConfig</span> sharedMemConfig;</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printSharedMemConfig</span>(sharedMemConfig);</span><br><span class="line">    <span class="built_in">cudaDeviceSetSharedMemConfig</span>(cudaSharedMemBankSizeEightByte);</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printSharedMemConfig</span>(sharedMemConfig);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="内存填充（memory-padding）"><a href="#内存填充（memory-padding）" class="headerlink" title="内存填充（memory padding）"></a>内存填充（memory padding）</h4><p>内存填充是避免存储单元冲突的一种方法。假设 5 个共享内存存储单元。如果所有线程访问 bank 0 的不同地址，那么会发生一个五向的存储单元冲突。解决这种存储单元冲突的一个方法是在每 5 个元素之后添加一个填充，改变从字到存储单元的映射，以错开访问每行数据</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/11.webp" alt=""></p><p>如上图所示，由于填充，之前所有属于 bank 0 的字，现在被传播到了不同的存储单元中。 填充的内存不能用于数据存储，其唯一的作用就是移动数据元素，以便将原来属于同一个存储单元中的数据分散到不同存储单元中。这样可以使得线程块可用的总共享内存的数量减少。 填充之后还需要根据前面的公式重新计算数组索引以确保能访问到正确的数据元素。例如下面的共享内存数组</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="type">int</span> a[<span class="number">5</span>][<span class="number">4</span>];</span><br></pre></td></tr></table></figure><p>我们可以更改声明以还原图例中的情况</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ <span class="type">int</span> a[<span class="number">5</span>][<span class="number">5</span>];</span><br></pre></td></tr></table></figure><h3 id="配置共享内存"><a href="#配置共享内存" class="headerlink" title="配置共享内存"></a>配置共享内存</h3><p>每个 SM 上有 64KB 的片上内存，SMEM 和 L1 共享这 64KB，并且可以配置，CUDA 为配置 L1 和 SMEM 提供以下两种方法</p><ul><li>按设备进行配置</li><li>按核函数进行配置</li></ul><p>为当前设备设置首选缓存配置</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaDeviceSetCacheConfig</span> <span class="params">( cudaFuncCache cacheConfig )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>cacheConfig</code>：请求的缓存配置，枚举类型</li><li><p><code>cudaFuncCachePreferNone = 0</code>: 默认函数缓存配置，无优先级</p></li><li><p><code>cudaFuncCachePreferShared = 1</code>: 首选更大的 SMEM 和更小的 L1 缓存</p></li><li><p><code>cudaFuncCachePreferL1 = 2</code>: 首选较大的 L1 缓存和较小的 SMEM</p></li><li><p><code>cudaFuncCachePreferEqual = 3</code>: 首选大小相同的 L1 缓存和 SMEM</p></li></ul><p>使用上面哪种更好要根据核函数使用了多少 SMEM</p><ul><li>SMEM 使用较多，那么首选更大的 SMEM</li><li>更多的寄存器使用，那么首选较大的 L1</li></ul><p>另一个函数是为当前核函数设置首选缓存配置</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaFuncSetCacheConfig</span> <span class="params">( <span class="type">const</span> <span class="type">void</span>* func, cudaFuncCache cacheConfig )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>func</code>: 设备函数指针</li><li><code>cacheConfig</code>: 请求的缓存配置</li></ul><p>L1 和 SMEM 虽然都在同一个片上，但是与 SMEM 的 bank 不同，L1 通过缓存行进行访问。我们可以完全控制 SMEM，但 L1 的删除工作是硬件完成的</p><p>GPU使用不同的启发式算法来处理数据。在GPU上，数百个线程共享相同的 L1，数千个线程共享有网的 L2。因此，数据处理在 GPU上可能会发生的更频繁而且更不可预知，所以使用 SMEM 不仅可以显式管理数据，还可以保证 SM 的局部性</p><h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>同步是并行的重要机制，其主要目的就是防止冲突。同步基本方法有</p><ul><li>障碍，是所有调用线程等待其余调用线程达到的障碍点</li><li>内存栅栏，所有调用线程必须等到全部内存修改对其余线程可见时才继续进行</li></ul><p>首先需要理解 CUDA 采用的弱排序内存模型</p><h4 id="弱排序内存模型"><a href="#弱排序内存模型" class="headerlink" title="弱排序内存模型"></a>弱排序内存模型</h4><p>CUDA 允许编译器大幅优化源代码以加速程序运行效率，这就会导致内存访问的顺序被改变，也就是说 GPU 线程在不同的内存，比如 SMEM，全局内存，锁页内存或对等设备内存中，写入数据的顺序是不一定和这些数据在源代码中访问的顺序相同。当线程的写入顺序对其他线程可见的时候，它可能和写操作被执行的实际顺序不一致。如果指令之间相互独立，线程从不同内存中读取数据和指令的顺序也不一定相同。在这种不正确情况下，为了保持内存管理的可控，必须在代码中使用障碍和内存栅栏以防止冲突</p><h4 id="显示障碍"><a href="#显示障碍" class="headerlink" title="显示障碍"></a>显示障碍</h4><p>CUDA 中，障碍点只对同一线程块内的线程执行，且只能设置在核函数中，使用如下函数设置一个障碍点</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> __syncthreads();</span><br></pre></td></tr></table></figure><p><code>__syncthreads()</code>作为一个障碍点，保证在同一线程块内所有线程没到达此障碍点时，不能继续向下执行，也就是阻塞 block 直至 block 内的线程全都执行到这一行。且在同一线程块内，此障碍点之前的所有全局内存，共享内存操作，对后面的线程都是可见的。</p><p><code>__syncthreads()</code>也可以解决同一线程块内，内存竞争的问题，保证执行的先后顺序</p><p>此外在条件语句中使用<code>__syncthreads()</code>，会导致无法预料的严重情况。如下面的代码，因块中的所有线程都没有达到相同的障碍点，会直接导致内核死锁</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (threadID % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">	__syncthreads();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	__syncthreads();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是<code>__syncthreads()</code>的局限就在于只能解决一个块内的线程同步，不能跨线程同步，线程块会以任何顺序，并行或串行地在任何 SM 上执行，线程块这种独立的特性使得 CUDA 在任意数量的核心中都是可扩展的，如果一个 CUDA 核函数要求线程块全局同步，那么只能结束核函数的运行来隐式的同步线程块</p><h4 id="内存栅栏"><a href="#内存栅栏" class="headerlink" title="内存栅栏"></a>内存栅栏</h4><p>内存栅栏能保证栅栏前的内核内存写操作对栅栏后的其他线程都是可见的，根据所需范围有以下三种栅栏</p><ul><li><p>线程块，在 block 内创建内存栅栏，阻塞线程束直至阻塞线程束发出的写操作完成，但由于阻塞线程束本身就是单指令多线程，该指令就没什么用</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  <span class="type">void</span> __threadfence_block();</span><br><span class="line"></span><br><span class="line">* 网格，在 grid 内创建内存栅栏，阻塞 grid 直至 grid 内的线程发出的读写操作完成，可以实现块间同步</span><br><span class="line"></span><br><span class="line">  ```cpp</span><br><span class="line">  <span class="type">void</span> __threadfence();</span><br></pre></td></tr></table></figure></li><li><p>系统，可以跨系统创建内存栅栏，挂起调用的线程，以确保该线程对全局内存、锁页主机内存和其他设备内存中的所有写操作对全部设备中的线程和主机线程是可见的</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> __threadfence_system();</span><br></pre></td></tr></table></figure></li></ul><h4 id="Volatile-修饰符"><a href="#Volatile-修饰符" class="headerlink" title="Volatile 修饰符"></a>Volatile 修饰符</h4><p>在全局或共享内存中使用 volatile 修饰符声明一个变量，阻止编译器优化，可以防止这个变量存入缓存，这个变量的任何引用都会直接被编译到全局内存中，忽略缓存。举例如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="type">float</span> vfloat;</span><br></pre></td></tr></table></figure><h2 id="共享内存的数据布局"><a href="#共享内存的数据布局" class="headerlink" title="共享内存的数据布局"></a>共享内存的数据布局</h2><p>这部分我们通过研究如何组织共享内存的数据布局，以达到更少的 bank conflict 和最佳的性能</p><h3 id="方形共享内存"><a href="#方形共享内存" class="headerlink" title="方形共享内存"></a>方形共享内存</h3><p>SMEM 可以直接缓存方形维度的全局数据，如下图所示，字节地址与存储体地址的逻辑映射图，在每个维度假设有 32 个元素，且按行主序进行存储</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/12.webp" alt=""></p><p>如下静态声明一个二维共享内存变量</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 32</span></span><br><span class="line">__shared__ <span class="type">int</span> a[N][N];</span><br></pre></td></tr></table></figure><p>我们可以用两种方式访问其中一个元素</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 行主序</span></span><br><span class="line">a[threadIdx.y][threadIdx.x];</span><br><span class="line"></span><br><span class="line"><span class="comment">//列主序</span></span><br><span class="line">a[threadIdx.y][threadIdx.x];</span><br></pre></td></tr></table></figure><p>行主序和列主序哪个效率更高，这取决于线程与共享内存存储体的映射关系。在一个线程束中的线程由连续的<code>threadIdx.x</code>来确定，也就是说，<code>threadIdx.y</code>对应上图中的 Row 行，<code>threadIdx.x</code>对应上图中的 Bank 列，而每个 bank 和线程束中的每个线程对应，邻近线程在最内层数组维度上访问相邻的阵列单元。因此，相比列主序，行主序有更好的性能和更少的 bank conflict</p><h4 id="行主序读写和列主序读写对比"><a href="#行主序读写和列主序读写对比" class="headerlink" title="行主序读写和列主序读写对比"></a>行主序读写和列主序读写对比</h4><p>下面的程序将全局线程索引值存入二维共享内存，再从共享内存中读取这些值并存到全局内存中，对比行主序和列主序</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X 32</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y 32</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadCol</span><span class="params">(<span class="type">int</span> * out)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">cudaSharedMemConfig</span> sharedMemConfig;</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, sharedMemConfig);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> nElem = DIM_X * DIM_Y;</span><br><span class="line">    <span class="type">int</span> nByte = <span class="built_in">sizeof</span>(<span class="type">int</span>)*nElem;</span><br><span class="line">    <span class="type">int</span> * out;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">int</span>**)&amp;out,nByte);</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(DIM_Y, DIM_X)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    </span><br><span class="line">    setRowReadRow&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out);</span><br><span class="line">    setColReadCol&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 4 字节访问模式下，因为相邻线程引用相邻字，可以看到按行访问使用的时间比列访问少了很多</p><p><img src="/image/CUDA编程-CUDA内存管理（二）/13.webp" alt=""></p><p>使用 <code>ncu --metrics l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum</code> 命令可以获取核函数运行阶段的共享内存加载事务数，<code>ncu --metrics l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum</code>命令可以获取共享内存存储事务数，关于<code>ncu --metrics</code>更多参数的具体解释可以看看<a href="https://aeeeeeep.top/2023/01/07/CUDA%E7%BC%96%E7%A8%8B%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7-metrics%E5%8F%82%E6%95%B0%E5%90%AB%E4%B9%89/">这篇博客</a></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadRow</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">32</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">32</span></span><br><span class="line"><span class="built_in">setColReadCol</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">1024</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">1024</span></span><br></pre></td></tr></table></figure><p>在对共享内存存储事务数/执行共享内存的访问次数，也就是二维共享内存的行<code>DIM_Y</code>，这里为 32，得到每次访问共享内存时的存储事务数 32/32 = 1，不会产生 bank conflict。但是在<code>setColReadCol</code>中每次访问共享内存时的存储事务数为 1024/32 = 32，会有 32 路 bank conflict，对应<code>DIM_Y=32</code>，就是因为<code>setRowReadRow</code>是邻近线程在最内层数组维度上访问相邻的阵列单元</p><p>下面的核函数为按行主序写和按列主序读</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadCol</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_X][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行上面两个核函数，可以看到冲突情况符合我们的理论，即邻近线程在最内层数组维度上访问相邻的阵列单元会减少冲突</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadCol</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">1024</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">32</span></span><br><span class="line"><span class="built_in">setColReadRow</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">32</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">1024</span></span><br></pre></td></tr></table></figure><p>设矩阵 size(4,4) 执行上面的四个核函数，输出<code>out</code>的值可以看到<code>setRowReadCol</code>和<code>setColReadRow</code>会对数组转置，这为之后我们将会讲到的转置算法作了基础</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X 4</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y 4</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadCol</span><span class="params">(<span class="type">int</span> * out)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadCol</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_X][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.x][threadIdx.y];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setColReadRow</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.x][threadIdx.y]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">enum</span> <span class="title class_">cudaSharedMemConfig</span> sharedMemConfig;</span><br><span class="line">    <span class="built_in">cudaDeviceGetSharedMemConfig</span>(&amp;sharedMemConfig);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, sharedMemConfig);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> nElem = DIM_X * DIM_Y;</span><br><span class="line">    <span class="type">int</span> nByte = <span class="built_in">sizeof</span>(<span class="type">int</span>)*nElem;</span><br><span class="line">    <span class="type">int</span> * out_h, * out_d;</span><br><span class="line">    out_h = (<span class="type">int</span>*)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">int</span>**)&amp;out_d,nByte);</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(DIM_Y, DIM_X)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setRowReadRow: &quot;</span>);</span><br><span class="line">    setRowReadRow&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setColReadCol: &quot;</span>);</span><br><span class="line">    setColReadCol&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setRowReadCol: &quot;</span>);</span><br><span class="line">    setRowReadCol&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;setColReadRow: &quot;</span>);</span><br><span class="line">    setColReadRow&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out_d);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(out_h, out_d, nByte, cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;nElem; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, out_h[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">setRowReadRow: <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> <span class="number">13</span> <span class="number">14</span> <span class="number">15</span> </span><br><span class="line">setColReadCol: <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> <span class="number">13</span> <span class="number">14</span> <span class="number">15</span> </span><br><span class="line">setRowReadCol: <span class="number">0</span> <span class="number">4</span> <span class="number">8</span> <span class="number">12</span> <span class="number">1</span> <span class="number">5</span> <span class="number">9</span> <span class="number">13</span> <span class="number">2</span> <span class="number">6</span> <span class="number">10</span> <span class="number">14</span> <span class="number">3</span> <span class="number">7</span> <span class="number">11</span> <span class="number">15</span> </span><br><span class="line">setColReadRow: <span class="number">0</span> <span class="number">4</span> <span class="number">8</span> <span class="number">12</span> <span class="number">1</span> <span class="number">5</span> <span class="number">9</span> <span class="number">13</span> <span class="number">2</span> <span class="number">6</span> <span class="number">10</span> <span class="number">14</span> <span class="number">3</span> <span class="number">7</span> <span class="number">11</span> <span class="number">15</span></span><br></pre></td></tr></table></figure><p>下面给出动态声明版本，前面提到过，动态共享内存数组只能是一维的，且要将所需大小按字节数作为核函数三重括号内的第三个参数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColDyn</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> row_idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=threadIdx.x*blockDim.y+threadIdx.y;</span><br><span class="line"></span><br><span class="line">    tile[row_idx]=row_idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[row_idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setRowReadColDyn&lt;&lt;&lt;grid, block, <span class="function">DIM_X * DIM_Y * <span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColDyn</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">1024</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">32</span></span><br></pre></td></tr></table></figure><h4 id="memory-padding"><a href="#memory-padding" class="headerlink" title="memory padding"></a>memory padding</h4><p>为了解决<code>setRowReadCol</code>，<code>setColReadRow</code>核函数的 bank conflict，我们要根据具体的数据分布来填充内存，在静态声明中，只需要将填充的列添加到二维共享内存分配中就可以了，代码如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PAD 1</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y][DIM_X+PAD];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[threadIdx.y][threadIdx.x];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setRowReadColPad&lt;&lt;&lt;grid,block&gt;&gt;&gt;(out);</span><br></pre></td></tr></table></figure><p>在动态声明中，由于需要执行二维线程索引到一维线程索引的转换，所以对于每一行，都要跳过填充的部分，代码如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PAD 1</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColDynPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> row_idx=threadIdx.y* (blockDim.x + PAD) +threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=threadIdx.x* (blockDim.y + PAD) +threadIdx.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> g_idx=threadIdx.y*blockDim.x +threadIdx.x;</span><br><span class="line"></span><br><span class="line">    tile[row_idx]=g_idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[g_idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setRowReadColDynPad&lt;&lt;&lt;grid, block, (DIM_X + PAD) * <span class="function">DIM_Y * <span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br></pre></td></tr></table></figure><p>使用 ncu 工具可以看到每次访问共享内存请求的事务数量为 1，无 bank conflict</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColPad</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">32</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">32</span></span><br><span class="line"><span class="built_in">setRowReadColDynPad</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">32</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">32</span></span><br></pre></td></tr></table></figure><h3 id="矩形共享内存"><a href="#矩形共享内存" class="headerlink" title="矩形共享内存"></a>矩形共享内存</h3><p>矩形共享内存和方形共享内存非常相似，不同的地方在于线程索引的要先映射为一维，保证访问是合并的</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br></pre></td></tr></table></figure><p>再通过二维方式访问，这里对原矩阵按列读取，irow 和 icol 对应的是转置后矩阵中的坐标</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br></pre></td></tr></table></figure><p>下面的程序将全局线程索引值存入二维共享内存，再从共享内存中读取这些值并存到全局内存中，对比行主序和列主序</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X_RECT 32</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y_RECT 16</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRect</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y_RECT][DIM_X_RECT];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[icol][irow];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 ncu 工具可以看到加载操作有 256/16 = 16 路冲突，而存储操作没有冲突</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColRect</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">256</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">16</span></span><br></pre></td></tr></table></figure><p>为了解决 bank conflict，下面给出 memory padding 版本的核函数，这里的<code>PAD_RECT=2</code>是因为将长方形矩阵一行有 16 个元素，为了满足 32 个存储体的数量，每次会访问两行的数据，所以要填充对应两行的 2 个元素以错开访问，而方形矩阵一行有 32 个元素，匹配 32 个存储体的数量，每行只需要填充一个数据即可错开访问</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PAD_RECT 2</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRectPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    __shared__ <span class="type">int</span> tile[DIM_Y_RECT][DIM_X_RECT+PAD_RECT];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    tile[threadIdx.y][threadIdx.x]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[icol][irow];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColRectPad</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">16</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">16</span></span><br></pre></td></tr></table></figure><p>下面再给出动态声明和 memory padding 版本的核函数供参考</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_X_RECT 32</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DIM_Y_RECT 16</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PAD_RECT 2</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRectDyn</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=icol*blockDim.x+irow;</span><br><span class="line">    tile[idx]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">setRowReadColRectDynPad</span><span class="params">(<span class="type">int</span> * out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx=threadIdx.y*blockDim.x+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> icol=idx%blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> irow=idx/blockDim.y;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> row_idx=threadIdx.y*(PAD_RECT+blockDim.x)+threadIdx.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> col_idx=icol*(PAD_RECT+blockDim.x)+irow;</span><br><span class="line">    tile[row_idx]=idx;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    out[idx]=tile[col_idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">block_rect</span><span class="params">(DIM_X_RECT,DIM_Y_RECT)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid_rect</span><span class="params">(<span class="number">1</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">setRowReadColRectDyn&lt;&lt;&lt;grid_rect,block_rect, <span class="function">DIM_X_RECT * DIM_Y_RECT*<span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br><span class="line">setRowReadColRectDynPad&lt;&lt;&lt;grid_rect,block_rect, (DIM_X_RECT+PAD_RECT) * <span class="function">DIM_Y_RECT*<span class="title">sizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;<span class="params">(out)</span></span>;</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">setRowReadColRectDyn</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">256</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">16</span></span><br><span class="line"><span class="built_in">setRowReadColRectDynPad</span>(<span class="type">int</span>*)</span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum	<span class="number">16</span></span><br><span class="line">	l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum	<span class="number">16</span></span><br></pre></td></tr></table></figure></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/p/d7bb3d7c/" class="article-nav-link"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">CUDA编程: CUDA内存管理（三）</div></a><a href="/p/aab372f6/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">CUDA编程: CUDA内存管理（一）</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li><a target="_blank" href=https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024 style="display:inline-block;text-decoration:none;"> <img src="/images/备案图标.webp" style="float:left;width:14px;height:14px;margin-top:2px;margin-right:-3px"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备32090202001024号</p><a target="_blank" href="https://beian.miit.gov.cn" style="display:inline-block;text-decoration:none"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">&nbsp苏ICP备2023045098号</p></a></li><li>Aeeeeeep Blog &copy; 2024</li><li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li><li>theme <a target="_blank" rel="noopener" href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes...</span><script>var now=new Date,grt=new Date("11/11/2021 00:08:39");function daysInYear(e){return e%4==0&&e%100!=0||e%400==0?366:365}function createTime(){now.setTime(now.getTime()+250);for(var e=0,t=new Date(grt.getTime());t<=now;){var n=daysInYear(t.getFullYear());t.setDate(t.getDate()+n),t<=now&&e++}t.setDate(t.getDate()-daysInYear(t.getFullYear()));var a=Math.floor((now-t)/864e5),r=now.getHours(),o=now.getMinutes(),i=r<10?"0"+r:r,g=o<10?"0"+o:o;document.getElementById("timeDate").innerHTML="Site has been running for "+e+"y "+a+"d ",document.getElementById("times").innerHTML=i+"h "+g+"m "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop" style="font-size:24px"><i class="fe fe-drop-up"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>