<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>CUDA编程: CUDA流,事件与同步 | Aeeeeeep Blog | The Gleaners</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.0.0"></head><body><main class="content"><section class="outer"><article id="post-CUDA编程-CUDA流-事件与同步" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">CUDA编程: CUDA流,事件与同步</h1></header><div class="article-meta"><a href="/2024/01/30/CUDA%E7%BC%96%E7%A8%8B-CUDA%E6%B5%81-%E4%BA%8B%E4%BB%B6%E4%B8%8E%E5%90%8C%E6%AD%A5/" class="article-date"><time datetime="2024-01-30T13:34:41.000Z" itemprop="datePublished">2024-01-30</time></a><div class="article-category"><a class="article-category-link" href="/categories/CUDA-%E7%BC%96%E7%A8%8B/">CUDA 编程</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>详细讲解 CUDA 流，事件的概念以及声明，以此为基础，深入了解 CUDA 流操作之间的依赖关系，流的同步与异步，以及如何优化事件的创建与管理等等。</p><span id="more"></span><h2 id="CUDA-流"><a href="#CUDA-流" class="headerlink" title="CUDA 流"></a>CUDA 流</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>CUDA 流是一系列异步的 CUDA 操作，这些操作按照主机代码所定义的顺序在设备上执行。流会封装这些操作，保持操作的顺序，允许操作在流中排队，并使它们在先前的所有操作之后执行。CUDA 流中的操作可以是主机与设备的内存数据传输，设备内核启动，主机和设备之间的同步等由主机发起但由设备处理的命令</p><p>在 CUDA 编程中，一般的执行模式如下</p><ul><li>将数据从主机传输到设备</li><li>在设备上执行内核</li><li>将结果从设备传输回主机</li></ul><p>因为不同的 CUDA 流中的操作是异步执行的，这使得它们可以并行运行，不会受到其它流中操作的影响，所以可以将内核执行和数据传输调度到不同的流中，完全隐藏CPU和GPU之间的通信延迟，提高程序的效率</p><p>流在 CUDA 的 API 调用粒度上可实现流水线或双缓冲技术。CUDA 的 API函数一般可以分为同步或异步。具有同步行为的函数会阻塞主机端线程，直到它们完成。具有异步行为的函数被调用后，会立即将控制权归还给主机</p><p>异步函数和流是在 CUDA 中构建网格级并发的基础。从软件上看，CUDA 操作在不同的流中并发运行，但从硬件上看，不总是如此。根据 PCIe 总线争用或每个SM资源的可用性，完成不同的 CUDA 流可能仍然需要互相等待。下面将详细了解在有多种计算能力的设备上，流是如何运行的</p><h3 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h3><p>所有的 CUDA 操作都是在流中进行的，流分为</p><ul><li>隐式声明（空流）</li><li>显式声明（非空流）</li></ul><p>如果没有显式地指定一个流，那么内核启动和数据传输将默认使用空流。在本章之前所有例子都是空流</p><p>基于流的异步内核启动和数据传输支持以下类型的粗粒度并发</p><ul><li>主机计算 - 设备计算</li><li>主机计算 - 主机与设备间的数据传输</li><li>设备计算 - 主机与设备间的数据传输</li><li>并发执行多个设备的计算</li></ul><p>我们首先要有一个概念，设备与主机是两个运算节点，以一般的 CUDA 程序举例，下面的 3 个操作会被发布到默认的流中，设备只需要按发布顺序执行，而其他主机上的操作设备一概不知</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="built_in">cudaMemcpy</span>(..., cudaMemcpyHostToDevice);</span><br><span class="line">kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(...);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(..., cudaMemcpyDeviceToHost);</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><p>但是主机要等待设备运算，数据向主机传输完成后才能执行后面的操作，也就是之前我们接触到的数据传输都是同步的。不同的是，内核启动是异步的，无论内核是否完成，主机的应用程序都立即恢复执行。</p><p>现在介绍一下异步的数据传输，下面是 <code>cudaMemcpy</code> 函数的异步版本</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaMemcpyAsync</span> <span class="params">( <span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span>* src, <span class="type">size_t</span> count, cudaMemcpyKind kind, cudaStream_t stream = <span class="number">0</span> )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>dst</code>：目标地址，指向要复制数据的位置</li><li><code>src</code>：源地址，指向要复制的数据的位置</li><li><code>count</code>：要复制的字节数。</li><li><code>kind</code>：指定复制的方向，可选值为<code>cudaMemcpyHostToDevice</code>、<code>cudaMemcpyDeviceToHost</code>、<code>cudaMemcpyDeviceToDevice</code>和<code>cudaMemcpyDefault</code></li><li><code>stream</code>：可选参数，指定将异步操作添加到的流</li></ul><p>其中<code>stream</code>默认被设置为空流。这个函数与主机是异步的，在调用发布后，控制权将立即返回到主机。</p><p>如果我们希望数据传输与非空流关联，可以使用下面的函数显式创建一个非空流</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaStreamCreate</span> <span class="params">( cudaStream_t* pStream )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>pStream</code>：指向新流标识符的指针</li></ul><p>返回到<code>pStream</code>中的流就可以被当作参数给其它异步 CUDA 的 API 函数使用。需要注意的是，当执行异步数据传输时，必须使用固定的主机内存，我们可以使用前面章节提到的两个函数分配固定内存</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMallocHost</span><span class="params">(<span class="type">void</span> **ptr, <span class="type">size_t</span> size)</span></span>;</span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaHostAlloc</span><span class="params">(<span class="type">void</span> **pHost, <span class="type">size_t</span> size, <span class="type">unsigned</span> <span class="type">int</span> flags)</span></span>;</span><br></pre></td></tr></table></figure><p>在非空流中启动内核，需要注意提供流标识符作为第四个参数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_name&lt;&lt;&lt;grid, block, sharedMemSize, stream&gt;&gt;&gt;(argument list);</span><br></pre></td></tr></table></figure><p>一个非空流声明与创建如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cudaStream_t stream;</span><br><span class="line"><span class="built_in">cudaStreamCreate</span>(&amp;stream);</span><br></pre></td></tr></table></figure><p>可以用如下代码释放流中的资源</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamDestroy</span><span class="params">(cudaStream_t stream)</span></span>;</span><br></pre></td></tr></table></figure><p>在一个流中，当 <code>cudaStreamDestroy</code> 函数被调用时，如果该流中仍有未完成的工作，<code>cudaStreamDestroy</code> 函数将立即返回，当流中所有工作都已完成时，与流相关的资源将被自动释放</p><p>因为所有流都是异步的，有两个专用的函数来检查流中的所有操作是否都已经完成</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamSynchronize</span><span class="params">(cudaStream_t stream)</span></span>;</span><br></pre></td></tr></table></figure><p><code>cudaStreamSynchronize</code>函数用于强制阻塞主机，直到给定流中的所有操作都完成</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamQuery</span><span class="params">(cudaStream_t stream)</span></span>;</span><br></pre></td></tr></table></figure><p><code>cudaStreamQuery</code>函数用于检查流中的所有操作是否都已经完成，但不会阻塞主机。当所有操作都完成时函数会返回<code>cudaSuccess</code>。否则返回<code>cudaErrorNotReady</code></p><p>下面这段代码是使用流的一个例子，在多个流中执行 CUDA 核函数和数据传输操作</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nStreams; i++) &#123;</span><br><span class="line">    <span class="type">int</span> offset = i * bytesPerStream;</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(&amp;d_a[offset], &amp;a[offset], bytePerStream, streams[i]);</span><br><span class="line">    kernel&lt;&lt;grid, block, <span class="number">0</span>, streams[i]&gt;&gt;(&amp;d_a[offset]);</span><br><span class="line">    <span class="built_in">cudaMemcpyAsync</span>(&amp;a[offset], &amp;d_a[offset], bytesPerStream, streams[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nStreams; i++) &#123;</span><br><span class="line">    <span class="built_in">cudaStreamSynchronize</span>(streams[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>流在 CUDA 中执行的时间轴如下图所示，H2D 是主机到设备的内存传输，D2H 是设备到主机的内存传输。数据传输和内核执行分布在 3 个并发流中，但是在执行时，数据传输并没有并发执行，这是因为 PCIe 总线是共享的，当第一个流占据了总线，后面的流就要等待总线空闲，但是如果 H2D 和 D2H 同时发生，就不会产生等待，而是同时进行</p><p><img src="/image/CUDA编程-CUDA流-事件与同步/1.png" alt=""></p><h2 id="流调度"><a href="#流调度" class="headerlink" title="流调度"></a>流调度</h2><p>前面我们说到，所有流都可以同时运行，但在硬件中没有流的概念，而是包含一个或多个执行内存拷贝操作的引擎和执行核函数的引擎。这些引擎彼此独立地对操作进行排队，这将导致如下图所示的任务调度情形</p><p><img src="/image/CUDA编程-CUDA流-事件与同步/5.png" alt=""></p><p>在不同流的操作中，存在相互的依赖，比如 memcpy A B C 为从主机拷贝数据到设备内存，kernel 需要等待 memcpy A B C 操作完成后再执行，Stream 1 需要等待 Stream 0 完成操作后再执行，如下图所示</p><p><img src="/image/CUDA编程-CUDA流-事件与同步/6.png" alt=""></p><p>为了避免这个问题，我们可以交错地执行不同流的拷贝内存操作和核函数运算操作，如下图所示</p><p><img src="/image/CUDA编程-CUDA流-事件与同步/7.png" alt=""></p><p>为了解决多个 Kernel 函数同时在 GPU 中运行的问题，节省代码编写成本，从 Kepler 架构开始，Nvidia 推出了 Hyper-Q 硬件技术，主机与设备之间最多可以建立 32 个工作队列，每个流分配一个工作队列，如果创建的流超过32个，则多个流共用一个工作队列</p><p>同时 Hyper-Q 技术还可以使不同流中的计算和使用带宽能够重叠，最大化 GPU 的资源利用率。例如 Stream1 中的计算要占用 60% 的核心和 60% 的显存带宽，而 Stream2 中的计算要占用 70% 的核心和 50% 的显存带宽，二者同时运行时会按一定的比率争用 GPU 资源</p><h2 id="流优先级"><a href="#流优先级" class="headerlink" title="流优先级"></a>流优先级</h2><p>对于计算能力在 3.5 以上的设备可以分配流的优先级，下面函数创建一个有指定优先级的流</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaStreamCreateWithPriority</span> <span class="params">( cudaStream_t* pStream, <span class="type">unsigned</span> <span class="type">int</span>  flags, <span class="type">int</span>  priority )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>pStream</code>：一个指向 <code>cudaStream_t</code> 类型的指针，用于存储创建的流的句柄</li><li><code>flags</code>：流的行为标志，可选参数，默认为0。当前支持的标志只有 <code>cudaStreamNonBlocking</code>，指定在创建的流中运行的工作可以与 Stream0（空流）中的工作同时运行，并且创建的流不应该与 Stream0 执行隐式同步</li><li><code>priority</code>：流的优先级，较低的数字代表较高的优先级。0 表示默认优先级。 可以使用 <code>cudaDeviceGetStreamPriorityRange</code> 查询有意义的数值优先级范围。 如果指定的优先级超出了 <code>cudaDeviceGetStreamPriorityRange</code> 返回的数值范围，它将自动被限制在范围内的最低或最高数字</li></ul><p>不同的设备有不同的优先级等级，下面函数可以查询当前设备的优先级分布情况</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaDeviceGetStreamPriorityRange</span> <span class="params">( <span class="type">int</span>* leastPriority, <span class="type">int</span>* greatestPriority )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>leastPriority</code>：指向整数的指针，返回设备支持的最低优先级</li><li><code>greatestPriority</code>：指向整数的指针，返回设备支持的最高优先级</li></ul><p>笔主的显卡优先级等级范围为 [0, -5]</p><h2 id="CUDA-事件"><a href="#CUDA-事件" class="headerlink" title="CUDA 事件"></a>CUDA 事件</h2><h3 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h3><p>CUDA 事件是 CUDA 流中的一个标记点，检查正在执行的流操作是否已经到达了该点。使用事件可以用来执行以下两个基本任务</p><ul><li>同步流的执行</li><li>监控设备的进展</li></ul><p>CUDA API 提供了在流中任意点插入事件以及查询事件完成的函数。只有当一个 CUDA 流中，事件标注点之前的所有操作都执行完成后，该事件才会完成，在默认流中的指定事件，适用于 CUDA 流中先前的所有操作</p><h3 id="声明-1"><a href="#声明-1" class="headerlink" title="声明"></a>声明</h3><p>一个 CUDA 事件声明如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t event;</span><br></pre></td></tr></table></figure><p>创建事件</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventCreate</span> <span class="params">( cudaEvent_t* event )</span></span></span><br></pre></td></tr></table></figure><p>销毁事件</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaEventDestroy</span> <span class="params">( cudaEvent_t event )</span></span></span><br></pre></td></tr></table></figure><p>如果回收指令执行的时候事件还没有完成，那么回收指令立即完成，当事件完成后，资源被回收</p><p>事件也可以看作是流的一次操作，通过下面函数排队添加到 CUDA 流</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaEventRecord</span> <span class="params">( cudaEvent_t event, cudaStream_t stream = <span class="number">0</span> )</span></span></span><br></pre></td></tr></table></figure><p>在流中的事件用于等待前面的操作完成，或测试流中操作的完成情况，可以使用下面的函数阻塞主机线程直到事件被完成，类似于<code>cudaStreamSynchronize</code>函数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventSynchronize</span> <span class="params">( cudaEvent_t event )</span></span></span><br></pre></td></tr></table></figure><p><code>cudaEventQuery</code>函数用于检查事件之前的所有操作是否都已经完成，但不会阻塞主机。当所有操作都完成时函数会返回<code>cudaSuccess</code>。否则返回<code>cudaErrorNotReady</code>。类似于<code>cudaStreamQuery</code></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventQuery</span> <span class="params">( cudaEvent_t event )</span></span></span><br></pre></td></tr></table></figure><h3 id="记录事件和计算运行时间"><a href="#记录事件和计算运行时间" class="headerlink" title="记录事件和计算运行时间"></a>记录事件和计算运行时间</h3><p>下面函数记录两个事件 start 和 stop 之间的时间间隔，毫秒单位。此外，这两个事件可以在不同流中</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaEventElapsedTime</span> <span class="params">( <span class="type">float</span>* ms, cudaEvent_t start, cudaEvent_t end )</span></span></span><br></pre></td></tr></table></figure><p>下面是一段记录事件时间间隔的示例代码，两个事件被插入到空流中，作为标记，然后记录他们之间的时间间隔。但是这里时间间隔可能会比实际大一些，因为这里用到 <code>cudaEventRecord</code> 函数是异步的，计算会有延时</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create two events</span></span><br><span class="line">cudaEvent_t start, stop;</span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;start);</span><br><span class="line"><span class="built_in">cudaEventCreate</span>(&amp;stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// record start event on the default stream</span></span><br><span class="line"><span class="built_in">cudaEventRecord</span>(start);</span><br><span class="line"></span><br><span class="line"><span class="comment">// execute kernel</span></span><br><span class="line">kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(arguments);</span><br><span class="line"></span><br><span class="line"><span class="comment">// record stop event on the default stream</span></span><br><span class="line"><span class="built_in">cudaEventRecord</span>(stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// wait until the stop event completes</span></span><br><span class="line"><span class="built_in">cudaEventSynchronize</span>(stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// calculate the elapsed time between two events</span></span><br><span class="line"><span class="type">float</span> time;</span><br><span class="line"><span class="built_in">cudaEventElapsedTime</span>(&amp;time, start, stop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// clean up the two events</span></span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(start);</span><br><span class="line"><span class="built_in">cudaEventDestroy</span>(stop);</span><br></pre></td></tr></table></figure><h2 id="流同步"><a href="#流同步" class="headerlink" title="流同步"></a>流同步</h2><p>在非空流中，所有操作对于主机来说都是并行的，如果我们想在某一刻等待，执行当前时刻所有操作同步，就会导致等待时资源的闲置，浪费性能</p><p>从主机的角度，CUDA 操作可以分为两类</p><ul><li>内核启动</li><li>内存操作</li></ul><p>其中内核启动总是异步的，内存操作可以是同步或异步</p><p>前面我们说到有两种类型的流，按同步异步分，又可分为</p><ul><li>同步流（空流）</li><li>异步流（非空流）</li></ul><p>显式声明的都是异步流，异步流通常不会阻塞主机。而在隐式声明的同步流中，部分操作会造成阻塞，让主机等待</p><p>异步流并不都是非阻塞的，可进一步分为如下两种类型</p><ul><li>阻塞流</li><li>非阻塞流</li></ul><p>如果一个异步流被声明为非阻塞的，就不会被空流阻塞，如果声明为阻塞流，则会被空流阻塞</p><h3 id="阻塞流与非阻塞流"><a href="#阻塞流与非阻塞流" class="headerlink" title="阻塞流与非阻塞流"></a>阻塞流与非阻塞流</h3><p><code>cudaStreamCreate</code>创建的是阻塞流，意味着流中的操作可以被阻塞，直到空流中某些操作完成。任何发布到阻塞流中的操作，都要等待空流中先前的操作执行结束才开始执行</p><p>举例代码如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kernel1&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, Stream1&gt;&gt;&gt;();</span><br><span class="line">Kernel2&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">Kernel3&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, Stream2&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure><p><code>Kernel1</code>在执行结束后才执行 <code>Kernel2</code>，<code>Kernel2</code> 执行结束后才执行 <code>Kernel3</code></p><p>下面的函数用于创建一个非阻塞流</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaStreamCreateWithFlags</span> <span class="params">( cudaStream_t* pStream, <span class="type">unsigned</span> <span class="type">int</span>  flags )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>pStream</code>：一个指向 <code>cudaStream_t</code> 类型的指针，用于存储创建的流的句柄</li><li><code>flags</code>：流的行为标志，可选参数，默认为0。当前支持的标志只有 <code>cudaStreamNonBlocking</code>，指定在创建的流中运行的工作可以与 Stream0（空流）中的工作同时运行，并且创建的流不应该与 Stream0 执行隐式同步</li></ul><h3 id="隐式同步"><a href="#隐式同步" class="headerlink" title="隐式同步"></a>隐式同步</h3><p>这里的同步也可以说是阻塞，例如在调用 <code>cudaMemcpy</code> 函数时，会隐式同步设备和主机，也可以说其它操作在数据传输完成前都会被阻塞。运行带有隐式同步行为的操作时会导致不必要的阻塞，造成性能下降。此外，如下与内存有关的操作都会有隐式同步，需要格外注意</p><ul><li>锁页主机内存分布</li><li>设备内存分配</li><li>设备内存初始化</li><li>同一设备上两地址之间的内存复制</li><li>一级缓存/共享内存配置修改</li></ul><h3 id="显式同步"><a href="#显式同步" class="headerlink" title="显式同步"></a>显式同步</h3><p>常见的显式同步有</p><ul><li>同步设备：<code>cudaDeviceSynchronize</code></li><li>同步流：<code>cudaStreamSynchronize</code>，<code>cudaStreamQuery</code></li><li>同步流中的事件：<code>cudaEventSynchronize</code>，<code>cudaEventQuery</code></li><li>使用事件跨流同步：<code>cudaEventRecord</code>，<code>cudaStreamWaitEvent</code></li></ul><p>其中，除了最后一个函数，其他我们都有所介绍</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaStreamWaitEvent</span> <span class="params">( cudaStream_t stream, cudaEvent_t event, <span class="type">unsigned</span> <span class="type">int</span>  flags = <span class="number">0</span> )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>stream</code>：要等待事件的 CUDA 流</li><li><code>event</code>：等待的 CUDA 事件</li><li><code>flags</code>：控制等待事件时的行为。可选参数，默认为 0。可以使用 <code>cudaEventBlockingSync</code>（阻塞同步）或<code>cudaEventDisableTiming</code>（禁用事件记录）等标志</li></ul><p>这个函数的作用是指定的流等待指定的事件，事件完成后流才能继续，其中的事件可以在任意流中，当在不同的流的时候，就实现了事件跨流同步</p><p>如下图所示，Stream2 在调用 <code>cudaStreamWaitEvent</code> 函数后执行跨流同步，确保 Stream1 创建的事件是满足依赖关系的</p><p><img src="/image/CUDA编程-CUDA流-事件与同步/8.png" alt=""></p><h3 id="可配置事件"><a href="#可配置事件" class="headerlink" title="可配置事件"></a>可配置事件</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ __device__ cudaError_t <span class="title">cudaEventCreateWithFlags</span> <span class="params">( cudaEvent_t* event, <span class="type">unsigned</span> <span class="type">int</span>  flags )</span></span></span><br></pre></td></tr></table></figure><ul><li><code>event</code>：指向<code>cudaEvent_t</code>类型的指针，用来存储创建的CUDA事件对象</li><li><code>flags</code>：用来指定事件对象的创建标志</li></ul><p>其中 flag 可选参数如下</p><ul><li><code>cudaEventDefault</code>：默认事件创建标志</li><li><code>cudaEventBlockingSync</code>：指定事件应该使用阻塞同步。 使用 <code>cudaEventSynchronize()</code> 等待使用此标志创建的事件的主机线程将阻塞，直到事件实际完成</li><li><code>cudaEventDisableTiming</code>：指定创建的事件不需要记录计时数据。 当与 <code>cudaStreamWaitEvent()</code> 和 <code>cudaEventQuery()</code> 一起使用时，使用指定此标志创建的事件和未指定 <code>cudaEventBlockingSync</code> 标志将提供最佳性能</li><li><code>cudaEventInterprocess</code>：指定创建的事件可以用作进程间事件，<code>cudaEventInterprocess</code> 必须与 <code>cudaEventDisableTiming</code> 一起指定</li></ul></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/2024/02/06/CUDA%E7%BC%96%E7%A8%8B-CUDA%E6%B5%81-%E5%B9%B6%E5%8F%91%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87/" class="article-nav-link"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">CUDA编程: CUDA流,并发与上下文</div></a><a href="/2024/01/23/CUDA%E7%BC%96%E7%A8%8B-CUDA%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%EF%BC%88%E4%B8%89%EF%BC%89/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">CUDA编程: CUDA内存管理（三）</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li><a target="_blank" href=https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024 style="display:inline-block;text-decoration:none;"> <img src="/images/备案图标.webp" style="float:left;width:14px;height:14px;margin-top:2px;margin-right:-3px"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备32090202001024号</p><a target="_blank" href="https://beian.miit.gov.cn" style="display:inline-block;text-decoration:none"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">&nbsp苏ICP备2023045098号</p></a></li><li>Aeeeeeep Blog | The Gleaners &copy; 2024</li><li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li><li>theme <a target="_blank" rel="noopener" href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes...</span><script>var now=new Date,grt=new Date("11/11/2021 00:08:39");function daysInYear(e){return e%4==0&&e%100!=0||e%400==0?366:365}function createTime(){now.setTime(now.getTime()+250);for(var e=0,t=new Date(grt.getTime());t<=now;){var n=daysInYear(t.getFullYear());t.setDate(t.getDate()+n),t<=now&&e++}t.setDate(t.getDate()-daysInYear(t.getFullYear()));var a=Math.floor((now-t)/864e5),r=now.getHours(),o=now.getMinutes(),i=r<10?"0"+r:r,g=o<10?"0"+o:o;document.getElementById("timeDate").innerHTML="Site has been running for "+e+"y "+a+"d ",document.getElementById("times").innerHTML=i+"h "+g+"m "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog | The Gleaners"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop"><i class="fe fe-rocket"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>