<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>CUDA编程: CUDA内存模型概述 | Aeeeeeep Blog | The Gleaners</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.0.0"></head><body><main class="content"><section class="outer"><article id="post-CUDA编程-CUDA内存模型概述" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">CUDA编程: CUDA内存模型概述</h1></header><div class="article-meta"><a href="/2024/01/02/CUDA%E7%BC%96%E7%A8%8B-CUDA%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/" class="article-date"><time datetime="2024-01-02T13:33:54.000Z" itemprop="datePublished">2024-01-02</time></a><div class="article-category"><a class="article-category-link" href="/categories/CUDA-%E7%BC%96%E7%A8%8B/">CUDA 编程</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>讲解 CUDA 内存层次结构，如寄存器，共享内存，纹理内存，全局内存等。</p><span id="more"></span><h2 id="内存层次结构"><a href="#内存层次结构" class="headerlink" title="内存层次结构"></a>内存层次结构</h2><p>首先了解一下应用程序遵循的局部性原则</p><ul><li><p>时间局部性</p><p>一个内存地址被访问，那么这个内存地址很可能会被多次访问，被访问的概率会随着时间逐渐降低</p></li><li><p>空间局部性</p><p>如果一个内存地址被访问，那么附近的地址也有可能被访问</p></li></ul><p>随着科技的发展，更低延时和低容量的内存层次结构被设计出来以提高计算机性能，内存结构变得复杂，诞生出了由多级带宽，容量组成的内存层次结构，如下图所示</p><p><img src="/image/CUDA编程-CUDA内存模型概述/1.png" alt=""></p><p>上述结构从下往上有如下特点</p><ul><li>更高的成本/bit</li><li>更低的容量</li><li>更低的延时</li><li>更高的访问频率</li></ul><p>CPU 的主存采用动态随机存储器（DRAM），更快的 CPU 一级缓存使用的是静态随机存储器（SRAM），当数据被频繁使用时，会保存在低延时、低容量的内存层次中，否则会保存在高延时，大容量的容器中。GPU 的主存和 CPU 一样使用 DRAM，内存层次结构也非常相似，与 CPU 内存模型不同的是，通过 CUDA，我们可以方便地控制 GPU 的内存</p><h2 id="CUDA-内存模型"><a href="#CUDA-内存模型" class="headerlink" title="CUDA 内存模型"></a>CUDA 内存模型</h2><p>CUDA 提供了多种可编程的不同类型的内存可以满足不同的计算需求。每种内存类型都有其特定的用途和性能特点</p><ul><li>寄存器（Registers）</li><li>共享内存（Shared Memory）</li><li>本地内存（Local Memory）</li><li>常量内存（Constant Memory）</li><li>纹理内存（Texture Memory）</li><li>全局内存（Global Memory）</li></ul><p><img src="/image/CUDA编程-CUDA内存模型概述/2.png" alt=""></p><p>如上图所示，每个核函数都有自己私有的本地内存，每个线程块有自己的共享内存，对同一线程块中所有的线程可见，其内容会持续线程块的整个生命周期。所有线程都可以访问全局内存。所有线程对常量内存和纹理内存都只读</p><p>在内存层次结构中，纹理内存为各种数据布局提供了不同的寻址模式和滤波模式，对于应用程序来说，全局内存、常量内存中的内容具有相同的生命周期</p><h2 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h2><p>寄存器是一种低容量、超高速度的内存类型，每个线程都可以使用寄存器来存储临时数据。当在核函数内的自变量没有其他修饰符，该变量就存储在寄存器中，在核函数中定义的的数组也存储在寄存器中</p><p>寄存器对于每个线程是私有的，核函数使用寄存器来通常保存被频繁使用的线程私有变量，寄存器变量的声明周期和核函数一致，执行完毕后，寄存器就不能访问了。</p><p>寄存器是 SM 中的较少资源，Fermi 架构中每个线程最多63个寄存器。Kepler结构扩展到255个寄存器，一个线程如果使用更少的寄存器，那么就会有更多的常驻线程块，SM上并发的线程块越多，效率越高，性能和使用率也就越高。</p><p>可以使用如下命令得到每个核函数运行时使用的寄存器数量、共享内存字节数以及每个线程所使用的常量内存和字节数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -Xptxas -v *.cu</span><br></pre></td></tr></table></figure><p>以第三章中的矩阵乘法和加法为例，输出表示编译器进行了两个操作：编译矩阵乘法函数<code>Z9MatrixMulP6MatrixS0_S0</code>和矩阵加法函数<code>Z9MatrixAddP6MatrixS0_S0</code>，分别针对<code>sm_52</code>架构，对于每个函数，都会输出函数属性，如堆栈帧大小、溢出存储和溢出加载的大小，并且报告使用的寄存器数量和全局内存<code>cmem[0]</code>大小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ptxas info    : 0 bytes gmem</span><br><span class="line">ptxas info    : Compiling entry <span class="keyword">function</span> <span class="string">&#x27;_Z9MatrixMulP6MatrixS0_S0_&#x27;</span> <span class="keyword">for</span> <span class="string">&#x27;sm_52&#x27;</span></span><br><span class="line">ptxas info    : Function properties <span class="keyword">for</span> _Z9MatrixMulP6MatrixS0_S0_</span><br><span class="line">    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads</span><br><span class="line">ptxas info    : Used 32 registers, 344 bytes cmem[0]</span><br><span class="line">ptxas info    : Compiling entry <span class="keyword">function</span> <span class="string">&#x27;_Z9MatrixAddP6MatrixS0_S0_&#x27;</span> <span class="keyword">for</span> <span class="string">&#x27;sm_52&#x27;</span></span><br><span class="line">ptxas info    : Function properties <span class="keyword">for</span> _Z9MatrixAddP6MatrixS0_S0_</span><br><span class="line">    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads</span><br><span class="line">ptxas info    : Used 18 registers, 344 bytes cmem[0]</span><br></pre></td></tr></table></figure><p>如果一个核函数使用了超过硬件数量的寄存器，会用本地内存代替多占用的寄存器。nvcc 会使用启发式策略来最小化寄存器的使用，为了避免寄存器溢出，可以在核函数的代码中配置额外的信息来辅助编译器优化，下面代码中的<code>maxThreadsPerBlock</code>意为每个块最多可以启动的线程数量，<code>minBlocksPerMultiprocessor</code>意为每个 SM 最少运行的线程块数量</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> __launch_bounds__ (maxThreadsPerBlock, minBlocksPerMultiprocessor)</span><br><span class="line"><span class="built_in">kernel_func</span> (...) &#123;</span><br><span class="line">	<span class="comment">//kernel body</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在调用下面的核函数时，最多可以使用 1024 个线程来执行该内核函数，在每个 SM 最少运行的线程块数量为 1</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> __launch_bounds__ (<span class="number">1024</span>, <span class="number">1</span>) <span class="built_in">MatrixAdd</span>(Matrix *A, Matrix *B, Matrix *C) &#123;</span><br><span class="line">        <span class="type">int</span> row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">        <span class="type">int</span> col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">        <span class="built_in">setValue</span>(C, row, col, <span class="built_in">getValue</span>(A, row, col) + <span class="built_in">getValue</span>(B, row, col));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以在编译时使用<code>-maxrregcount</code>来控制一个编译单元里所有核函数使用的寄存器的最大数量，但这可能会和<code>__launch_bounds__</code>产生冲突，如果使用<code>-maxrregcount</code>参数限制每个线程使用的寄存器数量为32，并且使用<code>__launch_bounds__</code>属性限制每个块可以启动的线程数量为1024，那么每个块中实际可以启动的线程数量就会受到限制，只能启动32个线程</p><h2 id="本地内存"><a href="#本地内存" class="headerlink" title="本地内存"></a>本地内存</h2><p>本地内存是每个线程私有的内存空间，用来存储线程私有的临时数据。核函数中符合存储在寄存器中但不能进入被核函数分配的寄存器空间中的变量将存储在本地内存中，以下几种变量可能存放在本地内存中的</p><ul><li>使用未知索引引用的本地数组</li><li>可能会占用大量寄存器空间的较大本地数组或者结构体</li><li>任何不满足核函数寄存器限定条件的变量</li></ul><p>本地内存本质上和全局内存存储在同一块存储区域，但本地内存为每个线程私有，且会比访问全局内存更快，对于2.0以上的设备，本地内存存储在每个 SM 的一级缓存和设备的二级缓存上</p><h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p>共享内存是一种由多个线程共同使用的内存，是线程之间相互通信的基本方式，用来存储临时数据和高频使用的数据。共享内存类似于 CPU 的一级缓存，但可被编程。每个 SM 都有一些由线程块分配的共享内存，因此，不能过度使用共享内存，否则可能会限制活跃线程束的数量。</p><p>共享内存在核函数内声明，生命周期和线程块一致，线程块运行开始，此块的共享内存被分配，当此块结束，则共享内存被释放</p><p>可以通过在核函数中使用<code>__shared__</code>修饰符将变量放在共享内存中</p><p>因为共享内存是线程块中线程都可以访问，且线程是并发执行的，所以当同一个线程块中的多个线程访问同一个内存地址时可能会发生以下情况</p><ul><li>线程 a 和线程 b 同时将同一数组中的数据拷贝到共享内存中，导致数据冲突</li><li>线程 a 和线程 b 同时计算 x 和 y 数组对应位置的和，并将结果存储到 z 数组中，导致结果不正确</li></ul><p>所以访问共享内存前必须使用如下的同步语句</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> __syncthreads();</span><br></pre></td></tr></table></figure><p>如果频繁使用以上语句让 SM 进入空闲状态，会影响性能</p><p>SM中的一级缓存和共享内存共享片上内存，片上内存（on-chip memory）是指位于GPU片上的内存，即与 SM 处理器相连的内存，包括一级缓存、共享内存和常量缓存等</p><p>片上内存的大小根据 SM 版本而不同，以本人电脑的 sm_52 版本为例，一级缓存和共享内存共享的片上内存大小默认为</p><ul><li>一级缓存：64KB</li><li>共享内存：32KB</li></ul><p>因此，sm_52 版本的 SM 中共享的片上内存大小为 64KB + 32KB = 96KB，默认通过静态划分，运行时可以通过下面语句进行设置分配方案</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaFuncSetCacheConfig</span><span class="params">(<span class="type">const</span> <span class="type">void</span> * func,<span class="keyword">enum</span> cudaFuncCache cacheConfig)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>func</code>: 指向内核函数的指针，表示需要设置缓存配置的内核函数</li><li><code>cudaFuncCache</code>: 表示内核函数的缓存配置，可以是以下值之一<ul><li><code>cudaFuncCachePreferNone</code>: 表示不使用缓存</li><li><code>cudaFuncCachePreferShared</code>: 表示优先使用共享内存</li><li><code>cudaFuncCachePreferL1</code>: 表示优先使用一级缓存</li><li><code>cudaFuncCachePreferEqual</code>: 表示优先使用 L1 缓存或共享内存，取决于哪个更快，使用该选项可能会带来额外的性能开销，不建议使用</li></ul></li></ul><p>下面的程序定义了一个用于设置缓存配置的函数<code>cudaFuncSetCacheConfig</code>，它接受一个指向CUDA函数的指针、一个预定义的缓存配置枚举值、一个备选的缓存配置枚举值作为参数，并返回一个错误码，还定义了一个空的内核函数<code>Kernel_func</code>用于演示</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置指定函数的缓存配置</span></span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaFuncSetCacheConfig</span><span class="params">(<span class="type">const</span> <span class="type">void</span> * func, <span class="keyword">enum</span> cudaFuncCache cacheConfig, <span class="keyword">enum</span> cudaFuncCache cacheConfigAlt)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 定义错误码</span></span><br><span class="line">  cudaError_t error = cudaSuccess;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用 CUDA 驱动 API 设置缓存配置</span></span><br><span class="line">  error = <span class="built_in">cudaFuncSetCacheConfig</span>(func, cacheConfig);</span><br><span class="line">  <span class="keyword">if</span> (error != cudaSuccess) &#123;</span><br><span class="line">    <span class="keyword">return</span> error;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用 CUDA 驱动 API 设置备用缓存配置</span></span><br><span class="line">  error = <span class="built_in">cudaFuncSetCacheConfig</span>(func, cacheConfigAlt);</span><br><span class="line">  <span class="keyword">if</span> (error != cudaSuccess) &#123;</span><br><span class="line">    <span class="keyword">return</span> error;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回成功</span></span><br><span class="line">  <span class="keyword">return</span> cudaSuccess;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">Kernel_func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 这是一个什么也不做的空内核</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 定义要设置的函数</span></span><br><span class="line">  <span class="type">void</span> *func = (<span class="type">void</span>*)Kernel_func;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 定义所需的缓存配置</span></span><br><span class="line">  <span class="keyword">enum</span> <span class="title class_">cudaFuncCache</span> cacheConfig = cudaFuncCachePreferL1;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 为函数设置缓存配置</span></span><br><span class="line">  cudaError_t error = <span class="built_in">cudaFuncSetCacheConfig</span>(func, cacheConfig, cudaFuncCachePreferNone);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 检查错误</span></span><br><span class="line">  <span class="keyword">if</span> (error != cudaSuccess) &#123;</span><br><span class="line">    <span class="comment">// 打印错误消息并退出</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Error setting cache configuration: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(error));</span><br><span class="line">    <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Success!\n&quot;</span>);</span><br><span class="line">  <span class="comment">// 缓存配置设置成功</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常量内存"><a href="#常量内存" class="headerlink" title="常量内存"></a>常量内存</h2><p>常量内存驻留在设备内存中，每个SM都有专用的常量内存缓存，可以通过在核函数中使用<code>__constant__</code>修饰符将变量放在常量内存中</p><p>常量内存需要在核函数外，全局范围内声明，对于所有设备，只可以声明 64KB 的常量内存，常量内存是静态声明的，主机端代码可以初始化常量内存，初始化后不能被核函数修改，并且对同一编译单元中的所有核函数可见，相关函数将数据从主内存复制到常量缓存（constant memory）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMemcpyToSymbol</span><span class="params">(<span class="type">const</span> <span class="type">void</span>* symbol,<span class="type">const</span> <span class="type">void</span> *src,<span class="type">size_t</span> count)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>symbol</code>: 指向常量缓存的指针，常量缓存是一种特殊的内存类型，用于存储在编译时不变的变量</li><li><code>src</code>: 指向主内存中的数据的指针，要复制的数据必须位于主内存中，因为SM处理器无法直接访问主内存</li><li><code>count</code>: 要复制的数据的字节数</li></ul><p>下面的程序在常量内存中定义了一个名为 <code>a</code> 的常量数组，并通过 <code>cudaMemcpyToSymbol</code> 函数将一个主机上的数组 <code>h_a</code> 复制到该常量数组中</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line">__constant__ <span class="type">int</span> a[<span class="number">100</span>];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> h_a[<span class="number">100</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++)</span><br><span class="line">        h_a[i] = i;</span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(a, h_a, <span class="built_in">sizeof</span>(h_a));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="纹理内存"><a href="#纹理内存" class="headerlink" title="纹理内存"></a>纹理内存</h2><p>纹理内存是一种用来存储纹理数据的内存类型，在每个 SM 的只读缓存中缓存，纹理内存是通过指定的缓存访问的全局内存，只读缓存包括硬件滤波的支持，它可以将浮点插入作为读取过程中的一部分来执行，纹理内存是对二维空间局部性的优化，所以通常用来存储渲染图像和视频的数据，同时对于某些需要滤波的程序性能更好，可以直接通过硬件完成计算</p><p>定义一个 CUDA 纹理对象需要使用<code>cudaCreateTextureObject</code> 函数，解释如下</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaCreateTextureObject</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    cudaTextureObject_t *pTexObject,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> cudaResourceDesc *pResDesc,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> cudaTextureDesc *pTexDesc,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> cudaResourceViewDesc *pResViewDesc</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br></pre></td></tr></table></figure><ul><li><code>pTexObject</code>：指向一个 <code>cudaTextureObject_t</code> 类型的指针，用于存储新创建的纹理对象</li><li><code>pResDesc</code>：指向一个 <code>cudaResourceDesc</code> 类型的指针，用于描述纹理资源</li><li><code>pTexDesc</code>：指向一个 <code>cudaTextureDesc</code> 类型的指针，用于描述纹理对象的属性</li><li><code>pResViewDesc</code>：指向一个 <code>cudaResourceViewDesc</code> 类型的指针，用于描述纹理视图的属性</li></ul><p>更具体的解释请看<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TEXTURE__OBJECT.html#group__CUDART__TEXTURE__OBJECT_1g16ac75814780c3a16e4c63869feb9ad3">官方文档</a></p><p>下面的代码创建了一个二维数据简单地模拟图像使用纹理内存</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义 CUDA 内核函数，名为 transformKernel</span></span><br><span class="line"><span class="comment">// 该函数有三个输入参数：</span></span><br><span class="line"><span class="comment">// - output：浮点型指针，指向结果数组</span></span><br><span class="line"><span class="comment">// - texObj：cudaTextureObject_t 类型，表示一个 CUDA 纹理对象</span></span><br><span class="line"><span class="comment">// - width 和 height：表示纹理对象的宽度和高度</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transformKernel</span><span class="params">(<span class="type">float</span>* output, cudaTextureObject_t texObj, <span class="type">int</span> width, <span class="type">int</span> height)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 计算当前线程的纵横坐标</span></span><br><span class="line">    <span class="type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果超出纹理对象的范围，则退出该函数</span></span><br><span class="line">    <span class="keyword">if</span> ( x&lt;<span class="number">0</span> || x&gt;width || y&lt;<span class="number">0</span> || y&gt;height )</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="comment">// 在纹理对象中查找 (x+0.5, y+0.5) 处的值，并将其赋值给 output 数组对应的位置</span></span><br><span class="line">    output[ y*width+x ] = <span class="built_in">tex2D</span>&lt;<span class="type">float</span>&gt;(texObj, x+<span class="number">0.5f</span>, y+<span class="number">0.5f</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定义纹理对象的尺寸</span></span><br><span class="line">    <span class="type">int</span> width = <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span> height = <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span> size = width*height*<span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分配内存空间给源数据</span></span><br><span class="line">    <span class="type">float</span> *h_data = <span class="keyword">new</span> <span class="type">float</span>[width*height];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化原始数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> y = <span class="number">0</span>; y&lt;height; y++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x&lt;width; x++) &#123;</span><br><span class="line">                h_data[y*width + x] = x;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印原始数据</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;old:\n&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> y = <span class="number">0</span>; y&lt;height; y++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x&lt;width; x++) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%f &quot;</span>, h_data[y*width + x]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建一个用于存储源数据的 CUDA 数组</span></span><br><span class="line">    cudaChannelFormatDesc channelDesc = <span class="built_in">cudaCreateChannelDesc</span>(<span class="number">32</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, cudaChannelFormatKindFloat);</span><br><span class="line">    cudaArray* cuArray;</span><br><span class="line">    <span class="built_in">cudaMallocArray</span>(&amp;cuArray, &amp;channelDesc, width, height);</span><br><span class="line">    <span class="comment">// 将源数据复制到 CUDA 数组中</span></span><br><span class="line">    <span class="built_in">cudaMemcpyToArray</span>(cuArray, <span class="number">0</span>, <span class="number">0</span>, h_data, size,cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定义一个 cudaResourceDesc 结构体，用于描述纹理资源</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">cudaResourceDesc</span> resDesc;</span><br><span class="line">    <span class="comment">// 将该结构体的所有字段清零</span></span><br><span class="line">    <span class="built_in">memset</span>(&amp;resDesc, <span class="number">0</span>, <span class="built_in">sizeof</span>(resDesc));</span><br><span class="line">    <span class="comment">// 设置纹理资源的类型为数组资源</span></span><br><span class="line">    resDesc.resType = cudaResourceTypeArray;</span><br><span class="line">    <span class="comment">// 设置纹理资源所指向的数组</span></span><br><span class="line">    resDesc.res.array.array = cuArray;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定义一个 cudaTextureDesc 结构体，用于描述纹理对象</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">cudaTextureDesc</span> texDesc;</span><br><span class="line">    <span class="comment">// 将该结构体的所有字段清零</span></span><br><span class="line">    <span class="built_in">memset</span>(&amp;texDesc, <span class="number">0</span>, <span class="built_in">sizeof</span>(texDesc));</span><br><span class="line">    <span class="comment">// 设置纹理坐标超出纹理范围时的采样模式</span></span><br><span class="line">    texDesc.addressMode[<span class="number">0</span>] = cudaAddressModeBorder;</span><br><span class="line">    texDesc.addressMode[<span class="number">1</span>] = cudaAddressModeBorder;</span><br><span class="line">    <span class="comment">// 设置纹理采样滤波模式</span></span><br><span class="line">    texDesc.filterMode = cudaFilterModeLinear;</span><br><span class="line">    <span class="comment">// 设置纹理的读取模式</span></span><br><span class="line">    texDesc.readMode = cudaReadModeElementType;</span><br><span class="line">    <span class="comment">// 设置纹理坐标是否归一化</span></span><br><span class="line">    texDesc.normalizedCoords = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定义一个 cudaTextureObject_t 类型的变量，表示纹理对象</span></span><br><span class="line">    cudaTextureObject_t texObj = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 使用纹理资源和纹理描述创建纹理对象</span></span><br><span class="line">    <span class="built_in">cudaCreateTextureObject</span>(&amp;texObj, &amp;resDesc, &amp;texDesc, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分配内存给存储结果数据的数组</span></span><br><span class="line">    <span class="type">float</span>* output;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;output, size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算线程块和网格的维度</span></span><br><span class="line">    <span class="function">dim3 <span class="title">dimBlock</span><span class="params">(<span class="number">4</span>, <span class="number">4</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">dimGrid</span><span class="params">( max( (width  + dimBlock.x - <span class="number">1</span>) / dimBlock.x,<span class="number">1</span>),</span></span></span><br><span class="line"><span class="params"><span class="function">                      max( (height + dimBlock.y - <span class="number">1</span>) / dimBlock.y,<span class="number">1</span>) )</span></span>;</span><br><span class="line">    <span class="comment">// 执行 CUDA 内核函数</span></span><br><span class="line">    transformKernel &lt;&lt;&lt;dimGrid, dimBlock &gt;&gt;&gt;(output, texObj, width, height);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果数据从 GPU 拷贝到 CPU 上</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(h_data, output, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印结果数据</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;new:\n&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> y = <span class="number">0</span>; y&lt;height; y++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x&lt;width; x++) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%f &quot;</span>,h_data[y*width + x]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 销毁纹理对象</span></span><br><span class="line">    <span class="built_in">cudaDestroyTextureObject</span>(texObj);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放 CUDA 数组的内存</span></span><br><span class="line">    <span class="built_in">cudaFreeArray</span>(cuArray);</span><br><span class="line">    <span class="comment">// 释放结果数据的内存</span></span><br><span class="line">    <span class="built_in">cudaFree</span>(output);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放原始数据的内存</span></span><br><span class="line">    <span class="keyword">delete</span>[]h_data;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>纹理内存这部分知识点偏多，后面有机会和大家细细道来</p><h2 id="全局内存"><a href="#全局内存" class="headerlink" title="全局内存"></a>全局内存</h2><p>全局内存也可以说是 GPU 的主存。它是 GPU 内存层次结构中最大容量、最高延时的内存类型，它的声明可以在所有 SM 设备上被访问到，并且与程序同生命周期，全局变量支持静态声明和动态声明</p><p>可以通过在核函数中使用<code>__device__</code>修饰符将变量放在全局内存中</p><p>我们在第三章中的所有程序在 GPU 上访问的内存都是全局内存，因为线程的执行不能跨线程块同步，当有多个线程并发地修改全局内存的同一位置时，会导致未定义的程序行为</p><p>全局内存访问必须是自然对齐的，也就是一次要读取 32 的整数倍字节的内存，所以当线程束执行内存加载或存储时，需要满足的传输数量通常取决于</p><ul><li>跨线程的内存地址分布</li><li>内存事务的对齐方式。</li></ul><p>一般满足内存请求的事务越多，未使用的字节被传输的可能性越大，数据吞吐量就会降低，也可以说，对齐的读写模式使得不需要的数据也被传输，所以，利用率低到时吞吐量下降。过去的设备因为没有足够的缓存，对内存访问要求非常严格，现在要求宽松了一些</p><h2 id="GPU-缓存"><a href="#GPU-缓存" class="headerlink" title="GPU 缓存"></a>GPU 缓存</h2><p>在 CUDA 中，GPU 缓存是不可编程的内存，有如下四种缓存</p><ul><li>一级缓存</li><li>二级缓存</li><li>只读常量缓存</li><li>只读纹理缓存</li></ul><p>每个 SM 都有一个一级缓存，所有 SM 公用一个二级缓存，一级和二级缓存都被用来存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。CUDA 允许我们配置读操作的数据是使用一级缓存和二级缓存，还是只使用二级缓存</p><p>CPU 读写过程都有可能被缓存，与 CPU 不同的是，GPU 写的过程不被缓存，只有读取会被缓存，每个 SM 有一个只读常量缓存，只读纹理缓存，它们用于设备内存中提高来自于各自内存空间内的读取性能</p><h2 id="CUDA-变量声明总结"><a href="#CUDA-变量声明总结" class="headerlink" title="CUDA 变量声明总结"></a>CUDA 变量声明总结</h2><p>下面总结了 CUDA 变量声明和它们相应的存储位置、作用域、生命周期和修饰符</p><div class="table-container"><table><thead><tr><th>修饰符</th><th>变量名称</th><th>存储器</th><th>作用域</th><th>生命周期</th></tr></thead><tbody><tr><td></td><td><code>float var</code></td><td>寄存器</td><td>线程</td><td>线程</td></tr><tr><td></td><td><code>float var[100]</code></td><td>本地</td><td>线程</td><td>线程</td></tr><tr><td><code>__shared__</code></td><td><code>float var +</code></td><td>共享</td><td>块</td><td>块</td></tr><tr><td><code>__device__</code></td><td><code>float var +</code></td><td>全局</td><td>全局</td><td>应用程序</td></tr><tr><td><code>__constant__</code></td><td><code>float var +</code></td><td>常量</td><td>全局</td><td>应用程序</td></tr></tbody></table></div><blockquote><p><code>float var +</code> 表示标量或数组</p></blockquote><p>下面总结了各类存储器的主要特征</p><div class="table-container"><table><thead><tr><th>存储器</th><th>片上/片外</th><th>缓存</th><th>存取</th><th>范围</th><th>生命周期</th></tr></thead><tbody><tr><td>寄存器</td><td>片上</td><td>N/A</td><td>R/W</td><td>一个线程</td><td>线程</td></tr><tr><td>本地</td><td>片外</td><td>+</td><td>R/W</td><td>一个线程</td><td>线程</td></tr><tr><td>共享</td><td>片上</td><td>N/A</td><td>R/W</td><td>块内所有线程</td><td>块</td></tr><tr><td>全局</td><td>片外</td><td>+</td><td>R/W</td><td>所有线程 + 主机</td><td>主机配置</td></tr><tr><td>常量</td><td>片外</td><td>Yes</td><td>R</td><td>所有线程 + 主机</td><td>主机配置</td></tr><tr><td>纹理</td><td>片外</td><td>Yes</td><td>R</td><td>所有线程 + 主机</td><td>主机配置</td></tr></tbody></table></div><blockquote><p><code>+</code> 表示计算能力在 2.X 以上的 GPU 支持</p></blockquote><h2 id="静态全局内存"><a href="#静态全局内存" class="headerlink" title="静态全局内存"></a>静态全局内存</h2><p>我们在第三章中使用 cudaMalloc 函数申请的都是动态内存，也就是动态分配，在 CUDA 中也支持静态内存，也可以说是静态分配，与动态分配相同，需要显式的将内存拷贝到设备端，需要使用的函数如下</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaMemcpyToSymbol</span> <span class="params">( <span class="type">const</span> <span class="type">void</span>* symbol, <span class="type">const</span> <span class="type">void</span>* src, <span class="type">size_t</span> count, <span class="type">size_t</span> offset = <span class="number">0</span>, cudaMemcpyKind kind = cudaMemcpyHostToDevice )</span></span></span><br></pre></td></tr></table></figure><p>从 CPU 内存中的变量值复制到 GPU 的全局内存中</p><ul><li><code>symbol</code>: 要复制数据的标识符，指的是定义在 GPU 的全局内存中的变量，不是变量地址</li><li><code>src</code>: 源数据的地址</li><li><code>count</code>: 要复制的数据的字节数</li><li><code>offset</code>: 目标标识符中的偏移量，表示从符号的哪个位置开始复制数据</li><li><code>kind</code>: 复制数据的类型，可以是 <code>cudaMemcpyHostToDevice</code> 或 <code>cudaMemcpyDeviceToHost</code></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__host__ cudaError_t <span class="title">cudaMemcpyFromSymbol</span> <span class="params">( <span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span>* symbol, <span class="type">size_t</span> count, <span class="type">size_t</span> offset = <span class="number">0</span>, cudaMemcpyKind kind = cudaMemcpyDeviceToHost )</span></span></span><br></pre></td></tr></table></figure><p>将 GPU 的全局内存中的变量值复制到 CPU 内存中</p><ul><li>dst：目标数据的地址</li><li>symbol：要复制数据的标识符，指的是定义在 GPU 的全局内存中的变量，不是变量地址</li><li>count：要复制的数据的字节数</li><li>offset：源标识符中的偏移量，表示从符号的哪个位置开始复制数据</li><li>kind：复制数据的类型，可以是 <code>cudaMemcpyHostToDevice</code> 或 <code>cudaMemcpyDeviceToHost</code></li></ul><p>举例程序如下</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line">__device__ <span class="type">float</span> devData;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">checkGlobalVariable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Device: The value of the global variable is %f\n&quot;</span>,devData);</span><br><span class="line">    devData+=<span class="number">2.0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> value=<span class="number">3.1415926f</span>;</span><br><span class="line">    <span class="built_in">cudaMemcpyToSymbol</span>(devData,&amp;value,<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Host: copy %f to the global variable\n&quot;</span>,value);</span><br><span class="line">    checkGlobalVariable&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">cudaMemcpyFromSymbol</span>(&amp;value,devData,<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Host: the value changed by the kernel to %f \n&quot;</span>,value);</span><br><span class="line">    <span class="built_in">cudaDeviceReset</span>();</span><br><span class="line">    <span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在以上代码中，如果使用如下代码拷贝是无效的，因为动态拷贝的方法无法对静态变量赋值</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpy</span>(&amp;value,devData,<span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br></pre></td></tr></table></figure><p>但是可以使用 <code>cudaGetSymbolAddress</code> 函数获取设备的全局变量的地址，而不能使用 <code>&amp;</code> 直接取地址，之后 再使用 <code>cudaMemcpy</code> 将值拷贝到主机上</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> *dptr=<span class="literal">NULL</span>;</span><br><span class="line"><span class="built_in">cudaGetSymbolAddress</span>((<span class="type">void</span>**)&amp;dptr,devData);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(dptr,&amp;value,<span class="built_in">sizeof</span>(<span class="type">float</span>),cudaMemcpyHostToDevice);</span><br></pre></td></tr></table></figure><p>有一个例外，CUDA 固定内存可以直接从主机引用 GPU 内存，下一章节我们将详细了解</p></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/2024/01/09/CUDA%E7%BC%96%E7%A8%8B-CUDA%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/" class="article-nav-link"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">CUDA编程: CUDA内存管理（一）</div></a><a href="/2023/12/26/CUDA%E7%BC%96%E7%A8%8B-PyCUDA%E7%BC%96%E7%A8%8B%E7%AE%80%E4%BB%8B/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">CUDA编程: PyCUDA编程简介</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li><a target="_blank" href=https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024 style="display:inline-block;text-decoration:none;"> <img src="/images/备案图标.webp" style="float:left;width:14px;height:14px;margin-top:2px;margin-right:-3px"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备32090202001024号</p><a target="_blank" href="https://beian.miit.gov.cn" style="display:inline-block;text-decoration:none"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">&nbsp苏ICP备2023045098号</p></a></li><li>Aeeeeeep Blog | The Gleaners &copy; 2024</li><li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li><li>theme <a target="_blank" rel="noopener" href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes...</span><script>var now=new Date,grt=new Date("11/11/2021 00:08:39");function daysInYear(e){return e%4==0&&e%100!=0||e%400==0?366:365}function createTime(){now.setTime(now.getTime()+250);for(var e=0,t=new Date(grt.getTime());t<=now;){var n=daysInYear(t.getFullYear());t.setDate(t.getDate()+n),t<=now&&e++}t.setDate(t.getDate()-daysInYear(t.getFullYear()));var a=Math.floor((now-t)/864e5),r=now.getHours(),o=now.getMinutes(),i=r<10?"0"+r:r,g=o<10?"0"+o:o;document.getElementById("timeDate").innerHTML="Site has been running for "+e+"y "+a+"d ",document.getElementById("times").innerHTML=i+"h "+g+"m "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog | The Gleaners"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop" style="font-size:24px"><i class="fe fe-drop-up"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>