<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>论文阅读: ZeRO-Offload: Democratizing Billion-Scale Model Training | Aeeeeeep Blog | The Gleaners</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 5.4.2"></head><body><main class="content"><section class="outer"><article id="post-论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">论文阅读: ZeRO-Offload: Democratizing Billion-Scale Model Training</h1></header><div class="article-meta"><a href="/2023/10/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/" class="article-date"><time datetime="2023-10-17T15:31:16.000Z" itemprop="datePublished">2023-10-17</time></a><div class="article-category"><a class="article-category-link" href="/categories/%E6%87%B5%E9%80%BC%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">懵逼的深度学习</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>ZeRO-Offload 主要优化在于尽量减少数据在 GPU 与 CPU 之间的移动，并减少 CPU 计算时间，同时最大限度地节省 GPU 上的内存。</p><span id="more"></span><p>原文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2101.06840.pdf">https://arxiv.org/pdf/2101.06840.pdf</a></p><p>开源代码：<a target="_blank" rel="noopener" href="https://github.com/microsoft/deepspeed">https://github.com/microsoft/deepspeed</a></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>使用 Pytorch 训练内存不够，单个 V100 上性能为 30 TFlops</p><p>目前的分布式训练框架动辄需要超过 10w 刀的设备，难以在单卡上发挥作用</p><p>对于基于注意力机制的 LLM 训练，内存瓶颈主要在模型状态上</p><p>现有的异构训练方法主要利用 CPU 内存，而忽略了 CPU 的计算潜力</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>ZeRO-Offload 优化：尽量减少数据在 GPU 与 CPU 之间的移动，并减少 CPU 计算时间，同时最大限度地节省 GPU 上的内存</p><p>单个 V100 上性能提高到 40 TFlops，在 128 卡上实现接近线性加速，对比MP，模型规模增加了 4.5 倍</p><p>ZeRO-Offload 利用了CPU内存和计算资源进行 Offload，并与 ZeRO-DP 相结合</p><h3 id="Efficiency"><a href="#Efficiency" class="headerlink" title="Efficiency"></a>Efficiency</h3><p>论文提出了一种名为Efficiency的offload策略，通过分析确定了CPU和GPU设备之间的最佳计算和数据划分策略，以在三个关键方面达到最优化：</p><ul><li>在CPU上的计算量比GPU少多个数量级，防止CPU性能瓶颈；</li><li>最小化CPU和GPU之间的通信量，防止通信瓶颈；</li><li>在实现最小通信量的同时，可证明地最大化节约GPU内存。</li></ul><p>分析表明，要在上述方面达到最优，必须将梯度、优化器状态和优化器计算卸载到CPU上，同时在 GPU 上保留参数、前向和反向计算。这种策略使模型规模增加了10倍，并且通信量最小。能够在一块 V100 GPU上训练130亿参数模型，性能为 40 TFLOPS，而没有 CPU offload 的情况下只能训练12亿参数模型，且性能只有30 TFLOPS。</p><p>offload 优化器计算要求CPU进行O(M)次计算，而GPU需进行O(MB)次计算，其中M和B分别为模型规模和 batch size 。在大多数情况下， batch size 较大，CPU计算量并不是瓶颈，但对于小 batch size，CPU计算量可能成为瓶颈。为了解决这个问题，采取了两种优化措施：</p><ul><li>高效的CPU优化器，其速度比现有技术快6倍；</li><li>延迟一步的参数更新，允许将CPU优化器步骤与GPU计算重叠，同时确保准确性。这两种措施共同保证了ZeRO-Offload在小 batch size 下也能保持效率。</li></ul><h3 id="Unique-Optimal-Offload-Strategy"><a href="#Unique-Optimal-Offload-Strategy" class="headerlink" title="Unique Optimal Offload Strategy"></a>Unique Optimal Offload Strategy</h3><p>为了确定最佳的下载策略，ZeRO-Offload将深度学习训练建模为数据流图，并使用基于第一原理的分析方法将该图分割为CPU和GPU设备之间的部分。</p><p>ZeRO-Offload 在以下三个关键方面优化了图的分割策略</p><ul><li>要求更少数量级的CPU计算，以防止CPU成为性能瓶颈；</li><li>确保最小化CPU和GPU内存之间的通信量；</li><li>可证明地实现最小通信量的同时最大化内存节省。</li></ul><p>训练的计算复杂度通常为O(MB)，其中M为模型大小，B为有效batch size。为避免CPU计算成为瓶颈，只有那些计算复杂度低于O(MB)的计算才能转移到CPU上</p><p>FWD 和 BWD 的计算复杂度都是O(MB)，必须在GPU上进行，而其余的计算，如范数计算、权重更新等，其复杂度为O(M)，可以转移到CPU上</p><p>基于此，数据流图中的前向传播和反向传播节点合并为一个 FWD-BWD Super Node 并分配到 GPU 上</p><p>还需要最小化 CPU 与 GPU 的通信带宽，如图中所示，最小通信量为 BWD后 GPU 发送到 CPU 的 2M 梯度与 CPU 发送到 GPU 的 2M 参数，只有将 fp32 模型状态（momentum 32、variance 32和p32），Param Update 和 float2half 计算放置在一起，为一个 CPU 上的 Update Super Node，才能达成最小通信量策略</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/1.webp" width="800"></p><p>另外，上图中 2M 大小的 parameter 16 为什么分别到 FWD 与 BWD 有总和 4M 的数据传输，这个问题如有朋友知道，欢迎评论区讨论</p><p>实验依据如下</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/2.webp" width="500"></p><p>总之，ZeRO-Offload 策略就是将所有的 fp32 模型状态和 fp16 梯度存储在 CPU 内存中，并在 CPU 上计算参数更新。而 fp16 参数则保留在GPU上，前向和反向计算在GPU上进行</p><h2 id="ZeRO-Offload-Schedule"><a href="#ZeRO-Offload-Schedule" class="headerlink" title="ZeRO-Offload Schedule"></a>ZeRO-Offload Schedule</h2><h3 id="单卡策略"><a href="#单卡策略" class="headerlink" title="单卡策略"></a>单卡策略</h3><p>ZeRO-Offload将数据进行分区，将fp16参数存储在GPU上，fp16梯度和所有优化器状态（如fp32动量、方差和参数）存储在CPU上。</p><p>在训练过程中，首先通过 FWD 计算损失。由于fp16参数已经位于GPU上，因此这部分计算不需要与CPU进行通信。</p><p>在 BWD 过程中，不同参数的梯度在后向调度的不同位置计算。ZeRO-Offload可以立即将这些梯度逐个或切分传输到 CPU 内存中。</p><p>因此，在将梯度传输到CPU内存之前，只需要在GPU内存中临时保存少量的梯度。此外，每个梯度传输可以与反向计算重叠，消除大部分通信成本。</p><p>在 BWD 之后，ZeRO-Offload在CPU上直接更新fp32参数和剩余的优化器状态（如动量和方差），并将更新后的 fp32 参数从 CPU 内存复制到 GPU 内存中的fp16参数中。</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/3.webp" width="800"></p><p>上图展示了 ZeRO-Offload 每个步骤中的计算通信过程，下图伪代码展示了具体的调度过程</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/4.webp" width="500"></p><h3 id="多卡策略"><a href="#多卡策略" class="headerlink" title="多卡策略"></a>多卡策略</h3><p>ZeRO-Offload 将梯度和优化器状态在不同的 GPU 之间进行 partition，并且每个 GPU 将自己的 part offload 到 CPU 内存中，存储持续整个训练过程</p><p>BWD 过程中，在 GPU 上 reduce-scatter 计算梯度并平均，每个 GPU 仅将属于其 part 的平均梯度 offload 到 CPU 内存中</p><p>一旦梯度在 CPU 上可用，优化器状态 part 对应的每个 DP 进程直接在 CPU 上并行更新对应的参数 part</p><p>更新完成后，参数 part 发送到 GPU，在 GPU 上对参数进行类似 ZeRO-2 的 all-gather 操作</p><p>下面是 ZeRO-Offload 的多卡数据布局示意图</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/5.webp" width="800"></p><p>此外，ZeRO-Offload 还可以与 MP 和 Megatron-LM 同时使用，通过 offload MP 进程对应的梯度、优化器状态和优化器计算实现</p><h2 id="Optimized-CPU-Execution"><a href="#Optimized-CPU-Execution" class="headerlink" title="Optimized CPU Execution"></a>Optimized CPU Execution</h2><h3 id="Implementing-the-CPU-Optimizer"><a href="#Implementing-the-CPU-Optimizer" class="headerlink" title="Implementing the CPU Optimizer"></a>Implementing the CPU Optimizer</h3><p>优化 CPU Optimizer 性能</p><ul><li>使用SIMD向量指令</li><li>循环展开</li><li>OMP 多线程并行计算</li><li>混合精度训练</li></ul><p>在混合精度训练模式下，内存中的参数有两个版本</p><ul><li>FP32 版本，用于优化器在 CPU 上进行更新</li><li>浮点转换 FP32 后用于在 FWD 中计算激活的 FP16，用于GPU</li></ul><p>此外，梯度的动量和方差也以 FP32 保存在 CPU 上，防止在更新参数时出现精度丢失</p><p>论文中的 adam 实现使用了 SIMD，通过将数据读入向量寄存器并使用多个融合乘加操作（FMA）构成主执行流水线，SIMD 矢量宽度由 simd_width 指定，并结合循环展开，自动调优的 unroll_width 为 8</p><p>同时，对计算的数据按 tile_width 分区，将 CPU上计算好的 FP32 数据 part 转换为 FP16 拷贝到 GPU 中，同时在 CPU 上计算下一个 数据 part，实现通信计算 overlap</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/6.webp" width="600"></p><h3 id="One-Step-Delayed-Parameter-Update（DPU）"><a href="#One-Step-Delayed-Parameter-Update（DPU）" class="headerlink" title="One-Step Delayed Parameter Update（DPU）"></a>One-Step Delayed Parameter Update（DPU）</h3><p>在 DPU 训练过程中，首先在前 N-1 个步骤中进行训练，避免在训练的早期阶段梯度变化较快时破坏训练的稳定性。</p><p>在第N步，从 GPU 获取梯度，但跳过 CPU 优化器步骤，也不更新 GPU 上的 fp16 参数。</p><p>在第 N+1 步，使用第N步的梯度在CPU上计算参数更新，在GPU上并行计算前向和后向传播，使用第 N-1 步更新的参数。</p><p>从这一步开始，每个步骤的模型将使用从 i-1 步更新的参数进行训练，实现了 CPU 与 GPU 的计算重叠</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/7.webp" width="1000"></p><p>作者通过对多个训练工作评估发现，如果在几十次迭代之后引入 DPU，不会对收敛产生影响</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>硬件配置</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/8.webp" width="500"></p><p>实验模型：GPT-2、BERT</p><p>实验数据集：SQuAD</p><p>对比框架：PyTorch DDP、Megatron、L2L、ZeRO</p><p>模型配置</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/9.webp" width="500"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>图7 在单个GPU，4个GPU和16个GPU（一个DGX-2节点）上可训练的最大模型参数量对比</p><p>图8 在 batch size 为 512 的单个GPU上使用 PyTorch，L2L 和 ZeRO-Offload 训练的 TFLOPS 对比</p><p>图9 使用 DPU 和不使用 DPU 的情况下，与 GPT-2 训练的 TFLOPS（batch_size = 8） 对比</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/10.webp" width="800"></p><p>图10 针对不同模型大小，使用PyTorch、ZeRO-2、MegatronLM、ZeRO-Offload（无 MP）以及ZeRO-Offload（有 MP）训练的 TFLOPS 对比</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/11.webp" width="600"></p><p>图11 针对不同 GPU 数量，ZeRO-2 和 ZeRO-Offload 的 TFLOPS 对比，从 64 卡开始 ZeRO-2 优于 ZeRO-Offload 是因为 ZeRO-2 没有 CPU-GPU 通信的额外开销</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/12.webp" width="600"></p><p>本文优化过的 CPU-Adam 与 PT-GPU 性能差距并不大，不会成为性能瓶颈</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/13.webp" width="600"></p><p>实验表明 DPU 策略在训练与微调上不会影响精度，最终的 F1 分数都是 0.92</p><p><img src="/image/论文阅读-ZeRO-Offload-Democratizing-Billion-Scale-Model-Training/14.webp" width="600"></p></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/" rel="tag">分布式训练框架</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/2023/10/11/%E8%AE%B0%E5%BD%95%E7%AC%ACn%E6%AC%A1%E4%BF%AE%E5%A4%8DUSB%E8%AE%BE%E5%A4%87%E6%97%A0%E6%B3%95%E8%AF%86%E5%88%AB%E6%8C%82%E8%BD%BD/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">记录第n次修复USB设备无法识别挂载</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li>Aeeeeeep Blog | The Gleaners &copy; 2023</li><li><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024" style="display:inline-block;text-decoration:none;height:20px;line-height:20px"><img src="/images/备案图标.webp" style="float:left"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备 32090202001024号</p></a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes, and seconds...</span><script>var now=new Date;function createTime(){var n=new Date("11/11/2021 00:08:39");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Site has been running for "+dnum+" d ",document.getElementById("times").innerHTML=hnum+" h "+mnum+" m "+snum+" s "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog | The Gleaners"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop"><i class="fe fe-rocket"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>