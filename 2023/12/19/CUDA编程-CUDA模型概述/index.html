<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>CUDA编程: CUDA模型概述 | Aeeeeeep Blog | The Gleaners</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 7.0.0"></head><body><main class="content"><section class="outer"><article id="post-CUDA编程-CUDA模型概述" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">CUDA编程: CUDA模型概述</h1></header><div class="article-meta"><a href="/2023/12/19/CUDA%E7%BC%96%E7%A8%8B-CUDA%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/" class="article-date"><time datetime="2023-12-19T13:33:20.000Z" itemprop="datePublished">2023-12-19</time></a><div class="article-category"><a class="article-category-link" href="/categories/CUDA-%E7%BC%96%E7%A8%8B/">CUDA 编程</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>讨论 GPU 的并行计算是如何在硬件上实现的，CUDA 中的模块理解以及 CPU和 GPU 之间的交互，指令的同步。</p><span id="more"></span><h2 id="GPU-架构与异构并行计算"><a href="#GPU-架构与异构并行计算" class="headerlink" title="GPU 架构与异构并行计算"></a>GPU 架构与异构并行计算</h2><h3 id="什么是异构并行计算"><a href="#什么是异构并行计算" class="headerlink" title="什么是异构并行计算"></a>什么是异构并行计算</h3><p>最初的计算机只包含中央处理器，为了处理越来越复杂的图形计算，GPU 营运而生，因其数据众多的轻量级线程，非常适合处理大规模异构并行计算。</p><p>下图所示是一个典型的异构并行架构，包括一个 CPU及其内存 和一个 GPU及其内存，GPU 设备端通过 PCIe 总线与基于 CPU 主机端进行交互。一个异构并行应用包括主机代码和设备代码，分别运行在主机端和设备端。应用由 CPU 初始化，在设备端进行数据运算前，CPU 负责管理设备端的环境，代码和数据。我们称 host 为 CPU 及其内存，device 为 GPU 及其内存。</p><p><img src="/image/CUDA编程-CUDA模型概述/0.png" alt=""></p><p>CPU 计算适合处理控制密集型任务，GPU 计算适合处理包含数据并行的计算密集型任务。在 CPU 上执行串行部分或任务并行部分，在 GPU 上执行数据密集型并行部分，这种异构并行架构使得计算能力可以充分被利用。</p><h3 id="NVIDIA-GPU-显卡架构发展历程"><a href="#NVIDIA-GPU-显卡架构发展历程" class="headerlink" title="NVIDIA GPU 显卡架构发展历程"></a>NVIDIA GPU 显卡架构发展历程</h3><ul><li><strong>Tesla</strong>（特斯拉）2008年，应用于早期的 CUDA 系列显卡芯片中，并不是真正意义上的 GPU 芯片。</li><li><strong>Fermi</strong>（费米）2010年，是第一个完整的 GPU 计算架构。首款可支持与共享存储结合纯 cache 层次的 GPU 架构，支持 ECC(Error Correcting Code) 的 GPU 架构。</li><li><strong>Kepler</strong>（开普勒）2012年，Fermi 的优化版。</li><li><strong>Maxwell</strong>（麦克斯韦）2014年，首次支持实时的动态全局光照效果，</li><li><strong>Pascal</strong>（帕斯卡）2016年，GPU 将处理器和数据集成在同一个程序包内，以实现更高的计算效率。</li><li><strong>Volta</strong>（伏打）2017年，首次将一个 CUDA 内核拆分为FP32 和 INT32 两部分，首次支持混合精度运算，提高了5倍于 Pascal 计算速度，还增加了专用于深度学习的 Tensor Core 张量单元。</li><li><strong>Turing</strong>（图灵）2018年，增加了 RT Core 专用光线追踪处理器，将实时光线追踪运算加速至上一代架构的 25 倍，并能以高出 CPU 30 多倍的速度进行电影效果的最终帧渲染。去掉了对 FP64 计算的支持。</li><li><strong>Ampere</strong>（安培）2020年，重新支持 FP64，新增异步拷贝指令能够从 global memory 中将数据直接加载到 SM shared memory，降低中间寄存器堆（RF）的需求。新增 BF16 数据类型，专为深度学习优化。</li></ul><h2 id="CUDA-编程模型"><a href="#CUDA-编程模型" class="headerlink" title="CUDA 编程模型"></a>CUDA 编程模型</h2><p>CUDA 是一个通用并行计算平台和编程模型，如下图所示，CUDA 平台可以通过 CUDA 加速库、编译器指令、应用程序编程接口或编程语言接口来使用。后面的章节我们会重点讲解 CUDA C 以及 PyCUDA 的编程。</p><p><img src="/image/CUDA编程-CUDA模型概述/1.png" alt=""></p><h3 id="CUDA-软件体系"><a href="#CUDA-软件体系" class="headerlink" title="CUDA 软件体系"></a>CUDA 软件体系</h3><p>CUDA 提供了两层 API 来调用底层 GPU 硬件</p><ul><li><p>CUDA 驱动 API (CUDA Driver API)</p><p>是一种基于句柄的底层接口,大多数对象通过句柄被引用,其函数前缀均为<code>cu</code>，在调用 Driver API 前必须进行初始化，再创建 CUDA 上下文，该上下文关联到特定设备并成为主机线程的当前上下文，通过加载 PTX 汇编形式 或 二进制对象形式 的内核，然后启动内核计算。Driver API 可以通过直接操作硬件执行一些复杂的功能，但其编程较为复杂，难度较大。</p></li><li><p>CUDA 运行时 API (CUDA Runtime API)</p><p>Runtime API 对 Driver API 进行了一定的封装，隐藏了部分实现细节，因此使用起来更为方便，因此我们更多使用的是 Runtime API。Runtime API 没有专门的初始化函数，它将在第一次调用运行时函数时自动完成初始化。使用时，通常需要包含头文件 <code>cuda_runtime.h</code>，其函数前缀均为cuda。</p></li></ul><p>如下图所示</p><p><img src="/image/CUDA编程-CUDA模型概述/2.png" alt=""></p><p>Runtime API 和 Driver API 之间没有明显的性能差距，这两种 API 不能混合使用，只用单独使用其一。</p><h3 id="CUDA-函数库-CUDA-Libraries"><a href="#CUDA-函数库-CUDA-Libraries" class="headerlink" title="CUDA 函数库 (CUDA Libraries)"></a>CUDA 函数库 (CUDA Libraries)</h3><p>CUDA 提供了几个较为成熟的高效函数库，可以直接调用这些库函数进行计算，常见的包括</p><ul><li><p>CUFFT：利用 CUDA 进行傅立叶变换的函数库</p></li><li><p>CUBLAS：利用 CUDA 进行加速的完整标准矩阵与向量的运算库</p></li><li><p>CUDPP：并行操作函数库</p></li><li><p>CUDNN：利用CUDA进行深度卷积神经网络</p></li></ul><h3 id="CUDA-应用程序-CUDA-Application"><a href="#CUDA-应用程序-CUDA-Application" class="headerlink" title="CUDA 应用程序 (CUDA Application)"></a>CUDA 应用程序 (CUDA Application)</h3><p>CUDA 程序包含在 host 上运行的主机代码和在 device 上运行的设备代码，设备代码会在编译时通过 CUDA nvcc 编译器从主机代码中分离，再转换成 PTX(ParallelThread Execution) 汇编语言，由 GPU 并行线程执行，主机代码由 CPU 执行。如下图所示</p><p><img src="/image/CUDA编程-CUDA模型概述/3.png" alt=""></p><p>执行流程如下</p><ul><li><p>分配 host 内存，并进行数据初始化（CPU初始化）</p></li><li><p>分配 device 内存，并从 host 将数据拷贝到 device 上（GPU初始化）</p></li><li><p>调用 CUDA 的核函数在 device 上完成指定的运算（GPU并行运算）</p></li><li><p>将 device上的运算结果拷贝到 host 上（将GPU结果传回CPU）</p></li><li><p>释放 device 和 host 上分配的内存（初始化清空）</p></li></ul><h3 id="CUDA-硬件结构"><a href="#CUDA-硬件结构" class="headerlink" title="CUDA 硬件结构"></a>CUDA 硬件结构</h3><ul><li><p>SP（Streaming Processor）也称为 CUDA core，是最基本的处理单元，最后具体的指令和任务都是在 SP 上处理的。GPU 进行并行计算，也就是很多个 SP 同时做处理。</p></li><li><p>SM（Streaming Multiprocessor）多个 SP 加上其他资源组成一个 SM，也叫 GPU 大核，其他资源如包括warp scheduler，register，shared memory 等。SM可以看做GPU的心脏（类似 CPU 核心）。每个 SM 都拥有 register 和 shared memory，CUDA 将这些资源分配给所有驻留在 SM 中的线程，但资源非常有限，SM 结构如下图所示。</p></li></ul><p><img src="/image/CUDA编程-CUDA模型概述/5.png" alt=""></p><p>每个 SM 包含的 SP 数量依据 GPU 架构而不同，如 Fermi 架构 GF100 是 32 个，GF10X 是 48 个，Kepler 架构都是 192 个，Maxwell 都是128 个。</p><p><img src="/image/CUDA编程-CUDA模型概述/6.png" alt=""></p><p>在软件逻辑上是所有 SP 是并行计算的，但是物理上并不是，比如只有 8 个 SM 却有 1024 个线程块需要调度处理，因为有些会处于挂起，就绪等其他状态，这有关 GPU 的线程调度，后续章节会展开讨论。</p><h2 id="三-理解-kernel-thread-block-grid-与-warp"><a href="#三-理解-kernel-thread-block-grid-与-warp" class="headerlink" title="三 理解 kernel, thread, block , grid 与 warp"></a>三 理解 kernel, thread, block , grid 与 warp</h2><h3 id="CUDA-线程模型"><a href="#CUDA-线程模型" class="headerlink" title="CUDA 线程模型"></a>CUDA 线程模型</h3><p>线程是程序执行的最基本单元，CUDA 的并行计算通过成千上万个线程的并行执行来实现。下图为 GPU 的线程结构</p><p><img src="/image/CUDA编程-CUDA模型概述/7.png" alt=""></p><p>CUDA的线程模型从小往大依次是</p><ul><li><p>Thread，线程，并行的基本单位</p></li><li><p>Block，线程块，互相合作的线程组，线程块有如下几个特点：</p><ul><li><p>以1维、2维或3维组织</p></li><li><p>允许彼此同步</p></li><li>可以通过共享内存快速交换数据</li></ul></li><li><p>Grid，网格，由一组 Block 组成</p><ul><li>以1维、2维组织</li></ul><ul><li>共享全局内存</li></ul></li></ul><h3 id="kernel"><a href="#kernel" class="headerlink" title="kernel"></a>kernel</h3><p>kernel 是在 device 上线程中并行执行的函数，是软件概念，核函数用<code>__global__</code>符号声明，并用 <code>&lt;&lt;&lt;grid, block&gt;&gt;&gt;</code> 执行配置语法指定内核调用的 CUDA 线程数，每个 kernel 的 thread 都有一个唯一的线程 ID，可以通过内置变量在内核中访问。block 一旦被分配好 SM，该 block 就会一直驻留在该 SM 中，直到执行结束。一个 SM 可以同时拥有多个 blocks。</p><h3 id="warp"><a href="#warp" class="headerlink" title="warp"></a>warp</h3><p>warp 是 SM 的基本执行单元，也称线程束，一个 warp 有 32 个并行的 thread， SM 旨在同时执行数百个 thread，为了管理如此大量的线程，采用了 SIMT （Single-Instruction, Multiple-Thread：单指令，多线程）的架构，也就是一个 warp 中的所有 thread 一次执行一条公共指令，并且每个thread会使用各自的data执行该指令。</p><p>一个块中的 warp 总数计算如下</p><script type="math/tex;mode=display">WarpsPerBlock = ceil(\frac{ThreadsPerBlock}{WarpSize}, 1)</script><p>对应下图</p><p><img src="/image/CUDA编程-CUDA模型概述/8.png" alt=""></p><p>从硬件角度来看，所有的 thread 以一维形式组织，每个 thread 都有个唯一的 ID，于是作为补全整数倍的 thread 在所在的 warp 中为 inactive 状态，会额外消耗 SM 资源，所以要设定 block 中的 thread 一般为32的倍数。</p><p>下面从硬件角度和软件角度解释 CUDA 的线程模型</p><div class="table-container"><table><thead><tr><th>软件</th><th>硬件</th><th>描述</th></tr></thead><tbody><tr><td>Thread</td><td>SP</td><td>每个线程由每个线程处理器（SP）执行</td></tr><tr><td>Block</td><td>SM</td><td>线程块由多核处理器（SM）执行</td></tr><tr><td>Grid</td><td>Device</td><td>一个 kernel 由一个 grid 来执行，一次只能在一个 GPU 上执行</td></tr></tbody></table></div><h3 id="线程索引"><a href="#线程索引" class="headerlink" title="线程索引"></a>线程索引</h3><p>确定线程的唯一索引，以 2D grid 和 2D block 的情况为例。</p><p>我们要计算的数值矩阵在内存中是 row-major（行主序） 线性存储的，如下图</p><p><img src="/image/CUDA编程-CUDA模型概述/9.png" alt=""></p><p>将 thread 和 block 索引映射到矩阵坐标</p><p>ix = threadIdx.x + blockIdx.x * blockDim.x</p><p>iy = threadIdx.y + blockIdx.y * blockDim.y</p><p>idx = iy * nx + ix</p><p>下图为 block 和 thread 索引，矩阵坐标以及线性地址之间的关系</p><p><img src="/image/CUDA编程-CUDA模型概述/10.png" alt=""></p><p>在实践应用中，常常会多一维 grid， 那就是三维情况的索引，如下图所示，设 (gridDim.x,gridDim.y) = (2,3), (blockDim.x,blockDim.y) = (4,2)，我们以 thread_id(3,1) block_id(0,1) 为例</p><p><img src="/image/CUDA编程-CUDA模型概述/11.png" alt=""></p><p>可以得到</p><p>ix = threadIdx.x + blockIdx.x <em>blockDim.x = 3 + 0 </em>4 = 3</p><p>iy = threadIdx.y + blockIdx.y <em>blockDim.y = 1 + 1 </em>2 = 3</p><p>coordinate(3,3)</p><p>global index: idx = iy <em>blockDim.x </em>gridDim.x + ix = 3 <em>4 </em>2 + 3 = 27</p></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CUDA/" rel="tag">CUDA</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/2023/12/19/CUDA%E7%BC%96%E7%A8%8B-CUDA-C%E7%BC%96%E7%A8%8B%E7%AE%80%E4%BB%8B/" class="article-nav-link"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">CUDA编程: CUDA C编程简介</div></a><a href="/2023/12/12/CUDA%E7%BC%96%E7%A8%8B-GPU%E7%BC%96%E7%A8%8B%E6%A6%82%E8%BF%B0%E5%92%8CCUDA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">CUDA编程: GPU编程概述和CUDA环境搭建</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li><a target="_blank" href=https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024 style="display:inline-block;text-decoration:none;"> <img src="/images/备案图标.webp" style="float:left;width:14px;height:14px;margin-top:2px;margin-right:-3px"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备32090202001024号</p><a target="_blank" href="https://beian.miit.gov.cn" style="display:inline-block;text-decoration:none"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">&nbsp苏ICP备2023045098号</p></a></li><li>Aeeeeeep Blog | The Gleaners &copy; 2024</li><li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li><li>theme <a target="_blank" rel="noopener" href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes, and seconds...</span><script>var now=new Date;function createTime(){var n=new Date("11/11/2021 00:08:39");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Site has been running for "+dnum+"d ",document.getElementById("times").innerHTML=hnum+"h "+mnum+"m "+snum+"s "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog | The Gleaners"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop"><i class="fe fe-rocket"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>