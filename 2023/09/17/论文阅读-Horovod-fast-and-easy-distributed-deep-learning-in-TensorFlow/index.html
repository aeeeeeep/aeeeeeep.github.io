<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>论文阅读: Horovod: fast and easy distributed deep learning in TensorFlow | Aeeeeeep Blog | The Gleaners</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 5.4.2"></head><body><main class="content"><section class="outer"><article id="post-论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">论文阅读: Horovod: fast and easy distributed deep learning in TensorFlow</h1></header><div class="article-meta"><a href="/2023/09/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/" class="article-date"><time datetime="2023-09-17T13:33:15.000Z" itemprop="datePublished">2023-09-17</time></a><div class="article-category"><a class="article-category-link" href="/categories/%E6%87%B5%E9%80%BC%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">懵逼的深度学习</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>最近忙实习去了，断更大半年。整理了一下论文，有十几篇没读，后面有时间慢慢更。</p><p>这篇论文主要工作是对 TensorFlow 框架 API 的重写，使用 ring-allreduce 和 broadcast 方法，进行数据并行。</p><span id="more"></span><p>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05799">https://arxiv.org/abs/1802.05799</a></p><p>code: <a target="_blank" rel="noopener" href="https://github.com/uber/horovod">https://github.com/uber/horovod</a></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>训练时的 GPU 通信耗时过大</p><p>当时分布式训练加速需要修改大量代码，成本过高</p><h3 id="TensorFlow-不足"><a href="#TensorFlow-不足" class="headerlink" title="TensorFlow 不足"></a>TensorFlow 不足</h3><p>TensorFlow 的分布式引入了许多复杂的概念和 API，使用成本变高，很难发现修复隐藏的 bug<br>使用 128 张 GPU 进行大规模训练时，通信与计算占比相当，可扩展性差</p><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/1.webp" width="800"></p><p>Facebook 首次提出数据并行，在多个节点上并行拆分数据来训练。不同批次数据的梯度在每个节点上单独计算，之后收集梯度求平均后广播到每个节点上，以保证每个节点中的模型副本参数一致</p><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/2.webp" width="800"></p><h3 id="Leveraging-a-different-type-of-algorithm"><a href="#Leveraging-a-different-type-of-algorithm" class="headerlink" title="Leveraging a different type of algorithm"></a>Leveraging a different type of algorithm</h3><p>TensorFlow 通过指定一个进程为 worker（工作进程） 或 parameter servers（参数服务器）</p><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/3.webp" width="800"></p><p>worker 负责前反向传播，发送计算得到的梯度，接收平均后的梯度和数据</p><p>有两个难点：</p><ul><li>worker 和 parameter servers 比例难以确定，太少的 parameter servers 会导致计算饱和，太多的 parameter servers 会导致通信饱和</li><li>学习曲线陡峭，大量代码重构</li></ul><p>ring allreduce 的提出解决了这个问题</p><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/4.webp" width="800"></p><p>N个节点中的每个节点与其两个对等节点进行通信，共进行了2 * (N - 1)次通信，节点发送和接收数据缓冲区的块。在第一次（N - 1）次迭代时，接收到的值会被添加到节点缓冲区中的值中。在第二次（N - 1）次迭代时，接<br>收到的值将替换节点缓冲区中的值</p><h2 id="Horovod"><a href="#Horovod" class="headerlink" title="Horovod"></a>Horovod</h2><p>做了如下工作</p><ul><li>将百度的 TensorFlow ring-allreduce 算法的实现转化为一个独立的 Python 包，命名为 Horovod</li><li>使用 NCCL 库实现了 TensorFlow ring-allreduce，并优化了性能</li><li>添加了对单机多卡的支持</li><li>改进了 API，添加 broadcast 操作，仅需 4 步即可使用 Horovod</li></ul><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/5.webp" width="800"></p><p>下面代码使用 mpirun 命令在 4 张卡的 4 个 server 上运行 train.py，支持 TensorFlow 和 Keras</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mpirun -np 16 -H server1:4,server2:4,server3:4,server4:4 python train.py </span><br></pre></td></tr></table></figure><h3 id="Horovod-Timeline"><a href="#Horovod-Timeline" class="headerlink" title="Horovod Timeline"></a>Horovod Timeline</h3><p>TensorFlow 和 CUDA Profiler 不足：只能显示单个 server 的 Profiler，需要用户手动交叉比对</p><p>改进：如下图所示，设置环境变量，就可以查看训练时每个节点在每个时间步骤中的具体操作，并且兼容 chrome://tracing</p><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/6.webp" width="800"></p><h3 id="Tensor-Fusion"><a href="#Tensor-Fusion" class="headerlink" title="Tensor Fusion"></a>Tensor Fusion</h3><p>观察 Profiler 时发现不足：大 Tensor 可以很好地利用带宽，但是小 Tensor 的 ring-allreduce 会影响效率</p><p>改进：</p><ul><li>整理要 allreduce 的 Tensor，分配到匹配的同数据类型的 buffer，如果没能成功分配，就创建一个 fusion buffer，默认为 64 MB；</li><li>将 Tensor 拷贝到 buffer，对 fusion buffer 执行 broadcast，再将 Tensor 拷贝出来。重复上述步骤；</li></ul><p>对比得到 65% 的性能提升</p><h2 id="Horovod-Benchmarks"><a href="#Horovod-Benchmarks" class="headerlink" title="Horovod Benchmarks"></a>Horovod Benchmarks</h2><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/7.webp" width="800"></p><p>上图所示，使用 Inception V3和ResNet-101模型进行实验，Horovod 相比 TensorFlow 性能提升了 88%</p><p>使用 RDMA 与 TCP 进行基准测试。在 Inception V3和 ResNet-101 模型上，RDMA 并没有显著提高性能，只比 TCP 网络多了 3% 到 4% 的增长</p><p><img src="/image/论文阅读-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/8.webp" width="800"></p><p>但是在 VGG-16 模型上，使用RDMA网络性能提高了30%。可以解释为 VGG-16 模型具有大量的参数，结合其较少的层数，使得通信成为关键路径，使得网络成为瓶颈</p><h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><ul><li>使 MPI 安装使用更方便</li><li>着重研究如何调整模型的超参以提高准确率</li><li>开发更多大模型训练示例</li></ul></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/" rel="tag">分布式训练框架</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/2023/09/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/" class="article-nav-link"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">论文阅读: PyTorch Distributed: Experiences on Accelerating Data Parallel Training</div></a><a href="/2023/02/23/2023MCM-ICM%E7%BE%8E%E8%B5%9BC%E9%A2%98%E7%AC%AC%E4%BA%8C%E9%A2%98%E6%80%9D%E8%B7%AF/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">2023MCM-ICM美赛C题第二问思路</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li><a target="_blank" href=https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024 style="display:inline-block;text-decoration:none;"> <img src="/images/备案图标.webp" style="float:left;width:14px;height:14px;margin-top:2px;margin-right:-3px"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备32090202001024号</p><a target="_blank" href="https://beian.miit.gov.cn" style="display:inline-block;text-decoration:none"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">&nbsp苏ICP备2023045098号</p></a></li><li>Aeeeeeep Blog | The Gleaners &copy; 2023</li><li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li><li>theme <a target="_blank" rel="noopener" href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes, and seconds...</span><script>var now=new Date;function createTime(){var n=new Date("11/11/2021 00:08:39");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Site has been running for "+dnum+"d ",document.getElementById("times").innerHTML=hnum+"h "+mnum+"m "+snum+"s "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog | The Gleaners"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop"><i class="fe fe-rocket"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>