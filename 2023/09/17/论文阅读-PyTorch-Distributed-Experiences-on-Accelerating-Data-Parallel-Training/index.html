<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>论文阅读: PyTorch Distributed: Experiences on Accelerating Data Parallel Training | Aeeeeeep Blog | The Gleaners</title><link rel="shortcut icon" href="/images/favicon64.ico"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css"><script src="/js/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 5.4.2"></head><body><main class="content"><section class="outer"><article id="post-论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal><div class="article-inner"><header class="article-header"><h1 class="article-title" itemprop="name">论文阅读: PyTorch Distributed: Experiences on Accelerating Data Parallel Training</h1></header><div class="article-meta"><a href="/2023/09/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/" class="article-date"><time datetime="2023-09-17T13:58:52.000Z" itemprop="datePublished">2023-09-17</time></a><div class="article-category"><a class="article-category-link" href="/categories/%E6%87%B5%E9%80%BC%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">懵逼的深度学习</a></div></div><div class="tocbot"></div><div class="article-entry" itemprop="articleBody"><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出的 DistributedDataParallel 在优化器运行之前进行梯度平均，用相同的梯度集更新所有模型副本，这样在数学上和本地训练完全等价，而且可以实现异步，比参数平均更加高效。</p><span id="more"></span><p>paper:</p><p>code:</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="PyTorch-训练流程"><a href="#PyTorch-训练流程" class="headerlink" title="PyTorch 训练流程"></a>PyTorch 训练流程</h3><ul><li>Forward pass：计算损失</li><li>Backward pass：计算梯度</li><li>Optimizer step：更新参数</li><li>数据并行</li></ul><p>PyTorch 有以下方式进行分布式训练，如</p><ul><li>DataParallel：单机多卡进行单进程多线程数据并行训练</li><li>DistributedDataParallel：多机多卡进行多进程数据并行训练</li><li>RPC（e.g. 参数服务器）：分布式模型并行训练</li></ul><p>另一种方案：参数平均计算所有模型权重的均值，但是当优化器中有依赖过去局部梯度的值（如 Adam 中的动量），优化器的状态可能会逐渐偏离，最终导致训练效果下降。另外，向后传递和参数平均不能重叠运行，浪费了性能</p><p>本文提出的 DistributedDataParallel 在优化器运行之前进行梯度平均，用相同的梯度集更新所有模型副本，这样在数学上和本地训练完全等价，而且可以实现异步，比参数平均更加高效</p><h2 id="AllReduce"><a href="#AllReduce" class="headerlink" title="AllReduce"></a>AllReduce</h2><p>次级实现</p><p>每个进程将其输入张量广播给所有对等进程，然后独立地应用算术运算，然而效率不高</p><p>于是 Nvidia 在 NCCL 后端中提出了基于环的 AllReduce 和基于树的 AllReduce</p><p>AllReduce 操作需要等待所有进程就绪后才能运行，是同步操作，而参数服务器中使用 P2P 通信</p><h2 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h2><p>API 实现</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/1.webp" width="300"></p><p>分布式训练时只需要修改少部分训练脚本</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/3.webp" width="500"></p><p>暴露更多接口以实现拦截信号和触发操作的机制进行优化</p><h2 id="梯度规约"><a href="#梯度规约" class="headerlink" title="梯度规约"></a>梯度规约</h2><h3 id="次级实现（All-Reduce）"><a href="#次级实现（All-Reduce）" class="headerlink" title="次级实现（All Reduce）"></a>次级实现（All Reduce）</h3><p>DDP控制所有的训练进程</p><p>在模型初始化时广播网络状态，让所有模型以相同状态开始训练<br>每次迭代时在局部 backward() 之后和优化器 step() 之前执行梯度，以相同的梯度更新权重</p><p>DDP 可以注册 autograd hooks，每次 backward() 后触发以下操作</p><ol><li>hooks 扫描所有局部模型参数</li><li>从每个参数中检索梯度张量</li><li>再使用 AllReduce 集体通信计算所有进程中参数的平均梯度</li><li>将结果返回梯度张量</li></ol><p>但是有两个性能问题</p><ul><li>在小 tensor 上的集合通信效率非常低</li><li>把梯度计算和同步分开之后，不能让它们通信重叠</li></ul><h3 id="梯度桶"><a href="#梯度桶" class="headerlink" title="梯度桶"></a>梯度桶</h3><p>下图显示了不同的参数规模在执行 All Reduce 时的效率，可以看到 tensor 越大，效率越高</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/2.webp" width="500"></p><p>梯度桶为了解决 All Reduce 在小 tensor 上的性能问题，将多个小 tensor 收集为一个桶，在达到一定规模后进行 All Reduce，这将 All Reduce 的操作转变为了异步</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/4.webp" width="500"></p><h3 id="通信和计算重叠"><a href="#通信和计算重叠" class="headerlink" title="通信和计算重叠"></a>通信和计算重叠</h3><p>在没有使用梯度桶机制之前，通信和梯度计算可以重叠。</p><p>在梯度桶机制下，需要等在同一个桶内的所有梯度都计算完成后，才能进行通信。为了重叠，PyTorch 引入 hook 机制，在反向传播计算完成后，调用自定义函数</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/5.webp" width="500"></p><p>每当一个梯度计算完成后，对应的 hook 将会被触发，当在同一个bucket中的梯度的hook都被fire后，就调用AllReduce对该bucket进行通信</p><p>但是这种策略会导致两个问题</p><ul><li><p>每个进程都是独立的，不能保证所有进程处理桶的顺序一致，如下图 (a) 所示</p><p>解决方法：将模型参数的反序作为桶的顺序，反向顺序可以近似表示反向传递中的梯度计算顺序</p></li><li><p>在某些阶段，网络中的一些层的梯度可以不需要使用，如 Dropout 等，这样这个层对应梯度的 hook 永远不会被触发，如下图 (b) 所示</p><p>解决方法：在前向传播结束后从输出开始遍历计算图，使用 bitmap（用于表示二进制数据的数据结构） 记录哪些参数参与计算，哪些参数没有参与计算，对于没有参与计算的参数，标记为 ready</p></li></ul><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/6.webp" width="500"></p><h3 id="梯度累积"><a href="#梯度累积" class="headerlink" title="梯度累积"></a>梯度累积</h3><p>传统梯度传播频率是在每次训练完成后传播，PyTorch 通过在在全局同步梯度之前进行 n 次局部训练迭代，减少梯度通信的时间，这种思路还可以解决大 batch size 占用资源过大的问题，可以将一个batch切分为多个micro<br>batch，在最后一个micro batch训练完成后，进行梯度更新</p><p>但是这种策略会导致某些迭代中没有参与计算的梯度（如 Dropout）和正常计算的梯度混合后，会导致有部分梯度在某些迭代中被累加，而在其他迭代中被清零，PyTorch也无法判断哪些梯度计算完成后立即进行同步，还是等<br>累加若干个迭代之后再进行同步</p><p>解决方法：提出了 “no_sync”上下文。当进行梯度累积并使用 “no_sync”上下文时，会有一些参数在某些迭代中未被使用，但在其他迭代中被使用。为了确保这些未使用参数的梯度不会在下一次迭代中被误用，使用 “bitmap”<br>来记录这些未使用参数的信息。在进入”no_sync”上下文之后，所有的 DDP hook 都被禁用，这意味着参数的梯度将被累积而不会在该上下文中进行通信。同时，全局未使用参数的信息也会被记录在 “bitmap” 中。这样，在下<br>一次通信时，PyTorch会使用 “bitmap” 来指导梯度通信，以确保未使用的参数不会被传输，从而保持梯度的正确性。</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/11.webp" width="500"></p><h2 id="集合通信"><a href="#集合通信" class="headerlink" title="集合通信"></a>集合通信</h2><p>PyTorch DDP 支持三种通讯库：NCCL，Gloo 和 MPI。这些库被包装到同一个 ProcessGroup API 中，在运行多个 ProcessGroup 时，会使用轮询调度将集体通信分派给各个 ProcessGroup 实例，获得更高的带宽利用率</p><h2 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h2><h3 id="python-前后端"><a href="#python-前后端" class="headerlink" title="python 前后端"></a>python 前后端</h3><p>可配置参数</p><ul><li>Process Group：指定进程组运行 AllReduce</li><li>bucket_cap_mb：调整桶大小优化训练速度</li><li><p>find_unused_parameters：控制 DDP 是否应该通过遍历计算图来检测未使用的参数</p></li><li><p>Model Buffers：在某些层中，例如BatchNorm层，需要维护一些状态，比如running variance（运行方差）和running mean（运行均值）。这些状态需要在训练过程中持续更新和使用，以确保模型在训练过程中的稳定性和性能。为了正确处理Model Buffers的同步和广播。DDP通过指定 rank 0 进程来处理。在启用no sync模式时，相应地调整缓冲区的广播，确保所有进程在进行本地计算之前，都拥有最新的Model Buffers的值</p></li></ul><h3 id="梯度规约的重点实现"><a href="#梯度规约的重点实现" class="headerlink" title="梯度规约的重点实现"></a>梯度规约的重点实现</h3><p>参数与桶的映射：确保同一 bucket 中的 parameter 都来自同一个device</p><p>Autograd Hook：通过为每个桶添加值为梯度数量的递减计数器来判断当前 backward 到了第几层，从而在合适的时候 AllReduce，在下一次前向传播时，重置计数器</p><p>桶规约：默认 bucket size 为 25M，实践中需要实验得到最佳大小</p><p>全局未使用参数：在 CPU 上创建 bitmap 来保存本地没有使用的参数信息，并通过一个额外的allreduce得到 global bitmap</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/7.webp" width="300"></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>通过 Latency Breakdown（对训练过程中不同阶段的延迟进行细分和分析）比较了不同模型、使用不同 backend、有无通信和训练的 overlap，得到反向传播是最耗时是阶段，AllReduce 就是在这一阶段中，仍然需要优化通信效率</p><p>下图实验了不同 bucket size</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/9.webp" width="800"></p><p>DDP通过使用多个round-robin（轮询调度）进程组从而充分利用带宽。下图实验比较了使用不同数量进程组对 latency 的影响</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/10.webp" width="800"></p><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><ul><li><p>通信后端：NCCL 优于 GLOO</p><p><img src="/image/论文阅读-PyTorch-Distributed-Experiences-on-Accelerating-Data-Parallel-Training/8.webp" width="300"></p></li><li><p>bucket size：大小随着模型的增大而增大</p></li><li><p>资源分配：用 NCCL 时建议把同一台机器上的所有进程都放到同一个进程组中</p></li></ul><h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><ul><li>梯度顺序预测：使用 autograd hook 记录 backward 的顺序，并相应地更新 bucket mapping 中的对应参数</li><li>Layer dropping：在forward的过程中随机 drop 掉几层网络，加速训练的同时避免过拟合，与此同时相应修改 parameter-to-bucket mapping，或从 bucket 层面 drop 网络层</li><li>梯度压缩：只通信需要高精度的梯度</li></ul></div><footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/" rel="tag">分布式训练框架</a></li></ul><div style="text-align:center;color:#ccc;font-size:14px">- ETX &nbsp;<i class="fe fe-smile"></i>&nbsp;Thank you for reading -</div><div><ul class="post-copyright"><li class="post-copyright-license"><strong>Copyright: </strong>All posts on this blog except otherwise stated, All adopt <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement. Please indicate the source of reprint!</li></ul><div></div></div></footer></div><nav class="article-nav"><a href="/2023/09/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ZeRO-Memory-Optimizations-Toward-Training-Trillion-Parameter-Models/" class="article-nav-link"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">论文阅读: ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</div></a><a href="/2023/09/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Horovod-fast-and-easy-distributed-deep-learning-in-TensorFlow/" class="article-nav-link"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">论文阅读: Horovod: fast and easy distributed deep learning in TensorFlow</div></a></nav><div class="gitalk" id="gitalk-container"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script><script type="text/javascript">var gitalk=new Gitalk({clientID:"1eb16485d4cf892a21bb",clientSecret:"d134888956393ad07790db31a3c50eea40618d43",repo:"gitalkIssue",owner:"aeeeeeep",admin:["aeeeeeep"],id:md5(location.pathname),distractionFreeMode:!1,pagerDirection:"last"});gitalk.render("gitalk-container")</script></article><script type="text/x-mathjax-config">MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></section><footer class="footer"><div class="outer"><div class="float-right"><div class="powered-by">&emsp;<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">Visitors:<span id="busuanzi_value_site_uv"></span></span>&emsp; <i class="fe fe-bookmark"></i>Article Views:<span id="busuanzi_value_page_pv"></span></div></div><ul class="list-inline"><li>Aeeeeeep Blog | The Gleaners &copy; 2023</li><li><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32090202001024" style="display:inline-block;text-decoration:none;height:20px;line-height:20px"><img src="/images/备案图标.webp" style="float:left"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#1e3e3f">苏公网安备 32090202001024号</p></a></li></ul><div class="float-left"><span id="timeDate">Loading days...</span><span id="times">Loading hours, minutes, and seconds...</span><script>var now=new Date;function createTime(){var n=new Date("11/11/2021 00:08:39");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="Site has been running for "+dnum+" d ",document.getElementById("times").innerHTML=hnum+" h "+mnum+" m "+snum+" s "}setInterval(createTime,250)</script></div></div></footer></main><aside class="sidebar"><button class="navbar-toggle"></button><nav class="navbar"><div class="logo"><a href="/"><img src="/images/aepBlack.svg" alt="Aeeeeeep Blog | The Gleaners"></a></div><ul class="nav nav-main"><li class="nav-item"><a class="nav-item-link" href="/">Home</a></li><li class="nav-item"><a class="nav-item-link" href="/archives">Archives</a></li><li class="nav-item"><a class="nav-item-link" href="/links">Links</a></li><li class="nav-item"><a class="nav-item-link" href="/about">About</a></li><li class="nav-item"><a class="nav-item-link nav-item-search" title="Search"><i class="fe fe-search"></i> Search</a></li></ul></nav><nav class="navbar navbar-bottom"><ul class="nav"><li class="nav-item"><div class="totop" id="totop"><i class="fe fe-rocket"></i></div></li><li class="nav-item"></li></ul></nav><div class="search-form-wrap"><div class="local-search local-search-plugin"><input type="search" id="local-search-input" class="local-search-input" placeholder="Search..."><div id="local-search-result" class="local-search-result"></div></div></div></aside><script src="/js/jquery-2.0.3.min.js"></script><script src="/js/jquery.justifiedGallery.min.js"></script><script src="/js/lazyload.min.js"></script><script src="/js/busuanzi-2.3.pure.min.js"></script><script src="/fancybox/jquery.fancybox.min.js"></script><script src="/js/copybtn.js"></script><script src="/js/tocbot.min.js"></script><script>tocbot.init({tocSelector:".tocbot",contentSelector:".article-entry",headingSelector:"h1, h2, h3, h4, h5, h6",hasInnerContainers:!0,scrollSmooth:!0,positionFixedSelector:".tocbot",positionFixedClass:"is-position-fixed",fixedSidebarOffset:"auto"})</script><script src="/js/ocean.js"></script><script src="/js/cursor.js"></script></body></html>